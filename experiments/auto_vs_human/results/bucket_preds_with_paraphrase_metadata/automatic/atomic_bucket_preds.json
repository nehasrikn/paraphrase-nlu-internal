{"atomic.train.23216": {"original_confidence": [0.9878169894218445, 0.012182870879769325], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.9878066182136536, 0.012193302623927593], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.23216.gpt3.3", "original_example": {"example_id": "atomic.train.23216", "premise_hypothesis_id": "atomic.train.10643", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-vnHA1XDF0yzKZWpV-JrKA==", "AtomicEventRelationId": "MN4J54UPJv9vwPKkIXvtLw==", "AtomicRelationType": "xAttr", "AtomicInference": "active"}, "premise": "PersonX rides all the rides", "hypothesis": "As a result, PersonX feels active", "update": "PersonX gets sick on the spinning wheel.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23216", "update_paraphrase": "The person gets dizzy and sick when spinning on the wheel.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2863247863247863, "pred_conf_shift": -1.0371208190917969e-05, "syntactic_distance": 0.2608695652173913}, {"confidence": [0.9884726405143738, 0.011527317576110363], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.23216.gpt3.0", "original_example": {"example_id": "atomic.train.23216", "premise_hypothesis_id": "atomic.train.10643", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-vnHA1XDF0yzKZWpV-JrKA==", "AtomicEventRelationId": "MN4J54UPJv9vwPKkIXvtLw==", "AtomicRelationType": "xAttr", "AtomicInference": "active"}, "premise": "PersonX rides all the rides", "hypothesis": "As a result, PersonX feels active", "update": "PersonX gets sick on the spinning wheel.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23216", "update_paraphrase": "The spinning wheel made personX feel nauseous.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4678571428571428, "pred_conf_shift": 0.0006556510925292969, "syntactic_distance": 0.4}, {"confidence": [0.986771821975708, 0.013228088617324829], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.23216.gpt3.1", "original_example": {"example_id": "atomic.train.23216", "premise_hypothesis_id": "atomic.train.10643", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-vnHA1XDF0yzKZWpV-JrKA==", "AtomicEventRelationId": "MN4J54UPJv9vwPKkIXvtLw==", "AtomicRelationType": "xAttr", "AtomicInference": "active"}, "premise": "PersonX rides all the rides", "hypothesis": "As a result, PersonX feels active", "update": "PersonX gets sick on the spinning wheel.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23216", "update_paraphrase": "PersonX gets dizzy and nauseous when spinning on the wheel.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3477124183006535, "pred_conf_shift": -0.0010451674461364746, "syntactic_distance": 0.22727272727272727}, {"confidence": [0.9891220927238464, 0.010877731256186962], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.23216.gpt3.4", "original_example": {"example_id": "atomic.train.23216", "premise_hypothesis_id": "atomic.train.10643", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-vnHA1XDF0yzKZWpV-JrKA==", "AtomicEventRelationId": "MN4J54UPJv9vwPKkIXvtLw==", "AtomicRelationType": "xAttr", "AtomicInference": "active"}, "premise": "PersonX rides all the rides", "hypothesis": "As a result, PersonX feels active", "update": "PersonX gets sick on the spinning wheel.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23216", "update_paraphrase": "The spinning wheel makes PersonX nauseous.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.411965811965812, "pred_conf_shift": 0.0013051033020019531, "syntactic_distance": 0.35}, {"confidence": [0.9887406229972839, 0.01125926710665226], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.23216.gpt3.2", "original_example": {"example_id": "atomic.train.23216", "premise_hypothesis_id": "atomic.train.10643", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-vnHA1XDF0yzKZWpV-JrKA==", "AtomicEventRelationId": "MN4J54UPJv9vwPKkIXvtLw==", "AtomicRelationType": "xAttr", "AtomicInference": "active"}, "premise": "PersonX rides all the rides", "hypothesis": "As a result, PersonX feels active", "update": "PersonX gets sick on the spinning wheel.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23216", "update_paraphrase": "The person gets sick on the spinning wheel.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.07692307692307687, "pred_conf_shift": 0.0009236335754394531, "syntactic_distance": 0.047619047619047616}, {"confidence": [0.9878485202789307, 0.012151448987424374], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.23216.gpt3.5", "original_example": {"example_id": "atomic.train.23216", "premise_hypothesis_id": "atomic.train.10643", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-vnHA1XDF0yzKZWpV-JrKA==", "AtomicEventRelationId": "MN4J54UPJv9vwPKkIXvtLw==", "AtomicRelationType": "xAttr", "AtomicInference": "active"}, "premise": "PersonX rides all the rides", "hypothesis": "As a result, PersonX feels active", "update": "PersonX gets sick on the spinning wheel.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23216", "update_paraphrase": "PersonX became nauseated while using the spinning wheel.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.34970214970214963, "pred_conf_shift": 3.153085708618164e-05, "syntactic_distance": 0.2}, {"confidence": [0.9887281060218811, 0.011271988041698933], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.23216.gpt3.7", "original_example": {"example_id": "atomic.train.23216", "premise_hypothesis_id": "atomic.train.10643", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-vnHA1XDF0yzKZWpV-JrKA==", "AtomicEventRelationId": "MN4J54UPJv9vwPKkIXvtLw==", "AtomicRelationType": "xAttr", "AtomicInference": "active"}, "premise": "PersonX rides all the rides", "hypothesis": "As a result, PersonX feels active", "update": "PersonX gets sick on the spinning wheel.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23216", "update_paraphrase": "PersonX becomes nauseated while riding the spinning wheel.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.35656750656750646, "pred_conf_shift": 0.0009111166000366211, "syntactic_distance": 0.1}, {"confidence": [0.9871809482574463, 0.012819129042327404], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.23216.gpt3.6", "original_example": {"example_id": "atomic.train.23216", "premise_hypothesis_id": "atomic.train.10643", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-vnHA1XDF0yzKZWpV-JrKA==", "AtomicEventRelationId": "MN4J54UPJv9vwPKkIXvtLw==", "AtomicRelationType": "xAttr", "AtomicInference": "active"}, "premise": "PersonX rides all the rides", "hypothesis": "As a result, PersonX feels active", "update": "PersonX gets sick on the spinning wheel.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23216", "update_paraphrase": "PersonX doesn't have a good time on the spinning wheel and ends up feeling ill.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5114885114885115, "pred_conf_shift": -0.0006360411643981934, "syntactic_distance": 0.43478260869565216}]}, "atomic.train.17751": {"original_confidence": [0.7871297001838684, 0.2128702849149704], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.6997674703598022, 0.300232470035553], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.17751.gpt3.4", "original_example": {"example_id": "atomic.train.17751", "premise_hypothesis_id": "atomic.train.8261", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8C08krwumLTPLK2aYwP7RQ==", "AtomicEventRelationId": "t7s_OD36gejzz7KenBWWPg==", "AtomicRelationType": "xWant", "AtomicInference": "to eat agian"}, "premise": "PersonX plays really", "hypothesis": "As a result, PersonX wants to eat agian", "update": "PersonX burned a ton of calories", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17751", "update_paraphrase": "PersonX burned a huge number of calories.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19000657462195925, "pred_conf_shift": 0.08736218512058258, "syntactic_distance": 0.0}, {"confidence": [0.6747190952301025, 0.32528090476989746], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.17751.gpt3.1", "original_example": {"example_id": "atomic.train.17751", "premise_hypothesis_id": "atomic.train.8261", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8C08krwumLTPLK2aYwP7RQ==", "AtomicEventRelationId": "t7s_OD36gejzz7KenBWWPg==", "AtomicRelationType": "xWant", "AtomicInference": "to eat agian"}, "premise": "PersonX plays really", "hypothesis": "As a result, PersonX wants to eat agian", "update": "PersonX burned a ton of calories", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17751", "update_paraphrase": "Person X burned a huge number of calories.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.26495726495726496, "pred_conf_shift": 0.11241061985492706, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.8505070805549622, 0.14949297904968262], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.17751.gpt3.2", "original_example": {"example_id": "atomic.train.17751", "premise_hypothesis_id": "atomic.train.8261", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8C08krwumLTPLK2aYwP7RQ==", "AtomicEventRelationId": "t7s_OD36gejzz7KenBWWPg==", "AtomicRelationType": "xWant", "AtomicInference": "to eat agian"}, "premise": "PersonX plays really", "hypothesis": "As a result, PersonX wants to eat agian", "update": "PersonX burned a ton of calories", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17751", "update_paraphrase": "PersonX burned a ton of calories.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": -0.06337730586528778, "syntactic_distance": 0.0}, {"confidence": [0.6269465088844299, 0.37305349111557007], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.17751.gpt3.0", "original_example": {"example_id": "atomic.train.17751", "premise_hypothesis_id": "atomic.train.8261", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8C08krwumLTPLK2aYwP7RQ==", "AtomicEventRelationId": "t7s_OD36gejzz7KenBWWPg==", "AtomicRelationType": "xWant", "AtomicInference": "to eat agian"}, "premise": "PersonX plays really", "hypothesis": "As a result, PersonX wants to eat agian", "update": "PersonX burned a ton of calories", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17751", "update_paraphrase": "PersonX burned a lot of calories", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.10555555555555557, "pred_conf_shift": 0.16018320620059967, "syntactic_distance": 0.0}]}, "atomic.train.11100": {"original_confidence": [0.8858262896537781, 0.11417368799448013], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.9027584195137024, 0.0972416028380394], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11100.gpt3.0", "original_example": {"example_id": "atomic.train.11100", "premise_hypothesis_id": "atomic.train.5224", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7eiXl-g7WIgslrCszbV_CQ==", "AtomicEventRelationId": "-bm6pKu20Qo5XAkvYMC6qQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to win over some voting event."}, "premise": "PersonX casts PersonX's vote", "hypothesis": "Because PersonX wanted to win over some voting event.", "update": "X voted for his opponent.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11100", "update_paraphrase": "To everyone's surprise, X cast his ballot in favor of his opponent.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5122230710466005, "pred_conf_shift": 0.016932129859924316, "syntactic_distance": 0.45454545454545453}, {"confidence": [0.5953327417373657, 0.40466734766960144], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11100.gpt3.2", "original_example": {"example_id": "atomic.train.11100", "premise_hypothesis_id": "atomic.train.5224", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7eiXl-g7WIgslrCszbV_CQ==", "AtomicEventRelationId": "-bm6pKu20Qo5XAkvYMC6qQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to win over some voting event."}, "premise": "PersonX casts PersonX's vote", "hypothesis": "Because PersonX wanted to win over some voting event.", "update": "X voted for his opponent.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11100", "update_paraphrase": "Despite being opponents, X voted for the other person.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.425970388155262, "pred_conf_shift": -0.29049354791641235, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.7073236107826233, 0.2926763892173767], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11100.gpt3.4", "original_example": {"example_id": "atomic.train.11100", "premise_hypothesis_id": "atomic.train.5224", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7eiXl-g7WIgslrCszbV_CQ==", "AtomicEventRelationId": "-bm6pKu20Qo5XAkvYMC6qQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to win over some voting event."}, "premise": "PersonX casts PersonX's vote", "hypothesis": "Because PersonX wanted to win over some voting event.", "update": "X voted for his opponent.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11100", "update_paraphrase": "In the voting booth, X chose his opponent over himself.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.49887445887445886, "pred_conf_shift": -0.17850267887115479, "syntactic_distance": 0.43478260869565216}, {"confidence": [0.9690030813217163, 0.030996814370155334], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11100.gpt3.7", "original_example": {"example_id": "atomic.train.11100", "premise_hypothesis_id": "atomic.train.5224", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7eiXl-g7WIgslrCszbV_CQ==", "AtomicEventRelationId": "-bm6pKu20Qo5XAkvYMC6qQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to win over some voting event."}, "premise": "PersonX casts PersonX's vote", "hypothesis": "Because PersonX wanted to win over some voting event.", "update": "X voted for his opponent.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11100", "update_paraphrase": "He cast his vote for the other candidate.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.559500328731098, "pred_conf_shift": 0.08317679166793823, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.9527689218521118, 0.04723113402724266], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11100.gpt3.8", "original_example": {"example_id": "atomic.train.11100", "premise_hypothesis_id": "atomic.train.5224", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7eiXl-g7WIgslrCszbV_CQ==", "AtomicEventRelationId": "-bm6pKu20Qo5XAkvYMC6qQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to win over some voting event."}, "premise": "PersonX casts PersonX's vote", "hypothesis": "Because PersonX wanted to win over some voting event.", "update": "X voted for his opponent.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11100", "update_paraphrase": "X cast his ballot for the other candidate.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4936396936396936, "pred_conf_shift": 0.06694263219833374, "syntactic_distance": 0.35714285714285715}, {"confidence": [0.9588340520858765, 0.04116591066122055], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11100.gpt3.6", "original_example": {"example_id": "atomic.train.11100", "premise_hypothesis_id": "atomic.train.5224", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7eiXl-g7WIgslrCszbV_CQ==", "AtomicEventRelationId": "-bm6pKu20Qo5XAkvYMC6qQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to win over some voting event."}, "premise": "PersonX casts PersonX's vote", "hypothesis": "Because PersonX wanted to win over some voting event.", "update": "X voted for his opponent.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11100", "update_paraphrase": "He cast his ballot for the other guy.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.623817208432593, "pred_conf_shift": 0.07300776243209839, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.7977972030639648, 0.20220284163951874], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11100.gpt3.5", "original_example": {"example_id": "atomic.train.11100", "premise_hypothesis_id": "atomic.train.5224", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7eiXl-g7WIgslrCszbV_CQ==", "AtomicEventRelationId": "-bm6pKu20Qo5XAkvYMC6qQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to win over some voting event."}, "premise": "PersonX casts PersonX's vote", "hypothesis": "Because PersonX wanted to win over some voting event.", "update": "X voted for his opponent.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11100", "update_paraphrase": "Even though X was running for office, he still voted for his opponent.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4444444444444444, "pred_conf_shift": -0.08802908658981323, "syntactic_distance": 0.5}, {"confidence": [0.8497878313064575, 0.15021222829818726], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11100.gpt3.3", "original_example": {"example_id": "atomic.train.11100", "premise_hypothesis_id": "atomic.train.5224", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7eiXl-g7WIgslrCszbV_CQ==", "AtomicEventRelationId": "-bm6pKu20Qo5XAkvYMC6qQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to win over some voting event."}, "premise": "PersonX casts PersonX's vote", "hypothesis": "Because PersonX wanted to win over some voting event.", "update": "X voted for his opponent.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11100", "update_paraphrase": "Despite being rivals, X cast his vote for his opponent.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3481481481481481, "pred_conf_shift": -0.03603845834732056, "syntactic_distance": 0.38095238095238093}, {"confidence": [0.9573017358779907, 0.04269833117723465], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11100.gpt3.1", "original_example": {"example_id": "atomic.train.11100", "premise_hypothesis_id": "atomic.train.5224", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7eiXl-g7WIgslrCszbV_CQ==", "AtomicEventRelationId": "-bm6pKu20Qo5XAkvYMC6qQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to win over some voting event."}, "premise": "PersonX casts PersonX's vote", "hypothesis": "Because PersonX wanted to win over some voting event.", "update": "X voted for his opponent.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11100", "update_paraphrase": "X cast his ballot for the person running against him.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5360750360750361, "pred_conf_shift": 0.07147544622421265, "syntactic_distance": 0.23529411764705882}]}, "atomic.train.19366": {"original_confidence": [0.8442295789718628, 0.15577039122581482], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.8765217661857605, 0.12347821891307831], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19366.gpt3.2", "original_example": {"example_id": "atomic.train.19366", "premise_hypothesis_id": "atomic.train.8980", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_z-OKSue92GwQ2Ob3yB41w==", "AtomicEventRelationId": "2VlPC95WFsc7v5j1DjTSEw==", "AtomicRelationType": "xAttr", "AtomicInference": "outdoorsy"}, "premise": "PersonX enjoys the weather", "hypothesis": "As a result, PersonX feels outdoorsy", "update": "PersonX likes listening to the rain hit the roof of their house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19366", "update_paraphrase": "PersonX enjoys the feeling of rain hitting the roof of their house.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22651515151515145, "pred_conf_shift": 0.032292187213897705, "syntactic_distance": 0.2}, {"confidence": [0.8912383317947388, 0.10876165330410004], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19366.gpt3.7", "original_example": {"example_id": "atomic.train.19366", "premise_hypothesis_id": "atomic.train.8980", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_z-OKSue92GwQ2Ob3yB41w==", "AtomicEventRelationId": "2VlPC95WFsc7v5j1DjTSEw==", "AtomicRelationType": "xAttr", "AtomicInference": "outdoorsy"}, "premise": "PersonX enjoys the weather", "hypothesis": "As a result, PersonX feels outdoorsy", "update": "PersonX likes listening to the rain hit the roof of their house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19366", "update_paraphrase": "PersonX finds it relaxing to listen to the rain patter on the roof of their home.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2798840048840049, "pred_conf_shift": 0.04700875282287598, "syntactic_distance": 0.1875}, {"confidence": [0.9138571619987488, 0.08614280819892883], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19366.gpt3.0", "original_example": {"example_id": "atomic.train.19366", "premise_hypothesis_id": "atomic.train.8980", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_z-OKSue92GwQ2Ob3yB41w==", "AtomicEventRelationId": "2VlPC95WFsc7v5j1DjTSEw==", "AtomicRelationType": "xAttr", "AtomicInference": "outdoorsy"}, "premise": "PersonX enjoys the weather", "hypothesis": "As a result, PersonX feels outdoorsy", "update": "PersonX likes listening to the rain hit the roof of their house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19366", "update_paraphrase": "PersonX finds it calming to listen to the rain hit the roof of their house.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1863823419378975, "pred_conf_shift": 0.06962758302688599, "syntactic_distance": 0.1875}, {"confidence": [0.7562105059623718, 0.2437894195318222], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19366.gpt3.4", "original_example": {"example_id": "atomic.train.19366", "premise_hypothesis_id": "atomic.train.8980", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_z-OKSue92GwQ2Ob3yB41w==", "AtomicEventRelationId": "2VlPC95WFsc7v5j1DjTSEw==", "AtomicRelationType": "xAttr", "AtomicInference": "outdoorsy"}, "premise": "PersonX enjoys the weather", "hypothesis": "As a result, PersonX feels outdoorsy", "update": "PersonX likes listening to the rain hit the roof of their house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19366", "update_paraphrase": "There's something calming to PersonX about listening to the rain pitter patter on the roof of their home.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.31380471380471386, "pred_conf_shift": -0.08801907300949097, "syntactic_distance": 0.3125}, {"confidence": [0.8479821085929871, 0.15201784670352936], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19366.gpt3.6", "original_example": {"example_id": "atomic.train.19366", "premise_hypothesis_id": "atomic.train.8980", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_z-OKSue92GwQ2Ob3yB41w==", "AtomicEventRelationId": "2VlPC95WFsc7v5j1DjTSEw==", "AtomicRelationType": "xAttr", "AtomicInference": "outdoorsy"}, "premise": "PersonX enjoys the weather", "hypothesis": "As a result, PersonX feels outdoorsy", "update": "PersonX likes listening to the rain hit the roof of their house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19366", "update_paraphrase": "PersonX enjoys the sound of raindrops hitting the roof of their house.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.26749500499500506, "pred_conf_shift": 0.0037525296211242676, "syntactic_distance": 0.2}, {"confidence": [0.9047972559928894, 0.09520278871059418], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19366.gpt3.1", "original_example": {"example_id": "atomic.train.19366", "premise_hypothesis_id": "atomic.train.8980", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_z-OKSue92GwQ2Ob3yB41w==", "AtomicEventRelationId": "2VlPC95WFsc7v5j1DjTSEw==", "AtomicRelationType": "xAttr", "AtomicInference": "outdoorsy"}, "premise": "PersonX enjoys the weather", "hypothesis": "As a result, PersonX feels outdoorsy", "update": "PersonX likes listening to the rain hit the roof of their house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19366", "update_paraphrase": "PersonX enjoys the sound of rain hitting the roof of their home.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.26599927849927857, "pred_conf_shift": 0.06056767702102661, "syntactic_distance": 0.2}, {"confidence": [0.6180192828178406, 0.38198068737983704], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19366.gpt3.8", "original_example": {"example_id": "atomic.train.19366", "premise_hypothesis_id": "atomic.train.8980", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_z-OKSue92GwQ2Ob3yB41w==", "AtomicEventRelationId": "2VlPC95WFsc7v5j1DjTSEw==", "AtomicRelationType": "xAttr", "AtomicInference": "outdoorsy"}, "premise": "PersonX enjoys the weather", "hypothesis": "As a result, PersonX feels outdoorsy", "update": "PersonX likes listening to the rain hit the roof of their house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19366", "update_paraphrase": "Listening to the sound of rain hitting the roof of their house is something PersonX enjoys.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2581632653061225, "pred_conf_shift": -0.22621029615402222, "syntactic_distance": 0.4117647058823529}, {"confidence": [0.7153156995773315, 0.2846842408180237], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19366.gpt3.3", "original_example": {"example_id": "atomic.train.19366", "premise_hypothesis_id": "atomic.train.8980", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_z-OKSue92GwQ2Ob3yB41w==", "AtomicEventRelationId": "2VlPC95WFsc7v5j1DjTSEw==", "AtomicRelationType": "xAttr", "AtomicInference": "outdoorsy"}, "premise": "PersonX enjoys the weather", "hypothesis": "As a result, PersonX feels outdoorsy", "update": "PersonX likes listening to the rain hit the roof of their house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19366", "update_paraphrase": "PersonX enjoys listening to the sound of the rain hitting the roof of their house.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.21010101010101007, "pred_conf_shift": -0.12891387939453125, "syntactic_distance": 0.0}, {"confidence": [0.7153788805007935, 0.28462114930152893], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19366.gpt3.5", "original_example": {"example_id": "atomic.train.19366", "premise_hypothesis_id": "atomic.train.8980", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_z-OKSue92GwQ2Ob3yB41w==", "AtomicEventRelationId": "2VlPC95WFsc7v5j1DjTSEw==", "AtomicRelationType": "xAttr", "AtomicInference": "outdoorsy"}, "premise": "PersonX enjoys the weather", "hypothesis": "As a result, PersonX feels outdoorsy", "update": "PersonX likes listening to the rain hit the roof of their house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19366", "update_paraphrase": "Person X enjoys listening to the sound of raindrops hitting the roof of their house.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22206682206682216, "pred_conf_shift": -0.12885069847106934, "syntactic_distance": 0.13333333333333333}]}, "atomic.train.30738": {"original_confidence": [0.9527098536491394, 0.04729008674621582], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.8649985790252686, 0.13500142097473145], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.30738.gpt3.1", "original_example": {"example_id": "atomic.train.30738", "premise_hypothesis_id": "atomic.train.13956", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Mw3vOeuipdWCcqaY9Ht7xQ==", "AtomicEventRelationId": "aFQRyX_9kBreQV7pgwXQhA==", "AtomicRelationType": "xNeed", "AtomicInference": "get home sale classified ads"}, "premise": "PersonX needs a home", "hypothesis": "Before, PersonX needed get home sale classified ads", "update": "personX is an enlisted soldier", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30738", "update_paraphrase": "Person X is a member of the military who is enlisted, as opposed to being an officer.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6065601065601065, "pred_conf_shift": -0.08771127462387085, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.9562208652496338, 0.043779175728559494], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.30738.gpt3.4", "original_example": {"example_id": "atomic.train.30738", "premise_hypothesis_id": "atomic.train.13956", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Mw3vOeuipdWCcqaY9Ht7xQ==", "AtomicEventRelationId": "aFQRyX_9kBreQV7pgwXQhA==", "AtomicRelationType": "xNeed", "AtomicInference": "get home sale classified ads"}, "premise": "PersonX needs a home", "hypothesis": "Before, PersonX needed get home sale classified ads", "update": "personX is an enlisted soldier", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30738", "update_paraphrase": "personX has enlisted in the military as a soldier.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4571428571428572, "pred_conf_shift": 0.0035110116004943848, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.9368380308151245, 0.06316208839416504], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.30738.gpt3.5", "original_example": {"example_id": "atomic.train.30738", "premise_hypothesis_id": "atomic.train.13956", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Mw3vOeuipdWCcqaY9Ht7xQ==", "AtomicEventRelationId": "aFQRyX_9kBreQV7pgwXQhA==", "AtomicRelationType": "xNeed", "AtomicInference": "get home sale classified ads"}, "premise": "PersonX needs a home", "hypothesis": "Before, PersonX needed get home sale classified ads", "update": "personX is an enlisted soldier", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30738", "update_paraphrase": "personX is a member of the armed forces who enlisted voluntarily", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5711538461538462, "pred_conf_shift": -0.015871822834014893, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.9286331534385681, 0.07136684656143188], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.30738.gpt3.0", "original_example": {"example_id": "atomic.train.30738", "premise_hypothesis_id": "atomic.train.13956", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Mw3vOeuipdWCcqaY9Ht7xQ==", "AtomicEventRelationId": "aFQRyX_9kBreQV7pgwXQhA==", "AtomicRelationType": "xNeed", "AtomicInference": "get home sale classified ads"}, "premise": "PersonX needs a home", "hypothesis": "Before, PersonX needed get home sale classified ads", "update": "personX is an enlisted soldier", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30738", "update_paraphrase": "This person is a soldier who has enlisted in the military.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4637820512820513, "pred_conf_shift": -0.02407670021057129, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.9518218636512756, 0.048178188502788544], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.30738.gpt3.7", "original_example": {"example_id": "atomic.train.30738", "premise_hypothesis_id": "atomic.train.13956", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Mw3vOeuipdWCcqaY9Ht7xQ==", "AtomicEventRelationId": "aFQRyX_9kBreQV7pgwXQhA==", "AtomicRelationType": "xNeed", "AtomicInference": "get home sale classified ads"}, "premise": "PersonX needs a home", "hypothesis": "Before, PersonX needed get home sale classified ads", "update": "personX is an enlisted soldier", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30738", "update_paraphrase": "personX is a member of the armed forces who has enlisted.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5667467948717949, "pred_conf_shift": -0.0008879899978637695, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.9205166697502136, 0.07948331534862518], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.30738.gpt3.2", "original_example": {"example_id": "atomic.train.30738", "premise_hypothesis_id": "atomic.train.13956", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Mw3vOeuipdWCcqaY9Ht7xQ==", "AtomicEventRelationId": "aFQRyX_9kBreQV7pgwXQhA==", "AtomicRelationType": "xNeed", "AtomicInference": "get home sale classified ads"}, "premise": "PersonX needs a home", "hypothesis": "Before, PersonX needed get home sale classified ads", "update": "personX is an enlisted soldier", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30738", "update_paraphrase": "personX is a member of the armed forces who is enlisted, as opposed to an officer.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5771847200418629, "pred_conf_shift": -0.03219318389892578, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.956354022026062, 0.043645940721035004], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.30738.gpt3.6", "original_example": {"example_id": "atomic.train.30738", "premise_hypothesis_id": "atomic.train.13956", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Mw3vOeuipdWCcqaY9Ht7xQ==", "AtomicEventRelationId": "aFQRyX_9kBreQV7pgwXQhA==", "AtomicRelationType": "xNeed", "AtomicInference": "get home sale classified ads"}, "premise": "PersonX needs a home", "hypothesis": "Before, PersonX needed get home sale classified ads", "update": "personX is an enlisted soldier", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30738", "update_paraphrase": "Person X is a member of the armed forces who has enlisted.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5595776772247361, "pred_conf_shift": 0.0036441683769226074, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.8216829895973206, 0.17831693589687347], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.30738.gpt3.3", "original_example": {"example_id": "atomic.train.30738", "premise_hypothesis_id": "atomic.train.13956", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Mw3vOeuipdWCcqaY9Ht7xQ==", "AtomicEventRelationId": "aFQRyX_9kBreQV7pgwXQhA==", "AtomicRelationType": "xNeed", "AtomicInference": "get home sale classified ads"}, "premise": "PersonX needs a home", "hypothesis": "Before, PersonX needed get home sale classified ads", "update": "personX is an enlisted soldier", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30738", "update_paraphrase": "personX is in the military and doesn't hold an officer's rank.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.531110556110556, "pred_conf_shift": -0.13102686405181885, "syntactic_distance": 0.3333333333333333}]}, "atomic.train.31062": {"original_confidence": [0.4968056380748749, 0.5031943917274475], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.03247262164950371, 0.9675275087356567], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31062.gpt3.5", "original_example": {"example_id": "atomic.train.31062", "premise_hypothesis_id": "atomic.train.14107", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gU2Q3qO_o7rujrSDGas0SA==", "AtomicEventRelationId": "NumKknFqZUMtXrjcxm-6jQ==", "AtomicRelationType": "xAttr", "AtomicInference": "determined"}, "premise": "PersonX gets a leg up", "hypothesis": "As a result, PersonX feels determined", "update": "They still have a long game to play", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31062", "update_paraphrase": "They still have a lot of game left to play.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2178130511463845, "pred_conf_shift": -0.46433301642537117, "syntactic_distance": 0.05}, {"confidence": [0.07176359742879868, 0.9282363653182983], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31062.gpt3.2", "original_example": {"example_id": "atomic.train.31062", "premise_hypothesis_id": "atomic.train.14107", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gU2Q3qO_o7rujrSDGas0SA==", "AtomicEventRelationId": "NumKknFqZUMtXrjcxm-6jQ==", "AtomicRelationType": "xAttr", "AtomicInference": "determined"}, "premise": "PersonX gets a leg up", "hypothesis": "As a result, PersonX feels determined", "update": "They still have a long game to play", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31062", "update_paraphrase": "There's still a lot of game left to play.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.25924369747899156, "pred_conf_shift": -0.4250420406460762, "syntactic_distance": 0.3}, {"confidence": [0.01947256736457348, 0.9805272817611694], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31062.gpt3.4", "original_example": {"example_id": "atomic.train.31062", "premise_hypothesis_id": "atomic.train.14107", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gU2Q3qO_o7rujrSDGas0SA==", "AtomicEventRelationId": "NumKknFqZUMtXrjcxm-6jQ==", "AtomicRelationType": "xAttr", "AtomicInference": "determined"}, "premise": "PersonX gets a leg up", "hypothesis": "As a result, PersonX feels determined", "update": "They still have a long game to play", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31062", "update_paraphrase": "though there's still a lot of game left to play.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3003968253968254, "pred_conf_shift": -0.4773330707103014, "syntactic_distance": 0.47368421052631576}, {"confidence": [0.5788221955299377, 0.42117786407470703], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31062.gpt3.0", "original_example": {"example_id": "atomic.train.31062", "premise_hypothesis_id": "atomic.train.14107", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gU2Q3qO_o7rujrSDGas0SA==", "AtomicEventRelationId": "NumKknFqZUMtXrjcxm-6jQ==", "AtomicRelationType": "xAttr", "AtomicInference": "determined"}, "premise": "PersonX gets a leg up", "hypothesis": "As a result, PersonX feels determined", "update": "They still have a long game to play", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31062", "update_paraphrase": "They still have a long game ahead of them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.20751633986928109, "pred_conf_shift": 0.08201655745506287, "syntactic_distance": 0.25}, {"confidence": [0.25647321343421936, 0.743526816368103], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31062.gpt3.1", "original_example": {"example_id": "atomic.train.31062", "premise_hypothesis_id": "atomic.train.14107", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gU2Q3qO_o7rujrSDGas0SA==", "AtomicEventRelationId": "NumKknFqZUMtXrjcxm-6jQ==", "AtomicRelationType": "xAttr", "AtomicInference": "determined"}, "premise": "PersonX gets a leg up", "hypothesis": "As a result, PersonX feels determined", "update": "They still have a long game to play", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31062", "update_paraphrase": "The game they are playing is still going on.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4628214922332569, "pred_conf_shift": -0.24033242464065552, "syntactic_distance": 0.4583333333333333}, {"confidence": [0.07330947369337082, 0.9266905784606934], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31062.gpt3.6", "original_example": {"example_id": "atomic.train.31062", "premise_hypothesis_id": "atomic.train.14107", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gU2Q3qO_o7rujrSDGas0SA==", "AtomicEventRelationId": "NumKknFqZUMtXrjcxm-6jQ==", "AtomicRelationType": "xAttr", "AtomicInference": "determined"}, "premise": "PersonX gets a leg up", "hypothesis": "As a result, PersonX feels determined", "update": "They still have a long game to play", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31062", "update_paraphrase": "There is still a lot of game left to play.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2929894179894179, "pred_conf_shift": -0.42349616438150406, "syntactic_distance": 0.3}, {"confidence": [0.1589812934398651, 0.8410186171531677], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31062.gpt3.3", "original_example": {"example_id": "atomic.train.31062", "premise_hypothesis_id": "atomic.train.14107", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gU2Q3qO_o7rujrSDGas0SA==", "AtomicEventRelationId": "NumKknFqZUMtXrjcxm-6jQ==", "AtomicRelationType": "xAttr", "AtomicInference": "determined"}, "premise": "PersonX gets a leg up", "hypothesis": "As a result, PersonX feels determined", "update": "They still have a long game to play", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31062", "update_paraphrase": "Though they have made progress, they still have a long way to go.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.36394557823129253, "pred_conf_shift": -0.33782434463500977, "syntactic_distance": 0.2}]}, "atomic.train.16617": {"original_confidence": [0.40792223811149597, 0.5920777320861816], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.022228950634598732, 0.9777711033821106], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16617.gpt3.1", "original_example": {"example_id": "atomic.train.16617", "premise_hypothesis_id": "atomic.train.7748", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "PWXpM87B9LmDJol5JlHnwg==", "AtomicEventRelationId": "y_uYBwJ1GFYJsh6tuIN8ig==", "AtomicRelationType": "xReact", "AtomicInference": "concerned"}, "premise": "PersonX goes check on PersonY", "hypothesis": "PersonX is seen as concerned", "update": "They just passed out", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16617", "update_paraphrase": "They fainted or collapsed.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.47166375291375295, "pred_conf_shift": 0.38569337129592896, "syntactic_distance": 0.3125}, {"confidence": [0.06506309658288956, 0.9349368810653687], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16617.gpt3.2", "original_example": {"example_id": "atomic.train.16617", "premise_hypothesis_id": "atomic.train.7748", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "PWXpM87B9LmDJol5JlHnwg==", "AtomicEventRelationId": "y_uYBwJ1GFYJsh6tuIN8ig==", "AtomicRelationType": "xReact", "AtomicInference": "concerned"}, "premise": "PersonX goes check on PersonY", "hypothesis": "PersonX is seen as concerned", "update": "They just passed out", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16617", "update_paraphrase": "They fainted.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5421245421245421, "pred_conf_shift": 0.342859148979187, "syntactic_distance": 0.2857142857142857}, {"confidence": [0.5838872194290161, 0.4161129593849182], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.16617.gpt3.4", "original_example": {"example_id": "atomic.train.16617", "premise_hypothesis_id": "atomic.train.7748", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "PWXpM87B9LmDJol5JlHnwg==", "AtomicEventRelationId": "y_uYBwJ1GFYJsh6tuIN8ig==", "AtomicRelationType": "xReact", "AtomicInference": "concerned"}, "premise": "PersonX goes check on PersonY", "hypothesis": "PersonX is seen as concerned", "update": "They just passed out", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16617", "update_paraphrase": "They got so drunk that they just passed out.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3846153846153846, "pred_conf_shift": -0.17596477270126343, "syntactic_distance": 0.29411764705882354}, {"confidence": [0.9122034311294556, 0.0877966359257698], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.16617.gpt3.0", "original_example": {"example_id": "atomic.train.16617", "premise_hypothesis_id": "atomic.train.7748", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "PWXpM87B9LmDJol5JlHnwg==", "AtomicEventRelationId": "y_uYBwJ1GFYJsh6tuIN8ig==", "AtomicRelationType": "xReact", "AtomicInference": "concerned"}, "premise": "PersonX goes check on PersonY", "hypothesis": "PersonX is seen as concerned", "update": "They just passed out", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16617", "update_paraphrase": "They simple fainted.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5364468864468864, "pred_conf_shift": -0.5042810961604118, "syntactic_distance": 0.125}, {"confidence": [0.7356808185577393, 0.26431915163993835], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.16617.gpt3.3", "original_example": {"example_id": "atomic.train.16617", "premise_hypothesis_id": "atomic.train.7748", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "PWXpM87B9LmDJol5JlHnwg==", "AtomicEventRelationId": "y_uYBwJ1GFYJsh6tuIN8ig==", "AtomicRelationType": "xReact", "AtomicInference": "concerned"}, "premise": "PersonX goes check on PersonY", "hypothesis": "PersonX is seen as concerned", "update": "They just passed out", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16617", "update_paraphrase": "They simply fainted.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5602564102564103, "pred_conf_shift": -0.3277585804462433, "syntactic_distance": 0.125}]}, "atomic.train.22951": {"original_confidence": [0.2074105590581894, 0.7925894260406494], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.9240128993988037, 0.07598713785409927], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.22951.gpt3.3", "original_example": {"example_id": "atomic.train.22951", "premise_hypothesis_id": "atomic.train.10521", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mwLsjHhkZ2513oLS-UJfYw==", "AtomicEventRelationId": "aTvBcuYIo9DxcHj9mS2Izw==", "AtomicRelationType": "xNeed", "AtomicInference": "to buy new outfit for work"}, "premise": "PersonX just started a new job", "hypothesis": "Before, PersonX needed to buy new outfit for work", "update": "PersonX got rid of all their business casual clothes.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22951", "update_paraphrase": "PersonX donated, threw away, or sold all of their business casual clothing.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.34591836734693876, "pred_conf_shift": -0.7166022881865501, "syntactic_distance": 0.391304347826087}, {"confidence": [0.9318155646324158, 0.06818448007106781], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.22951.gpt3.6", "original_example": {"example_id": "atomic.train.22951", "premise_hypothesis_id": "atomic.train.10521", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mwLsjHhkZ2513oLS-UJfYw==", "AtomicEventRelationId": "aTvBcuYIo9DxcHj9mS2Izw==", "AtomicRelationType": "xNeed", "AtomicInference": "to buy new outfit for work"}, "premise": "PersonX just started a new job", "hypothesis": "Before, PersonX needed to buy new outfit for work", "update": "PersonX got rid of all their business casual clothes.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22951", "update_paraphrase": "She / he no longer had any use for clothes that were appropriate for business settings.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6657191664544605, "pred_conf_shift": -0.7244049459695816, "syntactic_distance": 0.47058823529411764}, {"confidence": [0.5063461065292358, 0.49365389347076416], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.22951.gpt3.4", "original_example": {"example_id": "atomic.train.22951", "premise_hypothesis_id": "atomic.train.10521", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mwLsjHhkZ2513oLS-UJfYw==", "AtomicEventRelationId": "aTvBcuYIo9DxcHj9mS2Izw==", "AtomicRelationType": "xNeed", "AtomicInference": "to buy new outfit for work"}, "premise": "PersonX just started a new job", "hypothesis": "Before, PersonX needed to buy new outfit for work", "update": "PersonX got rid of all their business casual clothes.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22951", "update_paraphrase": "PersonX eliminated all of their professional clothing from their wardrobe.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4802057591531276, "pred_conf_shift": -0.29893553256988525, "syntactic_distance": 0.2631578947368421}, {"confidence": [0.07765550166368484, 0.9223445057868958], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.22951.gpt3.0", "original_example": {"example_id": "atomic.train.22951", "premise_hypothesis_id": "atomic.train.10521", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mwLsjHhkZ2513oLS-UJfYw==", "AtomicEventRelationId": "aTvBcuYIo9DxcHj9mS2Izw==", "AtomicRelationType": "xNeed", "AtomicInference": "to buy new outfit for work"}, "premise": "PersonX just started a new job", "hypothesis": "Before, PersonX needed to buy new outfit for work", "update": "PersonX got rid of all their business casual clothes.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22951", "update_paraphrase": "PersonX no longer owns any clothing that would be considered appropriate for business casual settings.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5693376068376068, "pred_conf_shift": 0.12975507974624634, "syntactic_distance": 0.42105263157894735}, {"confidence": [0.4524276554584503, 0.5475723743438721], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.22951.gpt3.8", "original_example": {"example_id": "atomic.train.22951", "premise_hypothesis_id": "atomic.train.10521", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mwLsjHhkZ2513oLS-UJfYw==", "AtomicEventRelationId": "aTvBcuYIo9DxcHj9mS2Izw==", "AtomicRelationType": "xNeed", "AtomicInference": "to buy new outfit for work"}, "premise": "PersonX just started a new job", "hypothesis": "Before, PersonX needed to buy new outfit for work", "update": "PersonX got rid of all their business casual clothes.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22951", "update_paraphrase": "PersonX disposed of all their business casual clothes.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.14331550802139043, "pred_conf_shift": -0.24501705169677734, "syntactic_distance": 0.1875}, {"confidence": [0.9495273232460022, 0.050472602248191833], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.22951.gpt3.2", "original_example": {"example_id": "atomic.train.22951", "premise_hypothesis_id": "atomic.train.10521", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mwLsjHhkZ2513oLS-UJfYw==", "AtomicEventRelationId": "aTvBcuYIo9DxcHj9mS2Izw==", "AtomicRelationType": "xNeed", "AtomicInference": "to buy new outfit for work"}, "premise": "PersonX just started a new job", "hypothesis": "Before, PersonX needed to buy new outfit for work", "update": "PersonX got rid of all their business casual clothes.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22951", "update_paraphrase": "PersonX sold, donated, or discarded all their clothing that would be considered \"business casual.\"", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42766798418972335, "pred_conf_shift": -0.7421168237924576, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.11612449586391449, 0.8838754892349243], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.22951.gpt3.1", "original_example": {"example_id": "atomic.train.22951", "premise_hypothesis_id": "atomic.train.10521", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mwLsjHhkZ2513oLS-UJfYw==", "AtomicEventRelationId": "aTvBcuYIo9DxcHj9mS2Izw==", "AtomicRelationType": "xNeed", "AtomicInference": "to buy new outfit for work"}, "premise": "PersonX just started a new job", "hypothesis": "Before, PersonX needed to buy new outfit for work", "update": "PersonX got rid of all their business casual clothes.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22951", "update_paraphrase": "PersonX banishes all their business casual clothes to the back of their closet.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.41085858585858587, "pred_conf_shift": 0.0912860631942749, "syntactic_distance": 0.5}, {"confidence": [0.6126283407211304, 0.387371689081192], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.22951.gpt3.7", "original_example": {"example_id": "atomic.train.22951", "premise_hypothesis_id": "atomic.train.10521", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mwLsjHhkZ2513oLS-UJfYw==", "AtomicEventRelationId": "aTvBcuYIo9DxcHj9mS2Izw==", "AtomicRelationType": "xNeed", "AtomicInference": "to buy new outfit for work"}, "premise": "PersonX just started a new job", "hypothesis": "Before, PersonX needed to buy new outfit for work", "update": "PersonX got rid of all their business casual clothes.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22951", "update_paraphrase": "PersonX disposed of their entire business casual wardrobe.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.32842451665981076, "pred_conf_shift": -0.4052177369594574, "syntactic_distance": 0.1875}, {"confidence": [0.5438889861106873, 0.45611098408699036], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.22951.gpt3.5", "original_example": {"example_id": "atomic.train.22951", "premise_hypothesis_id": "atomic.train.10521", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mwLsjHhkZ2513oLS-UJfYw==", "AtomicEventRelationId": "aTvBcuYIo9DxcHj9mS2Izw==", "AtomicRelationType": "xNeed", "AtomicInference": "to buy new outfit for work"}, "premise": "PersonX just started a new job", "hypothesis": "Before, PersonX needed to buy new outfit for work", "update": "PersonX got rid of all their business casual clothes.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22951", "update_paraphrase": "In an effort to streamline their wardrobe, PersonX got rid of all their business casual clothes.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28, "pred_conf_shift": -0.33647844195365906, "syntactic_distance": 0.36363636363636365}]}, "atomic.train.14400": {"original_confidence": [0.6133460402488708, 0.3866540193557739], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.47825291752815247, 0.5217471122741699], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.14400.gpt3.3", "original_example": {"example_id": "atomic.train.14400", "premise_hypothesis_id": "atomic.train.6720", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "wFOrqUpMl-Zs2bI-HWi96g==", "AtomicEventRelationId": "1mn5hMxi6firUbJaVJ0E5A==", "AtomicRelationType": "xIntent", "AtomicInference": "discuse matters"}, "premise": "PersonX sees PersonY in person", "hypothesis": "Because PersonX wanted discuse matters", "update": "PersonX is carrying PersonY's phone that they forget at PersonX's house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14400", "update_paraphrase": "PersonX has PersonY's phone with them that they forgot at PersonX's house.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2260869565217391, "pred_conf_shift": -0.13509312272071838, "syntactic_distance": 0.1875}, {"confidence": [0.8065756559371948, 0.193424254655838], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.14400.gpt3.4", "original_example": {"example_id": "atomic.train.14400", "premise_hypothesis_id": "atomic.train.6720", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "wFOrqUpMl-Zs2bI-HWi96g==", "AtomicEventRelationId": "1mn5hMxi6firUbJaVJ0E5A==", "AtomicRelationType": "xIntent", "AtomicInference": "discuse matters"}, "premise": "PersonX sees PersonY in person", "hypothesis": "Because PersonX wanted discuse matters", "update": "PersonX is carrying PersonY's phone that they forget at PersonX's house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14400", "update_paraphrase": "PersonX is holding onto PersonY's phone that they left at PersonX's house.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2064182194616977, "pred_conf_shift": 0.19322961568832397, "syntactic_distance": 0.0625}, {"confidence": [0.7651838064193726, 0.23481608927249908], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.14400.gpt3.8", "original_example": {"example_id": "atomic.train.14400", "premise_hypothesis_id": "atomic.train.6720", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "wFOrqUpMl-Zs2bI-HWi96g==", "AtomicEventRelationId": "1mn5hMxi6firUbJaVJ0E5A==", "AtomicRelationType": "xIntent", "AtomicInference": "discuse matters"}, "premise": "PersonX sees PersonY in person", "hypothesis": "Because PersonX wanted discuse matters", "update": "PersonX is carrying PersonY's phone that they forget at PersonX's house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14400", "update_paraphrase": "PersonX is holding onto PersonY's cell phone that was left behind at PersonX's residence.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39178711484593837, "pred_conf_shift": 0.1518377661705017, "syntactic_distance": 0.0625}, {"confidence": [0.629585862159729, 0.37041422724723816], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.14400.gpt3.0", "original_example": {"example_id": "atomic.train.14400", "premise_hypothesis_id": "atomic.train.6720", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "wFOrqUpMl-Zs2bI-HWi96g==", "AtomicEventRelationId": "1mn5hMxi6firUbJaVJ0E5A==", "AtomicRelationType": "xIntent", "AtomicInference": "discuse matters"}, "premise": "PersonX sees PersonY in person", "hypothesis": "Because PersonX wanted discuse matters", "update": "PersonX is carrying PersonY's phone that they forget at PersonX's house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14400", "update_paraphrase": "PersonX is carrying PersonY's phone that was left at PersonX's house.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.15537190082644625, "pred_conf_shift": 0.016239821910858154, "syntactic_distance": 0.0}, {"confidence": [0.40743887424468994, 0.5925610661506653], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.14400.gpt3.1", "original_example": {"example_id": "atomic.train.14400", "premise_hypothesis_id": "atomic.train.6720", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "wFOrqUpMl-Zs2bI-HWi96g==", "AtomicEventRelationId": "1mn5hMxi6firUbJaVJ0E5A==", "AtomicRelationType": "xIntent", "AtomicInference": "discuse matters"}, "premise": "PersonX sees PersonY in person", "hypothesis": "Because PersonX wanted discuse matters", "update": "PersonX is carrying PersonY's phone that they forget at PersonX's house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14400", "update_paraphrase": "PersonX has PersonY's phone with them that was left behind at PersonX's house.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3130952380952381, "pred_conf_shift": -0.2059071660041809, "syntactic_distance": 0.1875}, {"confidence": [0.673559844493866, 0.32644015550613403], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.14400.gpt3.7", "original_example": {"example_id": "atomic.train.14400", "premise_hypothesis_id": "atomic.train.6720", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "wFOrqUpMl-Zs2bI-HWi96g==", "AtomicEventRelationId": "1mn5hMxi6firUbJaVJ0E5A==", "AtomicRelationType": "xIntent", "AtomicInference": "discuse matters"}, "premise": "PersonX sees PersonY in person", "hypothesis": "Because PersonX wanted discuse matters", "update": "PersonX is carrying PersonY's phone that they forget at PersonX's house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14400", "update_paraphrase": "PersonX is holding on to PersonY's cell phone that they accidentally left at PersonX's residence.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.34723120017237663, "pred_conf_shift": 0.06021380424499512, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.7826783657073975, 0.21732154488563538], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.14400.gpt3.2", "original_example": {"example_id": "atomic.train.14400", "premise_hypothesis_id": "atomic.train.6720", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "wFOrqUpMl-Zs2bI-HWi96g==", "AtomicEventRelationId": "1mn5hMxi6firUbJaVJ0E5A==", "AtomicRelationType": "xIntent", "AtomicInference": "discuse matters"}, "premise": "PersonX sees PersonY in person", "hypothesis": "Because PersonX wanted discuse matters", "update": "PersonX is carrying PersonY's phone that they forget at PersonX's house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14400", "update_paraphrase": "PersonX is holding onto PersonY's cell phone that was accidentally left at PersonX's house.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.29990476190476184, "pred_conf_shift": 0.1693323254585266, "syntactic_distance": 0.0625}, {"confidence": [0.6140468120574951, 0.3859531581401825], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.14400.gpt3.6", "original_example": {"example_id": "atomic.train.14400", "premise_hypothesis_id": "atomic.train.6720", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "wFOrqUpMl-Zs2bI-HWi96g==", "AtomicEventRelationId": "1mn5hMxi6firUbJaVJ0E5A==", "AtomicRelationType": "xIntent", "AtomicInference": "discuse matters"}, "premise": "PersonX sees PersonY in person", "hypothesis": "Because PersonX wanted discuse matters", "update": "PersonX is carrying PersonY's phone that they forget at PersonX's house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14400", "update_paraphrase": "PersonX is holding on to PersonY's phone that was left behind at PersonX's house.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2952380952380953, "pred_conf_shift": 0.0007007718086242676, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.5979248881340027, 0.4020751416683197], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.14400.gpt3.5", "original_example": {"example_id": "atomic.train.14400", "premise_hypothesis_id": "atomic.train.6720", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "wFOrqUpMl-Zs2bI-HWi96g==", "AtomicEventRelationId": "1mn5hMxi6firUbJaVJ0E5A==", "AtomicRelationType": "xIntent", "AtomicInference": "discuse matters"}, "premise": "PersonX sees PersonY in person", "hypothesis": "Because PersonX wanted discuse matters", "update": "PersonX is carrying PersonY's phone that they forget at PersonX's house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14400", "update_paraphrase": "PersonX is carrying PersonY's phone that was left behind at PersonX's house.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.17173913043478267, "pred_conf_shift": -0.015421152114868164, "syntactic_distance": 0.0}]}, "atomic.train.11559": {"original_confidence": [0.6758555173873901, 0.32414448261260986], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.6599009037017822, 0.340099036693573], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11559.gpt3.3", "original_example": {"example_id": "atomic.train.11559", "premise_hypothesis_id": "atomic.train.5436", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "QWG31AJRCe6apkYUqIN8rA==", "AtomicEventRelationId": "5py4JHQTNwO219dE4AFyjw==", "AtomicRelationType": "xAttr", "AtomicInference": "dominant"}, "premise": "PersonX looks PersonY in the eye", "hypothesis": "As a result, PersonX feels dominant", "update": "PersonY is covered in blood", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11559", "update_paraphrase": "There is a lot of blood all over PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5512265512265512, "pred_conf_shift": 0.015954554080963135, "syntactic_distance": 0.35}, {"confidence": [0.6773590445518494, 0.3226410150527954], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11559.gpt3.5", "original_example": {"example_id": "atomic.train.11559", "premise_hypothesis_id": "atomic.train.5436", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "QWG31AJRCe6apkYUqIN8rA==", "AtomicEventRelationId": "5py4JHQTNwO219dE4AFyjw==", "AtomicRelationType": "xAttr", "AtomicInference": "dominant"}, "premise": "PersonX looks PersonY in the eye", "hypothesis": "As a result, PersonX feels dominant", "update": "PersonY is covered in blood", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11559", "update_paraphrase": "PersonY is soaked in blood.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.12527472527472527, "pred_conf_shift": -0.0015034675598144531, "syntactic_distance": 0.0}, {"confidence": [0.8026236891746521, 0.1973763108253479], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11559.gpt3.2", "original_example": {"example_id": "atomic.train.11559", "premise_hypothesis_id": "atomic.train.5436", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "QWG31AJRCe6apkYUqIN8rA==", "AtomicEventRelationId": "5py4JHQTNwO219dE4AFyjw==", "AtomicRelationType": "xAttr", "AtomicInference": "dominant"}, "premise": "PersonX looks PersonY in the eye", "hypothesis": "As a result, PersonX feels dominant", "update": "PersonY is covered in blood", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11559", "update_paraphrase": "PersonY is covered in blood from the injuries they sustained.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33333333333333337, "pred_conf_shift": -0.12676817178726196, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.6675900816917419, 0.33240991830825806], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11559.gpt3.4", "original_example": {"example_id": "atomic.train.11559", "premise_hypothesis_id": "atomic.train.5436", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "QWG31AJRCe6apkYUqIN8rA==", "AtomicEventRelationId": "5py4JHQTNwO219dE4AFyjw==", "AtomicRelationType": "xAttr", "AtomicInference": "dominant"}, "premise": "PersonX looks PersonY in the eye", "hypothesis": "As a result, PersonX feels dominant", "update": "PersonY is covered in blood", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11559", "update_paraphrase": "PersonY is oozing with blood.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.27142857142857146, "pred_conf_shift": 0.008265435695648193, "syntactic_distance": 0.0625}, {"confidence": [0.6851865649223328, 0.3148135244846344], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11559.gpt3.1", "original_example": {"example_id": "atomic.train.11559", "premise_hypothesis_id": "atomic.train.5436", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "QWG31AJRCe6apkYUqIN8rA==", "AtomicEventRelationId": "5py4JHQTNwO219dE4AFyjw==", "AtomicRelationType": "xAttr", "AtomicInference": "dominant"}, "premise": "PersonX looks PersonY in the eye", "hypothesis": "As a result, PersonX feels dominant", "update": "PersonY is covered in blood", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11559", "update_paraphrase": "PersonY is drenched in blood.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1314285714285714, "pred_conf_shift": -0.009330958127975464, "syntactic_distance": 0.0}, {"confidence": [0.7958462834358215, 0.20415373146533966], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11559.gpt3.0", "original_example": {"example_id": "atomic.train.11559", "premise_hypothesis_id": "atomic.train.5436", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "QWG31AJRCe6apkYUqIN8rA==", "AtomicEventRelationId": "5py4JHQTNwO219dE4AFyjw==", "AtomicRelationType": "xAttr", "AtomicInference": "dominant"}, "premise": "PersonX looks PersonY in the eye", "hypothesis": "As a result, PersonX feels dominant", "update": "PersonY is covered in blood", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11559", "update_paraphrase": "There is blood all over PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.44903581267217624, "pred_conf_shift": -0.1199907511472702, "syntactic_distance": 0.1875}]}, "atomic.train.3790": {"original_confidence": [0.6462283730506897, 0.3537716269493103], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.5089313387870789, 0.49106866121292114], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3790.gpt3.3", "original_example": {"example_id": "atomic.train.3790", "premise_hypothesis_id": "atomic.train.1781", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "KemmmMaNbi6zZWazfLBh0g==", "AtomicEventRelationId": "z4porMrXdNiAckSCFYPRbw==", "AtomicRelationType": "xReact", "AtomicInference": "smarter"}, "premise": "PersonX studies PersonY", "hypothesis": "PersonX is seen as smarter", "update": "PersonY makes the worst grades in class.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3790", "update_paraphrase": "PersonY always has the lowest grades in class.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22004662004662012, "pred_conf_shift": -0.13729703426361084, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.3979029655456543, 0.6020970940589905], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3790.gpt3.1", "original_example": {"example_id": "atomic.train.3790", "premise_hypothesis_id": "atomic.train.1781", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "KemmmMaNbi6zZWazfLBh0g==", "AtomicEventRelationId": "z4porMrXdNiAckSCFYPRbw==", "AtomicRelationType": "xReact", "AtomicInference": "smarter"}, "premise": "PersonX studies PersonY", "hypothesis": "PersonX is seen as smarter", "update": "PersonY makes the worst grades in class.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3790", "update_paraphrase": "Person Y always has the lowest grades in class.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.25393356643356646, "pred_conf_shift": -0.2483254075050354, "syntactic_distance": 0.2}, {"confidence": [0.5275408625602722, 0.4724591374397278], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3790.gpt3.6", "original_example": {"example_id": "atomic.train.3790", "premise_hypothesis_id": "atomic.train.1781", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "KemmmMaNbi6zZWazfLBh0g==", "AtomicEventRelationId": "z4porMrXdNiAckSCFYPRbw==", "AtomicRelationType": "xReact", "AtomicInference": "smarter"}, "premise": "PersonX studies PersonY", "hypothesis": "PersonX is seen as smarter", "update": "PersonY makes the worst grades in class.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3790", "update_paraphrase": "PersonY always gets the lowest grades in class.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22745402745402749, "pred_conf_shift": -0.11868751049041748, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.6162737011909485, 0.3837263286113739], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3790.gpt3.4", "original_example": {"example_id": "atomic.train.3790", "premise_hypothesis_id": "atomic.train.1781", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "KemmmMaNbi6zZWazfLBh0g==", "AtomicEventRelationId": "z4porMrXdNiAckSCFYPRbw==", "AtomicRelationType": "xReact", "AtomicInference": "smarter"}, "premise": "PersonX studies PersonY", "hypothesis": "PersonX is seen as smarter", "update": "PersonY makes the worst grades in class.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3790", "update_paraphrase": "PersonY consistently earns the lowest marks in class.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2686443381180223, "pred_conf_shift": -0.02995467185974121, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.7124180197715759, 0.28758183121681213], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3790.gpt3.5", "original_example": {"example_id": "atomic.train.3790", "premise_hypothesis_id": "atomic.train.1781", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "KemmmMaNbi6zZWazfLBh0g==", "AtomicEventRelationId": "z4porMrXdNiAckSCFYPRbw==", "AtomicRelationType": "xReact", "AtomicInference": "smarter"}, "premise": "PersonX studies PersonY", "hypothesis": "PersonX is seen as smarter", "update": "PersonY makes the worst grades in class.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3790", "update_paraphrase": "PersonY has the lowest grades out of anyone in class.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3475935828877006, "pred_conf_shift": 0.06618964672088623, "syntactic_distance": 0.0}, {"confidence": [0.7986747026443481, 0.20132531225681305], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3790.gpt3.2", "original_example": {"example_id": "atomic.train.3790", "premise_hypothesis_id": "atomic.train.1781", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "KemmmMaNbi6zZWazfLBh0g==", "AtomicEventRelationId": "z4porMrXdNiAckSCFYPRbw==", "AtomicRelationType": "xReact", "AtomicInference": "smarter"}, "premise": "PersonX studies PersonY", "hypothesis": "PersonX is seen as smarter", "update": "PersonY makes the worst grades in class.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3790", "update_paraphrase": "PersonY consistently has the lowest grades out of everyone in class.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.36629452418926106, "pred_conf_shift": 0.15244632959365845, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.5455715656280518, 0.454428493976593], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3790.gpt3.0", "original_example": {"example_id": "atomic.train.3790", "premise_hypothesis_id": "atomic.train.1781", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "KemmmMaNbi6zZWazfLBh0g==", "AtomicEventRelationId": "z4porMrXdNiAckSCFYPRbw==", "AtomicRelationType": "xReact", "AtomicInference": "smarter"}, "premise": "PersonX studies PersonY", "hypothesis": "PersonX is seen as smarter", "update": "PersonY makes the worst grades in class.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3790", "update_paraphrase": "PersonY has the lowest grades in class.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.17532467532467538, "pred_conf_shift": -0.10065680742263794, "syntactic_distance": 0.0}]}, "atomic.train.1275": {"original_confidence": [0.6393410563468933, 0.3606589436531067], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.8167963624000549, 0.18320366740226746], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1275.gpt3.4", "original_example": {"example_id": "atomic.train.1275", "premise_hypothesis_id": "atomic.train.603", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_bV_2H3aJ3urNfdI6qNGSw==", "AtomicEventRelationId": "o--5DJ6IP2Tw6ABXDNSlVA==", "AtomicRelationType": "xNeed", "AtomicInference": "a reason for the meeting"}, "premise": "PersonX calls PersonY into the office", "hypothesis": "Before, PersonX needed a reason for the meeting", "update": "PersonX sent an email to PersonY about it.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1275", "update_paraphrase": "PersonX emailed PersonY to let them know about the situation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42362514029180687, "pred_conf_shift": -0.17745527625083923, "syntactic_distance": 0.34782608695652173}, {"confidence": [0.8348566889762878, 0.1651432365179062], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1275.gpt3.6", "original_example": {"example_id": "atomic.train.1275", "premise_hypothesis_id": "atomic.train.603", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_bV_2H3aJ3urNfdI6qNGSw==", "AtomicEventRelationId": "o--5DJ6IP2Tw6ABXDNSlVA==", "AtomicRelationType": "xNeed", "AtomicInference": "a reason for the meeting"}, "premise": "PersonX calls PersonY into the office", "hypothesis": "Before, PersonX needed a reason for the meeting", "update": "PersonX sent an email to PersonY about it.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1275", "update_paraphrase": "PersonX emailed PersonY about the situation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.34329004329004326, "pred_conf_shift": -0.1955157071352005, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.9259998202323914, 0.07400024682283401], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1275.gpt3.5", "original_example": {"example_id": "atomic.train.1275", "premise_hypothesis_id": "atomic.train.603", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_bV_2H3aJ3urNfdI6qNGSw==", "AtomicEventRelationId": "o--5DJ6IP2Tw6ABXDNSlVA==", "AtomicRelationType": "xNeed", "AtomicInference": "a reason for the meeting"}, "premise": "PersonX calls PersonY into the office", "hypothesis": "Before, PersonX needed a reason for the meeting", "update": "PersonX sent an email to PersonY about it.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1275", "update_paraphrase": "PersonX found something out and shoot PersonY an email about the news.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4428937728937729, "pred_conf_shift": -0.2866586968302727, "syntactic_distance": 0.37037037037037035}, {"confidence": [0.9502027630805969, 0.04979722574353218], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1275.gpt3.2", "original_example": {"example_id": "atomic.train.1275", "premise_hypothesis_id": "atomic.train.603", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_bV_2H3aJ3urNfdI6qNGSw==", "AtomicEventRelationId": "o--5DJ6IP2Tw6ABXDNSlVA==", "AtomicRelationType": "xNeed", "AtomicInference": "a reason for the meeting"}, "premise": "PersonX calls PersonY into the office", "hypothesis": "Before, PersonX needed a reason for the meeting", "update": "PersonX sent an email to PersonY about it.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1275", "update_paraphrase": "PersonX contacted PersonY about the issue via email.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4142676767676768, "pred_conf_shift": -0.3108617179095745, "syntactic_distance": 0.037037037037037035}, {"confidence": [0.7331209182739258, 0.266879141330719], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1275.gpt3.0", "original_example": {"example_id": "atomic.train.1275", "premise_hypothesis_id": "atomic.train.603", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_bV_2H3aJ3urNfdI6qNGSw==", "AtomicEventRelationId": "o--5DJ6IP2Tw6ABXDNSlVA==", "AtomicRelationType": "xNeed", "AtomicInference": "a reason for the meeting"}, "premise": "PersonX calls PersonY into the office", "hypothesis": "Before, PersonX needed a reason for the meeting", "update": "PersonX sent an email to PersonY about it.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1275", "update_paraphrase": "PersonX emailed PersonY to let them know about it.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2973856209150326, "pred_conf_shift": -0.0937798023223877, "syntactic_distance": 0.30434782608695654}, {"confidence": [0.9474090933799744, 0.05259094014763832], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1275.gpt3.1", "original_example": {"example_id": "atomic.train.1275", "premise_hypothesis_id": "atomic.train.603", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_bV_2H3aJ3urNfdI6qNGSw==", "AtomicEventRelationId": "o--5DJ6IP2Tw6ABXDNSlVA==", "AtomicRelationType": "xNeed", "AtomicInference": "a reason for the meeting"}, "premise": "PersonX calls PersonY into the office", "hypothesis": "Before, PersonX needed a reason for the meeting", "update": "PersonX sent an email to PersonY about it.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1275", "update_paraphrase": "PersonX contacted PersonY about the situation via email.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.41145104895104895, "pred_conf_shift": -0.30806800350546837, "syntactic_distance": 0.037037037037037035}]}, "atomic.train.37943": {"original_confidence": [0.5964483022689819, 0.40355169773101807], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.3976660668849945, 0.6023339033126831], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37943.gpt3.3", "original_example": {"example_id": "atomic.train.37943", "premise_hypothesis_id": "atomic.train.17221", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gG9Jt3fwR_YV0f9h-scLaA==", "AtomicEventRelationId": "LoBARZ-EcmgBTjx_-oefeg==", "AtomicRelationType": "xAttr", "AtomicInference": "brave"}, "premise": "PersonX holds society together", "hypothesis": "As a result, PersonX feels brave", "update": "PersonX was frightened to stand up for society.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37943", "update_paraphrase": "PersonX was terrified to speak out for what they believed in.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4826771873863286, "pred_conf_shift": 0.19878220558166504, "syntactic_distance": 0.0625}, {"confidence": [0.4481164216995239, 0.5518835186958313], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37943.gpt3.1", "original_example": {"example_id": "atomic.train.37943", "premise_hypothesis_id": "atomic.train.17221", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gG9Jt3fwR_YV0f9h-scLaA==", "AtomicEventRelationId": "LoBARZ-EcmgBTjx_-oefeg==", "AtomicRelationType": "xAttr", "AtomicInference": "brave"}, "premise": "PersonX holds society together", "hypothesis": "As a result, PersonX feels brave", "update": "PersonX was frightened to stand up for society.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37943", "update_paraphrase": "PersonX was scared to speak up for what they believed in.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4142876129718235, "pred_conf_shift": 0.14833182096481323, "syntactic_distance": 0.0}, {"confidence": [0.04938049614429474, 0.9506194591522217], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37943.gpt3.7", "original_example": {"example_id": "atomic.train.37943", "premise_hypothesis_id": "atomic.train.17221", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gG9Jt3fwR_YV0f9h-scLaA==", "AtomicEventRelationId": "LoBARZ-EcmgBTjx_-oefeg==", "AtomicRelationType": "xAttr", "AtomicInference": "brave"}, "premise": "PersonX holds society together", "hypothesis": "As a result, PersonX feels brave", "update": "PersonX was frightened to stand up for society.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37943", "update_paraphrase": "It was scary for PersonX to stand up for what they believed in.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3992488992488992, "pred_conf_shift": 0.5470677614212036, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.9135653376579285, 0.08643461018800735], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37943.gpt3.4", "original_example": {"example_id": "atomic.train.37943", "premise_hypothesis_id": "atomic.train.17221", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gG9Jt3fwR_YV0f9h-scLaA==", "AtomicEventRelationId": "LoBARZ-EcmgBTjx_-oefeg==", "AtomicRelationType": "xAttr", "AtomicInference": "brave"}, "premise": "PersonX holds society together", "hypothesis": "As a result, PersonX feels brave", "update": "PersonX was frightened to stand up for society.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37943", "update_paraphrase": "PersonX was too scared to stand up for society.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1426470588235294, "pred_conf_shift": -0.3171170875430107, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.5976664423942566, 0.4023335874080658], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37943.gpt3.6", "original_example": {"example_id": "atomic.train.37943", "premise_hypothesis_id": "atomic.train.17221", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gG9Jt3fwR_YV0f9h-scLaA==", "AtomicEventRelationId": "LoBARZ-EcmgBTjx_-oefeg==", "AtomicRelationType": "xAttr", "AtomicInference": "brave"}, "premise": "PersonX holds society together", "hypothesis": "As a result, PersonX feels brave", "update": "PersonX was frightened to stand up for society.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37943", "update_paraphrase": "PersonX was scared to stand up for what was right in society.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3479166666666667, "pred_conf_shift": -0.0012181103229522705, "syntactic_distance": 0.0}, {"confidence": [0.21577614545822144, 0.7842238545417786], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37943.gpt3.8", "original_example": {"example_id": "atomic.train.37943", "premise_hypothesis_id": "atomic.train.17221", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gG9Jt3fwR_YV0f9h-scLaA==", "AtomicEventRelationId": "LoBARZ-EcmgBTjx_-oefeg==", "AtomicRelationType": "xAttr", "AtomicInference": "brave"}, "premise": "PersonX holds society together", "hypothesis": "As a result, PersonX feels brave", "update": "PersonX was frightened to stand up for society.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37943", "update_paraphrase": "PersonX was worried about speaking out for what they believed in publicly.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5515262515262516, "pred_conf_shift": 0.3806721568107605, "syntactic_distance": 0.125}, {"confidence": [0.29839667677879333, 0.701603353023529], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37943.gpt3.0", "original_example": {"example_id": "atomic.train.37943", "premise_hypothesis_id": "atomic.train.17221", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gG9Jt3fwR_YV0f9h-scLaA==", "AtomicEventRelationId": "LoBARZ-EcmgBTjx_-oefeg==", "AtomicRelationType": "xAttr", "AtomicInference": "brave"}, "premise": "PersonX holds society together", "hypothesis": "As a result, PersonX feels brave", "update": "PersonX was frightened to stand up for society.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37943", "update_paraphrase": "PersonX was terrified of speaking out for social change.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45996665872826864, "pred_conf_shift": 0.298051655292511, "syntactic_distance": 0.125}, {"confidence": [0.2850804924964905, 0.7149194478988647], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37943.gpt3.2", "original_example": {"example_id": "atomic.train.37943", "premise_hypothesis_id": "atomic.train.17221", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gG9Jt3fwR_YV0f9h-scLaA==", "AtomicEventRelationId": "LoBARZ-EcmgBTjx_-oefeg==", "AtomicRelationType": "xAttr", "AtomicInference": "brave"}, "premise": "PersonX holds society together", "hypothesis": "As a result, PersonX feels brave", "update": "PersonX was frightened to stand up for society.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37943", "update_paraphrase": "PersonX was scared to voice their opinions on social issues.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4963254338254338, "pred_conf_shift": 0.3113677501678467, "syntactic_distance": 0.0}]}, "atomic.train.4147": {"original_confidence": [0.13915462791919708, 0.8608453869819641], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.07406619191169739, 0.9259338974952698], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4147.gpt3.2", "original_example": {"example_id": "atomic.train.4147", "premise_hypothesis_id": "atomic.train.1952", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Fhjz4cPPHB18td5Tu7oV6Q==", "AtomicEventRelationId": "4lpiIWnwA9eJB_PLkfQvOQ==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonY yells at PersonX"}, "premise": "PersonX plays a prank on PersonY", "hypothesis": "PersonX then personY yells at PersonX", "update": "PersonY hates being surprised.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4147", "update_paraphrase": "Person Y does not enjoy being caught off guard.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5698318775241853, "pred_conf_shift": 0.06508851051330566, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.12443236261606216, 0.8755677342414856], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4147.gpt3.3", "original_example": {"example_id": "atomic.train.4147", "premise_hypothesis_id": "atomic.train.1952", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Fhjz4cPPHB18td5Tu7oV6Q==", "AtomicEventRelationId": "4lpiIWnwA9eJB_PLkfQvOQ==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonY yells at PersonX"}, "premise": "PersonX plays a prank on PersonY", "hypothesis": "PersonX then personY yells at PersonX", "update": "PersonY hates being surprised.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4147", "update_paraphrase": "PersonY hates it when people try to surprise them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5160304753064934, "pred_conf_shift": 0.014722347259521484, "syntactic_distance": 0.29411764705882354}, {"confidence": [0.05930140241980553, 0.940698504447937], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4147.gpt3.4", "original_example": {"example_id": "atomic.train.4147", "premise_hypothesis_id": "atomic.train.1952", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Fhjz4cPPHB18td5Tu7oV6Q==", "AtomicEventRelationId": "4lpiIWnwA9eJB_PLkfQvOQ==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonY yells at PersonX"}, "premise": "PersonX plays a prank on PersonY", "hypothesis": "PersonX then personY yells at PersonX", "update": "PersonY hates being surprised.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4147", "update_paraphrase": "Person Y detests being caught off guard.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4815184815184814, "pred_conf_shift": 0.0798531174659729, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.08387412130832672, 0.9161258339881897], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4147.gpt3.5", "original_example": {"example_id": "atomic.train.4147", "premise_hypothesis_id": "atomic.train.1952", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Fhjz4cPPHB18td5Tu7oV6Q==", "AtomicEventRelationId": "4lpiIWnwA9eJB_PLkfQvOQ==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonY yells at PersonX"}, "premise": "PersonX plays a prank on PersonY", "hypothesis": "PersonX then personY yells at PersonX", "update": "PersonY hates being surprised.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4147", "update_paraphrase": "PersonY does not like to be surprised.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4849796667978485, "pred_conf_shift": 0.055280447006225586, "syntactic_distance": 0.25}, {"confidence": [0.11565440148115158, 0.8843456506729126], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4147.gpt3.6", "original_example": {"example_id": "atomic.train.4147", "premise_hypothesis_id": "atomic.train.1952", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Fhjz4cPPHB18td5Tu7oV6Q==", "AtomicEventRelationId": "4lpiIWnwA9eJB_PLkfQvOQ==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonY yells at PersonX"}, "premise": "PersonX plays a prank on PersonY", "hypothesis": "PersonX then personY yells at PersonX", "update": "PersonY hates being surprised.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4147", "update_paraphrase": "PersonY hates it when people try to surprise him/her.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5222464815224996, "pred_conf_shift": 0.023500263690948486, "syntactic_distance": 0.29411764705882354}, {"confidence": [0.08606091886758804, 0.9139390587806702], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4147.gpt3.0", "original_example": {"example_id": "atomic.train.4147", "premise_hypothesis_id": "atomic.train.1952", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Fhjz4cPPHB18td5Tu7oV6Q==", "AtomicEventRelationId": "4lpiIWnwA9eJB_PLkfQvOQ==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonY yells at PersonX"}, "premise": "PersonX plays a prank on PersonY", "hypothesis": "PersonX then personY yells at PersonX", "update": "PersonY hates being surprised.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4147", "update_paraphrase": "PersonY can't stand surprises.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4531746031746031, "pred_conf_shift": 0.053093671798706055, "syntactic_distance": 0.3125}, {"confidence": [0.08451416343450546, 0.9154858589172363], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4147.gpt3.7", "original_example": {"example_id": "atomic.train.4147", "premise_hypothesis_id": "atomic.train.1952", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Fhjz4cPPHB18td5Tu7oV6Q==", "AtomicEventRelationId": "4lpiIWnwA9eJB_PLkfQvOQ==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonY yells at PersonX"}, "premise": "PersonX plays a prank on PersonY", "hypothesis": "PersonX then personY yells at PersonX", "update": "PersonY hates being surprised.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4147", "update_paraphrase": "PersonY does not like surprises.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5089786756453424, "pred_conf_shift": 0.05464047193527222, "syntactic_distance": 0.25}, {"confidence": [0.11760283261537552, 0.8823972344398499], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4147.gpt3.1", "original_example": {"example_id": "atomic.train.4147", "premise_hypothesis_id": "atomic.train.1952", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Fhjz4cPPHB18td5Tu7oV6Q==", "AtomicEventRelationId": "4lpiIWnwA9eJB_PLkfQvOQ==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonY yells at PersonX"}, "premise": "PersonX plays a prank on PersonY", "hypothesis": "PersonX then personY yells at PersonX", "update": "PersonY hates being surprised.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4147", "update_paraphrase": "PersonY hates getting surprises.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.24603174603174605, "pred_conf_shift": 0.021551847457885742, "syntactic_distance": 0.0}, {"confidence": [0.07995812594890594, 0.9200417995452881], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4147.gpt3.8", "original_example": {"example_id": "atomic.train.4147", "premise_hypothesis_id": "atomic.train.1952", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Fhjz4cPPHB18td5Tu7oV6Q==", "AtomicEventRelationId": "4lpiIWnwA9eJB_PLkfQvOQ==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonY yells at PersonX"}, "premise": "PersonX plays a prank on PersonY", "hypothesis": "PersonX then personY yells at PersonX", "update": "PersonY hates being surprised.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4147", "update_paraphrase": "PersonY can't stand being caught off guard.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5165945165945165, "pred_conf_shift": 0.059196412563323975, "syntactic_distance": 0.3125}]}, "atomic.train.15992": {"original_confidence": [0.7857577204704285, 0.21424229443073273], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.7715227007865906, 0.228477343916893], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15992.gpt3.2", "original_example": {"example_id": "atomic.train.15992", "premise_hypothesis_id": "atomic.train.7451", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Y2uBO4mw6yHdSN2piUVbTw==", "AtomicEventRelationId": "bcR-uA1v7uh2cx8LMZIbaw==", "AtomicRelationType": "xAttr", "AtomicInference": "diligent"}, "premise": "PersonX earns a lot of money", "hypothesis": "As a result, PersonX feels diligent", "update": "PersonX was happy with the inheritance.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15992", "update_paraphrase": "PersonX was thrilled to receive the inheritance.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33004602235371466, "pred_conf_shift": -0.01423501968383789, "syntactic_distance": 0.125}, {"confidence": [0.6916988492012024, 0.30830124020576477], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15992.gpt3.1", "original_example": {"example_id": "atomic.train.15992", "premise_hypothesis_id": "atomic.train.7451", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Y2uBO4mw6yHdSN2piUVbTw==", "AtomicEventRelationId": "bcR-uA1v7uh2cx8LMZIbaw==", "AtomicRelationType": "xAttr", "AtomicInference": "diligent"}, "premise": "PersonX earns a lot of money", "hypothesis": "As a result, PersonX feels diligent", "update": "PersonX was happy with the inheritance.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15992", "update_paraphrase": "PersonX was pleased with the inheritance they received.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.36366213151927435, "pred_conf_shift": -0.09405887126922607, "syntactic_distance": 0.125}, {"confidence": [0.8983774781227112, 0.10162235796451569], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15992.gpt3.0", "original_example": {"example_id": "atomic.train.15992", "premise_hypothesis_id": "atomic.train.7451", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Y2uBO4mw6yHdSN2piUVbTw==", "AtomicEventRelationId": "bcR-uA1v7uh2cx8LMZIbaw==", "AtomicRelationType": "xAttr", "AtomicInference": "diligent"}, "premise": "PersonX earns a lot of money", "hypothesis": "As a result, PersonX feels diligent", "update": "PersonX was happy with the inheritance.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15992", "update_paraphrase": "PersonX was delighted with what they inherited.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.34229595191133655, "pred_conf_shift": 0.11261975765228271, "syntactic_distance": 0.0625}, {"confidence": [0.803493857383728, 0.19650615751743317], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15992.gpt3.4", "original_example": {"example_id": "atomic.train.15992", "premise_hypothesis_id": "atomic.train.7451", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Y2uBO4mw6yHdSN2piUVbTw==", "AtomicEventRelationId": "bcR-uA1v7uh2cx8LMZIbaw==", "AtomicRelationType": "xAttr", "AtomicInference": "diligent"}, "premise": "PersonX earns a lot of money", "hypothesis": "As a result, PersonX feels diligent", "update": "PersonX was happy with the inheritance.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15992", "update_paraphrase": "PersonX was pleased with what they inherited.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.31894430355968817, "pred_conf_shift": 0.01773613691329956, "syntactic_distance": 0.1875}, {"confidence": [0.8219407796859741, 0.17805920541286469], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15992.gpt3.3", "original_example": {"example_id": "atomic.train.15992", "premise_hypothesis_id": "atomic.train.7451", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Y2uBO4mw6yHdSN2piUVbTw==", "AtomicEventRelationId": "bcR-uA1v7uh2cx8LMZIbaw==", "AtomicRelationType": "xAttr", "AtomicInference": "diligent"}, "premise": "PersonX earns a lot of money", "hypothesis": "As a result, PersonX feels diligent", "update": "PersonX was happy with the inheritance.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15992", "update_paraphrase": "PersonX was elated with the inheritance they received.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.38095238095238093, "pred_conf_shift": 0.036183059215545654, "syntactic_distance": 0.125}]}, "atomic.train.31622": {"original_confidence": [0.91385817527771, 0.08614177256822586], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.9298388361930847, 0.07016110420227051], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31622.gpt3.4", "original_example": {"example_id": "atomic.train.31622", "premise_hypothesis_id": "atomic.train.14365", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xmWfrNPdvXt-R5cBdihe-g==", "AtomicEventRelationId": "tBdYQD37LozhIxzgfBNPdg==", "AtomicRelationType": "xIntent", "AtomicInference": "to relieve their frustration"}, "premise": "PersonX looks for a dog to kick", "hypothesis": "Because PersonX wanted to relieve their frustration", "update": "They are just a bad person", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31622", "update_paraphrase": "They are a bad person.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.09090909090909094, "pred_conf_shift": 0.015980660915374756, "syntactic_distance": 0.05263157894736842}, {"confidence": [0.9319640398025513, 0.06803596019744873], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31622.gpt3.0", "original_example": {"example_id": "atomic.train.31622", "premise_hypothesis_id": "atomic.train.14365", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xmWfrNPdvXt-R5cBdihe-g==", "AtomicEventRelationId": "tBdYQD37LozhIxzgfBNPdg==", "AtomicRelationType": "xIntent", "AtomicInference": "to relieve their frustration"}, "premise": "PersonX looks for a dog to kick", "hypothesis": "Because PersonX wanted to relieve their frustration", "update": "They are just a bad person", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31622", "update_paraphrase": "This person is no good.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.670995670995671, "pred_conf_shift": 0.01810586452484131, "syntactic_distance": 0.2631578947368421}, {"confidence": [0.747586727142334, 0.25241315364837646], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31622.gpt3.5", "original_example": {"example_id": "atomic.train.31622", "premise_hypothesis_id": "atomic.train.14365", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xmWfrNPdvXt-R5cBdihe-g==", "AtomicEventRelationId": "tBdYQD37LozhIxzgfBNPdg==", "AtomicRelationType": "xIntent", "AtomicInference": "to relieve their frustration"}, "premise": "PersonX looks for a dog to kick", "hypothesis": "Because PersonX wanted to relieve their frustration", "update": "They are just a bad person", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31622", "update_paraphrase": "They're just a bad egg.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.25858585858585864, "pred_conf_shift": -0.16627144813537598, "syntactic_distance": 0.0}, {"confidence": [0.9204676747322083, 0.07953234761953354], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31622.gpt3.1", "original_example": {"example_id": "atomic.train.31622", "premise_hypothesis_id": "atomic.train.14365", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xmWfrNPdvXt-R5cBdihe-g==", "AtomicEventRelationId": "tBdYQD37LozhIxzgfBNPdg==", "AtomicRelationType": "xIntent", "AtomicInference": "to relieve their frustration"}, "premise": "PersonX looks for a dog to kick", "hypothesis": "Because PersonX wanted to relieve their frustration", "update": "They are just a bad person", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31622", "update_paraphrase": "They're not a good person.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.387012987012987, "pred_conf_shift": 0.006609499454498291, "syntactic_distance": 0.1}, {"confidence": [0.9556268453598022, 0.04437312111258507], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31622.gpt3.2", "original_example": {"example_id": "atomic.train.31622", "premise_hypothesis_id": "atomic.train.14365", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xmWfrNPdvXt-R5cBdihe-g==", "AtomicEventRelationId": "tBdYQD37LozhIxzgfBNPdg==", "AtomicRelationType": "xIntent", "AtomicInference": "to relieve their frustration"}, "premise": "PersonX looks for a dog to kick", "hypothesis": "Because PersonX wanted to relieve their frustration", "update": "They are just a bad person", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31622", "update_paraphrase": "They are simply a bad person.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.12916666666666665, "pred_conf_shift": 0.041768670082092285, "syntactic_distance": 0.14285714285714285}, {"confidence": [0.9361045360565186, 0.06389544159173965], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31622.gpt3.3", "original_example": {"example_id": "atomic.train.31622", "premise_hypothesis_id": "atomic.train.14365", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xmWfrNPdvXt-R5cBdihe-g==", "AtomicEventRelationId": "tBdYQD37LozhIxzgfBNPdg==", "AtomicRelationType": "xIntent", "AtomicInference": "to relieve their frustration"}, "premise": "PersonX looks for a dog to kick", "hypothesis": "Because PersonX wanted to relieve their frustration", "update": "They are just a bad person", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31622", "update_paraphrase": "This person is simply not a good person.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5226757369614512, "pred_conf_shift": 0.022246360778808594, "syntactic_distance": 0.30434782608695654}]}, "atomic.train.25743": {"original_confidence": [0.08949702233076096, 0.9105029702186584], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.05472336709499359, 0.9452766180038452], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25743.gpt3.4", "original_example": {"example_id": "atomic.train.25743", "premise_hypothesis_id": "atomic.train.11757", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B6nxETDDHNpsT_uj_Sehig==", "AtomicEventRelationId": "KKitiIIzgc9n0ZRdORdVXg==", "AtomicRelationType": "xAttr", "AtomicInference": "aggressive"}, "premise": "PersonX holds out PersonY's arms", "hypothesis": "As a result, PersonX feels aggressive", "update": "PersonX is about to break them", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25743", "update_paraphrase": "PersonX is on the verge of breaking them", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4082068724925868, "pred_conf_shift": 0.03477364778518677, "syntactic_distance": 0.1875}, {"confidence": [0.0965639278292656, 0.9034359455108643], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25743.gpt3.0", "original_example": {"example_id": "atomic.train.25743", "premise_hypothesis_id": "atomic.train.11757", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B6nxETDDHNpsT_uj_Sehig==", "AtomicEventRelationId": "KKitiIIzgc9n0ZRdORdVXg==", "AtomicRelationType": "xAttr", "AtomicInference": "aggressive"}, "premise": "PersonX holds out PersonY's arms", "hypothesis": "As a result, PersonX feels aggressive", "update": "PersonX is about to break them", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25743", "update_paraphrase": "PersonX is about to break them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": -0.0070670247077941895, "syntactic_distance": 0.0}, {"confidence": [0.08719634264707565, 0.9128036499023438], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25743.gpt3.1", "original_example": {"example_id": "atomic.train.25743", "premise_hypothesis_id": "atomic.train.11757", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B6nxETDDHNpsT_uj_Sehig==", "AtomicEventRelationId": "KKitiIIzgc9n0ZRdORdVXg==", "AtomicRelationType": "xAttr", "AtomicInference": "aggressive"}, "premise": "PersonX holds out PersonY's arms", "hypothesis": "As a result, PersonX feels aggressive", "update": "PersonX is about to break them", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25743", "update_paraphrase": "PersonX is about to make them break", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.21678321678321677, "pred_conf_shift": 0.0023006796836853027, "syntactic_distance": 0.0}, {"confidence": [0.12208575010299683, 0.8779142498970032], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25743.gpt3.3", "original_example": {"example_id": "atomic.train.25743", "premise_hypothesis_id": "atomic.train.11757", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B6nxETDDHNpsT_uj_Sehig==", "AtomicEventRelationId": "KKitiIIzgc9n0ZRdORdVXg==", "AtomicRelationType": "xAttr", "AtomicInference": "aggressive"}, "premise": "PersonX holds out PersonY's arms", "hypothesis": "As a result, PersonX feels aggressive", "update": "PersonX is about to break them", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25743", "update_paraphrase": "PersonX is about to cause them to break", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2653061224489796, "pred_conf_shift": -0.03258872032165527, "syntactic_distance": 0.0}]}, "atomic.train.34917": {"original_confidence": [0.8851372003555298, 0.11486281454563141], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.9343109130859375, 0.0656890794634819], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34917.gpt3.5", "original_example": {"example_id": "atomic.train.34917", "premise_hypothesis_id": "atomic.train.15835", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "iqXJpI3DpiMzU9salk6seA==", "AtomicEventRelationId": "tSE6NUQjrrhWYjQUAyEi_A==", "AtomicRelationType": "xIntent", "AtomicInference": "to get trained"}, "premise": "PersonX puts PersonY into practice", "hypothesis": "Because PersonX wanted to get trained", "update": "PersonX received a promotion.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34917", "update_paraphrase": "PersonX got a promotion at work.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4633333333333333, "pred_conf_shift": -0.049173735082149506, "syntactic_distance": 0.15789473684210525}, {"confidence": [0.8963250517845154, 0.10367484390735626], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34917.gpt3.6", "original_example": {"example_id": "atomic.train.34917", "premise_hypothesis_id": "atomic.train.15835", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "iqXJpI3DpiMzU9salk6seA==", "AtomicEventRelationId": "tSE6NUQjrrhWYjQUAyEi_A==", "AtomicRelationType": "xIntent", "AtomicInference": "to get trained"}, "premise": "PersonX puts PersonY into practice", "hypothesis": "Because PersonX wanted to get trained", "update": "PersonX received a promotion.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34917", "update_paraphrase": "PersonX got a raise in position.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.46325791855203613, "pred_conf_shift": -0.011187970638275146, "syntactic_distance": 0.125}, {"confidence": [0.9220455884933472, 0.07795453071594238], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34917.gpt3.3", "original_example": {"example_id": "atomic.train.34917", "premise_hypothesis_id": "atomic.train.15835", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "iqXJpI3DpiMzU9salk6seA==", "AtomicEventRelationId": "tSE6NUQjrrhWYjQUAyEi_A==", "AtomicRelationType": "xIntent", "AtomicInference": "to get trained"}, "premise": "PersonX puts PersonY into practice", "hypothesis": "Because PersonX wanted to get trained", "update": "PersonX received a promotion.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34917", "update_paraphrase": "PersonX was promoted.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45154061624649855, "pred_conf_shift": -0.036908283829689026, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.9314824938774109, 0.06851740926504135], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34917.gpt3.2", "original_example": {"example_id": "atomic.train.34917", "premise_hypothesis_id": "atomic.train.15835", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "iqXJpI3DpiMzU9salk6seA==", "AtomicEventRelationId": "tSE6NUQjrrhWYjQUAyEi_A==", "AtomicRelationType": "xIntent", "AtomicInference": "to get trained"}, "premise": "PersonX puts PersonY into practice", "hypothesis": "Because PersonX wanted to get trained", "update": "PersonX received a promotion.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34917", "update_paraphrase": "Person X was promoted.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4677601809954751, "pred_conf_shift": -0.04634540528059006, "syntactic_distance": 0.3125}, {"confidence": [0.7297305464744568, 0.27026933431625366], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34917.gpt3.1", "original_example": {"example_id": "atomic.train.34917", "premise_hypothesis_id": "atomic.train.15835", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "iqXJpI3DpiMzU9salk6seA==", "AtomicEventRelationId": "tSE6NUQjrrhWYjQUAyEi_A==", "AtomicRelationType": "xIntent", "AtomicInference": "to get trained"}, "premise": "PersonX puts PersonY into practice", "hypothesis": "Because PersonX wanted to get trained", "update": "PersonX received a promotion.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34917", "update_paraphrase": "PersonX was promoted to a higher position at their company.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5960084033613445, "pred_conf_shift": 0.15540651977062225, "syntactic_distance": 0.25}, {"confidence": [0.818696916103363, 0.18130303919315338], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34917.gpt3.4", "original_example": {"example_id": "atomic.train.34917", "premise_hypothesis_id": "atomic.train.15835", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "iqXJpI3DpiMzU9salk6seA==", "AtomicEventRelationId": "tSE6NUQjrrhWYjQUAyEi_A==", "AtomicRelationType": "xIntent", "AtomicInference": "to get trained"}, "premise": "PersonX puts PersonY into practice", "hypothesis": "Because PersonX wanted to get trained", "update": "PersonX received a promotion.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34917", "update_paraphrase": "Person X got a raise and a new title.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5855170470555086, "pred_conf_shift": 0.06644022464752197, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.8348615169525146, 0.16513849794864655], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34917.gpt3.0", "original_example": {"example_id": "atomic.train.34917", "premise_hypothesis_id": "atomic.train.15835", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "iqXJpI3DpiMzU9salk6seA==", "AtomicEventRelationId": "tSE6NUQjrrhWYjQUAyEi_A==", "AtomicRelationType": "xIntent", "AtomicInference": "to get trained"}, "premise": "PersonX puts PersonY into practice", "hypothesis": "Because PersonX wanted to get trained", "update": "PersonX received a promotion.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34917", "update_paraphrase": "PersonX was promoted to a higher position.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.48582887700534755, "pred_conf_shift": 0.05027568340301514, "syntactic_distance": 0.25}]}, "atomic.train.1006": {"original_confidence": [0.8384941220283508, 0.16150575876235962], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.47888004779815674, 0.5211198925971985], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1006.gpt3.2", "original_example": {"example_id": "atomic.train.1006", "premise_hypothesis_id": "atomic.train.474", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "kXS6_YwS2_Cd177zc1BnVg==", "AtomicEventRelationId": "nsDj2yHeaQXyW-waYUtY5A==", "AtomicRelationType": "xIntent", "AtomicInference": "they are aggressive, go getters"}, "premise": "PersonX gets PersonX's way", "hypothesis": "Because they are aggressive, go getters", "update": "Person X is filthy rich through inheritance.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1006", "update_paraphrase": "This person inherited a ton of money and is now very rich.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5894736842105264, "pred_conf_shift": -0.3596140742301941, "syntactic_distance": 0.44}, {"confidence": [0.1910175234079361, 0.8089824914932251], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1006.gpt3.5", "original_example": {"example_id": "atomic.train.1006", "premise_hypothesis_id": "atomic.train.474", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "kXS6_YwS2_Cd177zc1BnVg==", "AtomicEventRelationId": "nsDj2yHeaQXyW-waYUtY5A==", "AtomicRelationType": "xIntent", "AtomicInference": "they are aggressive, go getters"}, "premise": "PersonX gets PersonX's way", "hypothesis": "Because they are aggressive, go getters", "update": "Person X is filthy rich through inheritance.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1006", "update_paraphrase": "Person X inherited a large sum of money and is now extremely wealthy.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.555920745920746, "pred_conf_shift": -0.6474765986204147, "syntactic_distance": 0.36}, {"confidence": [0.907043993473053, 0.09295602887868881], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1006.gpt3.1", "original_example": {"example_id": "atomic.train.1006", "premise_hypothesis_id": "atomic.train.474", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "kXS6_YwS2_Cd177zc1BnVg==", "AtomicEventRelationId": "nsDj2yHeaQXyW-waYUtY5A==", "AtomicRelationType": "xIntent", "AtomicInference": "they are aggressive, go getters"}, "premise": "PersonX gets PersonX's way", "hypothesis": "Because they are aggressive, go getters", "update": "Person X is filthy rich through inheritance.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1006", "update_paraphrase": "Person X is obscenely wealthy because they inherited money.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4343919968919969, "pred_conf_shift": 0.06854987144470215, "syntactic_distance": 0.08333333333333333}, {"confidence": [0.7753933072090149, 0.22460664808750153], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1006.gpt3.0", "original_example": {"example_id": "atomic.train.1006", "premise_hypothesis_id": "atomic.train.474", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "kXS6_YwS2_Cd177zc1BnVg==", "AtomicEventRelationId": "nsDj2yHeaQXyW-waYUtY5A==", "AtomicRelationType": "xIntent", "AtomicInference": "they are aggressive, go getters"}, "premise": "PersonX gets PersonX's way", "hypothesis": "Because they are aggressive, go getters", "update": "Person X is filthy rich through inheritance.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1006", "update_paraphrase": "Person X is obscenely wealthy because they inherited a fortune.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.46766305589835006, "pred_conf_shift": -0.06310081481933594, "syntactic_distance": 0.08333333333333333}, {"confidence": [0.5549865365028381, 0.44501349329948425], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1006.gpt3.6", "original_example": {"example_id": "atomic.train.1006", "premise_hypothesis_id": "atomic.train.474", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "kXS6_YwS2_Cd177zc1BnVg==", "AtomicEventRelationId": "nsDj2yHeaQXyW-waYUtY5A==", "AtomicRelationType": "xIntent", "AtomicInference": "they are aggressive, go getters"}, "premise": "PersonX gets PersonX's way", "hypothesis": "Because they are aggressive, go getters", "update": "Person X is filthy rich through inheritance.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1006", "update_paraphrase": "Person X is extremely wealthy because they inherited a lot of money.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5236985236985238, "pred_conf_shift": -0.2835075855255127, "syntactic_distance": 0.08333333333333333}, {"confidence": [0.09562499821186066, 0.9043749570846558], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1006.gpt3.4", "original_example": {"example_id": "atomic.train.1006", "premise_hypothesis_id": "atomic.train.474", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "kXS6_YwS2_Cd177zc1BnVg==", "AtomicEventRelationId": "nsDj2yHeaQXyW-waYUtY5A==", "AtomicRelationType": "xIntent", "AtomicInference": "they are aggressive, go getters"}, "premise": "PersonX gets PersonX's way", "hypothesis": "Because they are aggressive, go getters", "update": "Person X is filthy rich through inheritance.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1006", "update_paraphrase": "Person X inherited a fortune and is now ultra-wealthy.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.47635003885003885, "pred_conf_shift": -0.7428691238164902, "syntactic_distance": 0.36}, {"confidence": [0.5043188333511353, 0.4956812262535095], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1006.gpt3.7", "original_example": {"example_id": "atomic.train.1006", "premise_hypothesis_id": "atomic.train.474", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "kXS6_YwS2_Cd177zc1BnVg==", "AtomicEventRelationId": "nsDj2yHeaQXyW-waYUtY5A==", "AtomicRelationType": "xIntent", "AtomicInference": "they are aggressive, go getters"}, "premise": "PersonX gets PersonX's way", "hypothesis": "Because they are aggressive, go getters", "update": "Person X is filthy rich through inheritance.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1006", "update_paraphrase": "Person X is stinking rich because they inherited a lot of money.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4796992481203008, "pred_conf_shift": -0.3341752886772156, "syntactic_distance": 0.125}, {"confidence": [0.5905229449272156, 0.4094771146774292], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1006.gpt3.3", "original_example": {"example_id": "atomic.train.1006", "premise_hypothesis_id": "atomic.train.474", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "kXS6_YwS2_Cd177zc1BnVg==", "AtomicEventRelationId": "nsDj2yHeaQXyW-waYUtY5A==", "AtomicRelationType": "xIntent", "AtomicInference": "they are aggressive, go getters"}, "premise": "PersonX gets PersonX's way", "hypothesis": "Because they are aggressive, go getters", "update": "Person X is filthy rich through inheritance.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1006", "update_paraphrase": "Person X is incredibly wealthy because they inherited a lot of money.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5241682294313874, "pred_conf_shift": -0.24797117710113525, "syntactic_distance": 0.08333333333333333}]}, "atomic.train.11568": {"original_confidence": [0.8768393993377686, 0.12316058576107025], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.6995329856872559, 0.30046698451042175], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11568.gpt3.5", "original_example": {"example_id": "atomic.train.11568", "premise_hypothesis_id": "atomic.train.5441", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xTeIoVSlFZ2OqierOQNn5w==", "AtomicEventRelationId": "naXzYMzzh7L3XeFnsLih-Q==", "AtomicRelationType": "xNeed", "AtomicInference": "to decide on a marketing scheme"}, "premise": "PersonX markets and sell a product or service", "hypothesis": "Before, PersonX needed to decide on a marketing scheme", "update": "Person X is a low level employee at a big firm.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11568", "update_paraphrase": "Person X is an entry-level employee at a large company.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3277777777777777, "pred_conf_shift": -0.1773064136505127, "syntactic_distance": 0.0}, {"confidence": [0.9080859422683716, 0.0919140875339508], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11568.gpt3.2", "original_example": {"example_id": "atomic.train.11568", "premise_hypothesis_id": "atomic.train.5441", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xTeIoVSlFZ2OqierOQNn5w==", "AtomicEventRelationId": "naXzYMzzh7L3XeFnsLih-Q==", "AtomicRelationType": "xNeed", "AtomicInference": "to decide on a marketing scheme"}, "premise": "PersonX markets and sell a product or service", "hypothesis": "Before, PersonX needed to decide on a marketing scheme", "update": "Person X is a low level employee at a big firm.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11568", "update_paraphrase": "Person X is a lowly employee working for a large corporation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33731268731268726, "pred_conf_shift": 0.031246542930603027, "syntactic_distance": 0.05555555555555555}, {"confidence": [0.8269035220146179, 0.1730964183807373], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11568.gpt3.7", "original_example": {"example_id": "atomic.train.11568", "premise_hypothesis_id": "atomic.train.5441", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xTeIoVSlFZ2OqierOQNn5w==", "AtomicEventRelationId": "naXzYMzzh7L3XeFnsLih-Q==", "AtomicRelationType": "xNeed", "AtomicInference": "to decide on a marketing scheme"}, "premise": "PersonX markets and sell a product or service", "hypothesis": "Before, PersonX needed to decide on a marketing scheme", "update": "Person X is a low level employee at a big firm.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11568", "update_paraphrase": "Person X is a bottom-rung worker at a large company.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.375079946508518, "pred_conf_shift": -0.049935877323150635, "syntactic_distance": 0.0}, {"confidence": [0.909815788269043, 0.09018412232398987], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11568.gpt3.0", "original_example": {"example_id": "atomic.train.11568", "premise_hypothesis_id": "atomic.train.5441", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xTeIoVSlFZ2OqierOQNn5w==", "AtomicEventRelationId": "naXzYMzzh7L3XeFnsLih-Q==", "AtomicRelationType": "xNeed", "AtomicInference": "to decide on a marketing scheme"}, "premise": "PersonX markets and sell a product or service", "hypothesis": "Before, PersonX needed to decide on a marketing scheme", "update": "Person X is a low level employee at a big firm.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11568", "update_paraphrase": "Person X is a lowly employee at a large company.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3294372294372294, "pred_conf_shift": 0.032976388931274414, "syntactic_distance": 0.0}, {"confidence": [0.9118813276290894, 0.0881187692284584], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11568.gpt3.1", "original_example": {"example_id": "atomic.train.11568", "premise_hypothesis_id": "atomic.train.5441", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xTeIoVSlFZ2OqierOQNn5w==", "AtomicEventRelationId": "naXzYMzzh7L3XeFnsLih-Q==", "AtomicRelationType": "xNeed", "AtomicInference": "to decide on a marketing scheme"}, "premise": "PersonX markets and sell a product or service", "hypothesis": "Before, PersonX needed to decide on a marketing scheme", "update": "Person X is a low level employee at a big firm.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11568", "update_paraphrase": "Person X is a lowly worker at a large company.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.36972789115646254, "pred_conf_shift": 0.0350419282913208, "syntactic_distance": 0.0}, {"confidence": [0.7197290658950806, 0.28027084469795227], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11568.gpt3.4", "original_example": {"example_id": "atomic.train.11568", "premise_hypothesis_id": "atomic.train.5441", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xTeIoVSlFZ2OqierOQNn5w==", "AtomicEventRelationId": "naXzYMzzh7L3XeFnsLih-Q==", "AtomicRelationType": "xNeed", "AtomicInference": "to decide on a marketing scheme"}, "premise": "PersonX markets and sell a product or service", "hypothesis": "Before, PersonX needed to decide on a marketing scheme", "update": "Person X is a low level employee at a big firm.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11568", "update_paraphrase": "Person X is an entry-level worker at a large company.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3893046107331822, "pred_conf_shift": -0.157110333442688, "syntactic_distance": 0.0}, {"confidence": [0.8279423713684082, 0.17205756902694702], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11568.gpt3.6", "original_example": {"example_id": "atomic.train.11568", "premise_hypothesis_id": "atomic.train.5441", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xTeIoVSlFZ2OqierOQNn5w==", "AtomicEventRelationId": "naXzYMzzh7L3XeFnsLih-Q==", "AtomicRelationType": "xNeed", "AtomicInference": "to decide on a marketing scheme"}, "premise": "PersonX markets and sell a product or service", "hypothesis": "Before, PersonX needed to decide on a marketing scheme", "update": "Person X is a low level employee at a big firm.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11568", "update_paraphrase": "At a big firm, Person X is an entry-level employee.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.30158730158730157, "pred_conf_shift": -0.04889702796936035, "syntactic_distance": 0.4166666666666667}, {"confidence": [0.7933624982833862, 0.20663763582706451], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11568.gpt3.3", "original_example": {"example_id": "atomic.train.11568", "premise_hypothesis_id": "atomic.train.5441", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xTeIoVSlFZ2OqierOQNn5w==", "AtomicEventRelationId": "naXzYMzzh7L3XeFnsLih-Q==", "AtomicRelationType": "xNeed", "AtomicInference": "to decide on a marketing scheme"}, "premise": "PersonX markets and sell a product or service", "hypothesis": "Before, PersonX needed to decide on a marketing scheme", "update": "Person X is a low level employee at a big firm.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11568", "update_paraphrase": "Person X is a low-ranking employee at a large company.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.34269381412238553, "pred_conf_shift": -0.08347690105438232, "syntactic_distance": 0.0}]}, "atomic.train.37024": {"original_confidence": [0.7503310441970825, 0.2496689260005951], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.372536838054657, 0.6274631023406982], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37024.gpt3.7", "original_example": {"example_id": "atomic.train.37024", "premise_hypothesis_id": "atomic.train.16801", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oK2yoAwX2NVuJAMZCjQlaA==", "AtomicEventRelationId": "QZxAS7AZtcjO9t-3AcuNuQ==", "AtomicRelationType": "xNeed", "AtomicInference": "Spend to much money."}, "premise": "PersonX has a gambling problem", "hypothesis": "Before, PersonX needed spend to much money.", "update": "PersonX gambles with candy", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37024", "update_paraphrase": "PersonX risks losing candy by gambling with it.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4444444444444445, "pred_conf_shift": -0.37779420614242554, "syntactic_distance": 0.2}, {"confidence": [0.792770266532898, 0.20722967386245728], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37024.gpt3.3", "original_example": {"example_id": "atomic.train.37024", "premise_hypothesis_id": "atomic.train.16801", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oK2yoAwX2NVuJAMZCjQlaA==", "AtomicEventRelationId": "QZxAS7AZtcjO9t-3AcuNuQ==", "AtomicRelationType": "xNeed", "AtomicInference": "Spend to much money."}, "premise": "PersonX has a gambling problem", "hypothesis": "Before, PersonX needed spend to much money.", "update": "PersonX gambles with candy", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37024", "update_paraphrase": "PersonX enjoys playing games with candy as stakes.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.41880341880341876, "pred_conf_shift": 0.04243922233581543, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.8397653698921204, 0.1602347195148468], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37024.gpt3.8", "original_example": {"example_id": "atomic.train.37024", "premise_hypothesis_id": "atomic.train.16801", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oK2yoAwX2NVuJAMZCjQlaA==", "AtomicEventRelationId": "QZxAS7AZtcjO9t-3AcuNuQ==", "AtomicRelationType": "xNeed", "AtomicInference": "Spend to much money."}, "premise": "PersonX has a gambling problem", "hypothesis": "Before, PersonX needed spend to much money.", "update": "PersonX gambles with candy", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37024", "update_paraphrase": "PersonX enjoys playing games with candy as the stakes.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4635108481262327, "pred_conf_shift": 0.08943432569503784, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.9214202165603638, 0.07857970893383026], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37024.gpt3.2", "original_example": {"example_id": "atomic.train.37024", "premise_hypothesis_id": "atomic.train.16801", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oK2yoAwX2NVuJAMZCjQlaA==", "AtomicEventRelationId": "QZxAS7AZtcjO9t-3AcuNuQ==", "AtomicRelationType": "xNeed", "AtomicInference": "Spend to much money."}, "premise": "PersonX has a gambling problem", "hypothesis": "Before, PersonX needed spend to much money.", "update": "PersonX gambles with candy", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37024", "update_paraphrase": "PersonX is betting with candy.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2698412698412699, "pred_conf_shift": 0.17108917236328125, "syntactic_distance": 0.1875}, {"confidence": [0.5834975838661194, 0.4165024161338806], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37024.gpt3.5", "original_example": {"example_id": "atomic.train.37024", "premise_hypothesis_id": "atomic.train.16801", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oK2yoAwX2NVuJAMZCjQlaA==", "AtomicEventRelationId": "QZxAS7AZtcjO9t-3AcuNuQ==", "AtomicRelationType": "xNeed", "AtomicInference": "Spend to much money."}, "premise": "PersonX has a gambling problem", "hypothesis": "Before, PersonX needed spend to much money.", "update": "PersonX gambles with candy", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37024", "update_paraphrase": "PersonX takes risks with candy", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2407407407407407, "pred_conf_shift": -0.16683346033096313, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.19053812325000763, 0.8094618320465088], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37024.gpt3.6", "original_example": {"example_id": "atomic.train.37024", "premise_hypothesis_id": "atomic.train.16801", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oK2yoAwX2NVuJAMZCjQlaA==", "AtomicEventRelationId": "QZxAS7AZtcjO9t-3AcuNuQ==", "AtomicRelationType": "xNeed", "AtomicInference": "Spend to much money."}, "premise": "PersonX has a gambling problem", "hypothesis": "Before, PersonX needed spend to much money.", "update": "PersonX gambles with candy", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37024", "update_paraphrase": "PersonX risks candy in gambling ventures.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.48333333333333334, "pred_conf_shift": -0.5597929209470749, "syntactic_distance": 0.1111111111111111}]}, "atomic.train.5731": {"original_confidence": [0.5976028442382812, 0.40239715576171875], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.018738800659775734, 0.9812611937522888], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.5731.gpt3.6", "original_example": {"example_id": "atomic.train.5731", "premise_hypothesis_id": "atomic.train.2702", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9GTom-eEx2-NNZWT1B9IUQ==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX stops eating fast food", "hypothesis": "PersonX is seen as better", "update": "PersonX's friends wish they had his will power.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5731", "update_paraphrase": "PersonX's friends envy his ability to stay disciplined.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42408008658008656, "pred_conf_shift": 0.5788640379905701, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.01990422233939171, 0.9800956845283508], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.5731.gpt3.2", "original_example": {"example_id": "atomic.train.5731", "premise_hypothesis_id": "atomic.train.2702", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9GTom-eEx2-NNZWT1B9IUQ==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX stops eating fast food", "hypothesis": "PersonX is seen as better", "update": "PersonX's friends wish they had his will power.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5731", "update_paraphrase": "PersonX's friends envy him for his strong will and discipline.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42047212047212046, "pred_conf_shift": 0.5776985287666321, "syntactic_distance": 0.2631578947368421}, {"confidence": [0.016708018258213997, 0.9832919239997864], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.5731.gpt3.5", "original_example": {"example_id": "atomic.train.5731", "premise_hypothesis_id": "atomic.train.2702", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9GTom-eEx2-NNZWT1B9IUQ==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX stops eating fast food", "hypothesis": "PersonX is seen as better", "update": "PersonX's friends wish they had his will power.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5731", "update_paraphrase": "PersonX's friends envy him for his ability to stick to his goals.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5031601731601731, "pred_conf_shift": 0.5808947682380676, "syntactic_distance": 0.2631578947368421}, {"confidence": [0.0725235864520073, 0.9274763464927673], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.5731.gpt3.1", "original_example": {"example_id": "atomic.train.5731", "premise_hypothesis_id": "atomic.train.2702", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9GTom-eEx2-NNZWT1B9IUQ==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX stops eating fast food", "hypothesis": "PersonX is seen as better", "update": "PersonX's friends wish they had his will power.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5731", "update_paraphrase": "PersonX's friends are always wishing they had as much self-control as he does.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45877825877825873, "pred_conf_shift": 0.5250791907310486, "syntactic_distance": 0.2631578947368421}, {"confidence": [0.06160210072994232, 0.9383978843688965], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.5731.gpt3.7", "original_example": {"example_id": "atomic.train.5731", "premise_hypothesis_id": "atomic.train.2702", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9GTom-eEx2-NNZWT1B9IUQ==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX stops eating fast food", "hypothesis": "PersonX is seen as better", "update": "PersonX's friends wish they had his will power.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5731", "update_paraphrase": "PersonX's friends admire him for his discipline and would like to have the same level of self-control.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.59384126984127, "pred_conf_shift": 0.5360007286071777, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.026080014184117317, 0.9739199876785278], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.5731.gpt3.4", "original_example": {"example_id": "atomic.train.5731", "premise_hypothesis_id": "atomic.train.2702", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9GTom-eEx2-NNZWT1B9IUQ==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX stops eating fast food", "hypothesis": "PersonX is seen as better", "update": "PersonX's friends wish they had his will power.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5731", "update_paraphrase": "PersonX's friends envy his/her discipline.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5141525141525141, "pred_conf_shift": 0.5715228319168091, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.025798676535487175, 0.9742013216018677], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.5731.gpt3.3", "original_example": {"example_id": "atomic.train.5731", "premise_hypothesis_id": "atomic.train.2702", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9GTom-eEx2-NNZWT1B9IUQ==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX stops eating fast food", "hypothesis": "PersonX is seen as better", "update": "PersonX's friends wish they had his will power.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5731", "update_paraphrase": "PersonX is very disciplined and his friends wish they could be more like him.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.48964646464646466, "pred_conf_shift": 0.5718041658401489, "syntactic_distance": 0.43478260869565216}, {"confidence": [0.021575067192316055, 0.9784248471260071], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.5731.gpt3.0", "original_example": {"example_id": "atomic.train.5731", "premise_hypothesis_id": "atomic.train.2702", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9GTom-eEx2-NNZWT1B9IUQ==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX stops eating fast food", "hypothesis": "PersonX is seen as better", "update": "PersonX's friends wish they had his will power.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5731", "update_paraphrase": "PersonX's friends envy his self discipline.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.435760667903525, "pred_conf_shift": 0.5760276913642883, "syntactic_distance": 0.2222222222222222}]}, "atomic.train.32817": {"original_confidence": [0.3171023428440094, 0.6828976273536682], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.32257404923439026, 0.6774259805679321], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.32817.gpt3.2", "original_example": {"example_id": "atomic.train.32817", "premise_hypothesis_id": "atomic.train.14900", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "X4An66UT9v7N0RfQOP5ApA==", "AtomicEventRelationId": "x62haQRJHADFPl2VvSrm0Q==", "AtomicRelationType": "xNeed", "AtomicInference": "nothing to do at home"}, "premise": "PersonX is really bored", "hypothesis": "Before, PersonX needed nothing to do at home", "update": "It is the weekend", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32817", "update_paraphrase": "Now is the time for relaxation because it is the weekend.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4666666666666667, "pred_conf_shift": -0.005471646785736084, "syntactic_distance": 0.3684210526315789}, {"confidence": [0.2286216765642166, 0.7713783383369446], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.32817.gpt3.4", "original_example": {"example_id": "atomic.train.32817", "premise_hypothesis_id": "atomic.train.14900", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "X4An66UT9v7N0RfQOP5ApA==", "AtomicEventRelationId": "x62haQRJHADFPl2VvSrm0Q==", "AtomicRelationType": "xNeed", "AtomicInference": "nothing to do at home"}, "premise": "PersonX is really bored", "hypothesis": "Before, PersonX needed nothing to do at home", "update": "It is the weekend", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32817", "update_paraphrase": "Now is the time when people generally rest and do not work.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6568181818181817, "pred_conf_shift": 0.08848071098327637, "syntactic_distance": 0.35294117647058826}, {"confidence": [0.0732707679271698, 0.9267293214797974], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.32817.gpt3.1", "original_example": {"example_id": "atomic.train.32817", "premise_hypothesis_id": "atomic.train.14900", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "X4An66UT9v7N0RfQOP5ApA==", "AtomicEventRelationId": "x62haQRJHADFPl2VvSrm0Q==", "AtomicRelationType": "xNeed", "AtomicInference": "nothing to do at home"}, "premise": "PersonX is really bored", "hypothesis": "Before, PersonX needed nothing to do at home", "update": "It is the weekend", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32817", "update_paraphrase": "It is the weekend, meaning there is no school and we can relax!", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5294117647058824, "pred_conf_shift": 0.24383169412612915, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.26417919993400574, 0.7358207702636719], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.32817.gpt3.0", "original_example": {"example_id": "atomic.train.32817", "premise_hypothesis_id": "atomic.train.14900", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "X4An66UT9v7N0RfQOP5ApA==", "AtomicEventRelationId": "x62haQRJHADFPl2VvSrm0Q==", "AtomicRelationType": "xNeed", "AtomicInference": "nothing to do at home"}, "premise": "PersonX is really bored", "hypothesis": "Before, PersonX needed nothing to do at home", "update": "It is the weekend", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32817", "update_paraphrase": "The weekend has arrived.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4222222222222222, "pred_conf_shift": 0.05292314291000366, "syntactic_distance": 0.3125}, {"confidence": [0.3766196370124817, 0.6233803629875183], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.32817.gpt3.5", "original_example": {"example_id": "atomic.train.32817", "premise_hypothesis_id": "atomic.train.14900", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "X4An66UT9v7N0RfQOP5ApA==", "AtomicEventRelationId": "x62haQRJHADFPl2VvSrm0Q==", "AtomicRelationType": "xNeed", "AtomicInference": "nothing to do at home"}, "premise": "PersonX is really bored", "hypothesis": "Before, PersonX needed nothing to do at home", "update": "It is the weekend", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32817", "update_paraphrase": "We get to enjoy two days off from work this weekend.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6685714285714286, "pred_conf_shift": -0.0595172643661499, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.31685417890548706, 0.6831457614898682], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.32817.gpt3.6", "original_example": {"example_id": "atomic.train.32817", "premise_hypothesis_id": "atomic.train.14900", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "X4An66UT9v7N0RfQOP5ApA==", "AtomicEventRelationId": "x62haQRJHADFPl2VvSrm0Q==", "AtomicRelationType": "xNeed", "AtomicInference": "nothing to do at home"}, "premise": "PersonX is really bored", "hypothesis": "Before, PersonX needed nothing to do at home", "update": "It is the weekend", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32817", "update_paraphrase": "It is the weekend.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": 0.00024813413619995117, "syntactic_distance": 0.0}, {"confidence": [0.1844083070755005, 0.8155916333198547], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.32817.gpt3.3", "original_example": {"example_id": "atomic.train.32817", "premise_hypothesis_id": "atomic.train.14900", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "X4An66UT9v7N0RfQOP5ApA==", "AtomicEventRelationId": "x62haQRJHADFPl2VvSrm0Q==", "AtomicRelationType": "xNeed", "AtomicInference": "nothing to do at home"}, "premise": "PersonX is really bored", "hypothesis": "Before, PersonX needed nothing to do at home", "update": "It is the weekend", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32817", "update_paraphrase": "We're in for a break! It's the weekend.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45000000000000007, "pred_conf_shift": 0.13269400596618652, "syntactic_distance": 0.45}]}, "atomic.train.29591": {"original_confidence": [0.6168255805969238, 0.38317441940307617], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.5477758646011353, 0.45222410559654236], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29591.gpt3.6", "original_example": {"example_id": "atomic.train.29591", "premise_hypothesis_id": "atomic.train.13427", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "RAHhvK3W7GsQFotjdnDfjQ==", "AtomicEventRelationId": "9uTOeo5x7aaDKk0kO8CAZw==", "AtomicRelationType": "xEffect", "AtomicInference": "hopes for the best"}, "premise": "PersonX prepares for PersonX's reception", "hypothesis": "PersonX then hopes for the best", "update": "Her friends don't mind that the reception will be a small one.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29591", "update_paraphrase": "It doesn't bother her friends that the wedding reception will be a small affair.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2458430458430459, "pred_conf_shift": 0.06904968619346619, "syntactic_distance": 0.36363636363636365}, {"confidence": [0.8799022436141968, 0.12009774893522263], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29591.gpt3.2", "original_example": {"example_id": "atomic.train.29591", "premise_hypothesis_id": "atomic.train.13427", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "RAHhvK3W7GsQFotjdnDfjQ==", "AtomicEventRelationId": "9uTOeo5x7aaDKk0kO8CAZw==", "AtomicRelationType": "xEffect", "AtomicInference": "hopes for the best"}, "premise": "PersonX prepares for PersonX's reception", "hypothesis": "PersonX then hopes for the best", "update": "Her friends don't mind that the reception will be a small one.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29591", "update_paraphrase": "Her close friends don't care that the wedding reception will be a tiny affair.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2440753690753691, "pred_conf_shift": -0.26307667046785355, "syntactic_distance": 0.043478260869565216}, {"confidence": [0.6791186928749084, 0.32088130712509155], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29591.gpt3.3", "original_example": {"example_id": "atomic.train.29591", "premise_hypothesis_id": "atomic.train.13427", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "RAHhvK3W7GsQFotjdnDfjQ==", "AtomicEventRelationId": "9uTOeo5x7aaDKk0kO8CAZw==", "AtomicRelationType": "xEffect", "AtomicInference": "hopes for the best"}, "premise": "PersonX prepares for PersonX's reception", "hypothesis": "PersonX then hopes for the best", "update": "Her friends don't mind that the reception will be a small one.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29591", "update_paraphrase": "Her friends don't mind that the reception will be small.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.12121212121212122, "pred_conf_shift": -0.06229311227798462, "syntactic_distance": 0.14285714285714285}, {"confidence": [0.9255451560020447, 0.07445470988750458], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29591.gpt3.0", "original_example": {"example_id": "atomic.train.29591", "premise_hypothesis_id": "atomic.train.13427", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "RAHhvK3W7GsQFotjdnDfjQ==", "AtomicEventRelationId": "9uTOeo5x7aaDKk0kO8CAZw==", "AtomicRelationType": "xEffect", "AtomicInference": "hopes for the best"}, "premise": "PersonX prepares for PersonX's reception", "hypothesis": "PersonX then hopes for the best", "update": "Her friends don't mind that the reception will be a small one.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29591", "update_paraphrase": "Her buddies don't care that the wedding ceremony will be a humble affair.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3130022918258212, "pred_conf_shift": -0.3087197095155716, "syntactic_distance": 0.0}, {"confidence": [0.6889442205429077, 0.3110557198524475], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29591.gpt3.5", "original_example": {"example_id": "atomic.train.29591", "premise_hypothesis_id": "atomic.train.13427", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "RAHhvK3W7GsQFotjdnDfjQ==", "AtomicEventRelationId": "9uTOeo5x7aaDKk0kO8CAZw==", "AtomicRelationType": "xEffect", "AtomicInference": "hopes for the best"}, "premise": "PersonX prepares for PersonX's reception", "hypothesis": "PersonX then hopes for the best", "update": "Her friends don't mind that the reception will be a small one.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29591", "update_paraphrase": "Her friends are okay with the fact that the wedding reception will be small.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.31934731934731936, "pred_conf_shift": -0.07211869955062866, "syntactic_distance": 0.3}, {"confidence": [0.7889981865882874, 0.2110019028186798], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29591.gpt3.1", "original_example": {"example_id": "atomic.train.29591", "premise_hypothesis_id": "atomic.train.13427", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "RAHhvK3W7GsQFotjdnDfjQ==", "AtomicEventRelationId": "9uTOeo5x7aaDKk0kO8CAZw==", "AtomicRelationType": "xEffect", "AtomicInference": "hopes for the best"}, "premise": "PersonX prepares for PersonX's reception", "hypothesis": "PersonX then hopes for the best", "update": "Her friends don't mind that the reception will be a small one.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29591", "update_paraphrase": "Her friends don't care that the reception will be a small one.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.08333333333333337, "pred_conf_shift": -0.17217251658439636, "syntactic_distance": 0.0}]}, "atomic.train.25231": {"original_confidence": [0.28630584478378296, 0.7136940360069275], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.2989979088306427, 0.7010020613670349], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25231.gpt3.0", "original_example": {"example_id": "atomic.train.25231", "premise_hypothesis_id": "atomic.train.11536", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B1aukSNrm6rTo-d3xwDRfQ==", "AtomicEventRelationId": "Twejy_hMEtcUUP7Q2BCPUw==", "AtomicRelationType": "xAttr", "AtomicInference": "free"}, "premise": "PersonX escapes from PersonX's cage", "hypothesis": "As a result, PersonX feels free", "update": "PersonX has escaped the house he was being held captive in.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25231", "update_paraphrase": "PersonX has run away from the house where he was being held prisoner.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2575396825396825, "pred_conf_shift": -0.012691974639892578, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.21291664242744446, 0.7870833873748779], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25231.gpt3.6", "original_example": {"example_id": "atomic.train.25231", "premise_hypothesis_id": "atomic.train.11536", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B1aukSNrm6rTo-d3xwDRfQ==", "AtomicEventRelationId": "Twejy_hMEtcUUP7Q2BCPUw==", "AtomicRelationType": "xAttr", "AtomicInference": "free"}, "premise": "PersonX escapes from PersonX's cage", "hypothesis": "As a result, PersonX feels free", "update": "PersonX has escaped the house he was being held captive in.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25231", "update_paraphrase": "PersonX has managed to leave the house where he was being held against his will.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.30402930402930406, "pred_conf_shift": 0.07338935136795044, "syntactic_distance": 0.0625}, {"confidence": [0.10231813043355942, 0.8976818323135376], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25231.gpt3.3", "original_example": {"example_id": "atomic.train.25231", "premise_hypothesis_id": "atomic.train.11536", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B1aukSNrm6rTo-d3xwDRfQ==", "AtomicEventRelationId": "Twejy_hMEtcUUP7Q2BCPUw==", "AtomicRelationType": "xAttr", "AtomicInference": "free"}, "premise": "PersonX escapes from PersonX's cage", "hypothesis": "As a result, PersonX feels free", "update": "PersonX has escaped the house he was being held captive in.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25231", "update_paraphrase": "PersonX has freed himself from the house where he was being kept against his will.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.35746475746475753, "pred_conf_shift": 0.1839877963066101, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.39391008019447327, 0.6060898900032043], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25231.gpt3.5", "original_example": {"example_id": "atomic.train.25231", "premise_hypothesis_id": "atomic.train.11536", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B1aukSNrm6rTo-d3xwDRfQ==", "AtomicEventRelationId": "Twejy_hMEtcUUP7Q2BCPUw==", "AtomicRelationType": "xAttr", "AtomicInference": "free"}, "premise": "PersonX escapes from PersonX's cage", "hypothesis": "As a result, PersonX feels free", "update": "PersonX has escaped the house he was being held captive in.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25231", "update_paraphrase": "PersonX managed to flee the house where he was being held prisoner.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.29188468536294626, "pred_conf_shift": -0.10760414600372314, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.3953014314174652, 0.604698657989502], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25231.gpt3.4", "original_example": {"example_id": "atomic.train.25231", "premise_hypothesis_id": "atomic.train.11536", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B1aukSNrm6rTo-d3xwDRfQ==", "AtomicEventRelationId": "Twejy_hMEtcUUP7Q2BCPUw==", "AtomicRelationType": "xAttr", "AtomicInference": "free"}, "premise": "PersonX escapes from PersonX's cage", "hypothesis": "As a result, PersonX feels free", "update": "PersonX has escaped the house he was being held captive in.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25231", "update_paraphrase": "PersonX has managed to flee the house he was being kept captive in.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23695286195286197, "pred_conf_shift": -0.10899537801742554, "syntactic_distance": 0.0625}, {"confidence": [0.359760582447052, 0.6402393579483032], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25231.gpt3.7", "original_example": {"example_id": "atomic.train.25231", "premise_hypothesis_id": "atomic.train.11536", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B1aukSNrm6rTo-d3xwDRfQ==", "AtomicEventRelationId": "Twejy_hMEtcUUP7Q2BCPUw==", "AtomicRelationType": "xAttr", "AtomicInference": "free"}, "premise": "PersonX escapes from PersonX's cage", "hypothesis": "As a result, PersonX feels free", "update": "PersonX has escaped the house he was being held captive in.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25231", "update_paraphrase": "PersonX managed to flee the house where he was being detained against his will.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37643867243867246, "pred_conf_shift": -0.07345467805862427, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.04405723139643669, 0.9559427499771118], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25231.gpt3.1", "original_example": {"example_id": "atomic.train.25231", "premise_hypothesis_id": "atomic.train.11536", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B1aukSNrm6rTo-d3xwDRfQ==", "AtomicEventRelationId": "Twejy_hMEtcUUP7Q2BCPUw==", "AtomicRelationType": "xAttr", "AtomicInference": "free"}, "premise": "PersonX escapes from PersonX's cage", "hypothesis": "As a result, PersonX feels free", "update": "PersonX has escaped the house he was being held captive in.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25231", "update_paraphrase": "PersonX has fled the scene of his captivity and is now free.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.48781291172595515, "pred_conf_shift": 0.24224871397018433, "syntactic_distance": 0.35}, {"confidence": [0.22435994446277618, 0.775640070438385], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25231.gpt3.8", "original_example": {"example_id": "atomic.train.25231", "premise_hypothesis_id": "atomic.train.11536", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B1aukSNrm6rTo-d3xwDRfQ==", "AtomicEventRelationId": "Twejy_hMEtcUUP7Q2BCPUw==", "AtomicRelationType": "xAttr", "AtomicInference": "free"}, "premise": "PersonX escapes from PersonX's cage", "hypothesis": "As a result, PersonX feels free", "update": "PersonX has escaped the house he was being held captive in.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25231", "update_paraphrase": "PersonX managed to break free from the house where he was being held against his will.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3746860135749024, "pred_conf_shift": 0.06194603443145752, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.21176323294639587, 0.7882367372512817], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25231.gpt3.2", "original_example": {"example_id": "atomic.train.25231", "premise_hypothesis_id": "atomic.train.11536", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B1aukSNrm6rTo-d3xwDRfQ==", "AtomicEventRelationId": "Twejy_hMEtcUUP7Q2BCPUw==", "AtomicRelationType": "xAttr", "AtomicInference": "free"}, "premise": "PersonX escapes from PersonX's cage", "hypothesis": "As a result, PersonX feels free", "update": "PersonX has escaped the house he was being held captive in.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25231", "update_paraphrase": "PersonXmanaged to break free from the home where he was being kept against his will.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4423520923520924, "pred_conf_shift": 0.07454270124435425, "syntactic_distance": 0.46153846153846156}]}, "atomic.train.16": {"original_confidence": [0.5250990390777588, 0.4749009311199188], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.42147985100746155, 0.5785201787948608], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16.gpt3.8", "original_example": {"example_id": "atomic.train.16", "premise_hypothesis_id": "atomic.train.9", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "H_E3mPn0CyacqXD3ZHPYvQ==", "AtomicEventRelationId": "nAz72JhLelmJd3doIsiX0w==", "AtomicRelationType": "xEffect", "AtomicInference": "has the favor returned"}, "premise": "PersonX finishes PersonY's work", "hypothesis": "PersonX then has the favor returned", "update": "This was PersonY's last day at the company.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16", "update_paraphrase": "This was the final day PersonY would be working at the company.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2971428571428572, "pred_conf_shift": -0.10361918807029724, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.4710347056388855, 0.5289652943611145], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16.gpt3.1", "original_example": {"example_id": "atomic.train.16", "premise_hypothesis_id": "atomic.train.9", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "H_E3mPn0CyacqXD3ZHPYvQ==", "AtomicEventRelationId": "nAz72JhLelmJd3doIsiX0w==", "AtomicRelationType": "xEffect", "AtomicInference": "has the favor returned"}, "premise": "PersonX finishes PersonY's work", "hypothesis": "PersonX then has the favor returned", "update": "This was PersonY's last day at the company.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16", "update_paraphrase": "The final day at the company for PersonY had arrived.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39545855379188716, "pred_conf_shift": -0.05406433343887329, "syntactic_distance": 0.4827586206896552}, {"confidence": [0.4505023956298828, 0.549497663974762], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16.gpt3.4", "original_example": {"example_id": "atomic.train.16", "premise_hypothesis_id": "atomic.train.9", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "H_E3mPn0CyacqXD3ZHPYvQ==", "AtomicEventRelationId": "nAz72JhLelmJd3doIsiX0w==", "AtomicRelationType": "xEffect", "AtomicInference": "has the favor returned"}, "premise": "PersonX finishes PersonY's work", "hypothesis": "PersonX then has the favor returned", "update": "This was PersonY's last day at the company.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16", "update_paraphrase": "Today was the final day on the job for PersonY at the company.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4087267230124373, "pred_conf_shift": -0.07459664344787598, "syntactic_distance": 0.34782608695652173}, {"confidence": [0.599434494972229, 0.400565505027771], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.16.gpt3.7", "original_example": {"example_id": "atomic.train.16", "premise_hypothesis_id": "atomic.train.9", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "H_E3mPn0CyacqXD3ZHPYvQ==", "AtomicEventRelationId": "nAz72JhLelmJd3doIsiX0w==", "AtomicRelationType": "xEffect", "AtomicInference": "has the favor returned"}, "premise": "PersonX finishes PersonY's work", "hypothesis": "PersonX then has the favor returned", "update": "This was PersonY's last day at the company.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16", "update_paraphrase": "The individual's last day at the company was today.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2508080155138978, "pred_conf_shift": 0.07433545589447021, "syntactic_distance": 0.44}, {"confidence": [0.8032671213150024, 0.19673283398151398], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.16.gpt3.3", "original_example": {"example_id": "atomic.train.16", "premise_hypothesis_id": "atomic.train.9", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "H_E3mPn0CyacqXD3ZHPYvQ==", "AtomicEventRelationId": "nAz72JhLelmJd3doIsiX0w==", "AtomicRelationType": "xEffect", "AtomicInference": "has the favor returned"}, "premise": "PersonX finishes PersonY's work", "hypothesis": "PersonX then has the favor returned", "update": "This was PersonY's last day at the company.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16", "update_paraphrase": "The individual in question was leaving the organization for good today.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5677933177933179, "pred_conf_shift": 0.27816808223724365, "syntactic_distance": 0.42857142857142855}, {"confidence": [0.5330505967140198, 0.46694934368133545], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.16.gpt3.5", "original_example": {"example_id": "atomic.train.16", "premise_hypothesis_id": "atomic.train.9", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "H_E3mPn0CyacqXD3ZHPYvQ==", "AtomicEventRelationId": "nAz72JhLelmJd3doIsiX0w==", "AtomicRelationType": "xEffect", "AtomicInference": "has the favor returned"}, "premise": "PersonX finishes PersonY's work", "hypothesis": "PersonX then has the favor returned", "update": "This was PersonY's last day at the company.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16", "update_paraphrase": "PersonY's last day working at the company was today.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2222222222222222, "pred_conf_shift": 0.007951557636260986, "syntactic_distance": 0.38461538461538464}, {"confidence": [0.4329259693622589, 0.5670740008354187], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16.gpt3.2", "original_example": {"example_id": "atomic.train.16", "premise_hypothesis_id": "atomic.train.9", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "H_E3mPn0CyacqXD3ZHPYvQ==", "AtomicEventRelationId": "nAz72JhLelmJd3doIsiX0w==", "AtomicRelationType": "xEffect", "AtomicInference": "has the favor returned"}, "premise": "PersonX finishes PersonY's work", "hypothesis": "PersonX then has the favor returned", "update": "This was PersonY's last day at the company.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16", "update_paraphrase": "This was the last day PersonY would be working at the company.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.24952380952380954, "pred_conf_shift": -0.09217306971549988, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.42499110102653503, 0.5750088691711426], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16.gpt3.6", "original_example": {"example_id": "atomic.train.16", "premise_hypothesis_id": "atomic.train.9", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "H_E3mPn0CyacqXD3ZHPYvQ==", "AtomicEventRelationId": "nAz72JhLelmJd3doIsiX0w==", "AtomicRelationType": "xEffect", "AtomicInference": "has the favor returned"}, "premise": "PersonX finishes PersonY's work", "hypothesis": "PersonX then has the favor returned", "update": "This was PersonY's last day at the company.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16", "update_paraphrase": "This was the final day that PersonY would be working at the company.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.32040816326530613, "pred_conf_shift": -0.10010793805122375, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.6210267543792725, 0.37897318601608276], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.16.gpt3.0", "original_example": {"example_id": "atomic.train.16", "premise_hypothesis_id": "atomic.train.9", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "H_E3mPn0CyacqXD3ZHPYvQ==", "AtomicEventRelationId": "nAz72JhLelmJd3doIsiX0w==", "AtomicRelationType": "xEffect", "AtomicInference": "has the favor returned"}, "premise": "PersonX finishes PersonY's work", "hypothesis": "PersonX then has the favor returned", "update": "This was PersonY's last day at the company.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16", "update_paraphrase": "Embarking on a new adventure, today was PersonY's final day at the company.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3777777777777778, "pred_conf_shift": 0.09592771530151367, "syntactic_distance": 0.48}]}, "atomic.train.23757": {"original_confidence": [0.4649834632873535, 0.5350165963172913], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.7278962731361389, 0.2721036970615387], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.23757.gpt3.1", "original_example": {"example_id": "atomic.train.23757", "premise_hypothesis_id": "atomic.train.10878", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2y_uM2r7rEtPzCdU1gIX1g==", "AtomicEventRelationId": "s8qrvj_sfXzQOMdeJvEU8Q==", "AtomicRelationType": "xEffect", "AtomicInference": "keeps a secret"}, "premise": "PersonX throws PersonY a surprise party", "hypothesis": "PersonX then keeps a secret", "update": "PersonX screwed up at the party.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23757", "update_paraphrase": "PersonX made a mess of things at the party.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4200466200466201, "pred_conf_shift": -0.26291289925575256, "syntactic_distance": 0.19047619047619047}, {"confidence": [0.568726658821106, 0.4312734007835388], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.23757.gpt3.2", "original_example": {"example_id": "atomic.train.23757", "premise_hypothesis_id": "atomic.train.10878", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2y_uM2r7rEtPzCdU1gIX1g==", "AtomicEventRelationId": "s8qrvj_sfXzQOMdeJvEU8Q==", "AtomicRelationType": "xEffect", "AtomicInference": "keeps a secret"}, "premise": "PersonX throws PersonY a surprise party", "hypothesis": "PersonX then keeps a secret", "update": "PersonX screwed up at the party.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23757", "update_paraphrase": "PersonX made a big mistake at the party.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3747680890538034, "pred_conf_shift": -0.10374319553375244, "syntactic_distance": 0.22727272727272727}, {"confidence": [0.6408817172050476, 0.3591182827949524], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.23757.gpt3.4", "original_example": {"example_id": "atomic.train.23757", "premise_hypothesis_id": "atomic.train.10878", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2y_uM2r7rEtPzCdU1gIX1g==", "AtomicEventRelationId": "s8qrvj_sfXzQOMdeJvEU8Q==", "AtomicRelationType": "xEffect", "AtomicInference": "keeps a secret"}, "premise": "PersonX throws PersonY a surprise party", "hypothesis": "PersonX then keeps a secret", "update": "PersonX screwed up at the party.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23757", "update_paraphrase": "PersonX made a mistake at the party.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3266733266733267, "pred_conf_shift": -0.17589831352233887, "syntactic_distance": 0.19047619047619047}]}, "atomic.train.10131": {"original_confidence": [0.7152646780014038, 0.2847352921962738], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.6977335214614868, 0.30226650834083557], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10131.gpt3.5", "original_example": {"example_id": "atomic.train.10131", "premise_hypothesis_id": "atomic.train.4776", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_8miNqSX7o1y7WXFgeZl1A==", "AtomicEventRelationId": "-U8MztBOj2Ws7Os9Aq-Agg==", "AtomicRelationType": "xReact", "AtomicInference": "excited"}, "premise": "PersonX quickly began", "hypothesis": "PersonX is seen as excited", "update": "PersonX is eating after lots of exercise", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10131", "update_paraphrase": "PersonX is refueling their body with food after getting a good workout in.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5523995612230906, "pred_conf_shift": 0.017531216144561768, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.8144314289093018, 0.1855686753988266], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10131.gpt3.0", "original_example": {"example_id": "atomic.train.10131", "premise_hypothesis_id": "atomic.train.4776", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_8miNqSX7o1y7WXFgeZl1A==", "AtomicEventRelationId": "-U8MztBOj2Ws7Os9Aq-Agg==", "AtomicRelationType": "xReact", "AtomicInference": "excited"}, "premise": "PersonX quickly began", "hypothesis": "PersonX is seen as excited", "update": "PersonX is eating after lots of exercise", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10131", "update_paraphrase": "Person X is eating a meal after exercising for a while.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4375288291954959, "pred_conf_shift": -0.0991666167974472, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.6876326203346252, 0.31236743927001953], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10131.gpt3.4", "original_example": {"example_id": "atomic.train.10131", "premise_hypothesis_id": "atomic.train.4776", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_8miNqSX7o1y7WXFgeZl1A==", "AtomicEventRelationId": "-U8MztBOj2Ws7Os9Aq-Agg==", "AtomicRelationType": "xReact", "AtomicInference": "excited"}, "premise": "PersonX quickly began", "hypothesis": "PersonX is seen as excited", "update": "PersonX is eating after lots of exercise", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10131", "update_paraphrase": "PersonX is eating a meal after completing a lot of physical activity.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.44699248120300744, "pred_conf_shift": 0.027632147073745728, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.7656823396682739, 0.23431773483753204], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10131.gpt3.7", "original_example": {"example_id": "atomic.train.10131", "premise_hypothesis_id": "atomic.train.4776", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_8miNqSX7o1y7WXFgeZl1A==", "AtomicEventRelationId": "-U8MztBOj2Ws7Os9Aq-Agg==", "AtomicRelationType": "xReact", "AtomicInference": "excited"}, "premise": "PersonX quickly began", "hypothesis": "PersonX is seen as excited", "update": "PersonX is eating after lots of exercise", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10131", "update_paraphrase": "After exercising, PersonX is now eating.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3709401709401709, "pred_conf_shift": -0.05041755735874176, "syntactic_distance": 0.4}, {"confidence": [0.6702613234519958, 0.32973867654800415], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10131.gpt3.2", "original_example": {"example_id": "atomic.train.10131", "premise_hypothesis_id": "atomic.train.4776", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_8miNqSX7o1y7WXFgeZl1A==", "AtomicEventRelationId": "-U8MztBOj2Ws7Os9Aq-Agg==", "AtomicRelationType": "xReact", "AtomicInference": "excited"}, "premise": "PersonX quickly began", "hypothesis": "PersonX is seen as excited", "update": "PersonX is eating after lots of exercise", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10131", "update_paraphrase": "PersonX is eating because they just worked out.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.41100529100529104, "pred_conf_shift": 0.04500338435173035, "syntactic_distance": 0.0625}, {"confidence": [0.7221086621284485, 0.2778913676738739], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10131.gpt3.1", "original_example": {"example_id": "atomic.train.10131", "premise_hypothesis_id": "atomic.train.4776", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_8miNqSX7o1y7WXFgeZl1A==", "AtomicEventRelationId": "-U8MztBOj2Ws7Os9Aq-Agg==", "AtomicRelationType": "xReact", "AtomicInference": "excited"}, "premise": "PersonX quickly began", "hypothesis": "PersonX is seen as excited", "update": "PersonX is eating after lots of exercise", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10131", "update_paraphrase": "After a lot of exercise, PersonX is now eating.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3303571428571428, "pred_conf_shift": -0.006843924522399902, "syntactic_distance": 0.36363636363636365}, {"confidence": [0.730396032333374, 0.2696039378643036], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10131.gpt3.3", "original_example": {"example_id": "atomic.train.10131", "premise_hypothesis_id": "atomic.train.4776", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_8miNqSX7o1y7WXFgeZl1A==", "AtomicEventRelationId": "-U8MztBOj2Ws7Os9Aq-Agg==", "AtomicRelationType": "xReact", "AtomicInference": "excited"}, "premise": "PersonX quickly began", "hypothesis": "PersonX is seen as excited", "update": "PersonX is eating after lots of exercise", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10131", "update_paraphrase": "PersonX is eating after exercising a lot.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.26734693877551025, "pred_conf_shift": -0.015131354331970215, "syntactic_distance": 0.0}, {"confidence": [0.774595320224762, 0.2254045158624649], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10131.gpt3.6", "original_example": {"example_id": "atomic.train.10131", "premise_hypothesis_id": "atomic.train.4776", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_8miNqSX7o1y7WXFgeZl1A==", "AtomicEventRelationId": "-U8MztBOj2Ws7Os9Aq-Agg==", "AtomicRelationType": "xReact", "AtomicInference": "excited"}, "premise": "PersonX quickly began", "hypothesis": "PersonX is seen as excited", "update": "PersonX is eating after lots of exercise", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10131", "update_paraphrase": "After completing a workout, PersonX is now eating.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4676094276094276, "pred_conf_shift": -0.0593307763338089, "syntactic_distance": 0.3333333333333333}]}, "atomic.train.15704": {"original_confidence": [0.2342599630355835, 0.7657400965690613], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.24461723864078522, 0.7553826570510864], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15704.gpt3.5", "original_example": {"example_id": "atomic.train.15704", "premise_hypothesis_id": "atomic.train.7323", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JDNnGzmH6C0qTtCbIgX-Wg==", "AtomicEventRelationId": "qQKLhu1vesOxvOSTdslAhA==", "AtomicRelationType": "xEffect", "AtomicInference": "braided the beard"}, "premise": "PersonX strokes PersonX's beard", "hypothesis": "PersonX then braided the beard", "update": "PersonX holds three chunks of their hair in their hands.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15704", "update_paraphrase": "PersonX is holding three clumps of their hair in their hands.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.14021164021164023, "pred_conf_shift": 0.010357275605201721, "syntactic_distance": 0.25}, {"confidence": [0.10837379097938538, 0.8916261792182922], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15704.gpt3.6", "original_example": {"example_id": "atomic.train.15704", "premise_hypothesis_id": "atomic.train.7323", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JDNnGzmH6C0qTtCbIgX-Wg==", "AtomicEventRelationId": "qQKLhu1vesOxvOSTdslAhA==", "AtomicRelationType": "xEffect", "AtomicInference": "braided the beard"}, "premise": "PersonX strokes PersonX's beard", "hypothesis": "PersonX then braided the beard", "update": "PersonX holds three chunks of their hair in their hands.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15704", "update_paraphrase": "In their hands, PersonX clenches three fistfuls of their hair.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28351648351648345, "pred_conf_shift": -0.12588617205619812, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.3142067492008209, 0.6857932209968567], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15704.gpt3.2", "original_example": {"example_id": "atomic.train.15704", "premise_hypothesis_id": "atomic.train.7323", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JDNnGzmH6C0qTtCbIgX-Wg==", "AtomicEventRelationId": "qQKLhu1vesOxvOSTdslAhA==", "AtomicRelationType": "xEffect", "AtomicInference": "braided the beard"}, "premise": "PersonX strokes PersonX's beard", "hypothesis": "PersonX then braided the beard", "update": "PersonX holds three chunks of their hair in their hands.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15704", "update_paraphrase": "In their hands, PersonX is holding three chunks of their hair.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22222222222222227, "pred_conf_shift": 0.07994678616523743, "syntactic_distance": 0.4166666666666667}, {"confidence": [0.24205276370048523, 0.7579471468925476], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15704.gpt3.1", "original_example": {"example_id": "atomic.train.15704", "premise_hypothesis_id": "atomic.train.7323", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JDNnGzmH6C0qTtCbIgX-Wg==", "AtomicEventRelationId": "qQKLhu1vesOxvOSTdslAhA==", "AtomicRelationType": "xEffect", "AtomicInference": "braided the beard"}, "premise": "PersonX strokes PersonX's beard", "hypothesis": "PersonX then braided the beard", "update": "PersonX holds three chunks of their hair in their hands.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15704", "update_paraphrase": "PersonX has three clumps of hair in their hands.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.21052631578947373, "pred_conf_shift": 0.007792800664901733, "syntactic_distance": 0.045454545454545456}, {"confidence": [0.033086974173784256, 0.966913104057312], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15704.gpt3.7", "original_example": {"example_id": "atomic.train.15704", "premise_hypothesis_id": "atomic.train.7323", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JDNnGzmH6C0qTtCbIgX-Wg==", "AtomicEventRelationId": "qQKLhu1vesOxvOSTdslAhA==", "AtomicRelationType": "xEffect", "AtomicInference": "braided the beard"}, "premise": "PersonX strokes PersonX's beard", "hypothesis": "PersonX then braided the beard", "update": "PersonX holds three chunks of their hair in their hands.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15704", "update_paraphrase": "In their hands, PersonX clasped three sizable tufts of their hair.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.31457431457431456, "pred_conf_shift": -0.20117298886179924, "syntactic_distance": 0.375}, {"confidence": [0.15498678386211395, 0.8450132012367249], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15704.gpt3.4", "original_example": {"example_id": "atomic.train.15704", "premise_hypothesis_id": "atomic.train.7323", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JDNnGzmH6C0qTtCbIgX-Wg==", "AtomicEventRelationId": "qQKLhu1vesOxvOSTdslAhA==", "AtomicRelationType": "xEffect", "AtomicInference": "braided the beard"}, "premise": "PersonX strokes PersonX's beard", "hypothesis": "PersonX then braided the beard", "update": "PersonX holds three chunks of their hair in their hands.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15704", "update_paraphrase": "With three chunks of their hair in their hands, PersonX looks in the mirror.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2657407407407408, "pred_conf_shift": -0.07927317917346954, "syntactic_distance": 0.4}, {"confidence": [0.18572331964969635, 0.8142766952514648], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15704.gpt3.0", "original_example": {"example_id": "atomic.train.15704", "premise_hypothesis_id": "atomic.train.7323", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JDNnGzmH6C0qTtCbIgX-Wg==", "AtomicEventRelationId": "qQKLhu1vesOxvOSTdslAhA==", "AtomicRelationType": "xEffect", "AtomicInference": "braided the beard"}, "premise": "PersonX strokes PersonX's beard", "hypothesis": "PersonX then braided the beard", "update": "PersonX holds three chunks of their hair in their hands.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15704", "update_paraphrase": "PersonX grip three tufts of their hair between their fingers.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.31085858585858583, "pred_conf_shift": -0.048536643385887146, "syntactic_distance": 0.25}, {"confidence": [0.23366481065750122, 0.7663351893424988], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15704.gpt3.3", "original_example": {"example_id": "atomic.train.15704", "premise_hypothesis_id": "atomic.train.7323", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JDNnGzmH6C0qTtCbIgX-Wg==", "AtomicEventRelationId": "qQKLhu1vesOxvOSTdslAhA==", "AtomicRelationType": "xEffect", "AtomicInference": "braided the beard"}, "premise": "PersonX strokes PersonX's beard", "hypothesis": "PersonX then braided the beard", "update": "PersonX holds three chunks of their hair in their hands.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15704", "update_paraphrase": "PersonX has three clumps of their hair in their hands.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.125, "pred_conf_shift": -0.0005951523780822754, "syntactic_distance": 0.045454545454545456}]}, "atomic.train.24298": {"original_confidence": [0.5971567034721375, 0.40284329652786255], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.512565016746521, 0.487434983253479], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.24298.gpt3.3", "original_example": {"example_id": "atomic.train.24298", "premise_hypothesis_id": "atomic.train.11119", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B4VzJls8O6tl0RVzeqGAHA==", "AtomicEventRelationId": "J-Qn5xjeTGIszVisR7-KHQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to eat"}, "premise": "PersonX takes PersonY food", "hypothesis": "Because PersonX wanted to eat", "update": "Person Y is overeating.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24298", "update_paraphrase": "Person Y is eating too much food.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3560606060606061, "pred_conf_shift": -0.08459168672561646, "syntactic_distance": 0.05263157894736842}, {"confidence": [0.6206263899803162, 0.37937358021736145], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.24298.gpt3.1", "original_example": {"example_id": "atomic.train.24298", "premise_hypothesis_id": "atomic.train.11119", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B4VzJls8O6tl0RVzeqGAHA==", "AtomicEventRelationId": "J-Qn5xjeTGIszVisR7-KHQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to eat"}, "premise": "PersonX takes PersonY food", "hypothesis": "Because PersonX wanted to eat", "update": "Person Y is overeating.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24298", "update_paraphrase": "person Y is consuming more food than necessary.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.44206349206349205, "pred_conf_shift": 0.02346968650817871, "syntactic_distance": 0.05263157894736842}, {"confidence": [0.5372309684753418, 0.4627689719200134], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.24298.gpt3.4", "original_example": {"example_id": "atomic.train.24298", "premise_hypothesis_id": "atomic.train.11119", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B4VzJls8O6tl0RVzeqGAHA==", "AtomicEventRelationId": "J-Qn5xjeTGIszVisR7-KHQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to eat"}, "premise": "PersonX takes PersonY food", "hypothesis": "Because PersonX wanted to eat", "update": "Person Y is overeating.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24298", "update_paraphrase": "Person Y is eating too much.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.29166666666666663, "pred_conf_shift": -0.059925734996795654, "syntactic_distance": 0.05263157894736842}, {"confidence": [0.5241702795028687, 0.47582975029945374], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.24298.gpt3.2", "original_example": {"example_id": "atomic.train.24298", "premise_hypothesis_id": "atomic.train.11119", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B4VzJls8O6tl0RVzeqGAHA==", "AtomicEventRelationId": "J-Qn5xjeTGIszVisR7-KHQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to eat"}, "premise": "PersonX takes PersonY food", "hypothesis": "Because PersonX wanted to eat", "update": "Person Y is overeating.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24298", "update_paraphrase": "Person Y is consuming too much food.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39202551834130783, "pred_conf_shift": -0.0729864239692688, "syntactic_distance": 0.05263157894736842}, {"confidence": [0.9039773344993591, 0.09602267295122147], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.24298.gpt3.0", "original_example": {"example_id": "atomic.train.24298", "premise_hypothesis_id": "atomic.train.11119", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B4VzJls8O6tl0RVzeqGAHA==", "AtomicEventRelationId": "J-Qn5xjeTGIszVisR7-KHQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to eat"}, "premise": "PersonX takes PersonY food", "hypothesis": "Because PersonX wanted to eat", "update": "Person Y is overeating.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24298", "update_paraphrase": "Person Y is eating too much and will probably make themselves sick.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5513392857142857, "pred_conf_shift": 0.3068206310272217, "syntactic_distance": 0.2916666666666667}]}, "atomic.train.9593": {"original_confidence": [0.10146477818489075, 0.8985351920127869], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.14300015568733215, 0.8569998145103455], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9593.gpt3.1", "original_example": {"example_id": "atomic.train.9593", "premise_hypothesis_id": "atomic.train.4522", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "McEQzVAvWV6taCtoJ4JkCg==", "AtomicEventRelationId": "mFdpY2USJ-3i7a2M6Z5S_w==", "AtomicRelationType": "xEffect", "AtomicInference": "muscle sore"}, "premise": "PersonX is playing football with PersonY's friends", "hypothesis": "PersonX then muscle sore", "update": "PersonX is overweight", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9593", "update_paraphrase": "PersonX could stand to lose a few pounds.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6993006993006992, "pred_conf_shift": -0.041535377502441406, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.13492515683174133, 0.8650748133659363], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9593.gpt3.5", "original_example": {"example_id": "atomic.train.9593", "premise_hypothesis_id": "atomic.train.4522", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "McEQzVAvWV6taCtoJ4JkCg==", "AtomicEventRelationId": "mFdpY2USJ-3i7a2M6Z5S_w==", "AtomicRelationType": "xEffect", "AtomicInference": "muscle sore"}, "premise": "PersonX is playing football with PersonY's friends", "hypothesis": "PersonX then muscle sore", "update": "PersonX is overweight", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9593", "update_paraphrase": "PersonX carries too much weight on their frame.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6432178932178932, "pred_conf_shift": -0.033460378646850586, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.1024814248085022, 0.8975184559822083], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9593.gpt3.6", "original_example": {"example_id": "atomic.train.9593", "premise_hypothesis_id": "atomic.train.4522", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "McEQzVAvWV6taCtoJ4JkCg==", "AtomicEventRelationId": "mFdpY2USJ-3i7a2M6Z5S_w==", "AtomicRelationType": "xEffect", "AtomicInference": "muscle sore"}, "premise": "PersonX is playing football with PersonY's friends", "hypothesis": "PersonX then muscle sore", "update": "PersonX is overweight", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9593", "update_paraphrase": "PersonX is heavy, carrying around extra weight.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4788461538461538, "pred_conf_shift": -0.0010167360305786133, "syntactic_distance": 0.13333333333333333}, {"confidence": [0.29741567373275757, 0.7025842666625977], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9593.gpt3.3", "original_example": {"example_id": "atomic.train.9593", "premise_hypothesis_id": "atomic.train.4522", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "McEQzVAvWV6taCtoJ4JkCg==", "AtomicEventRelationId": "mFdpY2USJ-3i7a2M6Z5S_w==", "AtomicRelationType": "xEffect", "AtomicInference": "muscle sore"}, "premise": "PersonX is playing football with PersonY's friends", "hypothesis": "PersonX then muscle sore", "update": "PersonX is overweight", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9593", "update_paraphrase": "PersonX is carrying around excess weight.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4209401709401709, "pred_conf_shift": -0.1959509253501892, "syntactic_distance": 0.25}, {"confidence": [0.18248017132282257, 0.8175198435783386], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9593.gpt3.0", "original_example": {"example_id": "atomic.train.9593", "premise_hypothesis_id": "atomic.train.4522", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "McEQzVAvWV6taCtoJ4JkCg==", "AtomicEventRelationId": "mFdpY2USJ-3i7a2M6Z5S_w==", "AtomicRelationType": "xEffect", "AtomicInference": "muscle sore"}, "premise": "PersonX is playing football with PersonY's friends", "hypothesis": "PersonX then muscle sore", "update": "PersonX is overweight", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9593", "update_paraphrase": "PersonX is carrying around extra weight.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4209401709401709, "pred_conf_shift": -0.08101534843444824, "syntactic_distance": 0.25}, {"confidence": [0.0892011746764183, 0.9107987880706787], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9593.gpt3.2", "original_example": {"example_id": "atomic.train.9593", "premise_hypothesis_id": "atomic.train.4522", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "McEQzVAvWV6taCtoJ4JkCg==", "AtomicEventRelationId": "mFdpY2USJ-3i7a2M6Z5S_w==", "AtomicRelationType": "xEffect", "AtomicInference": "muscle sore"}, "premise": "PersonX is playing football with PersonY's friends", "hypothesis": "PersonX then muscle sore", "update": "PersonX is overweight", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9593", "update_paraphrase": "PersonX would benefit from losing some weight.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6219696969696968, "pred_conf_shift": 0.012263596057891846, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.30283141136169434, 0.6971685886383057], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9593.gpt3.4", "original_example": {"example_id": "atomic.train.9593", "premise_hypothesis_id": "atomic.train.4522", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "McEQzVAvWV6taCtoJ4JkCg==", "AtomicEventRelationId": "mFdpY2USJ-3i7a2M6Z5S_w==", "AtomicRelationType": "xEffect", "AtomicInference": "muscle sore"}, "premise": "PersonX is playing football with PersonY's friends", "hypothesis": "PersonX then muscle sore", "update": "PersonX is overweight", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9593", "update_paraphrase": "PersonX is obese.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2274509803921569, "pred_conf_shift": -0.2013666033744812, "syntactic_distance": 0.0}]}, "atomic.train.29109": {"original_confidence": [0.030886735767126083, 0.9691132307052612], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.027462437748908997, 0.9725375175476074], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.29109.gpt3.5", "original_example": {"example_id": "atomic.train.29109", "premise_hypothesis_id": "atomic.train.13209", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ubUGHTBUSVmy7r8JrGp_fw==", "AtomicEventRelationId": "9QbcKcMAdQ6i7WNjwNdiIg==", "AtomicRelationType": "xEffect", "AtomicInference": "hits a tree"}, "premise": "PersonX swerves off the road", "hypothesis": "PersonX then hits a tree", "update": "Person X's car has a branch stuck through the windshield.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29109", "update_paraphrase": "Person X's car has a large branch sticking through the windshield.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1357753357753358, "pred_conf_shift": 0.0034242868423461914, "syntactic_distance": 0.0}, {"confidence": [0.029037825763225555, 0.9709621667861938], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.29109.gpt3.1", "original_example": {"example_id": "atomic.train.29109", "premise_hypothesis_id": "atomic.train.13209", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ubUGHTBUSVmy7r8JrGp_fw==", "AtomicEventRelationId": "9QbcKcMAdQ6i7WNjwNdiIg==", "AtomicRelationType": "xEffect", "AtomicInference": "hits a tree"}, "premise": "PersonX swerves off the road", "hypothesis": "PersonX then hits a tree", "update": "Person X's car has a branch stuck through the windshield.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29109", "update_paraphrase": "There's a branch sticking through the windshield of Person X's car.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2773707773707774, "pred_conf_shift": 0.0018489360809326172, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.03311379998922348, 0.9668862223625183], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.29109.gpt3.2", "original_example": {"example_id": "atomic.train.29109", "premise_hypothesis_id": "atomic.train.13209", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ubUGHTBUSVmy7r8JrGp_fw==", "AtomicEventRelationId": "9QbcKcMAdQ6i7WNjwNdiIg==", "AtomicRelationType": "xEffect", "AtomicInference": "hits a tree"}, "premise": "PersonX swerves off the road", "hypothesis": "PersonX then hits a tree", "update": "Person X's car has a branch stuck through the windshield.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29109", "update_paraphrase": "There's a branch poking through the windshield of Person X's car.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.31866281866281865, "pred_conf_shift": -0.00222700834274292, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.02807408571243286, 0.9719259738922119], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.29109.gpt3.7", "original_example": {"example_id": "atomic.train.29109", "premise_hypothesis_id": "atomic.train.13209", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ubUGHTBUSVmy7r8JrGp_fw==", "AtomicEventRelationId": "9QbcKcMAdQ6i7WNjwNdiIg==", "AtomicRelationType": "xEffect", "AtomicInference": "hits a tree"}, "premise": "PersonX swerves off the road", "hypothesis": "PersonX then hits a tree", "update": "Person X's car has a branch stuck through the windshield.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29109", "update_paraphrase": "Person X's car has a tree branch piercing the windshield.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.18317349317349324, "pred_conf_shift": 0.0028127431869506836, "syntactic_distance": 0.0}, {"confidence": [0.03764403983950615, 0.9623560309410095], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.29109.gpt3.3", "original_example": {"example_id": "atomic.train.29109", "premise_hypothesis_id": "atomic.train.13209", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ubUGHTBUSVmy7r8JrGp_fw==", "AtomicEventRelationId": "9QbcKcMAdQ6i7WNjwNdiIg==", "AtomicRelationType": "xEffect", "AtomicInference": "hits a tree"}, "premise": "PersonX swerves off the road", "hypothesis": "PersonX then hits a tree", "update": "Person X's car has a branch stuck through the windshield.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29109", "update_paraphrase": "There's a branch that's poking through the windshield of Person X's car.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3349173553719008, "pred_conf_shift": -0.006757199764251709, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.18290521204471588, 0.8170946836471558], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.29109.gpt3.0", "original_example": {"example_id": "atomic.train.29109", "premise_hypothesis_id": "atomic.train.13209", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ubUGHTBUSVmy7r8JrGp_fw==", "AtomicEventRelationId": "9QbcKcMAdQ6i7WNjwNdiIg==", "AtomicRelationType": "xEffect", "AtomicInference": "hits a tree"}, "premise": "PersonX swerves off the road", "hypothesis": "PersonX then hits a tree", "update": "Person X's car has a branch stuck through the windshield.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29109", "update_paraphrase": "Person X's car was involved in a minor collision with a tree, and now there's a branch sticking through the windshield.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.46084292052033987, "pred_conf_shift": -0.15201854705810547, "syntactic_distance": 0.42857142857142855}, {"confidence": [0.024763567373156548, 0.9752364158630371], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.29109.gpt3.6", "original_example": {"example_id": "atomic.train.29109", "premise_hypothesis_id": "atomic.train.13209", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ubUGHTBUSVmy7r8JrGp_fw==", "AtomicEventRelationId": "9QbcKcMAdQ6i7WNjwNdiIg==", "AtomicRelationType": "xEffect", "AtomicInference": "hits a tree"}, "premise": "PersonX swerves off the road", "hypothesis": "PersonX then hits a tree", "update": "Person X's car has a branch stuck through the windshield.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29109", "update_paraphrase": "A large branch is sticking through the windshield of Person X's car.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.334965034965035, "pred_conf_shift": 0.006123185157775879, "syntactic_distance": 0.25}, {"confidence": [0.03190416470170021, 0.9680959582328796], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.29109.gpt3.4", "original_example": {"example_id": "atomic.train.29109", "premise_hypothesis_id": "atomic.train.13209", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ubUGHTBUSVmy7r8JrGp_fw==", "AtomicEventRelationId": "9QbcKcMAdQ6i7WNjwNdiIg==", "AtomicRelationType": "xEffect", "AtomicInference": "hits a tree"}, "premise": "PersonX swerves off the road", "hypothesis": "PersonX then hits a tree", "update": "Person X's car has a branch stuck through the windshield.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29109", "update_paraphrase": "Person X's car has a tree branch pierced through the windshield.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.15791615791615793, "pred_conf_shift": -0.0010172724723815918, "syntactic_distance": 0.047619047619047616}]}, "atomic.train.9072": {"original_confidence": [0.7349298000335693, 0.26507025957107544], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.897064208984375, 0.1029357835650444], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9072.gpt3.7", "original_example": {"example_id": "atomic.train.9072", "premise_hypothesis_id": "atomic.train.4276", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gsFxV5JMBxGMtjAQfN76wQ==", "AtomicEventRelationId": "ICbXo840YDTai88C3tImIA==", "AtomicRelationType": "xWant", "AtomicInference": "be recognized for bravery"}, "premise": "PersonX beards the lion in his den", "hypothesis": "As a result, PersonX wants be recognized for bravery", "update": "The lion is a baby and is wandering aimlessly.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9072", "update_paraphrase": "The young lion is currently wandering around aimlessly.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.349673202614379, "pred_conf_shift": 0.16213440895080566, "syntactic_distance": 0.32}, {"confidence": [0.932994544506073, 0.06700541079044342], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9072.gpt3.0", "original_example": {"example_id": "atomic.train.9072", "premise_hypothesis_id": "atomic.train.4276", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gsFxV5JMBxGMtjAQfN76wQ==", "AtomicEventRelationId": "ICbXo840YDTai88C3tImIA==", "AtomicRelationType": "xWant", "AtomicInference": "be recognized for bravery"}, "premise": "PersonX beards the lion in his den", "hypothesis": "As a result, PersonX wants be recognized for bravery", "update": "The lion is a baby and is wandering aimlessly.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9072", "update_paraphrase": "The lion is still a cub and is currently just wandering around aimlessly.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3535714285714286, "pred_conf_shift": 0.19806474447250366, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.15134133398532867, 0.8486586213111877], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9072.gpt3.6", "original_example": {"example_id": "atomic.train.9072", "premise_hypothesis_id": "atomic.train.4276", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gsFxV5JMBxGMtjAQfN76wQ==", "AtomicEventRelationId": "ICbXo840YDTai88C3tImIA==", "AtomicRelationType": "xWant", "AtomicInference": "be recognized for bravery"}, "premise": "PersonX beards the lion in his den", "hypothesis": "As a result, PersonX wants be recognized for bravery", "update": "The lion is a baby and is wandering aimlessly.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9072", "update_paraphrase": "The lion cub is wandering around without any direction.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4083774250440917, "pred_conf_shift": -0.5835884660482407, "syntactic_distance": 0.30434782608695654}, {"confidence": [0.9746617078781128, 0.025338150560855865], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9072.gpt3.4", "original_example": {"example_id": "atomic.train.9072", "premise_hypothesis_id": "atomic.train.4276", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gsFxV5JMBxGMtjAQfN76wQ==", "AtomicEventRelationId": "ICbXo840YDTai88C3tImIA==", "AtomicRelationType": "xWant", "AtomicInference": "be recognized for bravery"}, "premise": "PersonX beards the lion in his den", "hypothesis": "As a result, PersonX wants be recognized for bravery", "update": "The lion is a baby and is wandering aimlessly.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9072", "update_paraphrase": "The lion cub is exploring its surroundings without any specific goal in mind.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5075563325563326, "pred_conf_shift": 0.23973190784454346, "syntactic_distance": 0.30434782608695654}, {"confidence": [0.7997786402702332, 0.20022143423557281], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9072.gpt3.8", "original_example": {"example_id": "atomic.train.9072", "premise_hypothesis_id": "atomic.train.4276", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gsFxV5JMBxGMtjAQfN76wQ==", "AtomicEventRelationId": "ICbXo840YDTai88C3tImIA==", "AtomicRelationType": "xWant", "AtomicInference": "be recognized for bravery"}, "premise": "PersonX beards the lion in his den", "hypothesis": "As a result, PersonX wants be recognized for bravery", "update": "The lion is a baby and is wandering aimlessly.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9072", "update_paraphrase": "The lion cub is young and is just wandering around without much purpose.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45693195693195693, "pred_conf_shift": 0.06484884023666382, "syntactic_distance": 0.11538461538461539}, {"confidence": [0.8959493637084961, 0.10405062884092331], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9072.gpt3.3", "original_example": {"example_id": "atomic.train.9072", "premise_hypothesis_id": "atomic.train.4276", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gsFxV5JMBxGMtjAQfN76wQ==", "AtomicEventRelationId": "ICbXo840YDTai88C3tImIA==", "AtomicRelationType": "xWant", "AtomicInference": "be recognized for bravery"}, "premise": "PersonX beards the lion in his den", "hypothesis": "As a result, PersonX wants be recognized for bravery", "update": "The lion is a baby and is wandering aimlessly.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9072", "update_paraphrase": "The lion is young and has no specific destination in mind.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.47095848595848594, "pred_conf_shift": 0.16101956367492676, "syntactic_distance": 0.12}, {"confidence": [0.8707478642463684, 0.12925204634666443], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9072.gpt3.1", "original_example": {"example_id": "atomic.train.9072", "premise_hypothesis_id": "atomic.train.4276", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gsFxV5JMBxGMtjAQfN76wQ==", "AtomicEventRelationId": "ICbXo840YDTai88C3tImIA==", "AtomicRelationType": "xWant", "AtomicInference": "be recognized for bravery"}, "premise": "PersonX beards the lion in his den", "hypothesis": "As a result, PersonX wants be recognized for bravery", "update": "The lion is a baby and is wandering aimlessly.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9072", "update_paraphrase": "The lion is a young one and doesn't seem to have a specific destination in mind.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.48769230769230765, "pred_conf_shift": 0.13581806421279907, "syntactic_distance": 0.04}, {"confidence": [0.8787301182746887, 0.12126989662647247], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9072.gpt3.2", "original_example": {"example_id": "atomic.train.9072", "premise_hypothesis_id": "atomic.train.4276", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gsFxV5JMBxGMtjAQfN76wQ==", "AtomicEventRelationId": "ICbXo840YDTai88C3tImIA==", "AtomicRelationType": "xWant", "AtomicInference": "be recognized for bravery"}, "premise": "PersonX beards the lion in his den", "hypothesis": "As a result, PersonX wants be recognized for bravery", "update": "The lion is a baby and is wandering aimlessly.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9072", "update_paraphrase": "The lion is a young one and currently has no specific destination in mind.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4836438923395445, "pred_conf_shift": 0.14380031824111938, "syntactic_distance": 0.14814814814814814}, {"confidence": [0.40677857398986816, 0.5932213068008423], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9072.gpt3.5", "original_example": {"example_id": "atomic.train.9072", "premise_hypothesis_id": "atomic.train.4276", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gsFxV5JMBxGMtjAQfN76wQ==", "AtomicEventRelationId": "ICbXo840YDTai88C3tImIA==", "AtomicRelationType": "xWant", "AtomicInference": "be recognized for bravery"}, "premise": "PersonX beards the lion in his den", "hypothesis": "As a result, PersonX wants be recognized for bravery", "update": "The lion is a baby and is wandering aimlessly.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9072", "update_paraphrase": "The lion is young and does not know where it is going.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.47419908134193844, "pred_conf_shift": -0.32815122604370117, "syntactic_distance": 0.08}]}, "atomic.train.2027": {"original_confidence": [0.9296087026596069, 0.07039126753807068], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.8592082262039185, 0.14079178869724274], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2027.gpt3.2", "original_example": {"example_id": "atomic.train.2027", "premise_hypothesis_id": "atomic.train.957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8f2bYBoieLfcC0aX67BIww==", "AtomicEventRelationId": "G2lWA0c7Nc58CgwQ6XwSEA==", "AtomicRelationType": "xWant", "AtomicInference": "to get payment"}, "premise": "PersonX shaves PersonY's beard", "hypothesis": "As a result, PersonX wants to get payment", "update": "PersonY loves going to the barber.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2027", "update_paraphrase": "Person Y enjoys going to the barber to get their hair cut.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4125874125874126, "pred_conf_shift": 0.07040052115917206, "syntactic_distance": 0.125}, {"confidence": [0.9390323758125305, 0.06096767634153366], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2027.gpt3.0", "original_example": {"example_id": "atomic.train.2027", "premise_hypothesis_id": "atomic.train.957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8f2bYBoieLfcC0aX67BIww==", "AtomicEventRelationId": "G2lWA0c7Nc58CgwQ6XwSEA==", "AtomicRelationType": "xWant", "AtomicInference": "to get payment"}, "premise": "PersonX shaves PersonY's beard", "hypothesis": "As a result, PersonX wants to get payment", "update": "PersonY loves going to the barber.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2027", "update_paraphrase": "PersonY enjoys visiting the barber.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.32649925831744014, "pred_conf_shift": -0.009423591196537018, "syntactic_distance": 0.0}, {"confidence": [0.8730934858322144, 0.12690649926662445], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2027.gpt3.5", "original_example": {"example_id": "atomic.train.2027", "premise_hypothesis_id": "atomic.train.957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8f2bYBoieLfcC0aX67BIww==", "AtomicEventRelationId": "G2lWA0c7Nc58CgwQ6XwSEA==", "AtomicRelationType": "xWant", "AtomicInference": "to get payment"}, "premise": "PersonX shaves PersonY's beard", "hypothesis": "As a result, PersonX wants to get payment", "update": "PersonY loves going to the barber.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2027", "update_paraphrase": "PersonY really enjoys going to the barber to get their hair cut.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4425019425019425, "pred_conf_shift": 0.05651523172855377, "syntactic_distance": 0.125}, {"confidence": [0.9261713027954102, 0.07382860034704208], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2027.gpt3.1", "original_example": {"example_id": "atomic.train.2027", "premise_hypothesis_id": "atomic.train.957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8f2bYBoieLfcC0aX67BIww==", "AtomicEventRelationId": "G2lWA0c7Nc58CgwQ6XwSEA==", "AtomicRelationType": "xWant", "AtomicInference": "to get payment"}, "premise": "PersonX shaves PersonY's beard", "hypothesis": "As a result, PersonX wants to get payment", "update": "PersonY loves going to the barber.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2027", "update_paraphrase": "PersonY enjoys visiting the barber for a haircut.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.48941058941058935, "pred_conf_shift": 0.003437332808971405, "syntactic_distance": 0.0}, {"confidence": [0.9189841151237488, 0.08101581782102585], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2027.gpt3.3", "original_example": {"example_id": "atomic.train.2027", "premise_hypothesis_id": "atomic.train.957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8f2bYBoieLfcC0aX67BIww==", "AtomicEventRelationId": "G2lWA0c7Nc58CgwQ6XwSEA==", "AtomicRelationType": "xWant", "AtomicInference": "to get payment"}, "premise": "PersonX shaves PersonY's beard", "hypothesis": "As a result, PersonX wants to get payment", "update": "PersonY loves going to the barber.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2027", "update_paraphrase": "The barber is one of PersonY's favorite places to go.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5294372294372295, "pred_conf_shift": 0.01062455028295517, "syntactic_distance": 0.25}, {"confidence": [0.9267650842666626, 0.07323489338159561], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2027.gpt3.4", "original_example": {"example_id": "atomic.train.2027", "premise_hypothesis_id": "atomic.train.957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8f2bYBoieLfcC0aX67BIww==", "AtomicEventRelationId": "G2lWA0c7Nc58CgwQ6XwSEA==", "AtomicRelationType": "xWant", "AtomicInference": "to get payment"}, "premise": "PersonX shaves PersonY's beard", "hypothesis": "As a result, PersonX wants to get payment", "update": "PersonY loves going to the barber.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2027", "update_paraphrase": "PersonY enjoys going to the barber.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.10858585858585862, "pred_conf_shift": 0.002843625843524933, "syntactic_distance": 0.0}, {"confidence": [0.880237340927124, 0.11976270377635956], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2027.gpt3.6", "original_example": {"example_id": "atomic.train.2027", "premise_hypothesis_id": "atomic.train.957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8f2bYBoieLfcC0aX67BIww==", "AtomicEventRelationId": "G2lWA0c7Nc58CgwQ6XwSEA==", "AtomicRelationType": "xWant", "AtomicInference": "to get payment"}, "premise": "PersonX shaves PersonY's beard", "hypothesis": "As a result, PersonX wants to get payment", "update": "PersonY loves going to the barber.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2027", "update_paraphrase": "PersonY enjoys getting haircuts at the barbershop.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39165321857629554, "pred_conf_shift": 0.04937143623828888, "syntactic_distance": 0.0}]}, "atomic.train.5244": {"original_confidence": [0.5532503128051758, 0.44674965739250183], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.9467532634735107, 0.05324675515294075], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5244.gpt3.0", "original_example": {"example_id": "atomic.train.5244", "premise_hypothesis_id": "atomic.train.2475", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "jKzFOv9jp2xRWBfgxxoktg==", "AtomicEventRelationId": "MHMLwfmrx3MHEXvh1lQtZw==", "AtomicRelationType": "xEffect", "AtomicInference": "gets greeted"}, "premise": "PersonX comes back home", "hypothesis": "PersonX then gets greeted", "update": "The lights are all off at the house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5244", "update_paraphrase": "The house is dark because all of the lights are off.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33132832080200497, "pred_conf_shift": 0.39350295066833496, "syntactic_distance": 0.2608695652173913}, {"confidence": [0.9771503806114197, 0.02284955605864525], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5244.gpt3.3", "original_example": {"example_id": "atomic.train.5244", "premise_hypothesis_id": "atomic.train.2475", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "jKzFOv9jp2xRWBfgxxoktg==", "AtomicEventRelationId": "MHMLwfmrx3MHEXvh1lQtZw==", "AtomicRelationType": "xEffect", "AtomicInference": "gets greeted"}, "premise": "PersonX comes back home", "hypothesis": "PersonX then gets greeted", "update": "The lights are all off at the house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5244", "update_paraphrase": "The lights are out at the house.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1777777777777777, "pred_conf_shift": 0.4239000678062439, "syntactic_distance": 0.08695652173913043}, {"confidence": [0.8927420377731323, 0.10725786536931992], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5244.gpt3.2", "original_example": {"example_id": "atomic.train.5244", "premise_hypothesis_id": "atomic.train.2475", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "jKzFOv9jp2xRWBfgxxoktg==", "AtomicEventRelationId": "MHMLwfmrx3MHEXvh1lQtZw==", "AtomicRelationType": "xEffect", "AtomicInference": "gets greeted"}, "premise": "PersonX comes back home", "hypothesis": "PersonX then gets greeted", "update": "The lights are all off at the house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5244", "update_paraphrase": "All of the lights are turned off in the house.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2638888888888889, "pred_conf_shift": 0.33949172496795654, "syntactic_distance": 0.4}, {"confidence": [0.9336482286453247, 0.06635163724422455], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5244.gpt3.5", "original_example": {"example_id": "atomic.train.5244", "premise_hypothesis_id": "atomic.train.2475", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "jKzFOv9jp2xRWBfgxxoktg==", "AtomicEventRelationId": "MHMLwfmrx3MHEXvh1lQtZw==", "AtomicRelationType": "xEffect", "AtomicInference": "gets greeted"}, "premise": "PersonX comes back home", "hypothesis": "PersonX then gets greeted", "update": "The lights are all off at the house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5244", "update_paraphrase": "All the lights in the house are turned off.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3382352941176471, "pred_conf_shift": 0.3803979158401489, "syntactic_distance": 0.4230769230769231}, {"confidence": [0.9818092584609985, 0.018190843984484673], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5244.gpt3.8", "original_example": {"example_id": "atomic.train.5244", "premise_hypothesis_id": "atomic.train.2475", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "jKzFOv9jp2xRWBfgxxoktg==", "AtomicEventRelationId": "MHMLwfmrx3MHEXvh1lQtZw==", "AtomicRelationType": "xEffect", "AtomicInference": "gets greeted"}, "premise": "PersonX comes back home", "hypothesis": "PersonX then gets greeted", "update": "The lights are all off at the house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5244", "update_paraphrase": "There is no light coming from any of the windows at the house.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39902082044939186, "pred_conf_shift": 0.42855894565582275, "syntactic_distance": 0.45}, {"confidence": [0.9250571131706238, 0.0749429240822792], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5244.gpt3.4", "original_example": {"example_id": "atomic.train.5244", "premise_hypothesis_id": "atomic.train.2475", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "jKzFOv9jp2xRWBfgxxoktg==", "AtomicEventRelationId": "MHMLwfmrx3MHEXvh1lQtZw==", "AtomicRelationType": "xEffect", "AtomicInference": "gets greeted"}, "premise": "PersonX comes back home", "hypothesis": "PersonX then gets greeted", "update": "The lights are all off at the house.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5244", "update_paraphrase": "All of the lights in the house are turned off.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3638888888888889, "pred_conf_shift": 0.371806800365448, "syntactic_distance": 0.4166666666666667}]}, "atomic.train.5728": {"original_confidence": [0.33060595393180847, 0.6693940162658691], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.4078677296638489, 0.5921322703361511], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.5728.gpt3.1", "original_example": {"example_id": "atomic.train.5728", "premise_hypothesis_id": "atomic.train.2701", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gHSg0KIcyICyuO8jGvLCCA==", "AtomicEventRelationId": "buEOHUzFuhW8PKxM9OP8dg==", "AtomicRelationType": "xNeed", "AtomicInference": "To execute the murder plan"}, "premise": "PersonX kills PersonX's mother", "hypothesis": "Before, PersonX needed to execute the murder plan", "update": "PersonX learned their mother had a Do Not Resuscitate Order.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5728", "update_paraphrase": "PersonX discovered that their mother had a Do Not Resuscitate Order in place.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2186700767263427, "pred_conf_shift": 0.0772617757320404, "syntactic_distance": 0.13333333333333333}, {"confidence": [0.42227092385292053, 0.5777290463447571], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.5728.gpt3.5", "original_example": {"example_id": "atomic.train.5728", "premise_hypothesis_id": "atomic.train.2701", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gHSg0KIcyICyuO8jGvLCCA==", "AtomicEventRelationId": "buEOHUzFuhW8PKxM9OP8dg==", "AtomicRelationType": "xNeed", "AtomicInference": "To execute the murder plan"}, "premise": "PersonX kills PersonX's mother", "hypothesis": "Before, PersonX needed to execute the murder plan", "update": "PersonX learned their mother had a Do Not Resuscitate Order.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5728", "update_paraphrase": "PersonX found out that their mother had a Do Not Resuscitate Order.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1515151515151515, "pred_conf_shift": 0.09166496992111206, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.43730658292770386, 0.5626934766769409], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.5728.gpt3.2", "original_example": {"example_id": "atomic.train.5728", "premise_hypothesis_id": "atomic.train.2701", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gHSg0KIcyICyuO8jGvLCCA==", "AtomicEventRelationId": "buEOHUzFuhW8PKxM9OP8dg==", "AtomicRelationType": "xNeed", "AtomicInference": "To execute the murder plan"}, "premise": "PersonX kills PersonX's mother", "hypothesis": "Before, PersonX needed to execute the murder plan", "update": "PersonX learned their mother had a Do Not Resuscitate Order.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5728", "update_paraphrase": "PersonX found out that their mother had a Do Not Resuscitate Order in place.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.24936868686868685, "pred_conf_shift": 0.10670062899589539, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.39141565561294556, 0.6085843443870544], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.5728.gpt3.3", "original_example": {"example_id": "atomic.train.5728", "premise_hypothesis_id": "atomic.train.2701", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gHSg0KIcyICyuO8jGvLCCA==", "AtomicEventRelationId": "buEOHUzFuhW8PKxM9OP8dg==", "AtomicRelationType": "xNeed", "AtomicInference": "To execute the murder plan"}, "premise": "PersonX kills PersonX's mother", "hypothesis": "Before, PersonX needed to execute the murder plan", "update": "PersonX learned their mother had a Do Not Resuscitate Order.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5728", "update_paraphrase": "PersonX discovered that their mother had a Do Not Resuscitate Order.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.10924369747899165, "pred_conf_shift": 0.060809701681137085, "syntactic_distance": 0.13333333333333333}, {"confidence": [0.4109433591365814, 0.5890566110610962], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.5728.gpt3.4", "original_example": {"example_id": "atomic.train.5728", "premise_hypothesis_id": "atomic.train.2701", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gHSg0KIcyICyuO8jGvLCCA==", "AtomicEventRelationId": "buEOHUzFuhW8PKxM9OP8dg==", "AtomicRelationType": "xNeed", "AtomicInference": "To execute the murder plan"}, "premise": "PersonX kills PersonX's mother", "hypothesis": "Before, PersonX needed to execute the murder plan", "update": "PersonX learned their mother had a Do Not Resuscitate Order.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5728", "update_paraphrase": "PersonX found out that their mother had signed a Do Not Resuscitate Order.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.21840478362217491, "pred_conf_shift": 0.08033740520477295, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.4745595157146454, 0.525440514087677], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.5728.gpt3.0", "original_example": {"example_id": "atomic.train.5728", "premise_hypothesis_id": "atomic.train.2701", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gHSg0KIcyICyuO8jGvLCCA==", "AtomicEventRelationId": "buEOHUzFuhW8PKxM9OP8dg==", "AtomicRelationType": "xNeed", "AtomicInference": "To execute the murder plan"}, "premise": "PersonX kills PersonX's mother", "hypothesis": "Before, PersonX needed to execute the murder plan", "update": "PersonX learned their mother had a Do Not Resuscitate Order.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5728", "update_paraphrase": "PersonX found out that their mother put in a request that she not receive CPR if necessary.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.504715140826252, "pred_conf_shift": 0.14395356178283691, "syntactic_distance": 0.23529411764705882}]}, "atomic.train.27405": {"original_confidence": [0.38165175914764404, 0.618348240852356], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.09753651171922684, 0.9024635553359985], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.27405.gpt3.0", "original_example": {"example_id": "atomic.train.27405", "premise_hypothesis_id": "atomic.train.12468", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "X7b-3dLzohq1NBmLBFiLRA==", "AtomicEventRelationId": "OsRwRiIiVPW7h1xpQicVNA==", "AtomicRelationType": "xAttr", "AtomicInference": "protective"}, "premise": "PersonX stays with PersonY", "hypothesis": "As a result, PersonX feels protective", "update": "PersonX is helping while PersonY is sick.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27405", "update_paraphrase": "PersonX is helping PersonY while PersonY is sick.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.06666666666666665, "pred_conf_shift": 0.2841153144836426, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.22644373774528503, 0.7735561728477478], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.27405.gpt3.3", "original_example": {"example_id": "atomic.train.27405", "premise_hypothesis_id": "atomic.train.12468", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "X7b-3dLzohq1NBmLBFiLRA==", "AtomicEventRelationId": "OsRwRiIiVPW7h1xpQicVNA==", "AtomicRelationType": "xAttr", "AtomicInference": "protective"}, "premise": "PersonX stays with PersonY", "hypothesis": "As a result, PersonX feels protective", "update": "PersonX is helping while PersonY is sick.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27405", "update_paraphrase": "Since PersonY is unwell, PersonX is helping out.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.313997113997114, "pred_conf_shift": 0.15520793199539185, "syntactic_distance": 0.2857142857142857}, {"confidence": [0.21104562282562256, 0.7889543175697327], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.27405.gpt3.6", "original_example": {"example_id": "atomic.train.27405", "premise_hypothesis_id": "atomic.train.12468", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "X7b-3dLzohq1NBmLBFiLRA==", "AtomicEventRelationId": "OsRwRiIiVPW7h1xpQicVNA==", "AtomicRelationType": "xAttr", "AtomicInference": "protective"}, "premise": "PersonX stays with PersonY", "hypothesis": "As a result, PersonX feels protective", "update": "PersonX is helping while PersonY is sick.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27405", "update_paraphrase": "PersonX is assisting PersonY while PersonY is unwell.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.30183150183150187, "pred_conf_shift": 0.1706060767173767, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.1806780993938446, 0.819321870803833], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.27405.gpt3.2", "original_example": {"example_id": "atomic.train.27405", "premise_hypothesis_id": "atomic.train.12468", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "X7b-3dLzohq1NBmLBFiLRA==", "AtomicEventRelationId": "OsRwRiIiVPW7h1xpQicVNA==", "AtomicRelationType": "xAttr", "AtomicInference": "protective"}, "premise": "PersonX stays with PersonY", "hypothesis": "As a result, PersonX feels protective", "update": "PersonX is helping while PersonY is sick.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27405", "update_paraphrase": "PersonY is unwell at the moment, and PersonX is helping out.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4331224331224331, "pred_conf_shift": 0.20097362995147705, "syntactic_distance": 0.4782608695652174}, {"confidence": [0.5009546875953674, 0.49904540181159973], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.27405.gpt3.4", "original_example": {"example_id": "atomic.train.27405", "premise_hypothesis_id": "atomic.train.12468", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "X7b-3dLzohq1NBmLBFiLRA==", "AtomicEventRelationId": "OsRwRiIiVPW7h1xpQicVNA==", "AtomicRelationType": "xAttr", "AtomicInference": "protective"}, "premise": "PersonX stays with PersonY", "hypothesis": "As a result, PersonX feels protective", "update": "PersonX is helping while PersonY is sick.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27405", "update_paraphrase": "PersonX is helping out while PersonY is unwell.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2519480519480519, "pred_conf_shift": -0.11930283904075623, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.6975127458572388, 0.30248725414276123], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.27405.gpt3.5", "original_example": {"example_id": "atomic.train.27405", "premise_hypothesis_id": "atomic.train.12468", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "X7b-3dLzohq1NBmLBFiLRA==", "AtomicEventRelationId": "OsRwRiIiVPW7h1xpQicVNA==", "AtomicRelationType": "xAttr", "AtomicInference": "protective"}, "premise": "PersonX stays with PersonY", "hypothesis": "As a result, PersonX feels protective", "update": "PersonX is helping while PersonY is sick.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27405", "update_paraphrase": "PersonX is helping out while PersonY is sick.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.06666666666666665, "pred_conf_shift": -0.3158609867095947, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.48167920112609863, 0.5183207988739014], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.27405.gpt3.1", "original_example": {"example_id": "atomic.train.27405", "premise_hypothesis_id": "atomic.train.12468", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "X7b-3dLzohq1NBmLBFiLRA==", "AtomicEventRelationId": "OsRwRiIiVPW7h1xpQicVNA==", "AtomicRelationType": "xAttr", "AtomicInference": "protective"}, "premise": "PersonX stays with PersonY", "hypothesis": "As a result, PersonX feels protective", "update": "PersonX is helping while PersonY is sick.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27405", "update_paraphrase": "PersonX is helping out while PersonY is ill.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2238095238095238, "pred_conf_shift": -0.10002744197845459, "syntactic_distance": 0.058823529411764705}]}, "atomic.train.11068": {"original_confidence": [0.032222215086221695, 0.9677777886390686], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.08235367387533188, 0.9176463484764099], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11068.gpt3.1", "original_example": {"example_id": "atomic.train.11068", "premise_hypothesis_id": "atomic.train.5208", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "IrCusmjyTI5-T2H9qZowIw==", "AtomicEventRelationId": "fBiQnHKxx0m5R8PiohkcBg==", "AtomicRelationType": "xIntent", "AtomicInference": "to help"}, "premise": "PersonX finds my keys", "hypothesis": "Because PersonX wanted to help", "update": "PersonX is a servant", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11068", "update_paraphrase": "PersonX is a servant.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": 0.050131458789110184, "syntactic_distance": 0.0}, {"confidence": [0.020097291097044945, 0.9799026846885681], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11068.gpt3.5", "original_example": {"example_id": "atomic.train.11068", "premise_hypothesis_id": "atomic.train.5208", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "IrCusmjyTI5-T2H9qZowIw==", "AtomicEventRelationId": "fBiQnHKxx0m5R8PiohkcBg==", "AtomicRelationType": "xIntent", "AtomicInference": "to help"}, "premise": "PersonX finds my keys", "hypothesis": "Because PersonX wanted to help", "update": "PersonX is a servant", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11068", "update_paraphrase": "Person X is a servant or worker who helps others.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.43956043956043955, "pred_conf_shift": -0.01212492398917675, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.017257023602724075, 0.9827430248260498], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11068.gpt3.3", "original_example": {"example_id": "atomic.train.11068", "premise_hypothesis_id": "atomic.train.5208", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "IrCusmjyTI5-T2H9qZowIw==", "AtomicEventRelationId": "fBiQnHKxx0m5R8PiohkcBg==", "AtomicRelationType": "xIntent", "AtomicInference": "to help"}, "premise": "PersonX finds my keys", "hypothesis": "Because PersonX wanted to help", "update": "PersonX is a servant", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11068", "update_paraphrase": "PersonX is a servant to others.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19999999999999996, "pred_conf_shift": -0.01496519148349762, "syntactic_distance": 0.125}, {"confidence": [0.6467224955558777, 0.3532775342464447], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11068.gpt3.0", "original_example": {"example_id": "atomic.train.11068", "premise_hypothesis_id": "atomic.train.5208", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "IrCusmjyTI5-T2H9qZowIw==", "AtomicEventRelationId": "fBiQnHKxx0m5R8PiohkcBg==", "AtomicRelationType": "xIntent", "AtomicInference": "to help"}, "premise": "PersonX finds my keys", "hypothesis": "Because PersonX wanted to help", "update": "PersonX is a servant", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11068", "update_paraphrase": "Person X works as a servant.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3153846153846154, "pred_conf_shift": 0.614500280469656, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.020339233800768852, 0.9796608090400696], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11068.gpt3.4", "original_example": {"example_id": "atomic.train.11068", "premise_hypothesis_id": "atomic.train.5208", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "IrCusmjyTI5-T2H9qZowIw==", "AtomicEventRelationId": "fBiQnHKxx0m5R8PiohkcBg==", "AtomicRelationType": "xIntent", "AtomicInference": "to help"}, "premise": "PersonX finds my keys", "hypothesis": "Because PersonX wanted to help", "update": "PersonX is a servant", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11068", "update_paraphrase": "PersonX is a servant of the people.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2727272727272727, "pred_conf_shift": -0.011882981285452843, "syntactic_distance": 0.125}]}, "atomic.train.34681": {"original_confidence": [0.250283420085907, 0.7497165203094482], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.34973493218421936, 0.6502650380134583], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34681.gpt3.5", "original_example": {"example_id": "atomic.train.34681", "premise_hypothesis_id": "atomic.train.15722", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Txk6WefT4snatLmrA1sUbw==", "AtomicEventRelationId": "6RlSASDPGJkGA9HHViRLBA==", "AtomicRelationType": "xAttr", "AtomicInference": "informative"}, "premise": "PersonX tells PersonY thing", "hypothesis": "As a result, PersonX feels informative", "update": "PersonX felt that PersonY should know.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34681", "update_paraphrase": "PersonX believes that PersonY should be privy to this information.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.43749999999999994, "pred_conf_shift": -0.09945148229598999, "syntactic_distance": 0.2}, {"confidence": [0.14560185372829437, 0.8543981909751892], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34681.gpt3.3", "original_example": {"example_id": "atomic.train.34681", "premise_hypothesis_id": "atomic.train.15722", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Txk6WefT4snatLmrA1sUbw==", "AtomicEventRelationId": "6RlSASDPGJkGA9HHViRLBA==", "AtomicRelationType": "xAttr", "AtomicInference": "informative"}, "premise": "PersonX tells PersonY thing", "hypothesis": "As a result, PersonX feels informative", "update": "PersonX felt that PersonY should know.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34681", "update_paraphrase": "PersonX thought that PersonY should be informed.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.31934731934731936, "pred_conf_shift": 0.10468167066574097, "syntactic_distance": 0.07142857142857142}, {"confidence": [0.04674435406923294, 0.9532555937767029], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34681.gpt3.4", "original_example": {"example_id": "atomic.train.34681", "premise_hypothesis_id": "atomic.train.15722", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Txk6WefT4snatLmrA1sUbw==", "AtomicEventRelationId": "6RlSASDPGJkGA9HHViRLBA==", "AtomicRelationType": "xAttr", "AtomicInference": "informative"}, "premise": "PersonX tells PersonY thing", "hypothesis": "As a result, PersonX feels informative", "update": "PersonX felt that PersonY should know.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34681", "update_paraphrase": "PersonX thought that PersonY should be aware of the situation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.44696969696969696, "pred_conf_shift": 0.20353907346725464, "syntactic_distance": 0.07142857142857142}, {"confidence": [0.03121599182486534, 0.9687840342521667], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34681.gpt3.2", "original_example": {"example_id": "atomic.train.34681", "premise_hypothesis_id": "atomic.train.15722", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Txk6WefT4snatLmrA1sUbw==", "AtomicEventRelationId": "6RlSASDPGJkGA9HHViRLBA==", "AtomicRelationType": "xAttr", "AtomicInference": "informative"}, "premise": "PersonX tells PersonY thing", "hypothesis": "As a result, PersonX feels informative", "update": "PersonX felt that PersonY should know.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34681", "update_paraphrase": "PersonX believes that PersonY should be aware of the situation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.43749999999999994, "pred_conf_shift": 0.2190675139427185, "syntactic_distance": 0.14285714285714285}, {"confidence": [0.041483644396066666, 0.9585163593292236], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34681.gpt3.8", "original_example": {"example_id": "atomic.train.34681", "premise_hypothesis_id": "atomic.train.15722", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Txk6WefT4snatLmrA1sUbw==", "AtomicEventRelationId": "6RlSASDPGJkGA9HHViRLBA==", "AtomicRelationType": "xAttr", "AtomicInference": "informative"}, "premise": "PersonX tells PersonY thing", "hypothesis": "As a result, PersonX feels informative", "update": "PersonX felt that PersonY should know.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34681", "update_paraphrase": "PersonX thought PersonY should be aware of the situation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4810966810966811, "pred_conf_shift": 0.2087998390197754, "syntactic_distance": 0.07142857142857142}, {"confidence": [0.06577394902706146, 0.9342259764671326], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34681.gpt3.6", "original_example": {"example_id": "atomic.train.34681", "premise_hypothesis_id": "atomic.train.15722", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Txk6WefT4snatLmrA1sUbw==", "AtomicEventRelationId": "6RlSASDPGJkGA9HHViRLBA==", "AtomicRelationType": "xAttr", "AtomicInference": "informative"}, "premise": "PersonX tells PersonY thing", "hypothesis": "As a result, PersonX feels informative", "update": "PersonX felt that PersonY should know.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34681", "update_paraphrase": "PersonX believed that PersonY ought to be aware of the situation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5454545454545454, "pred_conf_shift": 0.18450945615768433, "syntactic_distance": 0.07142857142857142}, {"confidence": [0.028969822451472282, 0.9710301756858826], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34681.gpt3.7", "original_example": {"example_id": "atomic.train.34681", "premise_hypothesis_id": "atomic.train.15722", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Txk6WefT4snatLmrA1sUbw==", "AtomicEventRelationId": "6RlSASDPGJkGA9HHViRLBA==", "AtomicRelationType": "xAttr", "AtomicInference": "informative"}, "premise": "PersonX tells PersonY thing", "hypothesis": "As a result, PersonX feels informative", "update": "PersonX felt that PersonY should know.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34681", "update_paraphrase": "PersonX thinks that PersonY should be aware of the situation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4458333333333333, "pred_conf_shift": 0.22131365537643433, "syntactic_distance": 0.14285714285714285}, {"confidence": [0.10960788279771805, 0.8903920650482178], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34681.gpt3.0", "original_example": {"example_id": "atomic.train.34681", "premise_hypothesis_id": "atomic.train.15722", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Txk6WefT4snatLmrA1sUbw==", "AtomicEventRelationId": "6RlSASDPGJkGA9HHViRLBA==", "AtomicRelationType": "xAttr", "AtomicInference": "informative"}, "premise": "PersonX tells PersonY thing", "hypothesis": "As a result, PersonX feels informative", "update": "PersonX felt that PersonY should know.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34681", "update_paraphrase": "PersonX thought it would be best if PersonY were to be made aware.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6259968102073366, "pred_conf_shift": 0.14067554473876953, "syntactic_distance": 0.0}, {"confidence": [0.046162333339452744, 0.9538375735282898], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34681.gpt3.1", "original_example": {"example_id": "atomic.train.34681", "premise_hypothesis_id": "atomic.train.15722", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Txk6WefT4snatLmrA1sUbw==", "AtomicEventRelationId": "6RlSASDPGJkGA9HHViRLBA==", "AtomicRelationType": "xAttr", "AtomicInference": "informative"}, "premise": "PersonX tells PersonY thing", "hypothesis": "As a result, PersonX feels informative", "update": "PersonX felt that PersonY should know.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34681", "update_paraphrase": "PersonX thought that PersonY needed to be aware of the situation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5543123543123543, "pred_conf_shift": 0.20412105321884155, "syntactic_distance": 0.07142857142857142}]}, "atomic.train.5341": {"original_confidence": [0.9460799694061279, 0.05391993746161461], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.02689506858587265, 0.9731049537658691], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.5341.gpt3.6", "original_example": {"example_id": "atomic.train.5341", "premise_hypothesis_id": "atomic.train.2522", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eYo0WhrNXcHsDBpsybI8xg==", "AtomicEventRelationId": "xR-IR4_tyDuAD86bFhfByg==", "AtomicRelationType": "xAttr", "AtomicInference": "driven"}, "premise": "PersonX wears PersonY out", "hypothesis": "As a result, PersonX feels driven", "update": "PersonX is happy to work out with PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5341", "update_paraphrase": "PersonX is eager to work out alongside PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.27788461538461534, "pred_conf_shift": 0.9191850163042545, "syntactic_distance": 0.0}, {"confidence": [0.5750350952148438, 0.42496490478515625], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5341.gpt3.2", "original_example": {"example_id": "atomic.train.5341", "premise_hypothesis_id": "atomic.train.2522", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eYo0WhrNXcHsDBpsybI8xg==", "AtomicEventRelationId": "xR-IR4_tyDuAD86bFhfByg==", "AtomicRelationType": "xAttr", "AtomicInference": "driven"}, "premise": "PersonX wears PersonY out", "hypothesis": "As a result, PersonX feels driven", "update": "PersonX is happy to work out with PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5341", "update_paraphrase": "PersonX is glad to be working out with PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.27094474153297676, "pred_conf_shift": 0.37104496732354164, "syntactic_distance": 0.0}, {"confidence": [0.22275924682617188, 0.7772408127784729], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.5341.gpt3.7", "original_example": {"example_id": "atomic.train.5341", "premise_hypothesis_id": "atomic.train.2522", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eYo0WhrNXcHsDBpsybI8xg==", "AtomicEventRelationId": "xR-IR4_tyDuAD86bFhfByg==", "AtomicRelationType": "xAttr", "AtomicInference": "driven"}, "premise": "PersonX wears PersonY out", "hypothesis": "As a result, PersonX feels driven", "update": "PersonX is happy to work out with PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5341", "update_paraphrase": "PersonX is pleased to be working out with PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2620745267804091, "pred_conf_shift": 0.7233208753168583, "syntactic_distance": 0.0625}, {"confidence": [0.521617591381073, 0.4783823788166046], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5341.gpt3.3", "original_example": {"example_id": "atomic.train.5341", "premise_hypothesis_id": "atomic.train.2522", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eYo0WhrNXcHsDBpsybI8xg==", "AtomicEventRelationId": "xR-IR4_tyDuAD86bFhfByg==", "AtomicRelationType": "xAttr", "AtomicInference": "driven"}, "premise": "PersonX wears PersonY out", "hypothesis": "As a result, PersonX feels driven", "update": "PersonX is happy to work out with PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5341", "update_paraphrase": "PersonX enjoys working out with PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.325036075036075, "pred_conf_shift": 0.42446244135499, "syntactic_distance": 0.2}, {"confidence": [0.5735254883766174, 0.42647454142570496], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5341.gpt3.4", "original_example": {"example_id": "atomic.train.5341", "premise_hypothesis_id": "atomic.train.2522", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eYo0WhrNXcHsDBpsybI8xg==", "AtomicEventRelationId": "xR-IR4_tyDuAD86bFhfByg==", "AtomicRelationType": "xAttr", "AtomicInference": "driven"}, "premise": "PersonX wears PersonY out", "hypothesis": "As a result, PersonX feels driven", "update": "PersonX is happy to work out with PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5341", "update_paraphrase": "PersonX is glad to workout with PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.32188552188552183, "pred_conf_shift": 0.37255460396409035, "syntactic_distance": 0.0}, {"confidence": [0.5083299875259399, 0.49167001247406006], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5341.gpt3.5", "original_example": {"example_id": "atomic.train.5341", "premise_hypothesis_id": "atomic.train.2522", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eYo0WhrNXcHsDBpsybI8xg==", "AtomicEventRelationId": "xR-IR4_tyDuAD86bFhfByg==", "AtomicRelationType": "xAttr", "AtomicInference": "driven"}, "premise": "PersonX wears PersonY out", "hypothesis": "As a result, PersonX feels driven", "update": "PersonX is happy to work out with PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5341", "update_paraphrase": "PersonX is pleased to work out with PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.10416666666666663, "pred_conf_shift": 0.43775007501244545, "syntactic_distance": 0.0}, {"confidence": [0.9460799694061279, 0.05391993746161461], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5341.gpt3.1", "original_example": {"example_id": "atomic.train.5341", "premise_hypothesis_id": "atomic.train.2522", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eYo0WhrNXcHsDBpsybI8xg==", "AtomicEventRelationId": "xR-IR4_tyDuAD86bFhfByg==", "AtomicRelationType": "xAttr", "AtomicInference": "driven"}, "premise": "PersonX wears PersonY out", "hypothesis": "As a result, PersonX feels driven", "update": "PersonX is happy to work out with PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5341", "update_paraphrase": "PersonX is happy to work out with PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": 0.0, "syntactic_distance": 0.0}, {"confidence": [0.9501847624778748, 0.04981524497270584], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5341.gpt3.0", "original_example": {"example_id": "atomic.train.5341", "premise_hypothesis_id": "atomic.train.2522", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eYo0WhrNXcHsDBpsybI8xg==", "AtomicEventRelationId": "xR-IR4_tyDuAD86bFhfByg==", "AtomicRelationType": "xAttr", "AtomicInference": "driven"}, "premise": "PersonX wears PersonY out", "hypothesis": "As a result, PersonX feels driven", "update": "PersonX is happy to work out with PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5341", "update_paraphrase": "PersonX is more than happy to work out with PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.11111111111111116, "pred_conf_shift": -0.004104692488908768, "syntactic_distance": 0.058823529411764705}]}, "atomic.train.14064": {"original_confidence": [0.38243570923805237, 0.6175642609596252], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.38678744435310364, 0.613212525844574], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.14064.gpt3.1", "original_example": {"example_id": "atomic.train.14064", "premise_hypothesis_id": "atomic.train.6566", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "1x4OXxg_pGK5vNIcF4sppw==", "AtomicEventRelationId": "zaAWcQG4e64LduzAI6Vqug==", "AtomicRelationType": "xNeed", "AtomicInference": "hit PersonY"}, "premise": "PersonX knocks PersonX down with a feather", "hypothesis": "Before, PersonX needed hit PersonY", "update": "Person Y is a toddler.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14064", "update_paraphrase": "Person Y is a young child who is not yet old enough to go to school.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5805675805675806, "pred_conf_shift": 0.0043517351150512695, "syntactic_distance": 0.14285714285714285}, {"confidence": [0.3891662359237671, 0.6108337044715881], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.14064.gpt3.2", "original_example": {"example_id": "atomic.train.14064", "premise_hypothesis_id": "atomic.train.6566", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "1x4OXxg_pGK5vNIcF4sppw==", "AtomicEventRelationId": "zaAWcQG4e64LduzAI6Vqug==", "AtomicRelationType": "xNeed", "AtomicInference": "hit PersonY"}, "premise": "PersonX knocks PersonX down with a feather", "hypothesis": "Before, PersonX needed hit PersonY", "update": "Person Y is a toddler.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14064", "update_paraphrase": "Person Y is still a young child.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3459595959595959, "pred_conf_shift": 0.006730526685714722, "syntactic_distance": 0.13043478260869565}, {"confidence": [0.2079177051782608, 0.7920823097229004], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.14064.gpt3.5", "original_example": {"example_id": "atomic.train.14064", "premise_hypothesis_id": "atomic.train.6566", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "1x4OXxg_pGK5vNIcF4sppw==", "AtomicEventRelationId": "zaAWcQG4e64LduzAI6Vqug==", "AtomicRelationType": "xNeed", "AtomicInference": "hit PersonY"}, "premise": "PersonX knocks PersonX down with a feather", "hypothesis": "Before, PersonX needed hit PersonY", "update": "Person Y is a toddler.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14064", "update_paraphrase": "Person Y is a small child.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2410468319559229, "pred_conf_shift": -0.17451800405979156, "syntactic_distance": 0.047619047619047616}, {"confidence": [0.17898213863372803, 0.8210178017616272], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.14064.gpt3.0", "original_example": {"example_id": "atomic.train.14064", "premise_hypothesis_id": "atomic.train.6566", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "1x4OXxg_pGK5vNIcF4sppw==", "AtomicEventRelationId": "zaAWcQG4e64LduzAI6Vqug==", "AtomicRelationType": "xNeed", "AtomicInference": "hit PersonY"}, "premise": "PersonX knocks PersonX down with a feather", "hypothesis": "Before, PersonX needed hit PersonY", "update": "Person Y is a toddler.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14064", "update_paraphrase": "Person Y is a very young child.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2696969696969697, "pred_conf_shift": -0.20345357060432434, "syntactic_distance": 0.047619047619047616}, {"confidence": [0.4129320979118347, 0.5870679616928101], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.14064.gpt3.6", "original_example": {"example_id": "atomic.train.14064", "premise_hypothesis_id": "atomic.train.6566", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "1x4OXxg_pGK5vNIcF4sppw==", "AtomicEventRelationId": "zaAWcQG4e64LduzAI6Vqug==", "AtomicRelationType": "xNeed", "AtomicInference": "hit PersonY"}, "premise": "PersonX knocks PersonX down with a feather", "hypothesis": "Before, PersonX needed hit PersonY", "update": "Person Y is a toddler.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14064", "update_paraphrase": "Person Y is a small child who is not yet old enough to attend school.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5611111111111111, "pred_conf_shift": 0.03049638867378235, "syntactic_distance": 0.14285714285714285}, {"confidence": [0.4390367269515991, 0.5609632730484009], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.14064.gpt3.3", "original_example": {"example_id": "atomic.train.14064", "premise_hypothesis_id": "atomic.train.6566", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "1x4OXxg_pGK5vNIcF4sppw==", "AtomicEventRelationId": "zaAWcQG4e64LduzAI6Vqug==", "AtomicRelationType": "xNeed", "AtomicInference": "hit PersonY"}, "premise": "PersonX knocks PersonX down with a feather", "hypothesis": "Before, PersonX needed hit PersonY", "update": "Person Y is a toddler.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14064", "update_paraphrase": "Person Y is a young child who is not yet old enough to attend school.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5595959595959596, "pred_conf_shift": 0.05660101771354675, "syntactic_distance": 0.14285714285714285}, {"confidence": [0.38602298498153687, 0.6139769554138184], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.14064.gpt3.4", "original_example": {"example_id": "atomic.train.14064", "premise_hypothesis_id": "atomic.train.6566", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "1x4OXxg_pGK5vNIcF4sppw==", "AtomicEventRelationId": "zaAWcQG4e64LduzAI6Vqug==", "AtomicRelationType": "xNeed", "AtomicInference": "hit PersonY"}, "premise": "PersonX knocks PersonX down with a feather", "hypothesis": "Before, PersonX needed hit PersonY", "update": "Person Y is a toddler.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14064", "update_paraphrase": "Person Y is still a baby/young child.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.35707070707070704, "pred_conf_shift": 0.003587275743484497, "syntactic_distance": 0.13043478260869565}]}, "atomic.train.6684": {"original_confidence": [0.08630957454442978, 0.913690447807312], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.15965034067630768, 0.8403496742248535], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.6684.gpt3.1", "original_example": {"example_id": "atomic.train.6684", "premise_hypothesis_id": "atomic.train.3163", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "LopsSDDbnQ-PHOcdI-ltaA==", "AtomicEventRelationId": "t5Q0uegGtnligdqO8tQtUA==", "AtomicRelationType": "xNeed", "AtomicInference": "to do everything they wanted to do during the trip"}, "premise": "PersonX ends PersonX's trip", "hypothesis": "Before, PersonX needed to do everything they wanted to do during the trip", "update": "PersonX's hotel reservation had three remaining days.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6684", "update_paraphrase": "PersonX had three days left on their hotel reservation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.36547619047619045, "pred_conf_shift": 0.0733407661318779, "syntactic_distance": 0.2631578947368421}, {"confidence": [0.13296914100646973, 0.8670307993888855], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.6684.gpt3.0", "original_example": {"example_id": "atomic.train.6684", "premise_hypothesis_id": "atomic.train.3163", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "LopsSDDbnQ-PHOcdI-ltaA==", "AtomicEventRelationId": "t5Q0uegGtnligdqO8tQtUA==", "AtomicRelationType": "xNeed", "AtomicInference": "to do everything they wanted to do during the trip"}, "premise": "PersonX ends PersonX's trip", "hypothesis": "Before, PersonX needed to do everything they wanted to do during the trip", "update": "PersonX's hotel reservation had three remaining days.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6684", "update_paraphrase": "There were three days left on PersonX's hotel reservation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4651442307692308, "pred_conf_shift": 0.04665956646203995, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.30342555046081543, 0.6965744495391846], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.6684.gpt3.3", "original_example": {"example_id": "atomic.train.6684", "premise_hypothesis_id": "atomic.train.3163", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "LopsSDDbnQ-PHOcdI-ltaA==", "AtomicEventRelationId": "t5Q0uegGtnligdqO8tQtUA==", "AtomicRelationType": "xNeed", "AtomicInference": "to do everything they wanted to do during the trip"}, "premise": "PersonX ends PersonX's trip", "hypothesis": "Before, PersonX needed to do everything they wanted to do during the trip", "update": "PersonX's hotel reservation had three remaining days.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6684", "update_paraphrase": "PersonX's hotel room was reserved for three more days.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.40703019568151144, "pred_conf_shift": 0.21711597591638565, "syntactic_distance": 0.19047619047619047}, {"confidence": [0.26019203662872314, 0.7398079633712769], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.6684.gpt3.2", "original_example": {"example_id": "atomic.train.6684", "premise_hypothesis_id": "atomic.train.3163", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "LopsSDDbnQ-PHOcdI-ltaA==", "AtomicEventRelationId": "t5Q0uegGtnligdqO8tQtUA==", "AtomicRelationType": "xNeed", "AtomicInference": "to do everything they wanted to do during the trip"}, "premise": "PersonX ends PersonX's trip", "hypothesis": "Before, PersonX needed to do everything they wanted to do during the trip", "update": "PersonX's hotel reservation had three remaining days.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6684", "update_paraphrase": "PersonX's hotel reservation was for three more days.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3006993006993007, "pred_conf_shift": 0.17388246208429337, "syntactic_distance": 0.19047619047619047}, {"confidence": [0.2187785804271698, 0.7812213897705078], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.6684.gpt3.4", "original_example": {"example_id": "atomic.train.6684", "premise_hypothesis_id": "atomic.train.3163", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "LopsSDDbnQ-PHOcdI-ltaA==", "AtomicEventRelationId": "t5Q0uegGtnligdqO8tQtUA==", "AtomicRelationType": "xNeed", "AtomicInference": "to do everything they wanted to do during the trip"}, "premise": "PersonX ends PersonX's trip", "hypothesis": "Before, PersonX needed to do everything they wanted to do during the trip", "update": "PersonX's hotel reservation had three remaining days.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6684", "update_paraphrase": "PersonX only had three days left on their hotel reservation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.376657329598506, "pred_conf_shift": 0.13246900588274002, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.1280415654182434, 0.8719584345817566], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.6684.gpt3.5", "original_example": {"example_id": "atomic.train.6684", "premise_hypothesis_id": "atomic.train.3163", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "LopsSDDbnQ-PHOcdI-ltaA==", "AtomicEventRelationId": "t5Q0uegGtnligdqO8tQtUA==", "AtomicRelationType": "xNeed", "AtomicInference": "to do everything they wanted to do during the trip"}, "premise": "PersonX ends PersonX's trip", "hypothesis": "Before, PersonX needed to do everything they wanted to do during the trip", "update": "PersonX's hotel reservation had three remaining days.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6684", "update_paraphrase": "There were only three days left on PersonX's hotel reservation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4966063348416289, "pred_conf_shift": 0.04173199087381363, "syntactic_distance": 0.3157894736842105}]}, "atomic.train.28248": {"original_confidence": [0.21087269484996796, 0.7891272306442261], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.0345776304602623, 0.9654223322868347], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.28248.gpt3.4", "original_example": {"example_id": "atomic.train.28248", "premise_hypothesis_id": "atomic.train.12828", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "3z3CsanqxR6oESdFdd2C5w==", "AtomicEventRelationId": "0z6hWCnuXfeGi7fJRhHmfA==", "AtomicRelationType": "xWant", "AtomicInference": "To expand business"}, "premise": "PersonX gives PersonY a haircut", "hypothesis": "As a result, PersonX wants to expand business", "update": "PersonX decides to switch careers.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.28248", "update_paraphrase": "PersonX has decided to make a career change.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42276697661313045, "pred_conf_shift": -0.17629506438970566, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.09291820228099823, 0.9070817828178406], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.28248.gpt3.3", "original_example": {"example_id": "atomic.train.28248", "premise_hypothesis_id": "atomic.train.12828", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "3z3CsanqxR6oESdFdd2C5w==", "AtomicEventRelationId": "0z6hWCnuXfeGi7fJRhHmfA==", "AtomicRelationType": "xWant", "AtomicInference": "To expand business"}, "premise": "PersonX gives PersonY a haircut", "hypothesis": "As a result, PersonX wants to expand business", "update": "PersonX decides to switch careers.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.28248", "update_paraphrase": "PersonX decides to change careers.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.15128205128205136, "pred_conf_shift": -0.11795449256896973, "syntactic_distance": 0.0}, {"confidence": [0.11261418461799622, 0.8873857855796814], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.28248.gpt3.1", "original_example": {"example_id": "atomic.train.28248", "premise_hypothesis_id": "atomic.train.12828", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "3z3CsanqxR6oESdFdd2C5w==", "AtomicEventRelationId": "0z6hWCnuXfeGi7fJRhHmfA==", "AtomicRelationType": "xWant", "AtomicInference": "To expand business"}, "premise": "PersonX gives PersonY a haircut", "hypothesis": "As a result, PersonX wants to expand business", "update": "PersonX decides to switch careers.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.28248", "update_paraphrase": "PersonX has decided to change careers.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2502164502164502, "pred_conf_shift": -0.09825851023197174, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.06305740028619766, 0.936942458152771], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.28248.gpt3.2", "original_example": {"example_id": "atomic.train.28248", "premise_hypothesis_id": "atomic.train.12828", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "3z3CsanqxR6oESdFdd2C5w==", "AtomicEventRelationId": "0z6hWCnuXfeGi7fJRhHmfA==", "AtomicRelationType": "xWant", "AtomicInference": "To expand business"}, "premise": "PersonX gives PersonY a haircut", "hypothesis": "As a result, PersonX wants to expand business", "update": "PersonX decides to switch careers.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.28248", "update_paraphrase": "PersonX decides to change career paths.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2944479762661581, "pred_conf_shift": -0.1478152945637703, "syntactic_distance": 0.0}, {"confidence": [0.12836813926696777, 0.8716318607330322], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.28248.gpt3.0", "original_example": {"example_id": "atomic.train.28248", "premise_hypothesis_id": "atomic.train.12828", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "3z3CsanqxR6oESdFdd2C5w==", "AtomicEventRelationId": "0z6hWCnuXfeGi7fJRhHmfA==", "AtomicRelationType": "xWant", "AtomicInference": "To expand business"}, "premise": "PersonX gives PersonY a haircut", "hypothesis": "As a result, PersonX wants to expand business", "update": "PersonX decides to switch careers.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.28248", "update_paraphrase": "PersonX is changing careers.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4149029982363316, "pred_conf_shift": -0.08250455558300018, "syntactic_distance": 0.26666666666666666}]}, "atomic.train.11433": {"original_confidence": [0.051421158015728, 0.9485787749290466], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.035391390323638916, 0.9646087288856506], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11433.gpt3.4", "original_example": {"example_id": "atomic.train.11433", "premise_hypothesis_id": "atomic.train.5377", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "z-zAlFMM0Y_c8e6j6J9pjg==", "AtomicEventRelationId": "QAQ3fW27Sdwfliu1GrCbPg==", "AtomicRelationType": "xNeed", "AtomicInference": "to receive flattery from persony"}, "premise": "PersonX returns PersonY's attention", "hypothesis": "Before, PersonX needed to receive flattery from persony", "update": "PersonX is a vain person.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11433", "update_paraphrase": "PersonX is conceited and cares a lot about their appearance.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4928571428571429, "pred_conf_shift": 0.016029953956604004, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.10436628013849258, 0.8956336379051208], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11433.gpt3.0", "original_example": {"example_id": "atomic.train.11433", "premise_hypothesis_id": "atomic.train.5377", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "z-zAlFMM0Y_c8e6j6J9pjg==", "AtomicEventRelationId": "QAQ3fW27Sdwfliu1GrCbPg==", "AtomicRelationType": "xNeed", "AtomicInference": "to receive flattery from persony"}, "premise": "PersonX returns PersonY's attention", "hypothesis": "Before, PersonX needed to receive flattery from persony", "update": "PersonX is a vain person.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11433", "update_paraphrase": "Person X is conceited and self-centered.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.48903873903873907, "pred_conf_shift": -0.05294513702392578, "syntactic_distance": 0.2631578947368421}, {"confidence": [0.6143171787261963, 0.3856828510761261], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11433.gpt3.8", "original_example": {"example_id": "atomic.train.11433", "premise_hypothesis_id": "atomic.train.5377", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "z-zAlFMM0Y_c8e6j6J9pjg==", "AtomicEventRelationId": "QAQ3fW27Sdwfliu1GrCbPg==", "AtomicRelationType": "xNeed", "AtomicInference": "to receive flattery from persony"}, "premise": "PersonX returns PersonY's attention", "hypothesis": "Before, PersonX needed to receive flattery from persony", "update": "PersonX is a vain person.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11433", "update_paraphrase": "PersonX is full of themselves and only concerned with their own appearance.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6367137764196588, "pred_conf_shift": -0.5628959238529205, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.038113176822662354, 0.9618868231773376], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11433.gpt3.5", "original_example": {"example_id": "atomic.train.11433", "premise_hypothesis_id": "atomic.train.5377", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "z-zAlFMM0Y_c8e6j6J9pjg==", "AtomicEventRelationId": "QAQ3fW27Sdwfliu1GrCbPg==", "AtomicRelationType": "xNeed", "AtomicInference": "to receive flattery from persony"}, "premise": "PersonX returns PersonY's attention", "hypothesis": "Before, PersonX needed to receive flattery from persony", "update": "PersonX is a vain person.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11433", "update_paraphrase": "PersonX is a person who is very concerned with their appearance.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4214743589743589, "pred_conf_shift": 0.013308048248291016, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.06425498425960541, 0.9357450604438782], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11433.gpt3.1", "original_example": {"example_id": "atomic.train.11433", "premise_hypothesis_id": "atomic.train.5377", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "z-zAlFMM0Y_c8e6j6J9pjg==", "AtomicEventRelationId": "QAQ3fW27Sdwfliu1GrCbPg==", "AtomicRelationType": "xNeed", "AtomicInference": "to receive flattery from persony"}, "premise": "PersonX returns PersonY's attention", "hypothesis": "Before, PersonX needed to receive flattery from persony", "update": "PersonX is a vain person.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11433", "update_paraphrase": "PersonX is a conceited person.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.16643356643356644, "pred_conf_shift": -0.012833714485168457, "syntactic_distance": 0.0}, {"confidence": [0.08880238980054855, 0.9111975431442261], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11433.gpt3.6", "original_example": {"example_id": "atomic.train.11433", "premise_hypothesis_id": "atomic.train.5377", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "z-zAlFMM0Y_c8e6j6J9pjg==", "AtomicEventRelationId": "QAQ3fW27Sdwfliu1GrCbPg==", "AtomicRelationType": "xNeed", "AtomicInference": "to receive flattery from persony"}, "premise": "PersonX returns PersonY's attention", "hypothesis": "Before, PersonX needed to receive flattery from persony", "update": "PersonX is a vain person.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11433", "update_paraphrase": "PersonX is a narcissistic person.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.15681818181818186, "pred_conf_shift": -0.03738123178482056, "syntactic_distance": 0.0}, {"confidence": [0.3748590350151062, 0.625140905380249], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11433.gpt3.7", "original_example": {"example_id": "atomic.train.11433", "premise_hypothesis_id": "atomic.train.5377", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "z-zAlFMM0Y_c8e6j6J9pjg==", "AtomicEventRelationId": "QAQ3fW27Sdwfliu1GrCbPg==", "AtomicRelationType": "xNeed", "AtomicInference": "to receive flattery from persony"}, "premise": "PersonX returns PersonY's attention", "hypothesis": "Before, PersonX needed to receive flattery from persony", "update": "PersonX is a vain person.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11433", "update_paraphrase": "PersonX is conceited and only cares about their own appearance.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5741702741702741, "pred_conf_shift": -0.3234378695487976, "syntactic_distance": 0.4090909090909091}, {"confidence": [0.12759166955947876, 0.8724082708358765], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11433.gpt3.2", "original_example": {"example_id": "atomic.train.11433", "premise_hypothesis_id": "atomic.train.5377", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "z-zAlFMM0Y_c8e6j6J9pjg==", "AtomicEventRelationId": "QAQ3fW27Sdwfliu1GrCbPg==", "AtomicRelationType": "xNeed", "AtomicInference": "to receive flattery from persony"}, "premise": "PersonX returns PersonY's attention", "hypothesis": "Before, PersonX needed to receive flattery from persony", "update": "PersonX is a vain person.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11433", "update_paraphrase": "PersonX is obsessed with their own appearance and very self-centered.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5742857142857143, "pred_conf_shift": -0.07617050409317017, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.0969402864575386, 0.903059720993042], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11433.gpt3.3", "original_example": {"example_id": "atomic.train.11433", "premise_hypothesis_id": "atomic.train.5377", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "z-zAlFMM0Y_c8e6j6J9pjg==", "AtomicEventRelationId": "QAQ3fW27Sdwfliu1GrCbPg==", "AtomicRelationType": "xNeed", "AtomicInference": "to receive flattery from persony"}, "premise": "PersonX returns PersonY's attention", "hypothesis": "Before, PersonX needed to receive flattery from persony", "update": "PersonX is a vain person.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11433", "update_paraphrase": "PersonX is interested in their appearance and tends to be self-centered.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5612745098039216, "pred_conf_shift": -0.04551905393600464, "syntactic_distance": 0.4}]}, "atomic.train.9820": {"original_confidence": [0.42923399806022644, 0.5707660913467407], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.567887544631958, 0.43211254477500916], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9820.gpt3.2", "original_example": {"example_id": "atomic.train.9820", "premise_hypothesis_id": "atomic.train.4631", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "GNuGKVMa0A1-pMVgqpDVLA==", "AtomicEventRelationId": "VQRZmineO3NP4p8lDuBUNQ==", "AtomicRelationType": "xWant", "AtomicInference": "to pass Y his phone."}, "premise": "PersonX reaches for PersonY's phone", "hypothesis": "As a result, PersonX wants to pass Y his phone.", "update": "PersonX is PersonY's teacher.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9820", "update_paraphrase": "PersonX teaches PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22176870748299315, "pred_conf_shift": 0.13865354657173157, "syntactic_distance": 0.06666666666666667}, {"confidence": [0.5369662046432495, 0.4630338251590729], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9820.gpt3.3", "original_example": {"example_id": "atomic.train.9820", "premise_hypothesis_id": "atomic.train.4631", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "GNuGKVMa0A1-pMVgqpDVLA==", "AtomicEventRelationId": "VQRZmineO3NP4p8lDuBUNQ==", "AtomicRelationType": "xWant", "AtomicInference": "to pass Y his phone."}, "premise": "PersonX reaches for PersonY's phone", "hypothesis": "As a result, PersonX wants to pass Y his phone.", "update": "PersonX is PersonY's teacher.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9820", "update_paraphrase": "Person Y's teacher is Person X.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.34395604395604396, "pred_conf_shift": 0.10773220658302307, "syntactic_distance": 0.3}, {"confidence": [0.2474585920572281, 0.7525414228439331], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9820.gpt3.6", "original_example": {"example_id": "atomic.train.9820", "premise_hypothesis_id": "atomic.train.4631", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "GNuGKVMa0A1-pMVgqpDVLA==", "AtomicEventRelationId": "VQRZmineO3NP4p8lDuBUNQ==", "AtomicRelationType": "xWant", "AtomicInference": "to pass Y his phone."}, "premise": "PersonX reaches for PersonY's phone", "hypothesis": "As a result, PersonX wants to pass Y his phone.", "update": "PersonX is PersonY's teacher.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9820", "update_paraphrase": "Person X is the teacher of person Y.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42624042624042624, "pred_conf_shift": -0.18177540600299835, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.5761473774909973, 0.4238526225090027], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9820.gpt3.4", "original_example": {"example_id": "atomic.train.9820", "premise_hypothesis_id": "atomic.train.4631", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "GNuGKVMa0A1-pMVgqpDVLA==", "AtomicEventRelationId": "VQRZmineO3NP4p8lDuBUNQ==", "AtomicRelationType": "xWant", "AtomicInference": "to pass Y his phone."}, "premise": "PersonX reaches for PersonY's phone", "hypothesis": "As a result, PersonX wants to pass Y his phone.", "update": "PersonX is PersonY's teacher.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9820", "update_paraphrase": "PersonY is taught by PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3275539275539275, "pred_conf_shift": 0.14691337943077087, "syntactic_distance": 0.1875}, {"confidence": [0.7768357992172241, 0.22316418588161469], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9820.gpt3.5", "original_example": {"example_id": "atomic.train.9820", "premise_hypothesis_id": "atomic.train.4631", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "GNuGKVMa0A1-pMVgqpDVLA==", "AtomicEventRelationId": "VQRZmineO3NP4p8lDuBUNQ==", "AtomicRelationType": "xWant", "AtomicInference": "to pass Y his phone."}, "premise": "PersonX reaches for PersonY's phone", "hypothesis": "As a result, PersonX wants to pass Y his phone.", "update": "PersonX is PersonY's teacher.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9820", "update_paraphrase": "PersonX is the one who teaches PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3956709956709957, "pred_conf_shift": 0.3476018011569977, "syntactic_distance": 0.125}, {"confidence": [0.578842043876648, 0.42115798592567444], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9820.gpt3.1", "original_example": {"example_id": "atomic.train.9820", "premise_hypothesis_id": "atomic.train.4631", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "GNuGKVMa0A1-pMVgqpDVLA==", "AtomicEventRelationId": "VQRZmineO3NP4p8lDuBUNQ==", "AtomicRelationType": "xWant", "AtomicInference": "to pass Y his phone."}, "premise": "PersonX reaches for PersonY's phone", "hypothesis": "As a result, PersonX wants to pass Y his phone.", "update": "PersonX is PersonY's teacher.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9820", "update_paraphrase": "PersonY's teacher is PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.175, "pred_conf_shift": 0.1496080458164215, "syntactic_distance": 0.125}, {"confidence": [0.2508046627044678, 0.7491952776908875], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9820.gpt3.0", "original_example": {"example_id": "atomic.train.9820", "premise_hypothesis_id": "atomic.train.4631", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "GNuGKVMa0A1-pMVgqpDVLA==", "AtomicEventRelationId": "VQRZmineO3NP4p8lDuBUNQ==", "AtomicRelationType": "xWant", "AtomicInference": "to pass Y his phone."}, "premise": "PersonX reaches for PersonY's phone", "hypothesis": "As a result, PersonX wants to pass Y his phone.", "update": "PersonX is PersonY's teacher.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9820", "update_paraphrase": "PersonX is the teacher of PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.32095238095238093, "pred_conf_shift": -0.17842933535575867, "syntactic_distance": 0.125}]}, "atomic.train.15043": {"original_confidence": [0.5962826013565063, 0.4037174582481384], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.5969457030296326, 0.40305429697036743], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15043.gpt3.7", "original_example": {"example_id": "atomic.train.15043", "premise_hypothesis_id": "atomic.train.7018", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "UsRFnsgdN90R7qgiY077JA==", "AtomicEventRelationId": "PDCz9Uo7_Xv3SsKAwU7BmA==", "AtomicRelationType": "xAttr", "AtomicInference": "seafaring"}, "premise": "PersonX transports PersonY to an island", "hypothesis": "As a result, PersonX feels seafaring", "update": "PersonX offers to transport PersonY home from the island later.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15043", "update_paraphrase": "PersonX offers to take PersonY home from the island at a later time.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.31752305665349145, "pred_conf_shift": -0.0006631612777709961, "syntactic_distance": 0.0}, {"confidence": [0.5451362133026123, 0.4548637568950653], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15043.gpt3.2", "original_example": {"example_id": "atomic.train.15043", "premise_hypothesis_id": "atomic.train.7018", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "UsRFnsgdN90R7qgiY077JA==", "AtomicEventRelationId": "PDCz9Uo7_Xv3SsKAwU7BmA==", "AtomicRelationType": "xAttr", "AtomicInference": "seafaring"}, "premise": "PersonX transports PersonY to an island", "hypothesis": "As a result, PersonX feels seafaring", "update": "PersonX offers to transport PersonY home from the island later.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15043", "update_paraphrase": "Person X offers to take Person Y home from the island at a later time.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2654545454545455, "pred_conf_shift": 0.05114629864692688, "syntactic_distance": 0.06666666666666667}, {"confidence": [0.8922615051269531, 0.10773849487304688], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15043.gpt3.1", "original_example": {"example_id": "atomic.train.15043", "premise_hypothesis_id": "atomic.train.7018", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "UsRFnsgdN90R7qgiY077JA==", "AtomicEventRelationId": "PDCz9Uo7_Xv3SsKAwU7BmA==", "AtomicRelationType": "xAttr", "AtomicInference": "seafaring"}, "premise": "PersonX transports PersonY to an island", "hypothesis": "As a result, PersonX feels seafaring", "update": "PersonX offers to transport PersonY home from the island later.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15043", "update_paraphrase": "PersonX proposes to take PersonY home from the island at a later time.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28137080310993356, "pred_conf_shift": -0.29597896337509155, "syntactic_distance": 0.0}, {"confidence": [0.4393261671066284, 0.5606738328933716], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15043.gpt3.4", "original_example": {"example_id": "atomic.train.15043", "premise_hypothesis_id": "atomic.train.7018", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "UsRFnsgdN90R7qgiY077JA==", "AtomicEventRelationId": "PDCz9Uo7_Xv3SsKAwU7BmA==", "AtomicRelationType": "xAttr", "AtomicInference": "seafaring"}, "premise": "PersonX transports PersonY to an island", "hypothesis": "As a result, PersonX feels seafaring", "update": "PersonX offers to transport PersonY home from the island later.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15043", "update_paraphrase": "PersonX offers to give PersonY a ride home from the island later on.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.32874082439299834, "pred_conf_shift": 0.15695637464523315, "syntactic_distance": 0.0}, {"confidence": [0.8282271027565002, 0.17177297174930573], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15043.gpt3.0", "original_example": {"example_id": "atomic.train.15043", "premise_hypothesis_id": "atomic.train.7018", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "UsRFnsgdN90R7qgiY077JA==", "AtomicEventRelationId": "PDCz9Uo7_Xv3SsKAwU7BmA==", "AtomicRelationType": "xAttr", "AtomicInference": "seafaring"}, "premise": "PersonX transports PersonY to an island", "hypothesis": "As a result, PersonX feels seafaring", "update": "PersonX offers to transport PersonY home from the island later.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15043", "update_paraphrase": "PersonX offers to drive PersonY home from the island at a later time.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3241106719367589, "pred_conf_shift": -0.2319444864988327, "syntactic_distance": 0.0}, {"confidence": [0.7564947605133057, 0.24350520968437195], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15043.gpt3.3", "original_example": {"example_id": "atomic.train.15043", "premise_hypothesis_id": "atomic.train.7018", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "UsRFnsgdN90R7qgiY077JA==", "AtomicEventRelationId": "PDCz9Uo7_Xv3SsKAwU7BmA==", "AtomicRelationType": "xAttr", "AtomicInference": "seafaring"}, "premise": "PersonX transports PersonY to an island", "hypothesis": "As a result, PersonX feels seafaring", "update": "PersonX offers to transport PersonY home from the island later.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15043", "update_paraphrase": "PersonX offers to transport PersonY back to the mainland later on.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2804232804232804, "pred_conf_shift": -0.16021224856376648, "syntactic_distance": 0.0}, {"confidence": [0.9352286458015442, 0.06477132439613342], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15043.gpt3.5", "original_example": {"example_id": "atomic.train.15043", "premise_hypothesis_id": "atomic.train.7018", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "UsRFnsgdN90R7qgiY077JA==", "AtomicEventRelationId": "PDCz9Uo7_Xv3SsKAwU7BmA==", "AtomicRelationType": "xAttr", "AtomicInference": "seafaring"}, "premise": "PersonX transports PersonY to an island", "hypothesis": "As a result, PersonX feels seafaring", "update": "PersonX offers to transport PersonY home from the island later.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15043", "update_paraphrase": "PersonX promised to give PersonY a ride back to the mainland later.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4085792994883904, "pred_conf_shift": -0.338946133852005, "syntactic_distance": 0.07142857142857142}, {"confidence": [0.9049949049949646, 0.09500499814748764], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15043.gpt3.6", "original_example": {"example_id": "atomic.train.15043", "premise_hypothesis_id": "atomic.train.7018", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "UsRFnsgdN90R7qgiY077JA==", "AtomicEventRelationId": "PDCz9Uo7_Xv3SsKAwU7BmA==", "AtomicRelationType": "xAttr", "AtomicInference": "seafaring"}, "premise": "PersonX transports PersonY to an island", "hypothesis": "As a result, PersonX feels seafaring", "update": "PersonX offers to transport PersonY home from the island later.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15043", "update_paraphrase": "PersonX tells PersonY that they will give them a ride home from the island later.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37004062604062604, "pred_conf_shift": -0.3087124601006508, "syntactic_distance": 0.29411764705882354}]}, "atomic.train.38353": {"original_confidence": [0.1611330509185791, 0.8388668894767761], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.4365848898887634, 0.5634151101112366], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38353.gpt3.4", "original_example": {"example_id": "atomic.train.38353", "premise_hypothesis_id": "atomic.train.17407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y2qCX-s_lhAnsozDKfokkQ==", "AtomicEventRelationId": "oaiRNf9Whqt2DNn_2EtYWw==", "AtomicRelationType": "xNeed", "AtomicInference": "Contact person Y"}, "premise": "PersonX wants to hang out with PersonY", "hypothesis": "Before, PersonX needed contact person Y", "update": "They live in different countries", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38353", "update_paraphrase": "They don't live in the same country.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3573717948717948, "pred_conf_shift": -0.27545177936553955, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.17574241757392883, 0.8242576122283936], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38353.gpt3.1", "original_example": {"example_id": "atomic.train.38353", "premise_hypothesis_id": "atomic.train.17407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y2qCX-s_lhAnsozDKfokkQ==", "AtomicEventRelationId": "oaiRNf9Whqt2DNn_2EtYWw==", "AtomicRelationType": "xNeed", "AtomicInference": "Contact person Y"}, "premise": "PersonX wants to hang out with PersonY", "hypothesis": "Before, PersonX needed contact person Y", "update": "They live in different countries", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38353", "update_paraphrase": "They reside in different countries.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.13499999999999995, "pred_conf_shift": -0.014609277248382568, "syntactic_distance": 0.0}, {"confidence": [0.22709700465202332, 0.7729030251502991], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38353.gpt3.0", "original_example": {"example_id": "atomic.train.38353", "premise_hypothesis_id": "atomic.train.17407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y2qCX-s_lhAnsozDKfokkQ==", "AtomicEventRelationId": "oaiRNf9Whqt2DNn_2EtYWw==", "AtomicRelationType": "xNeed", "AtomicInference": "Contact person Y"}, "premise": "PersonX wants to hang out with PersonY", "hypothesis": "Before, PersonX needed contact person Y", "update": "They live in different countries", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38353", "update_paraphrase": "They have residences in different nations.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2922077922077922, "pred_conf_shift": -0.06596386432647705, "syntactic_distance": 0.1875}, {"confidence": [0.15083453059196472, 0.8491654992103577], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38353.gpt3.5", "original_example": {"example_id": "atomic.train.38353", "premise_hypothesis_id": "atomic.train.17407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y2qCX-s_lhAnsozDKfokkQ==", "AtomicEventRelationId": "oaiRNf9Whqt2DNn_2EtYWw==", "AtomicRelationType": "xNeed", "AtomicInference": "Contact person Y"}, "premise": "PersonX wants to hang out with PersonY", "hypothesis": "Before, PersonX needed contact person Y", "update": "They live in different countries", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38353", "update_paraphrase": "They live in different parts of the world.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.29304029304029294, "pred_conf_shift": 0.010298609733581543, "syntactic_distance": 0.0}, {"confidence": [0.4390440881252289, 0.5609558820724487], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38353.gpt3.6", "original_example": {"example_id": "atomic.train.38353", "premise_hypothesis_id": "atomic.train.17407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y2qCX-s_lhAnsozDKfokkQ==", "AtomicEventRelationId": "oaiRNf9Whqt2DNn_2EtYWw==", "AtomicRelationType": "xNeed", "AtomicInference": "Contact person Y"}, "premise": "PersonX wants to hang out with PersonY", "hypothesis": "Before, PersonX needed contact person Y", "update": "They live in different countries", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38353", "update_paraphrase": "They live in separate countries.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.14932126696832587, "pred_conf_shift": -0.2779110074043274, "syntactic_distance": 0.0}, {"confidence": [0.20960146188735962, 0.7903985381126404], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38353.gpt3.2", "original_example": {"example_id": "atomic.train.38353", "premise_hypothesis_id": "atomic.train.17407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y2qCX-s_lhAnsozDKfokkQ==", "AtomicEventRelationId": "oaiRNf9Whqt2DNn_2EtYWw==", "AtomicRelationType": "xNeed", "AtomicInference": "Contact person Y"}, "premise": "PersonX wants to hang out with PersonY", "hypothesis": "Before, PersonX needed contact person Y", "update": "They live in different countries", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38353", "update_paraphrase": "They reside in different nations.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.27, "pred_conf_shift": -0.04846835136413574, "syntactic_distance": 0.0}]}, "atomic.train.26075": {"original_confidence": [0.21465964615345, 0.7853402495384216], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.1864987164735794, 0.813501238822937], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.26075.gpt3.4", "original_example": {"example_id": "atomic.train.26075", "premise_hypothesis_id": "atomic.train.11893", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DOktzaxfvjouj8Glh7Dszw==", "AtomicEventRelationId": "UClEtfgfkk7YQ5azDBQ7BA==", "AtomicRelationType": "xWant", "AtomicInference": "to not feel negativity"}, "premise": "PersonX really enjoy", "hypothesis": "As a result, PersonX wants to not feel negativity", "update": "X likes his alone time.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26075", "update_paraphrase": "X prefers time by himself.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.47333333333333333, "pred_conf_shift": 0.02816098928451538, "syntactic_distance": 0.35294117647058826}, {"confidence": [0.21267861127853394, 0.7873213887214661], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.26075.gpt3.1", "original_example": {"example_id": "atomic.train.26075", "premise_hypothesis_id": "atomic.train.11893", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DOktzaxfvjouj8Glh7Dszw==", "AtomicEventRelationId": "UClEtfgfkk7YQ5azDBQ7BA==", "AtomicRelationType": "xWant", "AtomicInference": "to not feel negativity"}, "premise": "PersonX really enjoy", "hypothesis": "As a result, PersonX wants to not feel negativity", "update": "X likes his alone time.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26075", "update_paraphrase": "X enjoys spending time by himself.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5307339125520943, "pred_conf_shift": 0.0019811391830444336, "syntactic_distance": 0.35714285714285715}, {"confidence": [0.20966826379299164, 0.7903316617012024], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.26075.gpt3.6", "original_example": {"example_id": "atomic.train.26075", "premise_hypothesis_id": "atomic.train.11893", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DOktzaxfvjouj8Glh7Dszw==", "AtomicEventRelationId": "UClEtfgfkk7YQ5azDBQ7BA==", "AtomicRelationType": "xWant", "AtomicInference": "to not feel negativity"}, "premise": "PersonX really enjoy", "hypothesis": "As a result, PersonX wants to not feel negativity", "update": "X likes his alone time.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26075", "update_paraphrase": "X enjoys spending time alone.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39090909090909093, "pred_conf_shift": 0.004991412162780762, "syntactic_distance": 0.35714285714285715}, {"confidence": [0.2122523933649063, 0.7877476215362549], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.26075.gpt3.2", "original_example": {"example_id": "atomic.train.26075", "premise_hypothesis_id": "atomic.train.11893", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DOktzaxfvjouj8Glh7Dszw==", "AtomicEventRelationId": "UClEtfgfkk7YQ5azDBQ7BA==", "AtomicRelationType": "xWant", "AtomicInference": "to not feel negativity"}, "premise": "PersonX really enjoy", "hypothesis": "As a result, PersonX wants to not feel negativity", "update": "X likes his alone time.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26075", "update_paraphrase": "X likes spending time alone.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3151515151515151, "pred_conf_shift": 0.002407371997833252, "syntactic_distance": 0.2857142857142857}, {"confidence": [0.28989291191101074, 0.7101070284843445], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.26075.gpt3.0", "original_example": {"example_id": "atomic.train.26075", "premise_hypothesis_id": "atomic.train.11893", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DOktzaxfvjouj8Glh7Dszw==", "AtomicEventRelationId": "UClEtfgfkk7YQ5azDBQ7BA==", "AtomicRelationType": "xWant", "AtomicInference": "to not feel negativity"}, "premise": "PersonX really enjoy", "hypothesis": "As a result, PersonX wants to not feel negativity", "update": "X likes his alone time.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26075", "update_paraphrase": "X appreciates time spent by himself.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5255050505050505, "pred_conf_shift": -0.07523322105407715, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.0856003388762474, 0.9143996834754944], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.26075.gpt3.5", "original_example": {"example_id": "atomic.train.26075", "premise_hypothesis_id": "atomic.train.11893", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DOktzaxfvjouj8Glh7Dszw==", "AtomicEventRelationId": "UClEtfgfkk7YQ5azDBQ7BA==", "AtomicRelationType": "xWant", "AtomicInference": "to not feel negativity"}, "premise": "PersonX really enjoy", "hypothesis": "As a result, PersonX wants to not feel negativity", "update": "X likes his alone time.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26075", "update_paraphrase": "X prefers to be alone.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5228571428571428, "pred_conf_shift": 0.12905943393707275, "syntactic_distance": 0.35714285714285715}, {"confidence": [0.14886192977428436, 0.8511379957199097], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.26075.gpt3.3", "original_example": {"example_id": "atomic.train.26075", "premise_hypothesis_id": "atomic.train.11893", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DOktzaxfvjouj8Glh7Dszw==", "AtomicEventRelationId": "UClEtfgfkk7YQ5azDBQ7BA==", "AtomicRelationType": "xWant", "AtomicInference": "to not feel negativity"}, "premise": "PersonX really enjoy", "hypothesis": "As a result, PersonX wants to not feel negativity", "update": "X likes his alone time.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26075", "update_paraphrase": "X prefers having time to himself.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5126852945034763, "pred_conf_shift": 0.06579774618148804, "syntactic_distance": 0.42857142857142855}]}, "atomic.train.18303": {"original_confidence": [0.20163781940937042, 0.798362135887146], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.24979129433631897, 0.7502086162567139], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18303.gpt3.5", "original_example": {"example_id": "atomic.train.18303", "premise_hypothesis_id": "atomic.train.8509", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DizBd1_so1iZKllTL_FRlw==", "AtomicEventRelationId": "U1fjWaYArya9cDWl3duwuQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to visit person Y's home"}, "premise": "PersonX talks to PersonY's neighbor", "hypothesis": "Before, PersonX needed to visit person Y's home", "update": "PersonX needed to return PersonY's lawn mowner.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18303", "update_paraphrase": "PersonX needed to give back PersonY's lawn mower.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3018181818181818, "pred_conf_shift": -0.04815351963043213, "syntactic_distance": 0.0}, {"confidence": [0.2580817937850952, 0.7419182062149048], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18303.gpt3.1", "original_example": {"example_id": "atomic.train.18303", "premise_hypothesis_id": "atomic.train.8509", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DizBd1_so1iZKllTL_FRlw==", "AtomicEventRelationId": "U1fjWaYArya9cDWl3duwuQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to visit person Y's home"}, "premise": "PersonX talks to PersonY's neighbor", "hypothesis": "Before, PersonX needed to visit person Y's home", "update": "PersonX needed to return PersonY's lawn mowner.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18303", "update_paraphrase": "PersonX needed to give PersonY's lawn mower back.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3018181818181818, "pred_conf_shift": -0.05644392967224121, "syntactic_distance": 0.0}, {"confidence": [0.38504815101623535, 0.6149518489837646], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18303.gpt3.0", "original_example": {"example_id": "atomic.train.18303", "premise_hypothesis_id": "atomic.train.8509", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DizBd1_so1iZKllTL_FRlw==", "AtomicEventRelationId": "U1fjWaYArya9cDWl3duwuQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to visit person Y's home"}, "premise": "PersonX talks to PersonY's neighbor", "hypothesis": "Before, PersonX needed to visit person Y's home", "update": "PersonX needed to return PersonY's lawn mowner.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18303", "update_paraphrase": "PersonX had to give PersonY's lawn mower back to them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.423321449792038, "pred_conf_shift": -0.18341028690338135, "syntactic_distance": 0.14285714285714285}, {"confidence": [0.3072226941585541, 0.6927773356437683], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18303.gpt3.3", "original_example": {"example_id": "atomic.train.18303", "premise_hypothesis_id": "atomic.train.8509", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DizBd1_so1iZKllTL_FRlw==", "AtomicEventRelationId": "U1fjWaYArya9cDWl3duwuQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to visit person Y's home"}, "premise": "PersonX talks to PersonY's neighbor", "hypothesis": "Before, PersonX needed to visit person Y's home", "update": "PersonX needed to return PersonY's lawn mowner.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18303", "update_paraphrase": "PersonX had to take PersonY's lawn mower back to them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.423321449792038, "pred_conf_shift": -0.10558480024337769, "syntactic_distance": 0.21428571428571427}, {"confidence": [0.2975914180278778, 0.7024086117744446], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18303.gpt3.2", "original_example": {"example_id": "atomic.train.18303", "premise_hypothesis_id": "atomic.train.8509", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DizBd1_so1iZKllTL_FRlw==", "AtomicEventRelationId": "U1fjWaYArya9cDWl3duwuQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to visit person Y's home"}, "premise": "PersonX talks to PersonY's neighbor", "hypothesis": "Before, PersonX needed to visit person Y's home", "update": "PersonX needed to return PersonY's lawn mowner.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18303", "update_paraphrase": "PersonX needed to give PersonY's lawn mower back to them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3318181818181818, "pred_conf_shift": -0.09595352411270142, "syntactic_distance": 0.0}, {"confidence": [0.34225013852119446, 0.6577499508857727], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18303.gpt3.4", "original_example": {"example_id": "atomic.train.18303", "premise_hypothesis_id": "atomic.train.8509", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DizBd1_so1iZKllTL_FRlw==", "AtomicEventRelationId": "U1fjWaYArya9cDWl3duwuQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to visit person Y's home"}, "premise": "PersonX talks to PersonY's neighbor", "hypothesis": "Before, PersonX needed to visit person Y's home", "update": "PersonX needed to return PersonY's lawn mowner.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18303", "update_paraphrase": "PersonX had to give PersonY's lawn mower back.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3497643097643097, "pred_conf_shift": -0.1406121850013733, "syntactic_distance": 0.14285714285714285}]}, "atomic.train.30104": {"original_confidence": [0.9748451113700867, 0.025154922157526016], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.9611198902130127, 0.03888016566634178], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.30104.gpt3.1", "original_example": {"example_id": "atomic.train.30104", "premise_hypothesis_id": "atomic.train.13673", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BL5rTOQOaX-YiJPm9S2CeQ==", "AtomicEventRelationId": "xU3v0O5lHF-Ln5Xh_XECVQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to put it on the oven"}, "premise": "PersonX makes a pizza", "hypothesis": "Before, PersonX needed to put it on the oven", "update": "It is a no bake desert pizza.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30104", "update_paraphrase": "This is a pizza that does not need to be baked in the oven.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5191987906273621, "pred_conf_shift": -0.013725221157073975, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.8477912545204163, 0.1522088348865509], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.30104.gpt3.5", "original_example": {"example_id": "atomic.train.30104", "premise_hypothesis_id": "atomic.train.13673", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BL5rTOQOaX-YiJPm9S2CeQ==", "AtomicEventRelationId": "xU3v0O5lHF-Ln5Xh_XECVQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to put it on the oven"}, "premise": "PersonX makes a pizza", "hypothesis": "Before, PersonX needed to put it on the oven", "update": "It is a no bake desert pizza.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30104", "update_paraphrase": "This pizza requires no baking!", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4873015873015873, "pred_conf_shift": -0.1270538568496704, "syntactic_distance": 0.21052631578947367}, {"confidence": [0.9722912311553955, 0.027708813548088074], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.30104.gpt3.6", "original_example": {"example_id": "atomic.train.30104", "premise_hypothesis_id": "atomic.train.13673", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BL5rTOQOaX-YiJPm9S2CeQ==", "AtomicEventRelationId": "xU3v0O5lHF-Ln5Xh_XECVQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to put it on the oven"}, "premise": "PersonX makes a pizza", "hypothesis": "Before, PersonX needed to put it on the oven", "update": "It is a no bake desert pizza.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30104", "update_paraphrase": "This is a pizza that does not require baking.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4333333333333333, "pred_conf_shift": -0.002553880214691162, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.9626131653785706, 0.037386953830718994], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.30104.gpt3.7", "original_example": {"example_id": "atomic.train.30104", "premise_hypothesis_id": "atomic.train.13673", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BL5rTOQOaX-YiJPm9S2CeQ==", "AtomicEventRelationId": "xU3v0O5lHF-Ln5Xh_XECVQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to put it on the oven"}, "premise": "PersonX makes a pizza", "hypothesis": "Before, PersonX needed to put it on the oven", "update": "It is a no bake desert pizza.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30104", "update_paraphrase": "This is a no bake pizza that is perfect for a desert.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3771929824561403, "pred_conf_shift": -0.012231945991516113, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.95158851146698, 0.048411473631858826], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.30104.gpt3.0", "original_example": {"example_id": "atomic.train.30104", "premise_hypothesis_id": "atomic.train.13673", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BL5rTOQOaX-YiJPm9S2CeQ==", "AtomicEventRelationId": "xU3v0O5lHF-Ln5Xh_XECVQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to put it on the oven"}, "premise": "PersonX makes a pizza", "hypothesis": "Before, PersonX needed to put it on the oven", "update": "It is a no bake desert pizza.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30104", "update_paraphrase": "This pizza doesn't require baking - it's a no-bake desert pizza.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.38235294117647056, "pred_conf_shift": -0.02325659990310669, "syntactic_distance": 0.4}, {"confidence": [0.9156122803688049, 0.08438767492771149], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.30104.gpt3.4", "original_example": {"example_id": "atomic.train.30104", "premise_hypothesis_id": "atomic.train.13673", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BL5rTOQOaX-YiJPm9S2CeQ==", "AtomicEventRelationId": "xU3v0O5lHF-Ln5Xh_XECVQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to put it on the oven"}, "premise": "PersonX makes a pizza", "hypothesis": "Before, PersonX needed to put it on the oven", "update": "It is a no bake desert pizza.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30104", "update_paraphrase": "This pizza doesn't need to be baked - it's already desert-ready!", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5349288735101884, "pred_conf_shift": -0.05923283100128174, "syntactic_distance": 0.4}, {"confidence": [0.9639620184898376, 0.036037955433130264], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.30104.gpt3.2", "original_example": {"example_id": "atomic.train.30104", "premise_hypothesis_id": "atomic.train.13673", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BL5rTOQOaX-YiJPm9S2CeQ==", "AtomicEventRelationId": "xU3v0O5lHF-Ln5Xh_XECVQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to put it on the oven"}, "premise": "PersonX makes a pizza", "hypothesis": "Before, PersonX needed to put it on the oven", "update": "It is a no bake desert pizza.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30104", "update_paraphrase": "This is a dessert pizza that does not require baking.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4168929110105581, "pred_conf_shift": -0.010883092880249023, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.9459726810455322, 0.054027386009693146], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.30104.gpt3.3", "original_example": {"example_id": "atomic.train.30104", "premise_hypothesis_id": "atomic.train.13673", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BL5rTOQOaX-YiJPm9S2CeQ==", "AtomicEventRelationId": "xU3v0O5lHF-Ln5Xh_XECVQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to put it on the oven"}, "premise": "PersonX makes a pizza", "hypothesis": "Before, PersonX needed to put it on the oven", "update": "It is a no bake desert pizza.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30104", "update_paraphrase": "This pizza does not need to be baked - it is ready to eat as is.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5631673881673882, "pred_conf_shift": -0.028872430324554443, "syntactic_distance": 0.46153846153846156}]}, "atomic.train.34863": {"original_confidence": [0.8189451694488525, 0.18105484545230865], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.6104806065559387, 0.3895193338394165], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34863.gpt3.2", "original_example": {"example_id": "atomic.train.34863", "premise_hypothesis_id": "atomic.train.15808", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "u6168AsNKsfmzzOG1ym4cw==", "AtomicEventRelationId": "VoJ__8zSOVFxm1jUdegbZw==", "AtomicRelationType": "xReact", "AtomicInference": "unburdened"}, "premise": "PersonX confronts PersonY", "hypothesis": "PersonX is seen as unburdened", "update": "PersonX wants nothing to do with them anymore", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34863", "update_paraphrase": "PersonX is no longer interested in having anything to do with them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.34194890077243023, "pred_conf_shift": 0.20846448838710785, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.35974642634391785, 0.6402535438537598], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34863.gpt3.0", "original_example": {"example_id": "atomic.train.34863", "premise_hypothesis_id": "atomic.train.15808", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "u6168AsNKsfmzzOG1ym4cw==", "AtomicEventRelationId": "VoJ__8zSOVFxm1jUdegbZw==", "AtomicRelationType": "xReact", "AtomicInference": "unburdened"}, "premise": "PersonX confronts PersonY", "hypothesis": "PersonX is seen as unburdened", "update": "PersonX wants nothing to do with them anymore", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34863", "update_paraphrase": "PersonX has completely cut off ties with them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.47286096256684496, "pred_conf_shift": 0.4591986984014511, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.6140784621238708, 0.38592156767845154], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34863.gpt3.4", "original_example": {"example_id": "atomic.train.34863", "premise_hypothesis_id": "atomic.train.15808", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "u6168AsNKsfmzzOG1ym4cw==", "AtomicEventRelationId": "VoJ__8zSOVFxm1jUdegbZw==", "AtomicRelationType": "xReact", "AtomicInference": "unburdened"}, "premise": "PersonX confronts PersonY", "hypothesis": "PersonX is seen as unburdened", "update": "PersonX wants nothing to do with them anymore", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34863", "update_paraphrase": "PersonX has no interest in having any kind of relationship with them anymore.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4325484039769754, "pred_conf_shift": 0.20486672222614288, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.3288404941558838, 0.671159565448761], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34863.gpt3.7", "original_example": {"example_id": "atomic.train.34863", "premise_hypothesis_id": "atomic.train.15808", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "u6168AsNKsfmzzOG1ym4cw==", "AtomicEventRelationId": "VoJ__8zSOVFxm1jUdegbZw==", "AtomicRelationType": "xReact", "AtomicInference": "unburdened"}, "premise": "PersonX confronts PersonY", "hypothesis": "PersonX is seen as unburdened", "update": "PersonX wants nothing to do with them anymore", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34863", "update_paraphrase": "PersonX wants nothing to do with that person/thing anymore.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.10784313725490197, "pred_conf_shift": 0.49010471999645233, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.22828315198421478, 0.7717167735099792], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34863.gpt3.5", "original_example": {"example_id": "atomic.train.34863", "premise_hypothesis_id": "atomic.train.15808", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "u6168AsNKsfmzzOG1ym4cw==", "AtomicEventRelationId": "VoJ__8zSOVFxm1jUdegbZw==", "AtomicRelationType": "xReact", "AtomicInference": "unburdened"}, "premise": "PersonX confronts PersonY", "hypothesis": "PersonX is seen as unburdened", "update": "PersonX wants nothing to do with them anymore", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34863", "update_paraphrase": "PersonX is done with them and wants nothing further to do with them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.29696969696969694, "pred_conf_shift": 0.5906619280576706, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.7430259585380554, 0.25697392225265503], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34863.gpt3.8", "original_example": {"example_id": "atomic.train.34863", "premise_hypothesis_id": "atomic.train.15808", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "u6168AsNKsfmzzOG1ym4cw==", "AtomicEventRelationId": "VoJ__8zSOVFxm1jUdegbZw==", "AtomicRelationType": "xReact", "AtomicInference": "unburdened"}, "premise": "PersonX confronts PersonY", "hypothesis": "PersonX is seen as unburdened", "update": "PersonX wants nothing to do with them anymore", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34863", "update_paraphrase": "PersonX wants nothing more to do with them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.21969696969696967, "pred_conf_shift": 0.07591907680034637, "syntactic_distance": 0.125}, {"confidence": [0.3083464801311493, 0.6916533708572388], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34863.gpt3.6", "original_example": {"example_id": "atomic.train.34863", "premise_hypothesis_id": "atomic.train.15808", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "u6168AsNKsfmzzOG1ym4cw==", "AtomicEventRelationId": "VoJ__8zSOVFxm1jUdegbZw==", "AtomicRelationType": "xReact", "AtomicInference": "unburdened"}, "premise": "PersonX confronts PersonY", "hypothesis": "PersonX is seen as unburdened", "update": "PersonX wants nothing to do with them anymore", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34863", "update_paraphrase": "PersonX wants to have nothing further to do with them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2328843995510662, "pred_conf_shift": 0.5105985254049301, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.40493276715278625, 0.5950672626495361], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34863.gpt3.1", "original_example": {"example_id": "atomic.train.34863", "premise_hypothesis_id": "atomic.train.15808", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "u6168AsNKsfmzzOG1ym4cw==", "AtomicEventRelationId": "VoJ__8zSOVFxm1jUdegbZw==", "AtomicRelationType": "xReact", "AtomicInference": "unburdened"}, "premise": "PersonX confronts PersonY", "hypothesis": "PersonX is seen as unburdened", "update": "PersonX wants nothing to do with them anymore", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34863", "update_paraphrase": "PersonX has no desire to associate with them any longer.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3784554951221618, "pred_conf_shift": 0.4140124171972275, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.5347532033920288, 0.4652467966079712], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34863.gpt3.3", "original_example": {"example_id": "atomic.train.34863", "premise_hypothesis_id": "atomic.train.15808", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "u6168AsNKsfmzzOG1ym4cw==", "AtomicEventRelationId": "VoJ__8zSOVFxm1jUdegbZw==", "AtomicRelationType": "xReact", "AtomicInference": "unburdened"}, "premise": "PersonX confronts PersonY", "hypothesis": "PersonX is seen as unburdened", "update": "PersonX wants nothing to do with them anymore", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34863", "update_paraphrase": "Person X has no desire to associate with them anymore.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3209768626435293, "pred_conf_shift": 0.28419195115566254, "syntactic_distance": 0.058823529411764705}]}, "atomic.train.20874": {"original_confidence": [0.573603630065918, 0.42639636993408203], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.7084521651268005, 0.2915478050708771], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.20874.gpt3.5", "original_example": {"example_id": "atomic.train.20874", "premise_hypothesis_id": "atomic.train.9640", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZvINXe1mu-LKUHseD0fndQ==", "AtomicEventRelationId": "F-woyYAnoMqumN3ut7KnAA==", "AtomicRelationType": "xNeed", "AtomicInference": "car"}, "premise": "PersonX goes home disappointed", "hypothesis": "Before, PersonX needed car", "update": "PersonX asked someone on a date and got rejected", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20874", "update_paraphrase": "PersonX was rejected when they asked someone out on a date.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2818181818181818, "pred_conf_shift": 0.13484853506088257, "syntactic_distance": 0.35}, {"confidence": [0.5990772843360901, 0.4009227156639099], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.20874.gpt3.7", "original_example": {"example_id": "atomic.train.20874", "premise_hypothesis_id": "atomic.train.9640", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZvINXe1mu-LKUHseD0fndQ==", "AtomicEventRelationId": "F-woyYAnoMqumN3ut7KnAA==", "AtomicRelationType": "xNeed", "AtomicInference": "car"}, "premise": "PersonX goes home disappointed", "hypothesis": "Before, PersonX needed car", "update": "PersonX asked someone on a date and got rejected", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20874", "update_paraphrase": "PersonX asked someone out on a date and got rejected.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.052631578947368474, "pred_conf_shift": 0.02547365427017212, "syntactic_distance": 0.04}, {"confidence": [0.5952804684638977, 0.4047194719314575], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.20874.gpt3.3", "original_example": {"example_id": "atomic.train.20874", "premise_hypothesis_id": "atomic.train.9640", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZvINXe1mu-LKUHseD0fndQ==", "AtomicEventRelationId": "F-woyYAnoMqumN3ut7KnAA==", "AtomicRelationType": "xNeed", "AtomicInference": "car"}, "premise": "PersonX goes home disappointed", "hypothesis": "Before, PersonX needed car", "update": "PersonX asked someone on a date and got rejected", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20874", "update_paraphrase": "PersonX was shot down when they popped the question to someone about going on a date.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5020779220779221, "pred_conf_shift": 0.021676838397979736, "syntactic_distance": 0.38095238095238093}, {"confidence": [0.663367509841919, 0.3366325795650482], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.20874.gpt3.1", "original_example": {"example_id": "atomic.train.20874", "premise_hypothesis_id": "atomic.train.9640", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZvINXe1mu-LKUHseD0fndQ==", "AtomicEventRelationId": "F-woyYAnoMqumN3ut7KnAA==", "AtomicRelationType": "xNeed", "AtomicInference": "car"}, "premise": "PersonX goes home disappointed", "hypothesis": "Before, PersonX needed car", "update": "PersonX asked someone on a date and got rejected", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20874", "update_paraphrase": "PersonX got turned down when they asked someone out on a date.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.32659932659932656, "pred_conf_shift": 0.08976387977600098, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.44415268301963806, 0.5558473467826843], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.20874.gpt3.6", "original_example": {"example_id": "atomic.train.20874", "premise_hypothesis_id": "atomic.train.9640", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZvINXe1mu-LKUHseD0fndQ==", "AtomicEventRelationId": "F-woyYAnoMqumN3ut7KnAA==", "AtomicRelationType": "xNeed", "AtomicInference": "car"}, "premise": "PersonX goes home disappointed", "hypothesis": "Before, PersonX needed car", "update": "PersonX asked someone on a date and got rejected", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20874", "update_paraphrase": "PersonX put themselves out there by asking someone on a date, but they were unfortunately rejected.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42473737373737375, "pred_conf_shift": -0.1294509470462799, "syntactic_distance": 0.2413793103448276}, {"confidence": [0.7087627053260803, 0.2912372648715973], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.20874.gpt3.2", "original_example": {"example_id": "atomic.train.20874", "premise_hypothesis_id": "atomic.train.9640", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZvINXe1mu-LKUHseD0fndQ==", "AtomicEventRelationId": "F-woyYAnoMqumN3ut7KnAA==", "AtomicRelationType": "xNeed", "AtomicInference": "car"}, "premise": "PersonX goes home disappointed", "hypothesis": "Before, PersonX needed car", "update": "PersonX asked someone on a date and got rejected", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20874", "update_paraphrase": "PersonX was turned down when they asked someone out on a date.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.34247234247234243, "pred_conf_shift": 0.13515907526016235, "syntactic_distance": 0.38095238095238093}, {"confidence": [0.47601303458213806, 0.5239869356155396], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.20874.gpt3.8", "original_example": {"example_id": "atomic.train.20874", "premise_hypothesis_id": "atomic.train.9640", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZvINXe1mu-LKUHseD0fndQ==", "AtomicEventRelationId": "F-woyYAnoMqumN3ut7KnAA==", "AtomicRelationType": "xNeed", "AtomicInference": "car"}, "premise": "PersonX goes home disappointed", "hypothesis": "Before, PersonX needed car", "update": "PersonX asked someone on a date and got rejected", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20874", "update_paraphrase": "PersonX asked someone to go out with them but got rejected.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.40777777777777774, "pred_conf_shift": -0.09759059548377991, "syntactic_distance": 0.041666666666666664}, {"confidence": [0.4914793074131012, 0.508520781993866], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.20874.gpt3.4", "original_example": {"example_id": "atomic.train.20874", "premise_hypothesis_id": "atomic.train.9640", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZvINXe1mu-LKUHseD0fndQ==", "AtomicEventRelationId": "F-woyYAnoMqumN3ut7KnAA==", "AtomicRelationType": "xNeed", "AtomicInference": "car"}, "premise": "PersonX goes home disappointed", "hypothesis": "Before, PersonX needed car", "update": "PersonX asked someone on a date and got rejected", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20874", "update_paraphrase": "PersonX put themselves out there and asked someone on a date, but got turned down.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3432539682539682, "pred_conf_shift": -0.08212432265281677, "syntactic_distance": 0.125}, {"confidence": [0.5999518632888794, 0.40004804730415344], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.20874.gpt3.0", "original_example": {"example_id": "atomic.train.20874", "premise_hypothesis_id": "atomic.train.9640", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZvINXe1mu-LKUHseD0fndQ==", "AtomicEventRelationId": "F-woyYAnoMqumN3ut7KnAA==", "AtomicRelationType": "xNeed", "AtomicInference": "car"}, "premise": "PersonX goes home disappointed", "hypothesis": "Before, PersonX needed car", "update": "PersonX asked someone on a date and got rejected", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20874", "update_paraphrase": "PersonX asked someone out on a date and got turned down.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.26857142857142857, "pred_conf_shift": 0.026348233222961426, "syntactic_distance": 0.04}]}, "atomic.train.9886": {"original_confidence": [0.7607719898223877, 0.23922806978225708], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.6906758546829224, 0.30932411551475525], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9886.gpt3.5", "original_example": {"example_id": "atomic.train.9886", "premise_hypothesis_id": "atomic.train.4662", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aFAcMTod4Nl1igbG0_4EOw==", "AtomicEventRelationId": "02GPxcm0d8kH9S5Q2VXg3w==", "AtomicRelationType": "xIntent", "AtomicInference": "to be warm"}, "premise": "PersonX makes a fire", "hypothesis": "Because PersonX wanted to be warm", "update": "PersonX had raw hamburger patties and a pan.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9886", "update_paraphrase": "PersonX had a pan and some raw hamburger patties.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.17254901960784313, "pred_conf_shift": -0.07009613513946533, "syntactic_distance": 0.0}, {"confidence": [0.5114245414733887, 0.4885753393173218], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9886.gpt3.2", "original_example": {"example_id": "atomic.train.9886", "premise_hypothesis_id": "atomic.train.4662", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aFAcMTod4Nl1igbG0_4EOw==", "AtomicEventRelationId": "02GPxcm0d8kH9S5Q2VXg3w==", "AtomicRelationType": "xIntent", "AtomicInference": "to be warm"}, "premise": "PersonX makes a fire", "hypothesis": "Because PersonX wanted to be warm", "update": "PersonX had raw hamburger patties and a pan.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9886", "update_paraphrase": "PersonX had some uncooked hamburger patties and a pan.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.15508021390374338, "pred_conf_shift": -0.24934744834899902, "syntactic_distance": 0.0}, {"confidence": [0.5444976687431335, 0.45550239086151123], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9886.gpt3.6", "original_example": {"example_id": "atomic.train.9886", "premise_hypothesis_id": "atomic.train.4662", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aFAcMTod4Nl1igbG0_4EOw==", "AtomicEventRelationId": "02GPxcm0d8kH9S5Q2VXg3w==", "AtomicRelationType": "xIntent", "AtomicInference": "to be warm"}, "premise": "PersonX makes a fire", "hypothesis": "Because PersonX wanted to be warm", "update": "PersonX had raw hamburger patties and a pan.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9886", "update_paraphrase": "PersonX had some raw ground beef and a frying pan.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.366064491064491, "pred_conf_shift": -0.21627432107925415, "syntactic_distance": 0.0}, {"confidence": [0.5070846676826477, 0.4929152727127075], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9886.gpt3.1", "original_example": {"example_id": "atomic.train.9886", "premise_hypothesis_id": "atomic.train.4662", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aFAcMTod4Nl1igbG0_4EOw==", "AtomicEventRelationId": "02GPxcm0d8kH9S5Q2VXg3w==", "AtomicRelationType": "xIntent", "AtomicInference": "to be warm"}, "premise": "PersonX makes a fire", "hypothesis": "Because PersonX wanted to be warm", "update": "PersonX had raw hamburger patties and a pan.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9886", "update_paraphrase": "PersonX had uncooked hamburger patties and a frying pan.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.27035056446821154, "pred_conf_shift": -0.25368732213974, "syntactic_distance": 0.0}, {"confidence": [0.46546220779418945, 0.5345377922058105], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9886.gpt3.0", "original_example": {"example_id": "atomic.train.9886", "premise_hypothesis_id": "atomic.train.4662", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aFAcMTod4Nl1igbG0_4EOw==", "AtomicEventRelationId": "02GPxcm0d8kH9S5Q2VXg3w==", "AtomicRelationType": "xIntent", "AtomicInference": "to be warm"}, "premise": "PersonX makes a fire", "hypothesis": "Because PersonX wanted to be warm", "update": "PersonX had raw hamburger patties and a pan.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9886", "update_paraphrase": "PersonX had uncooked hamburger patties and a pan.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.11249999999999999, "pred_conf_shift": -0.29530978202819824, "syntactic_distance": 0.0}, {"confidence": [0.6408791542053223, 0.35912084579467773], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9886.gpt3.4", "original_example": {"example_id": "atomic.train.9886", "premise_hypothesis_id": "atomic.train.4662", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aFAcMTod4Nl1igbG0_4EOw==", "AtomicEventRelationId": "02GPxcm0d8kH9S5Q2VXg3w==", "AtomicRelationType": "xIntent", "AtomicInference": "to be warm"}, "premise": "PersonX makes a fire", "hypothesis": "Because PersonX wanted to be warm", "update": "PersonX had raw hamburger patties and a pan.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9886", "update_paraphrase": "Person X had some raw hamburger patties and a pan.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.11965811965811968, "pred_conf_shift": -0.11989283561706543, "syntactic_distance": 0.10526315789473684}, {"confidence": [0.5955029726028442, 0.40449702739715576], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9886.gpt3.7", "original_example": {"example_id": "atomic.train.9886", "premise_hypothesis_id": "atomic.train.4662", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aFAcMTod4Nl1igbG0_4EOw==", "AtomicEventRelationId": "02GPxcm0d8kH9S5Q2VXg3w==", "AtomicRelationType": "xIntent", "AtomicInference": "to be warm"}, "premise": "PersonX makes a fire", "hypothesis": "Because PersonX wanted to be warm", "update": "PersonX had raw hamburger patties and a pan.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9886", "update_paraphrase": "Person X had a pack of raw hamburger patties and a frying pan.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.24542124542124544, "pred_conf_shift": -0.16526901721954346, "syntactic_distance": 0.10526315789473684}, {"confidence": [0.5706869959831238, 0.42931297421455383], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9886.gpt3.3", "original_example": {"example_id": "atomic.train.9886", "premise_hypothesis_id": "atomic.train.4662", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aFAcMTod4Nl1igbG0_4EOw==", "AtomicEventRelationId": "02GPxcm0d8kH9S5Q2VXg3w==", "AtomicRelationType": "xIntent", "AtomicInference": "to be warm"}, "premise": "PersonX makes a fire", "hypothesis": "Because PersonX wanted to be warm", "update": "PersonX had raw hamburger patties and a pan.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9886", "update_paraphrase": "PersonX had some uncooked hamburger patties and a frying pan.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.29068462401795736, "pred_conf_shift": -0.19008499383926392, "syntactic_distance": 0.0}]}, "atomic.train.26484": {"original_confidence": [0.8768013119697571, 0.12319867312908173], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.8299219012260437, 0.17007814347743988], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.26484.gpt3.2", "original_example": {"example_id": "atomic.train.26484", "premise_hypothesis_id": "atomic.train.12076", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "4ubmK88qZLqlMIPKsDZt3w==", "AtomicEventRelationId": "RQSGII1rOXQABK8XMQf_LA==", "AtomicRelationType": "xEffect", "AtomicInference": "good manrisame"}, "premise": "PersonX dresses alike", "hypothesis": "PersonX then good manrisame", "update": "PersonX is wearing white at a wedding and is not the bride", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26484", "update_paraphrase": "PersonX is wearing white to a wedding, but is not the bride.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19940476190476186, "pred_conf_shift": -0.04687941074371338, "syntactic_distance": 0.0}, {"confidence": [0.1952391117811203, 0.8047609329223633], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.26484.gpt3.1", "original_example": {"example_id": "atomic.train.26484", "premise_hypothesis_id": "atomic.train.12076", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "4ubmK88qZLqlMIPKsDZt3w==", "AtomicEventRelationId": "RQSGII1rOXQABK8XMQf_LA==", "AtomicRelationType": "xEffect", "AtomicInference": "good manrisame"}, "premise": "PersonX dresses alike", "hypothesis": "PersonX then good manrisame", "update": "PersonX is wearing white at a wedding and is not the bride", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26484", "update_paraphrase": "At the wedding, PersonX is stands out because they are wearing white while everyone else is not.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4109717868338558, "pred_conf_shift": -0.6815622001886368, "syntactic_distance": 0.4}, {"confidence": [0.7922431826591492, 0.20775684714317322], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.26484.gpt3.5", "original_example": {"example_id": "atomic.train.26484", "premise_hypothesis_id": "atomic.train.12076", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "4ubmK88qZLqlMIPKsDZt3w==", "AtomicEventRelationId": "RQSGII1rOXQABK8XMQf_LA==", "AtomicRelationType": "xEffect", "AtomicInference": "good manrisame"}, "premise": "PersonX dresses alike", "hypothesis": "PersonX then good manrisame", "update": "PersonX is wearing white at a wedding and is not the bride", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26484", "update_paraphrase": "PersonX is not the bride and is wearing white to the wedding.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.29464285714285715, "pred_conf_shift": -0.08455812931060791, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.7436478734016418, 0.25635212659835815], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.26484.gpt3.4", "original_example": {"example_id": "atomic.train.26484", "premise_hypothesis_id": "atomic.train.12076", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "4ubmK88qZLqlMIPKsDZt3w==", "AtomicEventRelationId": "RQSGII1rOXQABK8XMQf_LA==", "AtomicRelationType": "xEffect", "AtomicInference": "good manrisame"}, "premise": "PersonX dresses alike", "hypothesis": "PersonX then good manrisame", "update": "PersonX is wearing white at a wedding and is not the bride", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26484", "update_paraphrase": "At the wedding, PersonX is the only one not wearing white and is not the bride.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2833333333333333, "pred_conf_shift": -0.13315343856811523, "syntactic_distance": 0.3125}, {"confidence": [0.8468554615974426, 0.15314458310604095], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.26484.gpt3.0", "original_example": {"example_id": "atomic.train.26484", "premise_hypothesis_id": "atomic.train.12076", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "4ubmK88qZLqlMIPKsDZt3w==", "AtomicEventRelationId": "RQSGII1rOXQABK8XMQf_LA==", "AtomicRelationType": "xEffect", "AtomicInference": "good manrisame"}, "premise": "PersonX dresses alike", "hypothesis": "PersonX then good manrisame", "update": "PersonX is wearing white at a wedding and is not the bride", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26484", "update_paraphrase": "Person X is wearing white to the wedding, but is not the bride.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.24615384615384617, "pred_conf_shift": -0.029945850372314453, "syntactic_distance": 0.04}, {"confidence": [0.8329768180847168, 0.16702310740947723], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.26484.gpt3.3", "original_example": {"example_id": "atomic.train.26484", "premise_hypothesis_id": "atomic.train.12076", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "4ubmK88qZLqlMIPKsDZt3w==", "AtomicEventRelationId": "RQSGII1rOXQABK8XMQf_LA==", "AtomicRelationType": "xEffect", "AtomicInference": "good manrisame"}, "premise": "PersonX dresses alike", "hypothesis": "PersonX then good manrisame", "update": "PersonX is wearing white at a wedding and is not the bride", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26484", "update_paraphrase": "PersonX stands out in their all-white ensemble at the wedding, but they're not the bride.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.388658255324922, "pred_conf_shift": -0.04382449388504028, "syntactic_distance": 0.3448275862068966}]}, "atomic.train.12205": {"original_confidence": [0.505250871181488, 0.4947490990161896], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.4321672320365906, 0.5678327679634094], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.12205.gpt3.3", "original_example": {"example_id": "atomic.train.12205", "premise_hypothesis_id": "atomic.train.5738", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "tZojb_L_nt1aRsJa39l7mQ==", "AtomicEventRelationId": "icF_yQM5Cws6ZeM-NQUMpQ==", "AtomicRelationType": "xEffect", "AtomicInference": "becomes angry with PersonY"}, "premise": "PersonX makes PersonY sick", "hypothesis": "PersonX then becomes angry with PersonY", "update": "PersonX gave PersonY an STD.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12205", "update_paraphrase": "PersonX passed on an STD to PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39629629629629626, "pred_conf_shift": 0.07308366894721985, "syntactic_distance": 0.21739130434782608}, {"confidence": [0.5506874918937683, 0.4493125379085541], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.12205.gpt3.5", "original_example": {"example_id": "atomic.train.12205", "premise_hypothesis_id": "atomic.train.5738", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "tZojb_L_nt1aRsJa39l7mQ==", "AtomicEventRelationId": "icF_yQM5Cws6ZeM-NQUMpQ==", "AtomicRelationType": "xEffect", "AtomicInference": "becomes angry with PersonY"}, "premise": "PersonX makes PersonY sick", "hypothesis": "PersonX then becomes angry with PersonY", "update": "PersonX gave PersonY an STD.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12205", "update_paraphrase": "PersonX transmitted an STD to PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37979797979797975, "pred_conf_shift": -0.0454365611076355, "syntactic_distance": 0.19047619047619047}, {"confidence": [0.4356830418109894, 0.5643168687820435], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.12205.gpt3.6", "original_example": {"example_id": "atomic.train.12205", "premise_hypothesis_id": "atomic.train.5738", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "tZojb_L_nt1aRsJa39l7mQ==", "AtomicEventRelationId": "icF_yQM5Cws6ZeM-NQUMpQ==", "AtomicRelationType": "xEffect", "AtomicInference": "becomes angry with PersonY"}, "premise": "PersonX makes PersonY sick", "hypothesis": "PersonX then becomes angry with PersonY", "update": "PersonX gave PersonY an STD.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12205", "update_paraphrase": "PersonX passed along an STD to PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.40555555555555556, "pred_conf_shift": 0.06956776976585388, "syntactic_distance": 0.21739130434782608}, {"confidence": [0.4293462932109833, 0.5706536769866943], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.12205.gpt3.2", "original_example": {"example_id": "atomic.train.12205", "premise_hypothesis_id": "atomic.train.5738", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "tZojb_L_nt1aRsJa39l7mQ==", "AtomicEventRelationId": "icF_yQM5Cws6ZeM-NQUMpQ==", "AtomicRelationType": "xEffect", "AtomicInference": "becomes angry with PersonY"}, "premise": "PersonX makes PersonY sick", "hypothesis": "PersonX then becomes angry with PersonY", "update": "PersonX gave PersonY an STD.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12205", "update_paraphrase": "PersonX infected PersonY with an STD.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2705627705627706, "pred_conf_shift": 0.07590457797050476, "syntactic_distance": 0.15}, {"confidence": [0.7578239440917969, 0.24217602610588074], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.12205.gpt3.7", "original_example": {"example_id": "atomic.train.12205", "premise_hypothesis_id": "atomic.train.5738", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "tZojb_L_nt1aRsJa39l7mQ==", "AtomicEventRelationId": "icF_yQM5Cws6ZeM-NQUMpQ==", "AtomicRelationType": "xEffect", "AtomicInference": "becomes angry with PersonY"}, "premise": "PersonX makes PersonY sick", "hypothesis": "PersonX then becomes angry with PersonY", "update": "PersonX gave PersonY an STD.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12205", "update_paraphrase": "Person X gave person Y a sexually transmitted disease.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4369440083725798, "pred_conf_shift": -0.25257307291030884, "syntactic_distance": 0.13043478260869565}, {"confidence": [0.5625457167625427, 0.4374542534351349], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.12205.gpt3.1", "original_example": {"example_id": "atomic.train.12205", "premise_hypothesis_id": "atomic.train.5738", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "tZojb_L_nt1aRsJa39l7mQ==", "AtomicEventRelationId": "icF_yQM5Cws6ZeM-NQUMpQ==", "AtomicRelationType": "xEffect", "AtomicInference": "becomes angry with PersonY"}, "premise": "PersonX makes PersonY sick", "hypothesis": "PersonX then becomes angry with PersonY", "update": "PersonX gave PersonY an STD.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12205", "update_paraphrase": "PersonX spread an STD to PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3780885780885781, "pred_conf_shift": -0.05729484558105469, "syntactic_distance": 0.2857142857142857}, {"confidence": [0.7484492063522339, 0.2515508532524109], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.12205.gpt3.4", "original_example": {"example_id": "atomic.train.12205", "premise_hypothesis_id": "atomic.train.5738", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "tZojb_L_nt1aRsJa39l7mQ==", "AtomicEventRelationId": "icF_yQM5Cws6ZeM-NQUMpQ==", "AtomicRelationType": "xEffect", "AtomicInference": "becomes angry with PersonY"}, "premise": "PersonX makes PersonY sick", "hypothesis": "PersonX then becomes angry with PersonY", "update": "PersonX gave PersonY an STD.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12205", "update_paraphrase": "PersonX gave PersonY a sexually transmitted disease.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.35620490620490625, "pred_conf_shift": -0.2431982457637787, "syntactic_distance": 0.047619047619047616}, {"confidence": [0.5733574032783508, 0.42664265632629395], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.12205.gpt3.0", "original_example": {"example_id": "atomic.train.12205", "premise_hypothesis_id": "atomic.train.5738", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "tZojb_L_nt1aRsJa39l7mQ==", "AtomicEventRelationId": "icF_yQM5Cws6ZeM-NQUMpQ==", "AtomicRelationType": "xEffect", "AtomicInference": "becomes angry with PersonY"}, "premise": "PersonX makes PersonY sick", "hypothesis": "PersonX then becomes angry with PersonY", "update": "PersonX gave PersonY an STD.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12205", "update_paraphrase": "Person X passed on a sexually transmitted disease to Person Y.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6122405372405373, "pred_conf_shift": -0.06810644268989563, "syntactic_distance": 0.28}]}, "atomic.train.23217": {"original_confidence": [0.03314635902643204, 0.966853678226471], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.030894910916686058, 0.9691051244735718], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.23217.gpt3.3", "original_example": {"example_id": "atomic.train.23217", "premise_hypothesis_id": "atomic.train.10643", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-vnHA1XDF0yzKZWpV-JrKA==", "AtomicEventRelationId": "MN4J54UPJv9vwPKkIXvtLw==", "AtomicRelationType": "xAttr", "AtomicInference": "active"}, "premise": "PersonX rides all the rides", "hypothesis": "As a result, PersonX feels active", "update": "PersonX orders more carnival passes.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23217", "update_paraphrase": "PersonX buys additional carnival passes.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.31956043956043956, "pred_conf_shift": 0.00225144624710083, "syntactic_distance": 0.05555555555555555}, {"confidence": [0.04589437320828438, 0.9541054964065552], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.23217.gpt3.1", "original_example": {"example_id": "atomic.train.23217", "premise_hypothesis_id": "atomic.train.10643", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-vnHA1XDF0yzKZWpV-JrKA==", "AtomicEventRelationId": "MN4J54UPJv9vwPKkIXvtLw==", "AtomicRelationType": "xAttr", "AtomicInference": "active"}, "premise": "PersonX rides all the rides", "hypothesis": "As a result, PersonX feels active", "update": "PersonX orders more carnival passes.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23217", "update_paraphrase": "PersonX purchasing additional carnival passes.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.30027472527472526, "pred_conf_shift": -0.012748181819915771, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.026140054687857628, 0.9738600254058838], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.23217.gpt3.2", "original_example": {"example_id": "atomic.train.23217", "premise_hypothesis_id": "atomic.train.10643", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-vnHA1XDF0yzKZWpV-JrKA==", "AtomicEventRelationId": "MN4J54UPJv9vwPKkIXvtLw==", "AtomicRelationType": "xAttr", "AtomicInference": "active"}, "premise": "PersonX rides all the rides", "hypothesis": "As a result, PersonX feels active", "update": "PersonX orders more carnival passes.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23217", "update_paraphrase": "PersonX decides to buy more carnival passes.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.27106227106227104, "pred_conf_shift": 0.007006347179412842, "syntactic_distance": 0.3125}, {"confidence": [0.03694992884993553, 0.963050127029419], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.23217.gpt3.4", "original_example": {"example_id": "atomic.train.23217", "premise_hypothesis_id": "atomic.train.10643", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-vnHA1XDF0yzKZWpV-JrKA==", "AtomicEventRelationId": "MN4J54UPJv9vwPKkIXvtLw==", "AtomicRelationType": "xAttr", "AtomicInference": "active"}, "premise": "PersonX rides all the rides", "hypothesis": "As a result, PersonX feels active", "update": "PersonX orders more carnival passes.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23217", "update_paraphrase": "PersonX buys more tickets to the carnival.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.43685897435897436, "pred_conf_shift": -0.003803551197052002, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.03488050028681755, 0.965119481086731], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.23217.gpt3.0", "original_example": {"example_id": "atomic.train.23217", "premise_hypothesis_id": "atomic.train.10643", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-vnHA1XDF0yzKZWpV-JrKA==", "AtomicEventRelationId": "MN4J54UPJv9vwPKkIXvtLw==", "AtomicRelationType": "xAttr", "AtomicInference": "active"}, "premise": "PersonX rides all the rides", "hypothesis": "As a result, PersonX feels active", "update": "PersonX orders more carnival passes.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23217", "update_paraphrase": "PersonX buys more carnival passes.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.13384615384615378, "pred_conf_shift": -0.0017341971397399902, "syntactic_distance": 0.0}, {"confidence": [0.02796821855008602, 0.9720317125320435], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.23217.gpt3.5", "original_example": {"example_id": "atomic.train.23217", "premise_hypothesis_id": "atomic.train.10643", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-vnHA1XDF0yzKZWpV-JrKA==", "AtomicEventRelationId": "MN4J54UPJv9vwPKkIXvtLw==", "AtomicRelationType": "xAttr", "AtomicInference": "active"}, "premise": "PersonX rides all the rides", "hypothesis": "As a result, PersonX feels active", "update": "PersonX orders more carnival passes.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23217", "update_paraphrase": "PersonX decided to buy more carnival passes.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28917378917378916, "pred_conf_shift": 0.00517803430557251, "syntactic_distance": 0.375}]}, "atomic.train.38963": {"original_confidence": [0.7843261361122131, 0.21567383408546448], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.7044376134872437, 0.29556235671043396], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.38963.gpt3.2", "original_example": {"example_id": "atomic.train.38963", "premise_hypothesis_id": "atomic.train.17655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Wlv9HKvTVjpBJwysJ6nyxw==", "AtomicEventRelationId": "zyBqa8JscSuChXcNVQBRdA==", "AtomicRelationType": "xNeed", "AtomicInference": "to approach his/her sister"}, "premise": "PersonX tells PersonX's sister", "hypothesis": "Before, PersonX needed to approach his/her sister", "update": "They live in the same house", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38963", "update_paraphrase": "They are living in the same house.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.16263736263736267, "pred_conf_shift": 0.07988852262496948, "syntactic_distance": 0.1875}, {"confidence": [0.566177248954773, 0.4338228106498718], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.38963.gpt3.0", "original_example": {"example_id": "atomic.train.38963", "premise_hypothesis_id": "atomic.train.17655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Wlv9HKvTVjpBJwysJ6nyxw==", "AtomicEventRelationId": "zyBqa8JscSuChXcNVQBRdA==", "AtomicRelationType": "xNeed", "AtomicInference": "to approach his/her sister"}, "premise": "PersonX tells PersonX's sister", "hypothesis": "Before, PersonX needed to approach his/her sister", "update": "They live in the same house", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38963", "update_paraphrase": "The two of them dwell in the same abode.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.397936507936508, "pred_conf_shift": 0.21814897656440735, "syntactic_distance": 0.2857142857142857}, {"confidence": [0.7304903268814087, 0.2695096433162689], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.38963.gpt3.4", "original_example": {"example_id": "atomic.train.38963", "premise_hypothesis_id": "atomic.train.17655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Wlv9HKvTVjpBJwysJ6nyxw==", "AtomicEventRelationId": "zyBqa8JscSuChXcNVQBRdA==", "AtomicRelationType": "xNeed", "AtomicInference": "to approach his/her sister"}, "premise": "PersonX tells PersonX's sister", "hypothesis": "Before, PersonX needed to approach his/her sister", "update": "They live in the same house", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38963", "update_paraphrase": "They reside in the same abode.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23333333333333334, "pred_conf_shift": 0.05383580923080444, "syntactic_distance": 0.0}, {"confidence": [0.7796761393547058, 0.22032378613948822], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.38963.gpt3.7", "original_example": {"example_id": "atomic.train.38963", "premise_hypothesis_id": "atomic.train.17655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Wlv9HKvTVjpBJwysJ6nyxw==", "AtomicEventRelationId": "zyBqa8JscSuChXcNVQBRdA==", "AtomicRelationType": "xNeed", "AtomicInference": "to approach his/her sister"}, "premise": "PersonX tells PersonX's sister", "hypothesis": "Before, PersonX needed to approach his/her sister", "update": "They live in the same house", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38963", "update_paraphrase": "They live in the same house.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": 0.004649952054023743, "syntactic_distance": 0.0}, {"confidence": [0.5348794460296631, 0.4651206135749817], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.38963.gpt3.8", "original_example": {"example_id": "atomic.train.38963", "premise_hypothesis_id": "atomic.train.17655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Wlv9HKvTVjpBJwysJ6nyxw==", "AtomicEventRelationId": "zyBqa8JscSuChXcNVQBRdA==", "AtomicRelationType": "xNeed", "AtomicInference": "to approach his/her sister"}, "premise": "PersonX tells PersonX's sister", "hypothesis": "Before, PersonX needed to approach his/her sister", "update": "They live in the same house", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38963", "update_paraphrase": "They share a house.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.35761904761904767, "pred_conf_shift": 0.2494467794895172, "syntactic_distance": 0.1875}, {"confidence": [0.7960056066513062, 0.20399443805217743], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.38963.gpt3.1", "original_example": {"example_id": "atomic.train.38963", "premise_hypothesis_id": "atomic.train.17655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Wlv9HKvTVjpBJwysJ6nyxw==", "AtomicEventRelationId": "zyBqa8JscSuChXcNVQBRdA==", "AtomicRelationType": "xNeed", "AtomicInference": "to approach his/her sister"}, "premise": "PersonX tells PersonX's sister", "hypothesis": "Before, PersonX needed to approach his/her sister", "update": "They live in the same house", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38963", "update_paraphrase": "They live in the same house as one another.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19999999999999996, "pred_conf_shift": -0.011679396033287048, "syntactic_distance": 0.0}, {"confidence": [0.7960239052772522, 0.20397606492042542], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.38963.gpt3.6", "original_example": {"example_id": "atomic.train.38963", "premise_hypothesis_id": "atomic.train.17655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Wlv9HKvTVjpBJwysJ6nyxw==", "AtomicEventRelationId": "zyBqa8JscSuChXcNVQBRdA==", "AtomicRelationType": "xNeed", "AtomicInference": "to approach his/her sister"}, "premise": "PersonX tells PersonX's sister", "hypothesis": "Before, PersonX needed to approach his/her sister", "update": "They live in the same house", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38963", "update_paraphrase": "They live under the same roof.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3237433862433863, "pred_conf_shift": -0.011697769165039062, "syntactic_distance": 0.0}, {"confidence": [0.5427865982055664, 0.4572133719921112], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.38963.gpt3.3", "original_example": {"example_id": "atomic.train.38963", "premise_hypothesis_id": "atomic.train.17655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Wlv9HKvTVjpBJwysJ6nyxw==", "AtomicEventRelationId": "zyBqa8JscSuChXcNVQBRdA==", "AtomicRelationType": "xNeed", "AtomicInference": "to approach his/her sister"}, "premise": "PersonX tells PersonX's sister", "hypothesis": "Before, PersonX needed to approach his/her sister", "update": "They live in the same house", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38963", "update_paraphrase": "They share a residence.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5212554112554113, "pred_conf_shift": 0.24153953790664673, "syntactic_distance": 0.1875}, {"confidence": [0.6700391173362732, 0.3299609422683716], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.38963.gpt3.5", "original_example": {"example_id": "atomic.train.38963", "premise_hypothesis_id": "atomic.train.17655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Wlv9HKvTVjpBJwysJ6nyxw==", "AtomicEventRelationId": "zyBqa8JscSuChXcNVQBRdA==", "AtomicRelationType": "xNeed", "AtomicInference": "to approach his/her sister"}, "premise": "PersonX tells PersonX's sister", "hypothesis": "Before, PersonX needed to approach his/her sister", "update": "They live in the same house", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38963", "update_paraphrase": "They share the same household.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.34668109668109665, "pred_conf_shift": 0.1142871081829071, "syntactic_distance": 0.23529411764705882}]}, "atomic.train.38828": {"original_confidence": [0.29350706934928894, 0.7064930200576782], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.44591039419174194, 0.5540895462036133], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38828.gpt3.1", "original_example": {"example_id": "atomic.train.38828", "premise_hypothesis_id": "atomic.train.17602", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "n7fDWV_CMwwfeX2D69IKAg==", "AtomicEventRelationId": "voTpUq2Hp0uVeRMcmuzRIA==", "AtomicRelationType": "xIntent", "AtomicInference": "to do better"}, "premise": "PersonX is very upset with PersonX", "hypothesis": "Because PersonX wanted to do better", "update": "They got cheated on", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38828", "update_paraphrase": "Someone betrayed them by being unfaithful.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6786928104575163, "pred_conf_shift": 0.152403324842453, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.3607192635536194, 0.6392807960510254], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38828.gpt3.3", "original_example": {"example_id": "atomic.train.38828", "premise_hypothesis_id": "atomic.train.17602", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "n7fDWV_CMwwfeX2D69IKAg==", "AtomicEventRelationId": "voTpUq2Hp0uVeRMcmuzRIA==", "AtomicRelationType": "xIntent", "AtomicInference": "to do better"}, "premise": "PersonX is very upset with PersonX", "hypothesis": "Because PersonX wanted to do better", "update": "They got cheated on", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38828", "update_paraphrase": "Someone they were dating or married to was unfaithful to them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6895238095238094, "pred_conf_shift": 0.06721219420433044, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.34400680661201477, 0.6559932231903076], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38828.gpt3.0", "original_example": {"example_id": "atomic.train.38828", "premise_hypothesis_id": "atomic.train.17602", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "n7fDWV_CMwwfeX2D69IKAg==", "AtomicEventRelationId": "voTpUq2Hp0uVeRMcmuzRIA==", "AtomicRelationType": "xIntent", "AtomicInference": "to do better"}, "premise": "PersonX is very upset with PersonX", "hypothesis": "Because PersonX wanted to do better", "update": "They got cheated on", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38828", "update_paraphrase": "Their partner was unfaithful to them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6469467787114845, "pred_conf_shift": 0.05049973726272583, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.5170766115188599, 0.48292335867881775], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.38828.gpt3.8", "original_example": {"example_id": "atomic.train.38828", "premise_hypothesis_id": "atomic.train.17602", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "n7fDWV_CMwwfeX2D69IKAg==", "AtomicEventRelationId": "voTpUq2Hp0uVeRMcmuzRIA==", "AtomicRelationType": "xIntent", "AtomicInference": "to do better"}, "premise": "PersonX is very upset with PersonX", "hypothesis": "Because PersonX wanted to do better", "update": "They got cheated on", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38828", "update_paraphrase": "They were unfaithful to their partner.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5707142857142857, "pred_conf_shift": 0.22356954216957092, "syntactic_distance": 0.125}, {"confidence": [0.8613405227661133, 0.13865946233272552], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.38828.gpt3.4", "original_example": {"example_id": "atomic.train.38828", "premise_hypothesis_id": "atomic.train.17602", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "n7fDWV_CMwwfeX2D69IKAg==", "AtomicEventRelationId": "voTpUq2Hp0uVeRMcmuzRIA==", "AtomicRelationType": "xIntent", "AtomicInference": "to do better"}, "premise": "PersonX is very upset with PersonX", "hypothesis": "Because PersonX wanted to do better", "update": "They got cheated on", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38828", "update_paraphrase": "They were victims of infidelity.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5612299465240642, "pred_conf_shift": 0.5678334534168243, "syntactic_distance": 0.125}, {"confidence": [0.5512415170669556, 0.4487585425376892], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.38828.gpt3.2", "original_example": {"example_id": "atomic.train.38828", "premise_hypothesis_id": "atomic.train.17602", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "n7fDWV_CMwwfeX2D69IKAg==", "AtomicEventRelationId": "voTpUq2Hp0uVeRMcmuzRIA==", "AtomicRelationType": "xIntent", "AtomicInference": "to do better"}, "premise": "PersonX is very upset with PersonX", "hypothesis": "Because PersonX wanted to do better", "update": "They got cheated on", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38828", "update_paraphrase": "They were cheated on.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2142857142857143, "pred_conf_shift": 0.2577344477176666, "syntactic_distance": 0.0}, {"confidence": [0.3786603510379791, 0.6213396191596985], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38828.gpt3.6", "original_example": {"example_id": "atomic.train.38828", "premise_hypothesis_id": "atomic.train.17602", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "n7fDWV_CMwwfeX2D69IKAg==", "AtomicEventRelationId": "voTpUq2Hp0uVeRMcmuzRIA==", "AtomicRelationType": "xIntent", "AtomicInference": "to do better"}, "premise": "PersonX is very upset with PersonX", "hypothesis": "Because PersonX wanted to do better", "update": "They got cheated on", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38828", "update_paraphrase": "Someone was unfaithful to them and they found out.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6646520146520147, "pred_conf_shift": 0.08515328168869019, "syntactic_distance": 0.5}, {"confidence": [0.35277059674263, 0.6472294330596924], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38828.gpt3.5", "original_example": {"example_id": "atomic.train.38828", "premise_hypothesis_id": "atomic.train.17602", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "n7fDWV_CMwwfeX2D69IKAg==", "AtomicEventRelationId": "voTpUq2Hp0uVeRMcmuzRIA==", "AtomicRelationType": "xIntent", "AtomicInference": "to do better"}, "premise": "PersonX is very upset with PersonX", "hypothesis": "Because PersonX wanted to do better", "update": "They got cheated on", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38828", "update_paraphrase": "Someone they were in a relationship with was unfaithful to them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.7143570155334862, "pred_conf_shift": 0.059263527393341064, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.5227516889572144, 0.47724834084510803], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.38828.gpt3.7", "original_example": {"example_id": "atomic.train.38828", "premise_hypothesis_id": "atomic.train.17602", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "n7fDWV_CMwwfeX2D69IKAg==", "AtomicEventRelationId": "voTpUq2Hp0uVeRMcmuzRIA==", "AtomicRelationType": "xIntent", "AtomicInference": "to do better"}, "premise": "PersonX is very upset with PersonX", "hypothesis": "Because PersonX wanted to do better", "update": "They got cheated on", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38828", "update_paraphrase": "The person they were dating ended up cheating on them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5793650793650793, "pred_conf_shift": 0.22924461960792542, "syntactic_distance": 0.47619047619047616}]}, "atomic.train.10263": {"original_confidence": [0.8579991459846497, 0.14200082421302795], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.8153517842292786, 0.18464826047420502], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10263.gpt3.3", "original_example": {"example_id": "atomic.train.10263", "premise_hypothesis_id": "atomic.train.4832", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JfoNseCBg_JI7A1M-WazfQ==", "AtomicEventRelationId": "S5ICAZiQhTcWy4ztLOw8Ow==", "AtomicRelationType": "xEffect", "AtomicInference": "begins to smell"}, "premise": "PersonX causes the smell", "hypothesis": "PersonX then begins to smell", "update": "PersonX rolls around in their own waste as part of a prank.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10263", "update_paraphrase": "PersonX playing a prank by rolling around in their own fecal matter.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3807720057720057, "pred_conf_shift": 0.04264743626117706, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.9029295444488525, 0.09707045555114746], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10263.gpt3.6", "original_example": {"example_id": "atomic.train.10263", "premise_hypothesis_id": "atomic.train.4832", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JfoNseCBg_JI7A1M-WazfQ==", "AtomicEventRelationId": "S5ICAZiQhTcWy4ztLOw8Ow==", "AtomicRelationType": "xEffect", "AtomicInference": "begins to smell"}, "premise": "PersonX causes the smell", "hypothesis": "PersonX then begins to smell", "update": "PersonX rolls around in their own waste as part of a prank.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10263", "update_paraphrase": "PersonX deliberately covers themselves in their own excrement as a silly prank.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33015873015873015, "pred_conf_shift": -0.04493036866188049, "syntactic_distance": 0.14285714285714285}, {"confidence": [0.8689802885055542, 0.13101975619792938], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10263.gpt3.8", "original_example": {"example_id": "atomic.train.10263", "premise_hypothesis_id": "atomic.train.4832", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JfoNseCBg_JI7A1M-WazfQ==", "AtomicEventRelationId": "S5ICAZiQhTcWy4ztLOw8Ow==", "AtomicRelationType": "xEffect", "AtomicInference": "begins to smell"}, "premise": "PersonX causes the smell", "hypothesis": "PersonX then begins to smell", "update": "PersonX rolls around in their own waste as part of a prank.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10263", "update_paraphrase": "PersonX plays a prank by rolling around in their own waste.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3519668737060042, "pred_conf_shift": -0.010981068015098572, "syntactic_distance": 0.25}, {"confidence": [0.8008332252502441, 0.19916680455207825], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10263.gpt3.5", "original_example": {"example_id": "atomic.train.10263", "premise_hypothesis_id": "atomic.train.4832", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JfoNseCBg_JI7A1M-WazfQ==", "AtomicEventRelationId": "S5ICAZiQhTcWy4ztLOw8Ow==", "AtomicRelationType": "xEffect", "AtomicInference": "begins to smell"}, "premise": "PersonX causes the smell", "hypothesis": "PersonX then begins to smell", "update": "PersonX rolls around in their own waste as part of a prank.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10263", "update_paraphrase": "As part of a prank, PersonX rolls around in their own waste.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.20833333333333331, "pred_conf_shift": 0.05716598033905029, "syntactic_distance": 0.47619047619047616}, {"confidence": [0.90166175365448, 0.0983382984995842], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10263.gpt3.7", "original_example": {"example_id": "atomic.train.10263", "premise_hypothesis_id": "atomic.train.4832", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JfoNseCBg_JI7A1M-WazfQ==", "AtomicEventRelationId": "S5ICAZiQhTcWy4ztLOw8Ow==", "AtomicRelationType": "xEffect", "AtomicInference": "begins to smell"}, "premise": "PersonX causes the smell", "hypothesis": "PersonX then begins to smell", "update": "PersonX rolls around in their own waste as part of a prank.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10263", "update_paraphrase": "PersonX smear their own excrement on their body as part of a practical joke.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3571373071373071, "pred_conf_shift": -0.043662525713443756, "syntactic_distance": 0.21428571428571427}, {"confidence": [0.8980010151863098, 0.10199902206659317], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10263.gpt3.2", "original_example": {"example_id": "atomic.train.10263", "premise_hypothesis_id": "atomic.train.4832", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JfoNseCBg_JI7A1M-WazfQ==", "AtomicEventRelationId": "S5ICAZiQhTcWy4ztLOw8Ow==", "AtomicRelationType": "xEffect", "AtomicInference": "begins to smell"}, "premise": "PersonX causes the smell", "hypothesis": "PersonX then begins to smell", "update": "PersonX rolls around in their own waste as part of a prank.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10263", "update_paraphrase": "PersonX pretends to be sick or injured, rolling around in their own waste as part of a prank.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23015873015873012, "pred_conf_shift": -0.040001802146434784, "syntactic_distance": 0.45}, {"confidence": [0.8873304128646851, 0.11266958713531494], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10263.gpt3.1", "original_example": {"example_id": "atomic.train.10263", "premise_hypothesis_id": "atomic.train.4832", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JfoNseCBg_JI7A1M-WazfQ==", "AtomicEventRelationId": "S5ICAZiQhTcWy4ztLOw8Ow==", "AtomicRelationType": "xEffect", "AtomicInference": "begins to smell"}, "premise": "PersonX causes the smell", "hypothesis": "PersonX then begins to smell", "update": "PersonX rolls around in their own waste as part of a prank.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10263", "update_paraphrase": "PersonX covers themselves in their own feces as part of a prank.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.20277777777777783, "pred_conf_shift": -0.029331237077713013, "syntactic_distance": 0.07692307692307693}, {"confidence": [0.9024601578712463, 0.09753981232643127], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10263.gpt3.4", "original_example": {"example_id": "atomic.train.10263", "premise_hypothesis_id": "atomic.train.4832", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JfoNseCBg_JI7A1M-WazfQ==", "AtomicEventRelationId": "S5ICAZiQhTcWy4ztLOw8Ow==", "AtomicRelationType": "xEffect", "AtomicInference": "begins to smell"}, "premise": "PersonX causes the smell", "hypothesis": "PersonX then begins to smell", "update": "PersonX rolls around in their own waste as part of a prank.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10263", "update_paraphrase": "PersonX smeared themselves with their own feces as part of a joke.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2995014245014246, "pred_conf_shift": -0.04446101188659668, "syntactic_distance": 0.15384615384615385}, {"confidence": [0.8965372443199158, 0.10346284508705139], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10263.gpt3.0", "original_example": {"example_id": "atomic.train.10263", "premise_hypothesis_id": "atomic.train.4832", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JfoNseCBg_JI7A1M-WazfQ==", "AtomicEventRelationId": "S5ICAZiQhTcWy4ztLOw8Ow==", "AtomicRelationType": "xEffect", "AtomicInference": "begins to smell"}, "premise": "PersonX causes the smell", "hypothesis": "PersonX then begins to smell", "update": "PersonX rolls around in their own waste as part of a prank.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10263", "update_paraphrase": "PersonX covers themselves in their own body waste as part of a practical joke.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2338302722918107, "pred_conf_shift": -0.03853797912597656, "syntactic_distance": 0.07692307692307693}]}, "atomic.train.25179": {"original_confidence": [0.39333653450012207, 0.6066634654998779], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.7297638058662415, 0.27023622393608093], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.25179.gpt3.4", "original_example": {"example_id": "atomic.train.25179", "premise_hypothesis_id": "atomic.train.11513", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7zW3GWOzcYieILtCbrpSsQ==", "AtomicEventRelationId": "jiBs01APCUKNkQuDwHDpjw==", "AtomicRelationType": "xReact", "AtomicInference": "crude"}, "premise": "PersonX drops the f-bomb", "hypothesis": "PersonX is seen as crude", "update": "They are in a church", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25179", "update_paraphrase": "The religious institution they are in is a church.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2857142857142857, "pred_conf_shift": -0.336427241563797, "syntactic_distance": 0.47619047619047616}, {"confidence": [0.5765902996063232, 0.42340967059135437], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.25179.gpt3.8", "original_example": {"example_id": "atomic.train.25179", "premise_hypothesis_id": "atomic.train.11513", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7zW3GWOzcYieILtCbrpSsQ==", "AtomicEventRelationId": "jiBs01APCUKNkQuDwHDpjw==", "AtomicRelationType": "xReact", "AtomicInference": "crude"}, "premise": "PersonX drops the f-bomb", "hypothesis": "PersonX is seen as crude", "update": "They are in a church", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25179", "update_paraphrase": "The location they are currently occupying is a church.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3571428571428571, "pred_conf_shift": -0.18325379490852356, "syntactic_distance": 0.45}, {"confidence": [0.42629799246788025, 0.5737020373344421], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25179.gpt3.5", "original_example": {"example_id": "atomic.train.25179", "premise_hypothesis_id": "atomic.train.11513", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7zW3GWOzcYieILtCbrpSsQ==", "AtomicEventRelationId": "jiBs01APCUKNkQuDwHDpjw==", "AtomicRelationType": "xReact", "AtomicInference": "crude"}, "premise": "PersonX drops the f-bomb", "hypothesis": "PersonX is seen as crude", "update": "They are in a church", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25179", "update_paraphrase": "They are in a church.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": -0.03296142816543579, "syntactic_distance": 0.0}, {"confidence": [0.44741716980934143, 0.552582859992981], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25179.gpt3.7", "original_example": {"example_id": "atomic.train.25179", "premise_hypothesis_id": "atomic.train.11513", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7zW3GWOzcYieILtCbrpSsQ==", "AtomicEventRelationId": "jiBs01APCUKNkQuDwHDpjw==", "AtomicRelationType": "xReact", "AtomicInference": "crude"}, "premise": "PersonX drops the f-bomb", "hypothesis": "PersonX is seen as crude", "update": "They are in a church", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25179", "update_paraphrase": "The two of them are in a church.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2527472527472526, "pred_conf_shift": -0.05408060550689697, "syntactic_distance": 0.2857142857142857}, {"confidence": [0.5070919394493103, 0.4929080307483673], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.25179.gpt3.1", "original_example": {"example_id": "atomic.train.25179", "premise_hypothesis_id": "atomic.train.11513", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7zW3GWOzcYieILtCbrpSsQ==", "AtomicEventRelationId": "jiBs01APCUKNkQuDwHDpjw==", "AtomicRelationType": "xReact", "AtomicInference": "crude"}, "premise": "PersonX drops the f-bomb", "hypothesis": "PersonX is seen as crude", "update": "They are in a church", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25179", "update_paraphrase": "They are at a church.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19999999999999996, "pred_conf_shift": -0.11375543475151062, "syntactic_distance": 0.0}, {"confidence": [0.6662182211875916, 0.3337816894054413], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.25179.gpt3.3", "original_example": {"example_id": "atomic.train.25179", "premise_hypothesis_id": "atomic.train.11513", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7zW3GWOzcYieILtCbrpSsQ==", "AtomicEventRelationId": "jiBs01APCUKNkQuDwHDpjw==", "AtomicRelationType": "xReact", "AtomicInference": "crude"}, "premise": "PersonX drops the f-bomb", "hypothesis": "PersonX is seen as crude", "update": "They are in a church", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25179", "update_paraphrase": "They are located in a church.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.09090909090909094, "pred_conf_shift": -0.27288177609443665, "syntactic_distance": 0.1875}, {"confidence": [0.6305940747261047, 0.36940595507621765], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.25179.gpt3.6", "original_example": {"example_id": "atomic.train.25179", "premise_hypothesis_id": "atomic.train.11513", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7zW3GWOzcYieILtCbrpSsQ==", "AtomicEventRelationId": "jiBs01APCUKNkQuDwHDpjw==", "AtomicRelationType": "xReact", "AtomicInference": "crude"}, "premise": "PersonX drops the f-bomb", "hypothesis": "PersonX is seen as crude", "update": "They are in a church", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25179", "update_paraphrase": "They are in a church visiting.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.09090909090909094, "pred_conf_shift": -0.23725751042366028, "syntactic_distance": 0.0}, {"confidence": [0.5659907460212708, 0.43400928378105164], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.25179.gpt3.2", "original_example": {"example_id": "atomic.train.25179", "premise_hypothesis_id": "atomic.train.11513", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7zW3GWOzcYieILtCbrpSsQ==", "AtomicEventRelationId": "jiBs01APCUKNkQuDwHDpjw==", "AtomicRelationType": "xReact", "AtomicInference": "crude"}, "premise": "PersonX drops the f-bomb", "hypothesis": "PersonX is seen as crude", "update": "They are in a church", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25179", "update_paraphrase": "If they're not in a mosque, then they must be in a church.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5055555555555555, "pred_conf_shift": -0.1726541817188263, "syntactic_distance": 0.4782608695652174}]}, "atomic.train.8996": {"original_confidence": [0.9706928133964539, 0.02930711768567562], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.9762730598449707, 0.023726949468255043], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8996.gpt3.4", "original_example": {"example_id": "atomic.train.8996", "premise_hypothesis_id": "atomic.train.4242", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xccjlT9JxpWGmK1CNhiX8A==", "AtomicEventRelationId": "TjAOaLx6mTsC4do713H3hQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to make a lot of food"}, "premise": "PersonX cooks up a storm", "hypothesis": "Because PersonX wanted to make a lot of food", "update": "PersonX is being taunted by a hungry bully.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8996", "update_paraphrase": "PersonX is being harassed by a bully who is trying to get them to give them food.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5236363636363637, "pred_conf_shift": 0.005580246448516846, "syntactic_distance": 0.0}, {"confidence": [0.9632323980331421, 0.036767564713954926], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8996.gpt3.2", "original_example": {"example_id": "atomic.train.8996", "premise_hypothesis_id": "atomic.train.4242", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xccjlT9JxpWGmK1CNhiX8A==", "AtomicEventRelationId": "TjAOaLx6mTsC4do713H3hQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to make a lot of food"}, "premise": "PersonX cooks up a storm", "hypothesis": "Because PersonX wanted to make a lot of food", "update": "PersonX is being taunted by a hungry bully.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8996", "update_paraphrase": "PersonX is being teased by a hungry bully.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.07760989010989011, "pred_conf_shift": -0.007460415363311768, "syntactic_distance": 0.0}, {"confidence": [0.9624184966087341, 0.03758151829242706], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8996.gpt3.7", "original_example": {"example_id": "atomic.train.8996", "premise_hypothesis_id": "atomic.train.4242", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xccjlT9JxpWGmK1CNhiX8A==", "AtomicEventRelationId": "TjAOaLx6mTsC4do713H3hQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to make a lot of food"}, "premise": "PersonX cooks up a storm", "hypothesis": "Because PersonX wanted to make a lot of food", "update": "PersonX is being taunted by a hungry bully.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8996", "update_paraphrase": "A hungry bully is tormenting PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3904761904761905, "pred_conf_shift": -0.008274316787719727, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.9410822987556458, 0.058917682617902756], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8996.gpt3.3", "original_example": {"example_id": "atomic.train.8996", "premise_hypothesis_id": "atomic.train.4242", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xccjlT9JxpWGmK1CNhiX8A==", "AtomicEventRelationId": "TjAOaLx6mTsC4do713H3hQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to make a lot of food"}, "premise": "PersonX cooks up a storm", "hypothesis": "Because PersonX wanted to make a lot of food", "update": "PersonX is being taunted by a hungry bully.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8996", "update_paraphrase": "A bully is tormenting PersonX and making them feel uncomfortable.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5310405643738977, "pred_conf_shift": -0.029610514640808105, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.9762208461761475, 0.023779181763529778], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8996.gpt3.0", "original_example": {"example_id": "atomic.train.8996", "premise_hypothesis_id": "atomic.train.4242", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xccjlT9JxpWGmK1CNhiX8A==", "AtomicEventRelationId": "TjAOaLx6mTsC4do713H3hQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to make a lot of food"}, "premise": "PersonX cooks up a storm", "hypothesis": "Because PersonX wanted to make a lot of food", "update": "PersonX is being taunted by a hungry bully.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8996", "update_paraphrase": "A bully is threatening PersonX and demanding food.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5041316526610644, "pred_conf_shift": 0.0055280327796936035, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.8873363733291626, 0.11266367137432098], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8996.gpt3.1", "original_example": {"example_id": "atomic.train.8996", "premise_hypothesis_id": "atomic.train.4242", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xccjlT9JxpWGmK1CNhiX8A==", "AtomicEventRelationId": "TjAOaLx6mTsC4do713H3hQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to make a lot of food"}, "premise": "PersonX cooks up a storm", "hypothesis": "Because PersonX wanted to make a lot of food", "update": "PersonX is being taunted by a hungry bully.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8996", "update_paraphrase": "The bully is taunting PersonX and making them feel uncomfortable.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5534915701582368, "pred_conf_shift": -0.08335644006729126, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.9490651488304138, 0.050934772938489914], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8996.gpt3.6", "original_example": {"example_id": "atomic.train.8996", "premise_hypothesis_id": "atomic.train.4242", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xccjlT9JxpWGmK1CNhiX8A==", "AtomicEventRelationId": "TjAOaLx6mTsC4do713H3hQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to make a lot of food"}, "premise": "PersonX cooks up a storm", "hypothesis": "Because PersonX wanted to make a lot of food", "update": "PersonX is being taunted by a hungry bully.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8996", "update_paraphrase": "A hungry bully is jeering at PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3925925925925926, "pred_conf_shift": -0.02162766456604004, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.9453270435333252, 0.0546729639172554], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8996.gpt3.5", "original_example": {"example_id": "atomic.train.8996", "premise_hypothesis_id": "atomic.train.4242", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xccjlT9JxpWGmK1CNhiX8A==", "AtomicEventRelationId": "TjAOaLx6mTsC4do713H3hQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to make a lot of food"}, "premise": "PersonX cooks up a storm", "hypothesis": "Because PersonX wanted to make a lot of food", "update": "PersonX is being taunted by a hungry bully.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8996", "update_paraphrase": "A hungry bully is picking on PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4185185185185185, "pred_conf_shift": -0.025365769863128662, "syntactic_distance": 0.16666666666666666}]}, "atomic.train.8681": {"original_confidence": [0.6175334453582764, 0.38246652483940125], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.4561292827129364, 0.543870747089386], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.8681.gpt3.1", "original_example": {"example_id": "atomic.train.8681", "premise_hypothesis_id": "atomic.train.4094", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "MTKYG5ZGJY8o0OHaUdafYQ==", "AtomicEventRelationId": "-muf5ZsyADe4qXQbwLFTVA==", "AtomicRelationType": "xEffect", "AtomicInference": "gets ready to leave"}, "premise": "PersonX gets really excited", "hypothesis": "PersonX then gets ready to leave", "update": "PersonX is at school and heard their dad came back from an overseas military posting", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8681", "update_paraphrase": "PersonX, who is currently at school, was told by someone that their dad has returned from a military posting from overseas.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3845157928491262, "pred_conf_shift": 0.16140422224998474, "syntactic_distance": 0.4583333333333333}, {"confidence": [0.5159710645675659, 0.4840289354324341], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8681.gpt3.6", "original_example": {"example_id": "atomic.train.8681", "premise_hypothesis_id": "atomic.train.4094", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "MTKYG5ZGJY8o0OHaUdafYQ==", "AtomicEventRelationId": "-muf5ZsyADe4qXQbwLFTVA==", "AtomicRelationType": "xEffect", "AtomicInference": "gets ready to leave"}, "premise": "PersonX gets really excited", "hypothesis": "PersonX then gets ready to leave", "update": "PersonX is at school and heard their dad came back from an overseas military posting", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8681", "update_paraphrase": "Person X heard that their dad had returned from an overseas military posting while they were at school.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.34593184593184595, "pred_conf_shift": 0.10156241059303284, "syntactic_distance": 0.35}, {"confidence": [0.5643126964569092, 0.43568727374076843], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8681.gpt3.2", "original_example": {"example_id": "atomic.train.8681", "premise_hypothesis_id": "atomic.train.4094", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "MTKYG5ZGJY8o0OHaUdafYQ==", "AtomicEventRelationId": "-muf5ZsyADe4qXQbwLFTVA==", "AtomicRelationType": "xEffect", "AtomicInference": "gets ready to leave"}, "premise": "PersonX gets really excited", "hypothesis": "PersonX then gets ready to leave", "update": "PersonX is at school and heard their dad came back from an overseas military posting", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8681", "update_paraphrase": "PersonX is currently at school but was told by someone that their dad has returned from being stationed overseas in the military.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4223216723216724, "pred_conf_shift": 0.05322074890136719, "syntactic_distance": 0.08695652173913043}, {"confidence": [0.39365172386169434, 0.6063483953475952], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.8681.gpt3.5", "original_example": {"example_id": "atomic.train.8681", "premise_hypothesis_id": "atomic.train.4094", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "MTKYG5ZGJY8o0OHaUdafYQ==", "AtomicEventRelationId": "-muf5ZsyADe4qXQbwLFTVA==", "AtomicRelationType": "xEffect", "AtomicInference": "gets ready to leave"}, "premise": "PersonX gets really excited", "hypothesis": "PersonX then gets ready to leave", "update": "PersonX is at school and heard their dad came back from an overseas military posting", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8681", "update_paraphrase": "PersonX is currently at school and they overheard somebody say that their dad had returned from a military posting in another country.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37598469363175246, "pred_conf_shift": 0.22388187050819397, "syntactic_distance": 0.23076923076923078}, {"confidence": [0.5430468320846558, 0.4569531977176666], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8681.gpt3.7", "original_example": {"example_id": "atomic.train.8681", "premise_hypothesis_id": "atomic.train.4094", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "MTKYG5ZGJY8o0OHaUdafYQ==", "AtomicEventRelationId": "-muf5ZsyADe4qXQbwLFTVA==", "AtomicRelationType": "xEffect", "AtomicInference": "gets ready to leave"}, "premise": "PersonX gets really excited", "hypothesis": "PersonX then gets ready to leave", "update": "PersonX is at school and heard their dad came back from an overseas military posting", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8681", "update_paraphrase": "Their dad came back from an overseas military posting while PersonX was at school.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.24827586206896546, "pred_conf_shift": 0.07448667287826538, "syntactic_distance": 0.4}, {"confidence": [0.5156837105751038, 0.4843163788318634], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8681.gpt3.0", "original_example": {"example_id": "atomic.train.8681", "premise_hypothesis_id": "atomic.train.4094", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "MTKYG5ZGJY8o0OHaUdafYQ==", "AtomicEventRelationId": "-muf5ZsyADe4qXQbwLFTVA==", "AtomicRelationType": "xEffect", "AtomicInference": "gets ready to leave"}, "premise": "PersonX gets really excited", "hypothesis": "PersonX then gets ready to leave", "update": "PersonX is at school and heard their dad came back from an overseas military posting", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8681", "update_paraphrase": "PersonX heard that their dad came back from an overseas military posting while they were at school.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.26339285714285715, "pred_conf_shift": 0.10184985399246216, "syntactic_distance": 0.3684210526315789}, {"confidence": [0.4856157600879669, 0.5143842101097107], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.8681.gpt3.8", "original_example": {"example_id": "atomic.train.8681", "premise_hypothesis_id": "atomic.train.4094", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "MTKYG5ZGJY8o0OHaUdafYQ==", "AtomicEventRelationId": "-muf5ZsyADe4qXQbwLFTVA==", "AtomicRelationType": "xEffect", "AtomicInference": "gets ready to leave"}, "premise": "PersonX gets really excited", "hypothesis": "PersonX then gets ready to leave", "update": "PersonX is at school and heard their dad came back from an overseas military posting", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8681", "update_paraphrase": "PersonX is at school and just found out that their dad came back from an overseas military posting.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.12794612794612792, "pred_conf_shift": 0.13191768527030945, "syntactic_distance": 0.16}, {"confidence": [0.5299620032310486, 0.4700380265712738], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8681.gpt3.4", "original_example": {"example_id": "atomic.train.8681", "premise_hypothesis_id": "atomic.train.4094", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "MTKYG5ZGJY8o0OHaUdafYQ==", "AtomicEventRelationId": "-muf5ZsyADe4qXQbwLFTVA==", "AtomicRelationType": "xEffect", "AtomicInference": "gets ready to leave"}, "premise": "PersonX gets really excited", "hypothesis": "PersonX then gets ready to leave", "update": "PersonX is at school and heard their dad came back from an overseas military posting", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8681", "update_paraphrase": "PersonX is at school and heard that their dad came back from an overseas military posting.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.032258064516129004, "pred_conf_shift": 0.08757150173187256, "syntactic_distance": 0.045454545454545456}, {"confidence": [0.5962983965873718, 0.403701514005661], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8681.gpt3.3", "original_example": {"example_id": "atomic.train.8681", "premise_hypothesis_id": "atomic.train.4094", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "MTKYG5ZGJY8o0OHaUdafYQ==", "AtomicEventRelationId": "-muf5ZsyADe4qXQbwLFTVA==", "AtomicRelationType": "xEffect", "AtomicInference": "gets ready to leave"}, "premise": "PersonX gets really excited", "hypothesis": "PersonX then gets ready to leave", "update": "PersonX is at school and heard their dad came back from an overseas military posting", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8681", "update_paraphrase": "PersonX is currently at school but they heard from someone that their dad just came back from an overseas military posting.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.26011904761904764, "pred_conf_shift": 0.021234989166259766, "syntactic_distance": 0.2962962962962963}]}, "atomic.train.9078": {"original_confidence": [0.8951898813247681, 0.10480998456478119], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.8708286285400391, 0.12917126715183258], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9078.gpt3.1", "original_example": {"example_id": "atomic.train.9078", "premise_hypothesis_id": "atomic.train.4279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "imRxIJz-IKXWjeoaygrBhA==", "AtomicEventRelationId": "9IAohk2HP9AlBEhfoMw9Zw==", "AtomicRelationType": "xIntent", "AtomicInference": "to waste time"}, "premise": "PersonX spins around", "hypothesis": "Because PersonX wanted to waste time", "update": "PersonX had an appointment to make.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9078", "update_paraphrase": "PersonX had an appointment that needed to be made.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.297089947089947, "pred_conf_shift": -0.024361252784729004, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.8425423502922058, 0.15745757520198822], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9078.gpt3.3", "original_example": {"example_id": "atomic.train.9078", "premise_hypothesis_id": "atomic.train.4279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "imRxIJz-IKXWjeoaygrBhA==", "AtomicEventRelationId": "9IAohk2HP9AlBEhfoMw9Zw==", "AtomicRelationType": "xIntent", "AtomicInference": "to waste time"}, "premise": "PersonX spins around", "hypothesis": "Because PersonX wanted to waste time", "update": "PersonX had an appointment to make.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9078", "update_paraphrase": "PersonX had an appointment booked.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2161616161616161, "pred_conf_shift": -0.052647531032562256, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.9166433811187744, 0.08335676044225693], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9078.gpt3.2", "original_example": {"example_id": "atomic.train.9078", "premise_hypothesis_id": "atomic.train.4279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "imRxIJz-IKXWjeoaygrBhA==", "AtomicEventRelationId": "9IAohk2HP9AlBEhfoMw9Zw==", "AtomicRelationType": "xIntent", "AtomicInference": "to waste time"}, "premise": "PersonX spins around", "hypothesis": "Because PersonX wanted to waste time", "update": "PersonX had an appointment to make.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9078", "update_paraphrase": "PersonX had an appointment that needed to be kept.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3285714285714286, "pred_conf_shift": 0.021453499794006348, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.9147200584411621, 0.0852799192070961], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9078.gpt3.5", "original_example": {"example_id": "atomic.train.9078", "premise_hypothesis_id": "atomic.train.4279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "imRxIJz-IKXWjeoaygrBhA==", "AtomicEventRelationId": "9IAohk2HP9AlBEhfoMw9Zw==", "AtomicRelationType": "xIntent", "AtomicInference": "to waste time"}, "premise": "PersonX spins around", "hypothesis": "Because PersonX wanted to waste time", "update": "PersonX had an appointment to make.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9078", "update_paraphrase": "PersonX had to make an appointment.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1333333333333333, "pred_conf_shift": 0.019530177116394043, "syntactic_distance": 0.3125}, {"confidence": [0.8892676830291748, 0.11073224246501923], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9078.gpt3.4", "original_example": {"example_id": "atomic.train.9078", "premise_hypothesis_id": "atomic.train.4279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "imRxIJz-IKXWjeoaygrBhA==", "AtomicEventRelationId": "9IAohk2HP9AlBEhfoMw9Zw==", "AtomicRelationType": "xIntent", "AtomicInference": "to waste time"}, "premise": "PersonX spins around", "hypothesis": "Because PersonX wanted to waste time", "update": "PersonX had an appointment to make.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9078", "update_paraphrase": "PersonX had a meeting to attend.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37240047534165177, "pred_conf_shift": -0.005922198295593262, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.9216048717498779, 0.07839509844779968], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9078.gpt3.0", "original_example": {"example_id": "atomic.train.9078", "premise_hypothesis_id": "atomic.train.4279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "imRxIJz-IKXWjeoaygrBhA==", "AtomicEventRelationId": "9IAohk2HP9AlBEhfoMw9Zw==", "AtomicRelationType": "xIntent", "AtomicInference": "to waste time"}, "premise": "PersonX spins around", "hypothesis": "Because PersonX wanted to waste time", "update": "PersonX had an appointment to make.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9078", "update_paraphrase": "PersonX had an appointment to keep.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.10984848484848486, "pred_conf_shift": 0.026414990425109863, "syntactic_distance": 0.0}]}, "atomic.train.3758": {"original_confidence": [0.21225231885910034, 0.7877476215362549], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.17935563623905182, 0.8206443190574646], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3758.gpt3.0", "original_example": {"example_id": "atomic.train.3758", "premise_hypothesis_id": "atomic.train.1767", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oHcFNi0rXb6mZdEjRYMq6A==", "AtomicEventRelationId": "o7c5w4-XT2e_exg5b1WTrQ==", "AtomicRelationType": "xReact", "AtomicInference": "angry"}, "premise": "PersonX is losing money", "hypothesis": "PersonX is seen as angry", "update": "PersonX set a goal of spending a lot of money.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3758", "update_paraphrase": "PersonX's goal is to spend a lot of money.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22078272604588395, "pred_conf_shift": -0.03289668262004852, "syntactic_distance": 0.375}, {"confidence": [0.07842463999986649, 0.9215753078460693], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3758.gpt3.3", "original_example": {"example_id": "atomic.train.3758", "premise_hypothesis_id": "atomic.train.1767", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oHcFNi0rXb6mZdEjRYMq6A==", "AtomicEventRelationId": "o7c5w4-XT2e_exg5b1WTrQ==", "AtomicRelationType": "xReact", "AtomicInference": "angry"}, "premise": "PersonX is losing money", "hypothesis": "PersonX is seen as angry", "update": "PersonX set a goal of spending a lot of money.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3758", "update_paraphrase": "Person X planned to spend a lot of money.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.32186234817813764, "pred_conf_shift": -0.13382767885923386, "syntactic_distance": 0.3125}, {"confidence": [0.0321345180273056, 0.9678654074668884], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3758.gpt3.1", "original_example": {"example_id": "atomic.train.3758", "premise_hypothesis_id": "atomic.train.1767", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oHcFNi0rXb6mZdEjRYMq6A==", "AtomicEventRelationId": "o7c5w4-XT2e_exg5b1WTrQ==", "AtomicRelationType": "xReact", "AtomicInference": "angry"}, "premise": "PersonX is losing money", "hypothesis": "PersonX is seen as angry", "update": "PersonX set a goal of spending a lot of money.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3758", "update_paraphrase": "PersonX hoped to spend a lot of money.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.30880816714150044, "pred_conf_shift": -0.18011780083179474, "syntactic_distance": 0.2}, {"confidence": [0.10343097895383835, 0.8965689539909363], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3758.gpt3.4", "original_example": {"example_id": "atomic.train.3758", "premise_hypothesis_id": "atomic.train.1767", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oHcFNi0rXb6mZdEjRYMq6A==", "AtomicEventRelationId": "o7c5w4-XT2e_exg5b1WTrQ==", "AtomicRelationType": "xReact", "AtomicInference": "angry"}, "premise": "PersonX is losing money", "hypothesis": "PersonX is seen as angry", "update": "PersonX set a goal of spending a lot of money.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3758", "update_paraphrase": "PersonX's goal was to spend a lot of money.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2155195681511471, "pred_conf_shift": -0.108821339905262, "syntactic_distance": 0.35294117647058826}, {"confidence": [0.23440071940422058, 0.7655993103981018], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3758.gpt3.5", "original_example": {"example_id": "atomic.train.3758", "premise_hypothesis_id": "atomic.train.1767", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oHcFNi0rXb6mZdEjRYMq6A==", "AtomicEventRelationId": "o7c5w4-XT2e_exg5b1WTrQ==", "AtomicRelationType": "xReact", "AtomicInference": "angry"}, "premise": "PersonX is losing money", "hypothesis": "PersonX is seen as angry", "update": "PersonX set a goal of spending a lot of money.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3758", "update_paraphrase": "PersonX decided to spend a lot of money.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.32393162393162395, "pred_conf_shift": 0.02214840054512024, "syntactic_distance": 0.2}, {"confidence": [0.10936843603849411, 0.8906315565109253], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3758.gpt3.2", "original_example": {"example_id": "atomic.train.3758", "premise_hypothesis_id": "atomic.train.1767", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oHcFNi0rXb6mZdEjRYMq6A==", "AtomicEventRelationId": "o7c5w4-XT2e_exg5b1WTrQ==", "AtomicRelationType": "xReact", "AtomicInference": "angry"}, "premise": "PersonX is losing money", "hypothesis": "PersonX is seen as angry", "update": "PersonX set a goal of spending a lot of money.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3758", "update_paraphrase": "The person's goal was to spend a lot of money.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2456959706959707, "pred_conf_shift": -0.10288388282060623, "syntactic_distance": 0.29411764705882354}]}, "atomic.train.32770": {"original_confidence": [0.392341673374176, 0.6076583862304688], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.5905624628067017, 0.4094375669956207], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.32770.gpt3.3", "original_example": {"example_id": "atomic.train.32770", "premise_hypothesis_id": "atomic.train.14881", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_-icuJP6QsDVjTh2oh0lzg==", "AtomicEventRelationId": "ZCo_Muwgw3W23m1NQfrcmg==", "AtomicRelationType": "xWant", "AtomicInference": "to get out of the car"}, "premise": "PersonX stops my car", "hypothesis": "As a result, PersonX wants to get out of the car", "update": "They want to drive", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32770", "update_paraphrase": "They want to drive.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": 0.19822078943252563, "syntactic_distance": 0.0}, {"confidence": [0.1754881739616394, 0.8245118856430054], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.32770.gpt3.4", "original_example": {"example_id": "atomic.train.32770", "premise_hypothesis_id": "atomic.train.14881", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_-icuJP6QsDVjTh2oh0lzg==", "AtomicEventRelationId": "ZCo_Muwgw3W23m1NQfrcmg==", "AtomicRelationType": "xWant", "AtomicInference": "to get out of the car"}, "premise": "PersonX stops my car", "hypothesis": "As a result, PersonX wants to get out of the car", "update": "They want to drive", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32770", "update_paraphrase": "They're hoping to drive.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.25, "pred_conf_shift": -0.21685349941253662, "syntactic_distance": 0.2}, {"confidence": [0.4456806480884552, 0.5543192625045776], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.32770.gpt3.6", "original_example": {"example_id": "atomic.train.32770", "premise_hypothesis_id": "atomic.train.14881", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_-icuJP6QsDVjTh2oh0lzg==", "AtomicEventRelationId": "ZCo_Muwgw3W23m1NQfrcmg==", "AtomicRelationType": "xWant", "AtomicInference": "to get out of the car"}, "premise": "PersonX stops my car", "hypothesis": "As a result, PersonX wants to get out of the car", "update": "They want to drive", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32770", "update_paraphrase": "They wish to drive.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1875, "pred_conf_shift": 0.053338974714279175, "syntactic_distance": 0.0}, {"confidence": [0.8818134069442749, 0.11818661540746689], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.32770.gpt3.0", "original_example": {"example_id": "atomic.train.32770", "premise_hypothesis_id": "atomic.train.14881", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_-icuJP6QsDVjTh2oh0lzg==", "AtomicEventRelationId": "ZCo_Muwgw3W23m1NQfrcmg==", "AtomicRelationType": "xWant", "AtomicInference": "to get out of the car"}, "premise": "PersonX stops my car", "hypothesis": "As a result, PersonX wants to get out of the car", "update": "They want to drive", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32770", "update_paraphrase": "They want to use the car.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28928571428571426, "pred_conf_shift": 0.4894717335700989, "syntactic_distance": 0.0}, {"confidence": [0.7492842078208923, 0.25071585178375244], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.32770.gpt3.2", "original_example": {"example_id": "atomic.train.32770", "premise_hypothesis_id": "atomic.train.14881", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_-icuJP6QsDVjTh2oh0lzg==", "AtomicEventRelationId": "ZCo_Muwgw3W23m1NQfrcmg==", "AtomicRelationType": "xWant", "AtomicInference": "to get out of the car"}, "premise": "PersonX stops my car", "hypothesis": "As a result, PersonX wants to get out of the car", "update": "They want to drive", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32770", "update_paraphrase": "They would like to operate the vehicle.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5401744719926538, "pred_conf_shift": 0.3569425344467163, "syntactic_distance": 0.26666666666666666}]}, "atomic.train.30236": {"original_confidence": [0.4839617609977722, 0.5160382390022278], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.11689982563257217, 0.8831002116203308], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30236.gpt3.3", "original_example": {"example_id": "atomic.train.30236", "premise_hypothesis_id": "atomic.train.13734", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aN4WvU_qnX3fZhuumYLgGw==", "AtomicEventRelationId": "VTKOwdDJgZI4Gewkkw08Zg==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gets apples for free"}, "premise": "PersonX plants an apple tree", "hypothesis": "PersonX then personX gets apples for free", "update": "PersonX's local goes through long-term drought", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30236", "update_paraphrase": "PersonX's local area has been facing a prolonged drought.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4646582175993941, "pred_conf_shift": -0.36706193536520004, "syntactic_distance": 0.2631578947368421}, {"confidence": [0.13075847923755646, 0.8692415952682495], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30236.gpt3.6", "original_example": {"example_id": "atomic.train.30236", "premise_hypothesis_id": "atomic.train.13734", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aN4WvU_qnX3fZhuumYLgGw==", "AtomicEventRelationId": "VTKOwdDJgZI4Gewkkw08Zg==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gets apples for free"}, "premise": "PersonX plants an apple tree", "hypothesis": "PersonX then personX gets apples for free", "update": "PersonX's local goes through long-term drought", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30236", "update_paraphrase": "The area where PersonX lives has been experiencing a prolonged drought.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5922681559723993, "pred_conf_shift": -0.35320328176021576, "syntactic_distance": 0.4090909090909091}, {"confidence": [0.42727920413017273, 0.5727207660675049], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30236.gpt3.2", "original_example": {"example_id": "atomic.train.30236", "premise_hypothesis_id": "atomic.train.13734", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aN4WvU_qnX3fZhuumYLgGw==", "AtomicEventRelationId": "VTKOwdDJgZI4Gewkkw08Zg==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gets apples for free"}, "premise": "PersonX plants an apple tree", "hypothesis": "PersonX then personX gets apples for free", "update": "PersonX's local goes through long-term drought", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30236", "update_paraphrase": "Sentence: PersonX's local area has been facing a long-term drought.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4426542207792208, "pred_conf_shift": -0.05668255686759949, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.3840489685535431, 0.6159510612487793], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30236.gpt3.1", "original_example": {"example_id": "atomic.train.30236", "premise_hypothesis_id": "atomic.train.13734", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aN4WvU_qnX3fZhuumYLgGw==", "AtomicEventRelationId": "VTKOwdDJgZI4Gewkkw08Zg==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gets apples for free"}, "premise": "PersonX plants an apple tree", "hypothesis": "PersonX then personX gets apples for free", "update": "PersonX's local goes through long-term drought", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30236", "update_paraphrase": "PersonX's hometown experiences long-term drought conditions.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39219771241830065, "pred_conf_shift": -0.09991279244422913, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.3204227685928345, 0.6795772314071655], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30236.gpt3.5", "original_example": {"example_id": "atomic.train.30236", "premise_hypothesis_id": "atomic.train.13734", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aN4WvU_qnX3fZhuumYLgGw==", "AtomicEventRelationId": "VTKOwdDJgZI4Gewkkw08Zg==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gets apples for free"}, "premise": "PersonX plants an apple tree", "hypothesis": "PersonX then personX gets apples for free", "update": "PersonX's local goes through long-term drought", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30236", "update_paraphrase": "PersonX's area is facing a long-term drought.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4304584304584304, "pred_conf_shift": -0.16353899240493774, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.24838866293430328, 0.7516112923622131], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30236.gpt3.4", "original_example": {"example_id": "atomic.train.30236", "premise_hypothesis_id": "atomic.train.13734", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aN4WvU_qnX3fZhuumYLgGw==", "AtomicEventRelationId": "VTKOwdDJgZI4Gewkkw08Zg==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gets apples for free"}, "premise": "PersonX plants an apple tree", "hypothesis": "PersonX then personX gets apples for free", "update": "PersonX's local goes through long-term drought", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30236", "update_paraphrase": "PersonX's hometown is going through a prolonged period of drought.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.48840890522875813, "pred_conf_shift": -0.23557309806346893, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.31637486815452576, 0.6836251020431519], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30236.gpt3.0", "original_example": {"example_id": "atomic.train.30236", "premise_hypothesis_id": "atomic.train.13734", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aN4WvU_qnX3fZhuumYLgGw==", "AtomicEventRelationId": "VTKOwdDJgZI4Gewkkw08Zg==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gets apples for free"}, "premise": "PersonX plants an apple tree", "hypothesis": "PersonX then personX gets apples for free", "update": "PersonX's local goes through long-term drought", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30236", "update_paraphrase": "PersonX's local area is going through a long-term drought.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.32763532763532766, "pred_conf_shift": -0.16758689284324646, "syntactic_distance": 0.2631578947368421}, {"confidence": [0.49516335129737854, 0.5048367381095886], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30236.gpt3.7", "original_example": {"example_id": "atomic.train.30236", "premise_hypothesis_id": "atomic.train.13734", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aN4WvU_qnX3fZhuumYLgGw==", "AtomicEventRelationId": "VTKOwdDJgZI4Gewkkw08Zg==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gets apples for free"}, "premise": "PersonX plants an apple tree", "hypothesis": "PersonX then personX gets apples for free", "update": "PersonX's local goes through long-term drought", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30236", "update_paraphrase": "Due to a long-term drought, PersonX's local area is facing water shortages.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.549738841405508, "pred_conf_shift": 0.011201590299606323, "syntactic_distance": 0.4230769230769231}, {"confidence": [0.16638366878032684, 0.833616316318512], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30236.gpt3.8", "original_example": {"example_id": "atomic.train.30236", "premise_hypothesis_id": "atomic.train.13734", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aN4WvU_qnX3fZhuumYLgGw==", "AtomicEventRelationId": "VTKOwdDJgZI4Gewkkw08Zg==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gets apples for free"}, "premise": "PersonX plants an apple tree", "hypothesis": "PersonX then personX gets apples for free", "update": "PersonX's local goes through long-term drought", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30236", "update_paraphrase": "The area where personX lives has been experiencing a long period of drought.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6269313634964604, "pred_conf_shift": -0.3175780922174454, "syntactic_distance": 0.4090909090909091}]}, "atomic.train.26954": {"original_confidence": [0.8388673067092896, 0.16113261878490448], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.7627728581428528, 0.23722709715366364], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.26954.gpt3.4", "original_example": {"example_id": "atomic.train.26954", "premise_hypothesis_id": "atomic.train.12267", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "hgPrYQckyeqZ7STrGG8iWQ==", "AtomicEventRelationId": "OpsWnirDtmfic8BLnTIonQ==", "AtomicRelationType": "xReact", "AtomicInference": "unaware"}, "premise": "PersonX runs through PersonY's head", "hypothesis": "PersonX is seen as unaware", "update": "X and Y are engaged.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26954", "update_paraphrase": "X and Y have decided to get married.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42857142857142855, "pred_conf_shift": -0.07609444856643677, "syntactic_distance": 0.10526315789473684}, {"confidence": [0.8519145250320435, 0.14808551967144012], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.26954.gpt3.3", "original_example": {"example_id": "atomic.train.26954", "premise_hypothesis_id": "atomic.train.12267", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "hgPrYQckyeqZ7STrGG8iWQ==", "AtomicEventRelationId": "OpsWnirDtmfic8BLnTIonQ==", "AtomicRelationType": "xReact", "AtomicInference": "unaware"}, "premise": "PersonX runs through PersonY's head", "hypothesis": "PersonX is seen as unaware", "update": "X and Y are engaged.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26954", "update_paraphrase": "X and Y are getting married.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23376623376623373, "pred_conf_shift": 0.013047218322753906, "syntactic_distance": 0.10526315789473684}, {"confidence": [0.8060796856880188, 0.1939203143119812], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.26954.gpt3.5", "original_example": {"example_id": "atomic.train.26954", "premise_hypothesis_id": "atomic.train.12267", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "hgPrYQckyeqZ7STrGG8iWQ==", "AtomicEventRelationId": "OpsWnirDtmfic8BLnTIonQ==", "AtomicRelationType": "xReact", "AtomicInference": "unaware"}, "premise": "PersonX runs through PersonY's head", "hypothesis": "PersonX is seen as unaware", "update": "X and Y are engaged.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26954", "update_paraphrase": "X and Y are committed to each other and plan to get married.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5317460317460317, "pred_conf_shift": -0.03278762102127075, "syntactic_distance": 0.2727272727272727}, {"confidence": [0.6893490552902222, 0.31065088510513306], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.26954.gpt3.7", "original_example": {"example_id": "atomic.train.26954", "premise_hypothesis_id": "atomic.train.12267", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "hgPrYQckyeqZ7STrGG8iWQ==", "AtomicEventRelationId": "OpsWnirDtmfic8BLnTIonQ==", "AtomicRelationType": "xReact", "AtomicInference": "unaware"}, "premise": "PersonX runs through PersonY's head", "hypothesis": "PersonX is seen as unaware", "update": "X and Y are engaged.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26954", "update_paraphrase": "X and Y are in a relationship and have decided to get married.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5317460317460317, "pred_conf_shift": -0.14951825141906738, "syntactic_distance": 0.2727272727272727}, {"confidence": [0.6874819993972778, 0.31251800060272217], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.26954.gpt3.1", "original_example": {"example_id": "atomic.train.26954", "premise_hypothesis_id": "atomic.train.12267", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "hgPrYQckyeqZ7STrGG8iWQ==", "AtomicEventRelationId": "OpsWnirDtmfic8BLnTIonQ==", "AtomicRelationType": "xReact", "AtomicInference": "unaware"}, "premise": "PersonX runs through PersonY's head", "hypothesis": "PersonX is seen as unaware", "update": "X and Y are engaged.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26954", "update_paraphrase": "X and Y are betrothed.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.16249999999999998, "pred_conf_shift": -0.15138530731201172, "syntactic_distance": 0.0}, {"confidence": [0.8082765340805054, 0.19172340631484985], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.26954.gpt3.6", "original_example": {"example_id": "atomic.train.26954", "premise_hypothesis_id": "atomic.train.12267", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "hgPrYQckyeqZ7STrGG8iWQ==", "AtomicEventRelationId": "OpsWnirDtmfic8BLnTIonQ==", "AtomicRelationType": "xReact", "AtomicInference": "unaware"}, "premise": "PersonX runs through PersonY's head", "hypothesis": "PersonX is seen as unaware", "update": "X and Y are engaged.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26954", "update_paraphrase": "X and Y are soon to be married.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3516483516483516, "pred_conf_shift": -0.03059077262878418, "syntactic_distance": 0.15789473684210525}, {"confidence": [0.8201956748962402, 0.17980438470840454], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.26954.gpt3.0", "original_example": {"example_id": "atomic.train.26954", "premise_hypothesis_id": "atomic.train.12267", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "hgPrYQckyeqZ7STrGG8iWQ==", "AtomicEventRelationId": "OpsWnirDtmfic8BLnTIonQ==", "AtomicRelationType": "xReact", "AtomicInference": "unaware"}, "premise": "PersonX runs through PersonY's head", "hypothesis": "PersonX is seen as unaware", "update": "X and Y are engaged.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26954", "update_paraphrase": "X and Y are set to get married.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3516483516483516, "pred_conf_shift": -0.018671631813049316, "syntactic_distance": 0.10526315789473684}, {"confidence": [0.8329581618309021, 0.16704179346561432], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.26954.gpt3.8", "original_example": {"example_id": "atomic.train.26954", "premise_hypothesis_id": "atomic.train.12267", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "hgPrYQckyeqZ7STrGG8iWQ==", "AtomicEventRelationId": "OpsWnirDtmfic8BLnTIonQ==", "AtomicRelationType": "xReact", "AtomicInference": "unaware"}, "premise": "PersonX runs through PersonY's head", "hypothesis": "PersonX is seen as unaware", "update": "X and Y are engaged.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26954", "update_paraphrase": "X and Y are betrothed; they are going to get married.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4732142857142857, "pred_conf_shift": -0.005909144878387451, "syntactic_distance": 0.15789473684210525}, {"confidence": [0.8337216377258301, 0.1662783920764923], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.26954.gpt3.2", "original_example": {"example_id": "atomic.train.26954", "premise_hypothesis_id": "atomic.train.12267", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "hgPrYQckyeqZ7STrGG8iWQ==", "AtomicEventRelationId": "OpsWnirDtmfic8BLnTIonQ==", "AtomicRelationType": "xReact", "AtomicInference": "unaware"}, "premise": "PersonX runs through PersonY's head", "hypothesis": "PersonX is seen as unaware", "update": "X and Y are engaged.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26954", "update_paraphrase": "X and Y are fianc\u00e9s.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.18571428571428567, "pred_conf_shift": -0.005145668983459473, "syntactic_distance": 0.16666666666666666}]}, "atomic.train.6610": {"original_confidence": [0.7277888059616089, 0.2722111940383911], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.9072744846343994, 0.09272557497024536], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.6610.gpt3.1", "original_example": {"example_id": "atomic.train.6610", "premise_hypothesis_id": "atomic.train.3126", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2vdypFnPYc5WUp4GQ2Kbrg==", "AtomicEventRelationId": "e36HBzvABtLMjRclLxlH4A==", "AtomicRelationType": "xWant", "AtomicInference": "He bakes it."}, "premise": "PersonX cooks a meal", "hypothesis": "As a result, he bakes it.", "update": "PersonX throws away microwave meal boxes", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6610", "update_paraphrase": "PersonX dispose of microwave meal boxes.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28205128205128205, "pred_conf_shift": 0.17948567867279053, "syntactic_distance": 0.42105263157894735}, {"confidence": [0.20833176374435425, 0.7916682362556458], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.6610.gpt3.4", "original_example": {"example_id": "atomic.train.6610", "premise_hypothesis_id": "atomic.train.3126", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2vdypFnPYc5WUp4GQ2Kbrg==", "AtomicEventRelationId": "e36HBzvABtLMjRclLxlH4A==", "AtomicRelationType": "xWant", "AtomicInference": "He bakes it."}, "premise": "PersonX cooks a meal", "hypothesis": "As a result, he bakes it.", "update": "PersonX throws away microwave meal boxes", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6610", "update_paraphrase": "PersonX discards microwave meal boxes.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2187812187812188, "pred_conf_shift": -0.5194570422172546, "syntactic_distance": 0.1}, {"confidence": [0.8401368260383606, 0.1598632037639618], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.6610.gpt3.3", "original_example": {"example_id": "atomic.train.6610", "premise_hypothesis_id": "atomic.train.3126", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2vdypFnPYc5WUp4GQ2Kbrg==", "AtomicEventRelationId": "e36HBzvABtLMjRclLxlH4A==", "AtomicRelationType": "xWant", "AtomicInference": "He bakes it."}, "premise": "PersonX cooks a meal", "hypothesis": "As a result, he bakes it.", "update": "PersonX throws away microwave meal boxes", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6610", "update_paraphrase": "PersonX disposes of microwave meal boxes.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2838827838827839, "pred_conf_shift": 0.11234802007675171, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.7908747792243958, 0.20912519097328186], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.6610.gpt3.0", "original_example": {"example_id": "atomic.train.6610", "premise_hypothesis_id": "atomic.train.3126", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2vdypFnPYc5WUp4GQ2Kbrg==", "AtomicEventRelationId": "e36HBzvABtLMjRclLxlH4A==", "AtomicRelationType": "xWant", "AtomicInference": "He bakes it."}, "premise": "PersonX cooks a meal", "hypothesis": "As a result, he bakes it.", "update": "PersonX throws away microwave meal boxes", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6610", "update_paraphrase": "PersonX habitually disposes of microwave meal packaging.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4007607776838546, "pred_conf_shift": 0.06308597326278687, "syntactic_distance": 0.38095238095238093}, {"confidence": [0.2247539609670639, 0.7752460241317749], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.6610.gpt3.2", "original_example": {"example_id": "atomic.train.6610", "premise_hypothesis_id": "atomic.train.3126", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2vdypFnPYc5WUp4GQ2Kbrg==", "AtomicEventRelationId": "e36HBzvABtLMjRclLxlH4A==", "AtomicRelationType": "xWant", "AtomicInference": "He bakes it."}, "premise": "PersonX cooks a meal", "hypothesis": "As a result, he bakes it.", "update": "PersonX throws away microwave meal boxes", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6610", "update_paraphrase": "PersonX gets rid of microwave meal boxes", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3066433566433566, "pred_conf_shift": -0.503034844994545, "syntactic_distance": 0.3157894736842105}]}, "atomic.train.34466": {"original_confidence": [0.6882999539375305, 0.3116999566555023], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.533560037612915, 0.46643996238708496], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34466.gpt3.6", "original_example": {"example_id": "atomic.train.34466", "premise_hypothesis_id": "atomic.train.15621", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "awMrEXosH4lHZrTerTU-3Q==", "AtomicEventRelationId": "zGBOAflZgyp_SPrCKxosUQ==", "AtomicRelationType": "xAttr", "AtomicInference": "Annoying"}, "premise": "PersonX talks much", "hypothesis": "As a result, PersonX feels annoying", "update": "PersonX is at a party socializing.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34466", "update_paraphrase": "PersonX is mingling at a party.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2894736842105263, "pred_conf_shift": -0.15473991632461548, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.8053762316703796, 0.19462378323078156], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34466.gpt3.0", "original_example": {"example_id": "atomic.train.34466", "premise_hypothesis_id": "atomic.train.15621", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "awMrEXosH4lHZrTerTU-3Q==", "AtomicEventRelationId": "zGBOAflZgyp_SPrCKxosUQ==", "AtomicRelationType": "xAttr", "AtomicInference": "Annoying"}, "premise": "PersonX talks much", "hypothesis": "As a result, PersonX feels annoying", "update": "PersonX is at a party socializing.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34466", "update_paraphrase": "At the party, PersonX is chatting and mingling with others.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4717105263157895, "pred_conf_shift": 0.11707627773284912, "syntactic_distance": 0.4}, {"confidence": [0.963446855545044, 0.03655312582850456], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34466.gpt3.2", "original_example": {"example_id": "atomic.train.34466", "premise_hypothesis_id": "atomic.train.15621", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "awMrEXosH4lHZrTerTU-3Q==", "AtomicEventRelationId": "zGBOAflZgyp_SPrCKxosUQ==", "AtomicRelationType": "xAttr", "AtomicInference": "Annoying"}, "premise": "PersonX talks much", "hypothesis": "As a result, PersonX feels annoying", "update": "PersonX is at a party socializing.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34466", "update_paraphrase": "PersonX is at a party and enjoying himself/herself.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22706766917293236, "pred_conf_shift": 0.2751469016075134, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.6451433300971985, 0.3548566401004791], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34466.gpt3.1", "original_example": {"example_id": "atomic.train.34466", "premise_hypothesis_id": "atomic.train.15621", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "awMrEXosH4lHZrTerTU-3Q==", "AtomicEventRelationId": "zGBOAflZgyp_SPrCKxosUQ==", "AtomicRelationType": "xAttr", "AtomicInference": "Annoying"}, "premise": "PersonX talks much", "hypothesis": "As a result, PersonX feels annoying", "update": "PersonX is at a party socializing.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34466", "update_paraphrase": "PersonX is mingling and socializing at a party.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2604395604395605, "pred_conf_shift": -0.04315662384033203, "syntactic_distance": 0.35}, {"confidence": [0.3391213119029999, 0.660878598690033], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34466.gpt3.3", "original_example": {"example_id": "atomic.train.34466", "premise_hypothesis_id": "atomic.train.15621", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "awMrEXosH4lHZrTerTU-3Q==", "AtomicEventRelationId": "zGBOAflZgyp_SPrCKxosUQ==", "AtomicRelationType": "xAttr", "AtomicInference": "Annoying"}, "premise": "PersonX talks much", "hypothesis": "As a result, PersonX feels annoying", "update": "PersonX is at a party socializing.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34466", "update_paraphrase": "PersonX is at a party and is talking to other people.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3519356460532931, "pred_conf_shift": -0.34917864203453064, "syntactic_distance": 0.2857142857142857}, {"confidence": [0.9676451683044434, 0.03235483169555664], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34466.gpt3.8", "original_example": {"example_id": "atomic.train.34466", "premise_hypothesis_id": "atomic.train.15621", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "awMrEXosH4lHZrTerTU-3Q==", "AtomicEventRelationId": "zGBOAflZgyp_SPrCKxosUQ==", "AtomicRelationType": "xAttr", "AtomicInference": "Annoying"}, "premise": "PersonX talks much", "hypothesis": "As a result, PersonX feels annoying", "update": "PersonX is at a party socializing.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34466", "update_paraphrase": "PersonX is enjoying themselves at the party by mingling with other guests.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5281676413255361, "pred_conf_shift": 0.27934521436691284, "syntactic_distance": 0.3}, {"confidence": [0.9585763216018677, 0.04142361506819725], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34466.gpt3.7", "original_example": {"example_id": "atomic.train.34466", "premise_hypothesis_id": "atomic.train.15621", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "awMrEXosH4lHZrTerTU-3Q==", "AtomicEventRelationId": "zGBOAflZgyp_SPrCKxosUQ==", "AtomicRelationType": "xAttr", "AtomicInference": "Annoying"}, "premise": "PersonX talks much", "hypothesis": "As a result, PersonX feels annoying", "update": "PersonX is at a party socializing.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34466", "update_paraphrase": "Person X is enjoying themselves at a party, mingling with others.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.35889497499404627, "pred_conf_shift": 0.27027636766433716, "syntactic_distance": 0.3}, {"confidence": [0.964428186416626, 0.03557183966040611], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34466.gpt3.4", "original_example": {"example_id": "atomic.train.34466", "premise_hypothesis_id": "atomic.train.15621", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "awMrEXosH4lHZrTerTU-3Q==", "AtomicEventRelationId": "zGBOAflZgyp_SPrCKxosUQ==", "AtomicRelationType": "xAttr", "AtomicInference": "Annoying"}, "premise": "PersonX talks much", "hypothesis": "As a result, PersonX feels annoying", "update": "PersonX is at a party socializing.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34466", "update_paraphrase": "PersonX is enjoying themselves at a party by talking with other people.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.43765432098765433, "pred_conf_shift": 0.27612823247909546, "syntactic_distance": 0.3}]}, "atomic.train.8861": {"original_confidence": [0.55936199426651, 0.44063800573349], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.30973151326179504, 0.6902685761451721], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.8861.gpt3.6", "original_example": {"example_id": "atomic.train.8861", "premise_hypothesis_id": "atomic.train.4176", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Uyi46HLhF7DKqj1_zOl5Yg==", "AtomicEventRelationId": "AXj_rUB5w-vvAAVypQUOiQ==", "AtomicRelationType": "xWant", "AtomicInference": "to watch PersonY unwrap the gift"}, "premise": "PersonX gives PersonY a gift", "hypothesis": "As a result, PersonX wants to watch PersonY unwrap the gift", "update": "X hand delivers the gift.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8861", "update_paraphrase": "X personally gives the gift to the intended recipient.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5209314495028781, "pred_conf_shift": 0.24963057041168213, "syntactic_distance": 0.2727272727272727}, {"confidence": [0.23635712265968323, 0.7636427879333496], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.8861.gpt3.3", "original_example": {"example_id": "atomic.train.8861", "premise_hypothesis_id": "atomic.train.4176", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Uyi46HLhF7DKqj1_zOl5Yg==", "AtomicEventRelationId": "AXj_rUB5w-vvAAVypQUOiQ==", "AtomicRelationType": "xWant", "AtomicInference": "to watch PersonY unwrap the gift"}, "premise": "PersonX gives PersonY a gift", "hypothesis": "As a result, PersonX wants to watch PersonY unwrap the gift", "update": "X hand delivers the gift.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8861", "update_paraphrase": "X deliverers the package by hand.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.36730945821854916, "pred_conf_shift": 0.3230047821998596, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.18785424530506134, 0.8121457099914551], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.8861.gpt3.2", "original_example": {"example_id": "atomic.train.8861", "premise_hypothesis_id": "atomic.train.4176", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Uyi46HLhF7DKqj1_zOl5Yg==", "AtomicEventRelationId": "AXj_rUB5w-vvAAVypQUOiQ==", "AtomicRelationType": "xWant", "AtomicInference": "to watch PersonY unwrap the gift"}, "premise": "PersonX gives PersonY a gift", "hypothesis": "As a result, PersonX wants to watch PersonY unwrap the gift", "update": "X hand delivers the gift.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8861", "update_paraphrase": "X makes sure the gift is delivered by hand.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4843937575030011, "pred_conf_shift": 0.3715077042579651, "syntactic_distance": 0.29411764705882354}, {"confidence": [0.3356677293777466, 0.6643323302268982], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.8861.gpt3.4", "original_example": {"example_id": "atomic.train.8861", "premise_hypothesis_id": "atomic.train.4176", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Uyi46HLhF7DKqj1_zOl5Yg==", "AtomicEventRelationId": "AXj_rUB5w-vvAAVypQUOiQ==", "AtomicRelationType": "xWant", "AtomicInference": "to watch PersonY unwrap the gift"}, "premise": "PersonX gives PersonY a gift", "hypothesis": "As a result, PersonX wants to watch PersonY unwrap the gift", "update": "X hand delivers the gift.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8861", "update_paraphrase": "X personally delivers the gift.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.18571428571428567, "pred_conf_shift": 0.2236943244934082, "syntactic_distance": 0.15789473684210525}, {"confidence": [0.15057019889354706, 0.8494297862052917], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.8861.gpt3.0", "original_example": {"example_id": "atomic.train.8861", "premise_hypothesis_id": "atomic.train.4176", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Uyi46HLhF7DKqj1_zOl5Yg==", "AtomicEventRelationId": "AXj_rUB5w-vvAAVypQUOiQ==", "AtomicRelationType": "xWant", "AtomicInference": "to watch PersonY unwrap the gift"}, "premise": "PersonX gives PersonY a gift", "hypothesis": "As a result, PersonX wants to watch PersonY unwrap the gift", "update": "X hand delivers the gift.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8861", "update_paraphrase": "The gift is hand delivered by X.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4313725490196079, "pred_conf_shift": 0.40879178047180176, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.4495358467102051, 0.5504641532897949], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.8861.gpt3.1", "original_example": {"example_id": "atomic.train.8861", "premise_hypothesis_id": "atomic.train.4176", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Uyi46HLhF7DKqj1_zOl5Yg==", "AtomicEventRelationId": "AXj_rUB5w-vvAAVypQUOiQ==", "AtomicRelationType": "xWant", "AtomicInference": "to watch PersonY unwrap the gift"}, "premise": "PersonX gives PersonY a gift", "hypothesis": "As a result, PersonX wants to watch PersonY unwrap the gift", "update": "X hand delivers the gift.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8861", "update_paraphrase": "X delivers the gift by hand.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.27272727272727276, "pred_conf_shift": 0.10982614755630493, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.03150962293148041, 0.9684903621673584], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.8861.gpt3.5", "original_example": {"example_id": "atomic.train.8861", "premise_hypothesis_id": "atomic.train.4176", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Uyi46HLhF7DKqj1_zOl5Yg==", "AtomicEventRelationId": "AXj_rUB5w-vvAAVypQUOiQ==", "AtomicRelationType": "xWant", "AtomicInference": "to watch PersonY unwrap the gift"}, "premise": "PersonX gives PersonY a gift", "hypothesis": "As a result, PersonX wants to watch PersonY unwrap the gift", "update": "X hand delivers the gift.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8861", "update_paraphrase": "X gives the gift in person.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.40326340326340326, "pred_conf_shift": 0.5278523564338684, "syntactic_distance": 0.3157894736842105}]}, "atomic.train.21524": {"original_confidence": [0.28367897868156433, 0.7163210511207581], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.29812151193618774, 0.7018784880638123], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.21524.gpt3.3", "original_example": {"example_id": "atomic.train.21524", "premise_hypothesis_id": "atomic.train.9915", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "lVdoeI2zLZAOPTbCD7ccxw==", "AtomicEventRelationId": "bvRZ9yX-QzgN0g8N2tKiuw==", "AtomicRelationType": "xNeed", "AtomicInference": "To apply bright makeup"}, "premise": "PersonX shines like the sun", "hypothesis": "Before, PersonX needed to apply bright makeup", "update": "PersonX got very sweaty.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21524", "update_paraphrase": "PersonX became very sweaty.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22499999999999998, "pred_conf_shift": 0.014442533254623413, "syntactic_distance": 0.0}, {"confidence": [0.3038414418697357, 0.6961585283279419], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.21524.gpt3.5", "original_example": {"example_id": "atomic.train.21524", "premise_hypothesis_id": "atomic.train.9915", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "lVdoeI2zLZAOPTbCD7ccxw==", "AtomicEventRelationId": "bvRZ9yX-QzgN0g8N2tKiuw==", "AtomicRelationType": "xNeed", "AtomicInference": "To apply bright makeup"}, "premise": "PersonX shines like the sun", "hypothesis": "Before, PersonX needed to apply bright makeup", "update": "PersonX got very sweaty.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21524", "update_paraphrase": "PersonX became very sweaty and uncomfortable.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4596153846153846, "pred_conf_shift": 0.020162463188171387, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.3046897053718567, 0.6953102350234985], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.21524.gpt3.6", "original_example": {"example_id": "atomic.train.21524", "premise_hypothesis_id": "atomic.train.9915", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "lVdoeI2zLZAOPTbCD7ccxw==", "AtomicEventRelationId": "bvRZ9yX-QzgN0g8N2tKiuw==", "AtomicRelationType": "xNeed", "AtomicInference": "To apply bright makeup"}, "premise": "PersonX shines like the sun", "hypothesis": "Before, PersonX needed to apply bright makeup", "update": "PersonX got very sweaty.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21524", "update_paraphrase": "PersonX got super sweaty.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.14898989898989895, "pred_conf_shift": 0.02101072669029236, "syntactic_distance": 0.0}, {"confidence": [0.3054022490978241, 0.6945977807044983], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.21524.gpt3.4", "original_example": {"example_id": "atomic.train.21524", "premise_hypothesis_id": "atomic.train.9915", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "lVdoeI2zLZAOPTbCD7ccxw==", "AtomicEventRelationId": "bvRZ9yX-QzgN0g8N2tKiuw==", "AtomicRelationType": "xNeed", "AtomicInference": "To apply bright makeup"}, "premise": "PersonX shines like the sun", "hypothesis": "Before, PersonX needed to apply bright makeup", "update": "PersonX got very sweaty.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21524", "update_paraphrase": "PersonX was very sweaty.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22499999999999998, "pred_conf_shift": 0.021723270416259766, "syntactic_distance": 0.0625}, {"confidence": [0.2824215888977051, 0.7175784111022949], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.21524.gpt3.0", "original_example": {"example_id": "atomic.train.21524", "premise_hypothesis_id": "atomic.train.9915", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "lVdoeI2zLZAOPTbCD7ccxw==", "AtomicEventRelationId": "bvRZ9yX-QzgN0g8N2tKiuw==", "AtomicRelationType": "xNeed", "AtomicInference": "To apply bright makeup"}, "premise": "PersonX shines like the sun", "hypothesis": "Before, PersonX needed to apply bright makeup", "update": "PersonX got very sweaty.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21524", "update_paraphrase": "PersonX was sweating a lot.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5206349206349207, "pred_conf_shift": -0.001257389783859253, "syntactic_distance": 0.25}, {"confidence": [0.3461439907550812, 0.6538559794425964], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.21524.gpt3.1", "original_example": {"example_id": "atomic.train.21524", "premise_hypothesis_id": "atomic.train.9915", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "lVdoeI2zLZAOPTbCD7ccxw==", "AtomicEventRelationId": "bvRZ9yX-QzgN0g8N2tKiuw==", "AtomicRelationType": "xNeed", "AtomicInference": "To apply bright makeup"}, "premise": "PersonX shines like the sun", "hypothesis": "Before, PersonX needed to apply bright makeup", "update": "PersonX got very sweaty.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21524", "update_paraphrase": "PersonX broke out in a sweat.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.49797979797979797, "pred_conf_shift": 0.062465012073516846, "syntactic_distance": 0.3333333333333333}]}, "atomic.train.20538": {"original_confidence": [0.4916888177394867, 0.5083112120628357], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.37771525979042053, 0.6222847104072571], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.20538.gpt3.3", "original_example": {"example_id": "atomic.train.20538", "premise_hypothesis_id": "atomic.train.9497", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ofMIVjvruDtdgxeshzUqDA==", "AtomicEventRelationId": "91t3GzzFWnsmJBUE5OFq4w==", "AtomicRelationType": "xEffect", "AtomicInference": "talks to the teller"}, "premise": "PersonX calls the bank", "hypothesis": "PersonX then talks to the teller", "update": "PersonX just needs to know the bank's hours.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20538", "update_paraphrase": "PersonX needs to know when the bank is open.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2745098039215686, "pred_conf_shift": -0.11397355794906616, "syntactic_distance": 0.1875}, {"confidence": [0.4829452931880951, 0.5170547366142273], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.20538.gpt3.2", "original_example": {"example_id": "atomic.train.20538", "premise_hypothesis_id": "atomic.train.9497", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ofMIVjvruDtdgxeshzUqDA==", "AtomicEventRelationId": "91t3GzzFWnsmJBUE5OFq4w==", "AtomicRelationType": "xEffect", "AtomicInference": "talks to the teller"}, "premise": "PersonX calls the bank", "hypothesis": "PersonX then talks to the teller", "update": "PersonX just needs to know the bank's hours.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20538", "update_paraphrase": "All PersonX needs to do is figure out the bank's hours.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.30325814536340845, "pred_conf_shift": -0.008743524551391602, "syntactic_distance": 0.21052631578947367}, {"confidence": [0.6580986976623535, 0.34190136194229126], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.20538.gpt3.4", "original_example": {"example_id": "atomic.train.20538", "premise_hypothesis_id": "atomic.train.9497", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ofMIVjvruDtdgxeshzUqDA==", "AtomicEventRelationId": "91t3GzzFWnsmJBUE5OFq4w==", "AtomicRelationType": "xEffect", "AtomicInference": "talks to the teller"}, "premise": "PersonX calls the bank", "hypothesis": "PersonX then talks to the teller", "update": "PersonX just needs to know the bank's hours.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20538", "update_paraphrase": "PersonX just needs to know when the bank is open.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.27168510501843834, "pred_conf_shift": 0.16640987992286682, "syntactic_distance": 0.05555555555555555}, {"confidence": [0.6575632095336914, 0.3424367606639862], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.20538.gpt3.6", "original_example": {"example_id": "atomic.train.20538", "premise_hypothesis_id": "atomic.train.9497", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ofMIVjvruDtdgxeshzUqDA==", "AtomicEventRelationId": "91t3GzzFWnsmJBUE5OFq4w==", "AtomicRelationType": "xEffect", "AtomicInference": "talks to the teller"}, "premise": "PersonX calls the bank", "hypothesis": "PersonX then talks to the teller", "update": "PersonX just needs to know the bank's hours.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20538", "update_paraphrase": "PersonX only needs to be aware of the bank's operating hours.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.35872899030793765, "pred_conf_shift": 0.1658743917942047, "syntactic_distance": 0.05555555555555555}, {"confidence": [0.5798566341400146, 0.42014336585998535], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.20538.gpt3.1", "original_example": {"example_id": "atomic.train.20538", "premise_hypothesis_id": "atomic.train.9497", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ofMIVjvruDtdgxeshzUqDA==", "AtomicEventRelationId": "91t3GzzFWnsmJBUE5OFq4w==", "AtomicRelationType": "xEffect", "AtomicInference": "talks to the teller"}, "premise": "PersonX calls the bank", "hypothesis": "PersonX then talks to the teller", "update": "PersonX just needs to know the bank's hours.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20538", "update_paraphrase": "PersonX only needs to be aware of the bank's hours.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2946127946127946, "pred_conf_shift": 0.08816781640052795, "syntactic_distance": 0.0}, {"confidence": [0.4509831964969635, 0.5490168929100037], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.20538.gpt3.5", "original_example": {"example_id": "atomic.train.20538", "premise_hypothesis_id": "atomic.train.9497", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ofMIVjvruDtdgxeshzUqDA==", "AtomicEventRelationId": "91t3GzzFWnsmJBUE5OFq4w==", "AtomicRelationType": "xEffect", "AtomicInference": "talks to the teller"}, "premise": "PersonX calls the bank", "hypothesis": "PersonX then talks to the teller", "update": "PersonX just needs to know the bank's hours.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20538", "update_paraphrase": "All PersonX needs to do is find out what time the bank is open.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4733044733044732, "pred_conf_shift": -0.04070562124252319, "syntactic_distance": 0.21052631578947367}, {"confidence": [0.5424219965934753, 0.4575779438018799], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.20538.gpt3.7", "original_example": {"example_id": "atomic.train.20538", "premise_hypothesis_id": "atomic.train.9497", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ofMIVjvruDtdgxeshzUqDA==", "AtomicEventRelationId": "91t3GzzFWnsmJBUE5OFq4w==", "AtomicRelationType": "xEffect", "AtomicInference": "talks to the teller"}, "premise": "PersonX calls the bank", "hypothesis": "PersonX then talks to the teller", "update": "PersonX just needs to know the bank's hours.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20538", "update_paraphrase": "PersonX just needs to know the bank's operating hours.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.05882352941176472, "pred_conf_shift": 0.05073317885398865, "syntactic_distance": 0.0}, {"confidence": [0.48091161251068115, 0.5190885066986084], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.20538.gpt3.0", "original_example": {"example_id": "atomic.train.20538", "premise_hypothesis_id": "atomic.train.9497", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ofMIVjvruDtdgxeshzUqDA==", "AtomicEventRelationId": "91t3GzzFWnsmJBUE5OFq4w==", "AtomicRelationType": "xEffect", "AtomicInference": "talks to the teller"}, "premise": "PersonX calls the bank", "hypothesis": "PersonX then talks to the teller", "update": "PersonX just needs to know the bank's hours.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20538", "update_paraphrase": "All PersonX requires is the bank's hours of operation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4052418170065228, "pred_conf_shift": -0.010777205228805542, "syntactic_distance": 0.35}]}, "atomic.train.8741": {"original_confidence": [0.11086580902338028, 0.8891341686248779], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.059774499386548996, 0.9402254223823547], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.8741.gpt3.3", "original_example": {"example_id": "atomic.train.8741", "premise_hypothesis_id": "atomic.train.4124", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "VFNbejTDXKqojl22XHhFZQ==", "AtomicEventRelationId": "rkUDECX6gh-kN980V3x5BA==", "AtomicRelationType": "xEffect", "AtomicInference": "register a complaint"}, "premise": "PersonX proves PersonY wrong", "hypothesis": "PersonX then register a complaint", "update": "PersonX looks angry.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8741", "update_paraphrase": "It looks like PersonX is angry.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.41269841269841273, "pred_conf_shift": 0.05109125375747681, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.10093449801206589, 0.8990655541419983], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.8741.gpt3.1", "original_example": {"example_id": "atomic.train.8741", "premise_hypothesis_id": "atomic.train.4124", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "VFNbejTDXKqojl22XHhFZQ==", "AtomicEventRelationId": "rkUDECX6gh-kN980V3x5BA==", "AtomicRelationType": "xEffect", "AtomicInference": "register a complaint"}, "premise": "PersonX proves PersonY wrong", "hypothesis": "PersonX then register a complaint", "update": "PersonX looks angry.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8741", "update_paraphrase": "Person X seems to be angry.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5091575091575091, "pred_conf_shift": 0.009931385517120361, "syntactic_distance": 0.2}, {"confidence": [0.05682253837585449, 0.9431774020195007], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.8741.gpt3.2", "original_example": {"example_id": "atomic.train.8741", "premise_hypothesis_id": "atomic.train.4124", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "VFNbejTDXKqojl22XHhFZQ==", "AtomicEventRelationId": "rkUDECX6gh-kN980V3x5BA==", "AtomicRelationType": "xEffect", "AtomicInference": "register a complaint"}, "premise": "PersonX proves PersonY wrong", "hypothesis": "PersonX then register a complaint", "update": "PersonX looks angry.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8741", "update_paraphrase": "PersonX looks like they're angry.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.25, "pred_conf_shift": 0.0540432333946228, "syntactic_distance": 0.2}, {"confidence": [0.11820464581251144, 0.881795346736908], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.8741.gpt3.0", "original_example": {"example_id": "atomic.train.8741", "premise_hypothesis_id": "atomic.train.4124", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "VFNbejTDXKqojl22XHhFZQ==", "AtomicEventRelationId": "rkUDECX6gh-kN980V3x5BA==", "AtomicRelationType": "xEffect", "AtomicInference": "register a complaint"}, "premise": "PersonX proves PersonY wrong", "hypothesis": "PersonX then register a complaint", "update": "PersonX looks angry.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8741", "update_paraphrase": "PersonX appears to be angry.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3928571428571429, "pred_conf_shift": -0.007338821887969971, "syntactic_distance": 0.14285714285714285}]}, "atomic.train.1286": {"original_confidence": [0.41837963461875916, 0.5816203951835632], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.8892316818237305, 0.11076825857162476], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1286.gpt3.6", "original_example": {"example_id": "atomic.train.1286", "premise_hypothesis_id": "atomic.train.609", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZHckFqfAohyq-uCST8zg6g==", "AtomicEventRelationId": "Xu0FC80rTmCJ7xu2oRZHmQ==", "AtomicRelationType": "xWant", "AtomicInference": "to send PersonY a reminder"}, "premise": "PersonX gives PersonY a time", "hypothesis": "As a result, PersonX wants to send PersonY a reminder", "update": "PersonX forgot PersonY's name.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1286", "update_paraphrase": "PersonX can't remember PersonY's name.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2814814814814815, "pred_conf_shift": 0.4708520472049713, "syntactic_distance": 0.35294117647058826}, {"confidence": [0.8449659943580627, 0.15503402054309845], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1286.gpt3.0", "original_example": {"example_id": "atomic.train.1286", "premise_hypothesis_id": "atomic.train.609", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZHckFqfAohyq-uCST8zg6g==", "AtomicEventRelationId": "Xu0FC80rTmCJ7xu2oRZHmQ==", "AtomicRelationType": "xWant", "AtomicInference": "to send PersonY a reminder"}, "premise": "PersonX gives PersonY a time", "hypothesis": "As a result, PersonX wants to send PersonY a reminder", "update": "PersonX forgot PersonY's name.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1286", "update_paraphrase": "The name of the other person escaped PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5810485810485809, "pred_conf_shift": 0.4265863597393036, "syntactic_distance": 0.4117647058823529}, {"confidence": [0.9324529767036438, 0.06754707545042038], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1286.gpt3.4", "original_example": {"example_id": "atomic.train.1286", "premise_hypothesis_id": "atomic.train.609", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZHckFqfAohyq-uCST8zg6g==", "AtomicEventRelationId": "Xu0FC80rTmCJ7xu2oRZHmQ==", "AtomicRelationType": "xWant", "AtomicInference": "to send PersonY a reminder"}, "premise": "PersonX gives PersonY a time", "hypothesis": "As a result, PersonX wants to send PersonY a reminder", "update": "PersonX forgot PersonY's name.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1286", "update_paraphrase": "PersonX forgot who PersonY was.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.32486772486772486, "pred_conf_shift": 0.5140733420848846, "syntactic_distance": 0.1875}, {"confidence": [0.9466268420219421, 0.0533730685710907], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1286.gpt3.5", "original_example": {"example_id": "atomic.train.1286", "premise_hypothesis_id": "atomic.train.609", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZHckFqfAohyq-uCST8zg6g==", "AtomicEventRelationId": "Xu0FC80rTmCJ7xu2oRZHmQ==", "AtomicRelationType": "xWant", "AtomicInference": "to send PersonY a reminder"}, "premise": "PersonX gives PersonY a time", "hypothesis": "As a result, PersonX wants to send PersonY a reminder", "update": "PersonX forgot PersonY's name.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1286", "update_paraphrase": "PersonX could not remember who PersonY was.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5222222222222221, "pred_conf_shift": 0.528247207403183, "syntactic_distance": 0.29411764705882354}, {"confidence": [0.9622195363044739, 0.03778039664030075], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1286.gpt3.2", "original_example": {"example_id": "atomic.train.1286", "premise_hypothesis_id": "atomic.train.609", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZHckFqfAohyq-uCST8zg6g==", "AtomicEventRelationId": "Xu0FC80rTmCJ7xu2oRZHmQ==", "AtomicRelationType": "xWant", "AtomicInference": "to send PersonY a reminder"}, "premise": "PersonX gives PersonY a time", "hypothesis": "As a result, PersonX wants to send PersonY a reminder", "update": "PersonX forgot PersonY's name.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1286", "update_paraphrase": "PersonX blanked on PersonY's name.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2561728395061728, "pred_conf_shift": 0.5438399016857147, "syntactic_distance": 0.3125}, {"confidence": [0.6359901428222656, 0.3640097677707672], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1286.gpt3.7", "original_example": {"example_id": "atomic.train.1286", "premise_hypothesis_id": "atomic.train.609", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZHckFqfAohyq-uCST8zg6g==", "AtomicEventRelationId": "Xu0FC80rTmCJ7xu2oRZHmQ==", "AtomicRelationType": "xWant", "AtomicInference": "to send PersonY a reminder"}, "premise": "PersonX gives PersonY a time", "hypothesis": "As a result, PersonX wants to send PersonY a reminder", "update": "PersonX forgot PersonY's name.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1286", "update_paraphrase": "PersonX completely forgot PersonY's name.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.11111111111111116, "pred_conf_shift": 0.21761050820350647, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.7798551321029663, 0.22014488279819489], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1286.gpt3.1", "original_example": {"example_id": "atomic.train.1286", "premise_hypothesis_id": "atomic.train.609", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZHckFqfAohyq-uCST8zg6g==", "AtomicEventRelationId": "Xu0FC80rTmCJ7xu2oRZHmQ==", "AtomicRelationType": "xWant", "AtomicInference": "to send PersonY a reminder"}, "premise": "PersonX gives PersonY a time", "hypothesis": "As a result, PersonX wants to send PersonY a reminder", "update": "PersonX forgot PersonY's name.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1286", "update_paraphrase": "PersonX couldn't remember PersonY's name.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.26739926739926745, "pred_conf_shift": 0.36147549748420715, "syntactic_distance": 0.35294117647058826}, {"confidence": [0.6451749205589294, 0.35482504963874817], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1286.gpt3.3", "original_example": {"example_id": "atomic.train.1286", "premise_hypothesis_id": "atomic.train.609", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZHckFqfAohyq-uCST8zg6g==", "AtomicEventRelationId": "Xu0FC80rTmCJ7xu2oRZHmQ==", "AtomicRelationType": "xWant", "AtomicInference": "to send PersonY a reminder"}, "premise": "PersonX gives PersonY a time", "hypothesis": "As a result, PersonX wants to send PersonY a reminder", "update": "PersonX forgot PersonY's name.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1286", "update_paraphrase": "PersonX was unable to remember PersonY's name.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4075757575757576, "pred_conf_shift": 0.2267952859401703, "syntactic_distance": 0.25}]}, "atomic.train.29981": {"original_confidence": [0.8199125528335571, 0.18008743226528168], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.8756982684135437, 0.12430178374052048], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29981.gpt3.8", "original_example": {"example_id": "atomic.train.29981", "premise_hypothesis_id": "atomic.train.13615", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Zq0xZJaXgmQKLhG-1JVYgQ==", "AtomicEventRelationId": "QnU190JqJBwVgGvveuFstA==", "AtomicRelationType": "xNeed", "AtomicInference": "to know about something"}, "premise": "PersonX is looking forward to it", "hypothesis": "Before, PersonX needed to know about something", "update": "PersonX had planned the vacation for the family.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29981", "update_paraphrase": "PersonX had organized the family vacation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3248299319727891, "pred_conf_shift": -0.0557856485247612, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.5433078408241272, 0.4566921591758728], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29981.gpt3.2", "original_example": {"example_id": "atomic.train.29981", "premise_hypothesis_id": "atomic.train.13615", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Zq0xZJaXgmQKLhG-1JVYgQ==", "AtomicEventRelationId": "QnU190JqJBwVgGvveuFstA==", "AtomicRelationType": "xNeed", "AtomicInference": "to know about something"}, "premise": "PersonX is looking forward to it", "hypothesis": "Before, PersonX needed to know about something", "update": "PersonX had planned the vacation for the family.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29981", "update_paraphrase": "PersonX spent a lot of time organizing a trip the whole family could enjoy.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.565991851285969, "pred_conf_shift": 0.2766047269105911, "syntactic_distance": 0.21052631578947367}, {"confidence": [0.7366358637809753, 0.26336416602134705], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29981.gpt3.6", "original_example": {"example_id": "atomic.train.29981", "premise_hypothesis_id": "atomic.train.13615", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Zq0xZJaXgmQKLhG-1JVYgQ==", "AtomicEventRelationId": "QnU190JqJBwVgGvveuFstA==", "AtomicRelationType": "xNeed", "AtomicInference": "to know about something"}, "premise": "PersonX is looking forward to it", "hypothesis": "Before, PersonX needed to know about something", "update": "PersonX had planned the vacation for the family.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29981", "update_paraphrase": "PersonX had planned a vacation for the family.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.11249999999999999, "pred_conf_shift": 0.08327673375606537, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.8172585368156433, 0.18274140357971191], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29981.gpt3.0", "original_example": {"example_id": "atomic.train.29981", "premise_hypothesis_id": "atomic.train.13615", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Zq0xZJaXgmQKLhG-1JVYgQ==", "AtomicEventRelationId": "QnU190JqJBwVgGvveuFstA==", "AtomicRelationType": "xNeed", "AtomicInference": "to know about something"}, "premise": "PersonX is looking forward to it", "hypothesis": "Before, PersonX needed to know about something", "update": "PersonX had planned the vacation for the family.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29981", "update_paraphrase": "PersonX had created and organized the family's vacation plans.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.31572936867054513, "pred_conf_shift": 0.002653971314430237, "syntactic_distance": 0.21052631578947367}, {"confidence": [0.8816818594932556, 0.11831815540790558], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29981.gpt3.1", "original_example": {"example_id": "atomic.train.29981", "premise_hypothesis_id": "atomic.train.13615", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Zq0xZJaXgmQKLhG-1JVYgQ==", "AtomicEventRelationId": "QnU190JqJBwVgGvveuFstA==", "AtomicRelationType": "xNeed", "AtomicInference": "to know about something"}, "premise": "PersonX is looking forward to it", "hypothesis": "Before, PersonX needed to know about something", "update": "PersonX had planned the vacation for the family.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29981", "update_paraphrase": "PersonX meticulously planned the ideal vacation for the family.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2082043343653251, "pred_conf_shift": -0.0617692768573761, "syntactic_distance": 0.2631578947368421}, {"confidence": [0.8699343800544739, 0.13006563484668732], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29981.gpt3.5", "original_example": {"example_id": "atomic.train.29981", "premise_hypothesis_id": "atomic.train.13615", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Zq0xZJaXgmQKLhG-1JVYgQ==", "AtomicEventRelationId": "QnU190JqJBwVgGvveuFstA==", "AtomicRelationType": "xNeed", "AtomicInference": "to know about something"}, "premise": "PersonX is looking forward to it", "hypothesis": "Before, PersonX needed to know about something", "update": "PersonX had planned the vacation for the family.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29981", "update_paraphrase": "PersonX had organized and planned the family vacation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.35416666666666663, "pred_conf_shift": -0.05002179741859436, "syntactic_distance": 0.15789473684210525}, {"confidence": [0.8582191467285156, 0.14178088307380676], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29981.gpt3.7", "original_example": {"example_id": "atomic.train.29981", "premise_hypothesis_id": "atomic.train.13615", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Zq0xZJaXgmQKLhG-1JVYgQ==", "AtomicEventRelationId": "QnU190JqJBwVgGvveuFstA==", "AtomicRelationType": "xNeed", "AtomicInference": "to know about something"}, "premise": "PersonX is looking forward to it", "hypothesis": "Before, PersonX needed to know about something", "update": "PersonX had planned the vacation for the family.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29981", "update_paraphrase": "PersonX had arranged the vacation for the family in advance.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2740740740740741, "pred_conf_shift": -0.038306549191474915, "syntactic_distance": 0.05263157894736842}, {"confidence": [0.8983204960823059, 0.10167953372001648], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29981.gpt3.4", "original_example": {"example_id": "atomic.train.29981", "premise_hypothesis_id": "atomic.train.13615", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Zq0xZJaXgmQKLhG-1JVYgQ==", "AtomicEventRelationId": "QnU190JqJBwVgGvveuFstA==", "AtomicRelationType": "xNeed", "AtomicInference": "to know about something"}, "premise": "PersonX is looking forward to it", "hypothesis": "Before, PersonX needed to know about something", "update": "PersonX had planned the vacation for the family.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29981", "update_paraphrase": "PersonX had organized and set up the family vacation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3290849673202614, "pred_conf_shift": -0.0784078985452652, "syntactic_distance": 0.2}, {"confidence": [0.7014405131340027, 0.29855960607528687], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29981.gpt3.3", "original_example": {"example_id": "atomic.train.29981", "premise_hypothesis_id": "atomic.train.13615", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Zq0xZJaXgmQKLhG-1JVYgQ==", "AtomicEventRelationId": "QnU190JqJBwVgGvveuFstA==", "AtomicRelationType": "xNeed", "AtomicInference": "to know about something"}, "premise": "PersonX is looking forward to it", "hypothesis": "Before, PersonX needed to know about something", "update": "PersonX had planned the vacation for the family.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29981", "update_paraphrase": "PersonX had meticulously planned the family vacation down to the last detail.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3494736842105264, "pred_conf_shift": 0.11847217381000519, "syntactic_distance": 0.1}]}, "atomic.train.21420": {"original_confidence": [0.9200598001480103, 0.07994009554386139], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.8551241159439087, 0.14487585425376892], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.21420.gpt3.6", "original_example": {"example_id": "atomic.train.21420", "premise_hypothesis_id": "atomic.train.9873", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8oBDwS2qBnjvIoC18aaNoA==", "AtomicEventRelationId": "X-OihNMi_kGeQWhZmwSYiA==", "AtomicRelationType": "xWant", "AtomicInference": "nothing"}, "premise": "PersonX poses PersonY threat", "hypothesis": "As a result, PersonX wants nothing", "update": "PersonX feels the need to eliminate the threat.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21420", "update_paraphrase": "PersonX has the urge to get rid of the danger.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42795414462081127, "pred_conf_shift": -0.06493568420410156, "syntactic_distance": 0.05555555555555555}, {"confidence": [0.9015898704528809, 0.09841012209653854], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.21420.gpt3.1", "original_example": {"example_id": "atomic.train.21420", "premise_hypothesis_id": "atomic.train.9873", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8oBDwS2qBnjvIoC18aaNoA==", "AtomicEventRelationId": "X-OihNMi_kGeQWhZmwSYiA==", "AtomicRelationType": "xWant", "AtomicInference": "nothing"}, "premise": "PersonX poses PersonY threat", "hypothesis": "As a result, PersonX wants nothing", "update": "PersonX feels the need to eliminate the threat.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21420", "update_paraphrase": "PersonX believes that eliminating the threat is necessary.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.367032967032967, "pred_conf_shift": -0.018469929695129395, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.8747098445892334, 0.12529006600379944], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.21420.gpt3.3", "original_example": {"example_id": "atomic.train.21420", "premise_hypothesis_id": "atomic.train.9873", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8oBDwS2qBnjvIoC18aaNoA==", "AtomicEventRelationId": "X-OihNMi_kGeQWhZmwSYiA==", "AtomicRelationType": "xWant", "AtomicInference": "nothing"}, "premise": "PersonX poses PersonY threat", "hypothesis": "As a result, PersonX wants nothing", "update": "PersonX feels the need to eliminate the threat.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21420", "update_paraphrase": "PersonX feels that it is necessary to get rid of the threat.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.41334443334443327, "pred_conf_shift": -0.045349955558776855, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.8663467168807983, 0.13365334272384644], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.21420.gpt3.0", "original_example": {"example_id": "atomic.train.21420", "premise_hypothesis_id": "atomic.train.9873", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8oBDwS2qBnjvIoC18aaNoA==", "AtomicEventRelationId": "X-OihNMi_kGeQWhZmwSYiA==", "AtomicRelationType": "xWant", "AtomicInference": "nothing"}, "premise": "PersonX poses PersonY threat", "hypothesis": "As a result, PersonX wants nothing", "update": "PersonX feels the need to eliminate the threat.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21420", "update_paraphrase": "PersonX believes that the threat must be eliminated.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3950019278966648, "pred_conf_shift": -0.053713083267211914, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.35192036628723145, 0.6480796337127686], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.21420.gpt3.4", "original_example": {"example_id": "atomic.train.21420", "premise_hypothesis_id": "atomic.train.9873", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8oBDwS2qBnjvIoC18aaNoA==", "AtomicEventRelationId": "X-OihNMi_kGeQWhZmwSYiA==", "AtomicRelationType": "xWant", "AtomicInference": "nothing"}, "premise": "PersonX poses PersonY threat", "hypothesis": "As a result, PersonX wants nothing", "update": "PersonX feels the need to eliminate the threat.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21420", "update_paraphrase": "PersonX wants to get rid of the threat entirely.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4730186192123908, "pred_conf_shift": -0.5681394338607788, "syntactic_distance": 0.25}, {"confidence": [0.8625496625900269, 0.13745038211345673], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.21420.gpt3.8", "original_example": {"example_id": "atomic.train.21420", "premise_hypothesis_id": "atomic.train.9873", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8oBDwS2qBnjvIoC18aaNoA==", "AtomicEventRelationId": "X-OihNMi_kGeQWhZmwSYiA==", "AtomicRelationType": "xWant", "AtomicInference": "nothing"}, "premise": "PersonX poses PersonY threat", "hypothesis": "As a result, PersonX wants nothing", "update": "PersonX feels the need to eliminate the threat.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21420", "update_paraphrase": "PersonX needs to get rid of the threat.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2981150793650794, "pred_conf_shift": -0.0575101375579834, "syntactic_distance": 0.25}, {"confidence": [0.8622449636459351, 0.13775499165058136], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.21420.gpt3.2", "original_example": {"example_id": "atomic.train.21420", "premise_hypothesis_id": "atomic.train.9873", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8oBDwS2qBnjvIoC18aaNoA==", "AtomicEventRelationId": "X-OihNMi_kGeQWhZmwSYiA==", "AtomicRelationType": "xWant", "AtomicInference": "nothing"}, "premise": "PersonX poses PersonY threat", "hypothesis": "As a result, PersonX wants nothing", "update": "PersonX feels the need to eliminate the threat.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21420", "update_paraphrase": "Person X feels like they need to get rid of the danger.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.35167887667887665, "pred_conf_shift": -0.057814836502075195, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.8518431782722473, 0.14815674722194672], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.21420.gpt3.5", "original_example": {"example_id": "atomic.train.21420", "premise_hypothesis_id": "atomic.train.9873", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8oBDwS2qBnjvIoC18aaNoA==", "AtomicEventRelationId": "X-OihNMi_kGeQWhZmwSYiA==", "AtomicRelationType": "xWant", "AtomicInference": "nothing"}, "premise": "PersonX poses PersonY threat", "hypothesis": "As a result, PersonX wants nothing", "update": "PersonX feels the need to eliminate the threat.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21420", "update_paraphrase": "PersonX has the urge to get rid of the problem.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.43430335097001765, "pred_conf_shift": -0.06821662187576294, "syntactic_distance": 0.05555555555555555}]}, "atomic.train.21957": {"original_confidence": [0.5788215398788452, 0.42117851972579956], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.7835337519645691, 0.2164662480354309], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.21957.gpt3.0", "original_example": {"example_id": "atomic.train.21957", "premise_hypothesis_id": "atomic.train.10101", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h7kfP4QgdcOAkeXsh758gg==", "AtomicEventRelationId": "MiOQGUBWTfsahJT8en2PsA==", "AtomicRelationType": "xEffect", "AtomicInference": "gets tired"}, "premise": "PersonX pushes the car", "hypothesis": "PersonX then gets tired", "update": "PersonX is skinny", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21957", "update_paraphrase": "PersonX is slender.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23076923076923084, "pred_conf_shift": -0.20471227169036865, "syntactic_distance": 0.0}, {"confidence": [0.6507152915000916, 0.34928470849990845], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.21957.gpt3.2", "original_example": {"example_id": "atomic.train.21957", "premise_hypothesis_id": "atomic.train.10101", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h7kfP4QgdcOAkeXsh758gg==", "AtomicEventRelationId": "MiOQGUBWTfsahJT8en2PsA==", "AtomicRelationType": "xEffect", "AtomicInference": "gets tired"}, "premise": "PersonX pushes the car", "hypothesis": "PersonX then gets tired", "update": "PersonX is skinny", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21957", "update_paraphrase": "PersonX is thin.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.21538461538461545, "pred_conf_shift": -0.07189381122589111, "syntactic_distance": 0.0}, {"confidence": [0.7403690218925476, 0.2596310079097748], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.21957.gpt3.4", "original_example": {"example_id": "atomic.train.21957", "premise_hypothesis_id": "atomic.train.10101", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h7kfP4QgdcOAkeXsh758gg==", "AtomicEventRelationId": "MiOQGUBWTfsahJT8en2PsA==", "AtomicRelationType": "xEffect", "AtomicInference": "gets tired"}, "premise": "PersonX pushes the car", "hypothesis": "PersonX then gets tired", "update": "PersonX is skinny", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21957", "update_paraphrase": "PersonX is not overweight.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3632119514472455, "pred_conf_shift": -0.16154751181602478, "syntactic_distance": 0.06666666666666667}, {"confidence": [0.36773911118507385, 0.6322608590126038], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.21957.gpt3.6", "original_example": {"example_id": "atomic.train.21957", "premise_hypothesis_id": "atomic.train.10101", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h7kfP4QgdcOAkeXsh758gg==", "AtomicEventRelationId": "MiOQGUBWTfsahJT8en2PsA==", "AtomicRelationType": "xEffect", "AtomicInference": "gets tired"}, "premise": "PersonX pushes the car", "hypothesis": "PersonX then gets tired", "update": "PersonX is skinny", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21957", "update_paraphrase": "PersonX is very thin.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3194805194805195, "pred_conf_shift": 0.2110823392868042, "syntactic_distance": 0.06666666666666667}, {"confidence": [0.7302187085151672, 0.26978129148483276], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.21957.gpt3.1", "original_example": {"example_id": "atomic.train.21957", "premise_hypothesis_id": "atomic.train.10101", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h7kfP4QgdcOAkeXsh758gg==", "AtomicEventRelationId": "MiOQGUBWTfsahJT8en2PsA==", "AtomicRelationType": "xEffect", "AtomicInference": "gets tired"}, "premise": "PersonX pushes the car", "hypothesis": "PersonX then gets tired", "update": "PersonX is skinny", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21957", "update_paraphrase": "Person X is slimmer than the average person.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5897435897435896, "pred_conf_shift": -0.1513972282409668, "syntactic_distance": 0.1875}, {"confidence": [0.7807008028030396, 0.21929924190044403], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.21957.gpt3.5", "original_example": {"example_id": "atomic.train.21957", "premise_hypothesis_id": "atomic.train.10101", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h7kfP4QgdcOAkeXsh758gg==", "AtomicEventRelationId": "MiOQGUBWTfsahJT8en2PsA==", "AtomicRelationType": "xEffect", "AtomicInference": "gets tired"}, "premise": "PersonX pushes the car", "hypothesis": "PersonX then gets tired", "update": "PersonX is skinny", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21957", "update_paraphrase": "Person X is thin.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33626373626373623, "pred_conf_shift": -0.20187927782535553, "syntactic_distance": 0.06666666666666667}, {"confidence": [0.4324345588684082, 0.567565381526947], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.21957.gpt3.3", "original_example": {"example_id": "atomic.train.21957", "premise_hypothesis_id": "atomic.train.10101", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h7kfP4QgdcOAkeXsh758gg==", "AtomicEventRelationId": "MiOQGUBWTfsahJT8en2PsA==", "AtomicRelationType": "xEffect", "AtomicInference": "gets tired"}, "premise": "PersonX pushes the car", "hypothesis": "PersonX then gets tired", "update": "PersonX is skinny", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21957", "update_paraphrase": "Person X is very thin.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.41923076923076924, "pred_conf_shift": 0.14638686180114746, "syntactic_distance": 0.125}]}, "atomic.train.4546": {"original_confidence": [0.9505137801170349, 0.0494861975312233], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.9749024510383606, 0.025097666308283806], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.4546.gpt3.5", "original_example": {"example_id": "atomic.train.4546", "premise_hypothesis_id": "atomic.train.2141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7auTJKxij8_IKb2P6GRLpw==", "AtomicEventRelationId": "KOXe5e-HFg0p9k4bsAWsWA==", "AtomicRelationType": "xWant", "AtomicInference": "to take a shower"}, "premise": "PersonX is really dirty", "hypothesis": "As a result, PersonX wants to take a shower", "update": "One of PersonX's favorite things to do is mud wrestling", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4546", "update_paraphrase": "PersonX loves mud wrestling!", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5232600732600732, "pred_conf_shift": 0.024388670921325684, "syntactic_distance": 0.25}, {"confidence": [0.9553921818733215, 0.04460784047842026], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.4546.gpt3.4", "original_example": {"example_id": "atomic.train.4546", "premise_hypothesis_id": "atomic.train.2141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7auTJKxij8_IKb2P6GRLpw==", "AtomicEventRelationId": "KOXe5e-HFg0p9k4bsAWsWA==", "AtomicRelationType": "xWant", "AtomicInference": "to take a shower"}, "premise": "PersonX is really dirty", "hypothesis": "As a result, PersonX wants to take a shower", "update": "One of PersonX's favorite things to do is mud wrestling", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4546", "update_paraphrase": "Mud wrestling is one of PersonX's favorite things to do.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.15000000000000002, "pred_conf_shift": 0.004878401756286621, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.966830849647522, 0.03316904604434967], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.4546.gpt3.6", "original_example": {"example_id": "atomic.train.4546", "premise_hypothesis_id": "atomic.train.2141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7auTJKxij8_IKb2P6GRLpw==", "AtomicEventRelationId": "KOXe5e-HFg0p9k4bsAWsWA==", "AtomicRelationType": "xWant", "AtomicInference": "to take a shower"}, "premise": "PersonX is really dirty", "hypothesis": "As a result, PersonX wants to take a shower", "update": "One of PersonX's favorite things to do is mud wrestling", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4546", "update_paraphrase": "PersonX's favorite pastime is mud wrestling.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33653846153846156, "pred_conf_shift": 0.01631706953048706, "syntactic_distance": 0.17391304347826086}, {"confidence": [0.9516316056251526, 0.048368390649557114], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.4546.gpt3.1", "original_example": {"example_id": "atomic.train.4546", "premise_hypothesis_id": "atomic.train.2141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7auTJKxij8_IKb2P6GRLpw==", "AtomicEventRelationId": "KOXe5e-HFg0p9k4bsAWsWA==", "AtomicRelationType": "xWant", "AtomicInference": "to take a shower"}, "premise": "PersonX is really dirty", "hypothesis": "As a result, PersonX wants to take a shower", "update": "One of PersonX's favorite things to do is mud wrestling", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4546", "update_paraphrase": "One of PersonX's favorite hobbies is mud wrestling.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1743589743589743, "pred_conf_shift": 0.0011178255081176758, "syntactic_distance": 0.0}, {"confidence": [0.9556413888931274, 0.04435858130455017], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.4546.gpt3.2", "original_example": {"example_id": "atomic.train.4546", "premise_hypothesis_id": "atomic.train.2141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7auTJKxij8_IKb2P6GRLpw==", "AtomicEventRelationId": "KOXe5e-HFg0p9k4bsAWsWA==", "AtomicRelationType": "xWant", "AtomicInference": "to take a shower"}, "premise": "PersonX is really dirty", "hypothesis": "As a result, PersonX wants to take a shower", "update": "One of PersonX's favorite things to do is mud wrestling", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4546", "update_paraphrase": "Mud wrestling is one of PersonX's favorite activities.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3472222222222222, "pred_conf_shift": 0.005127608776092529, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.96065753698349, 0.03934247046709061], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.4546.gpt3.3", "original_example": {"example_id": "atomic.train.4546", "premise_hypothesis_id": "atomic.train.2141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7auTJKxij8_IKb2P6GRLpw==", "AtomicEventRelationId": "KOXe5e-HFg0p9k4bsAWsWA==", "AtomicRelationType": "xWant", "AtomicInference": "to take a shower"}, "premise": "PersonX is really dirty", "hypothesis": "As a result, PersonX wants to take a shower", "update": "One of PersonX's favorite things to do is mud wrestling", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4546", "update_paraphrase": "PersonX really enjoys mud wrestling as one of their favorite pastimes.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4683308754737326, "pred_conf_shift": 0.010143756866455078, "syntactic_distance": 0.32}, {"confidence": [0.9499487280845642, 0.050051260739564896], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.4546.gpt3.7", "original_example": {"example_id": "atomic.train.4546", "premise_hypothesis_id": "atomic.train.2141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7auTJKxij8_IKb2P6GRLpw==", "AtomicEventRelationId": "KOXe5e-HFg0p9k4bsAWsWA==", "AtomicRelationType": "xWant", "AtomicInference": "to take a shower"}, "premise": "PersonX is really dirty", "hypothesis": "As a result, PersonX wants to take a shower", "update": "One of PersonX's favorite things to do is mud wrestling", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4546", "update_paraphrase": "One of PersonX's favorite pastimes is mud wrestling.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.17619047619047612, "pred_conf_shift": -0.0005650520324707031, "syntactic_distance": 0.0}, {"confidence": [0.9442932605743408, 0.0557066947221756], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.4546.gpt3.0", "original_example": {"example_id": "atomic.train.4546", "premise_hypothesis_id": "atomic.train.2141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7auTJKxij8_IKb2P6GRLpw==", "AtomicEventRelationId": "KOXe5e-HFg0p9k4bsAWsWA==", "AtomicRelationType": "xWant", "AtomicInference": "to take a shower"}, "premise": "PersonX is really dirty", "hypothesis": "As a result, PersonX wants to take a shower", "update": "One of PersonX's favorite things to do is mud wrestling", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4546", "update_paraphrase": "One of the things that PersonX enjoys doing is mud wrestling.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2765203050917337, "pred_conf_shift": -0.006220519542694092, "syntactic_distance": 0.0}]}, "atomic.train.3170": {"original_confidence": [0.18313045799732208, 0.8168694972991943], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.13656382262706757, 0.8634361624717712], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3170.gpt3.6", "original_example": {"example_id": "atomic.train.3170", "premise_hypothesis_id": "atomic.train.1493", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "SsdhuzRZWVThB1XcS5KlQg==", "AtomicEventRelationId": "KKitiIIzgc9n0ZRdORdVXg==", "AtomicRelationType": "xAttr", "AtomicInference": "aggressive"}, "premise": "PersonX sets a trap", "hypothesis": "As a result, PersonX feels aggressive", "update": "PersonX is a hunter", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3170", "update_paraphrase": "PersonX is someone who likes to hunt.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4727272727272728, "pred_conf_shift": -0.04656663537025452, "syntactic_distance": 0.125}, {"confidence": [0.24590983986854553, 0.7540901899337769], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3170.gpt3.7", "original_example": {"example_id": "atomic.train.3170", "premise_hypothesis_id": "atomic.train.1493", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "SsdhuzRZWVThB1XcS5KlQg==", "AtomicEventRelationId": "KKitiIIzgc9n0ZRdORdVXg==", "AtomicRelationType": "xAttr", "AtomicInference": "aggressive"}, "premise": "PersonX sets a trap", "hypothesis": "As a result, PersonX feels aggressive", "update": "PersonX is a hunter", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3170", "update_paraphrase": "PersonX is someone who hunts for sport or food.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5814185814185814, "pred_conf_shift": 0.06277938187122345, "syntactic_distance": 0.125}, {"confidence": [0.6235107779502869, 0.3764892518520355], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3170.gpt3.5", "original_example": {"example_id": "atomic.train.3170", "premise_hypothesis_id": "atomic.train.1493", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "SsdhuzRZWVThB1XcS5KlQg==", "AtomicEventRelationId": "KKitiIIzgc9n0ZRdORdVXg==", "AtomicRelationType": "xAttr", "AtomicInference": "aggressive"}, "premise": "PersonX sets a trap", "hypothesis": "As a result, PersonX feels aggressive", "update": "PersonX is a hunter", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3170", "update_paraphrase": "PersonX enjoys going out and hunting for game.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6254578754578755, "pred_conf_shift": 0.4403803199529648, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.8806967735290527, 0.11930316686630249], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3170.gpt3.3", "original_example": {"example_id": "atomic.train.3170", "premise_hypothesis_id": "atomic.train.1493", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "SsdhuzRZWVThB1XcS5KlQg==", "AtomicEventRelationId": "KKitiIIzgc9n0ZRdORdVXg==", "AtomicRelationType": "xAttr", "AtomicInference": "aggressive"}, "premise": "PersonX sets a trap", "hypothesis": "As a result, PersonX feels aggressive", "update": "PersonX is a hunter", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3170", "update_paraphrase": "PersonX enjoys going hunting.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5833853646353646, "pred_conf_shift": 0.6975663155317307, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.1561429351568222, 0.8438569903373718], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3170.gpt3.2", "original_example": {"example_id": "atomic.train.3170", "premise_hypothesis_id": "atomic.train.1493", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "SsdhuzRZWVThB1XcS5KlQg==", "AtomicEventRelationId": "KKitiIIzgc9n0ZRdORdVXg==", "AtomicRelationType": "xAttr", "AtomicInference": "aggressive"}, "premise": "PersonX sets a trap", "hypothesis": "As a result, PersonX feels aggressive", "update": "PersonX is a hunter", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3170", "update_paraphrase": "PersonX is someone who hunts.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39538239538239534, "pred_conf_shift": -0.026987522840499878, "syntactic_distance": 0.125}, {"confidence": [0.03125598654150963, 0.9687440395355225], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3170.gpt3.0", "original_example": {"example_id": "atomic.train.3170", "premise_hypothesis_id": "atomic.train.1493", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "SsdhuzRZWVThB1XcS5KlQg==", "AtomicEventRelationId": "KKitiIIzgc9n0ZRdORdVXg==", "AtomicRelationType": "xAttr", "AtomicInference": "aggressive"}, "premise": "PersonX sets a trap", "hypothesis": "As a result, PersonX feels aggressive", "update": "PersonX is a hunter", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3170", "update_paraphrase": "PersonX likes to hunt for game.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5257142857142858, "pred_conf_shift": -0.15187447145581245, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.28189513087272644, 0.7181048393249512], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3170.gpt3.4", "original_example": {"example_id": "atomic.train.3170", "premise_hypothesis_id": "atomic.train.1493", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "SsdhuzRZWVThB1XcS5KlQg==", "AtomicEventRelationId": "KKitiIIzgc9n0ZRdORdVXg==", "AtomicRelationType": "xAttr", "AtomicInference": "aggressive"}, "premise": "PersonX sets a trap", "hypothesis": "As a result, PersonX feels aggressive", "update": "PersonX is a hunter", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3170", "update_paraphrase": "PersonX is an individual who hunts for sport or food.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5784374355802927, "pred_conf_shift": 0.09876467287540436, "syntactic_distance": 0.125}]}, "atomic.train.11558": {"original_confidence": [0.8052197098731995, 0.19478029012680054], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.5706894397735596, 0.4293105900287628], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11558.gpt3.0", "original_example": {"example_id": "atomic.train.11558", "premise_hypothesis_id": "atomic.train.5436", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "QWG31AJRCe6apkYUqIN8rA==", "AtomicEventRelationId": "5py4JHQTNwO219dE4AFyjw==", "AtomicRelationType": "xAttr", "AtomicInference": "dominant"}, "premise": "PersonX looks PersonY in the eye", "hypothesis": "As a result, PersonX feels dominant", "update": "PersonY is a child", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11558", "update_paraphrase": "PersonY is younger than the average adult.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5512987012987014, "pred_conf_shift": -0.2345302700996399, "syntactic_distance": 0.1875}, {"confidence": [0.4341828227043152, 0.5658172965049744], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11558.gpt3.1", "original_example": {"example_id": "atomic.train.11558", "premise_hypothesis_id": "atomic.train.5436", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "QWG31AJRCe6apkYUqIN8rA==", "AtomicEventRelationId": "5py4JHQTNwO219dE4AFyjw==", "AtomicRelationType": "xAttr", "AtomicInference": "dominant"}, "premise": "PersonX looks PersonY in the eye", "hypothesis": "As a result, PersonX feels dominant", "update": "PersonY is a child", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11558", "update_paraphrase": "PersonY is a young person.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23076923076923078, "pred_conf_shift": -0.3710368871688843, "syntactic_distance": 0.058823529411764705}]}, "atomic.train.17743": {"original_confidence": [0.015414300374686718, 0.9845855832099915], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.0896022766828537, 0.9103977680206299], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17743.gpt3.1", "original_example": {"example_id": "atomic.train.17743", "premise_hypothesis_id": "atomic.train.8257", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "1aJVJ_PPDuBTdIVXODB2Jg==", "AtomicEventRelationId": "9maf4VvEd5V-0GWZOpCwzg==", "AtomicRelationType": "xEffect", "AtomicInference": "forgives"}, "premise": "PersonX spares PersonY life", "hypothesis": "PersonX then forgives", "update": "PersonY is sorry", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17743", "update_paraphrase": "PersonY is remorseful.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.20555555555555555, "pred_conf_shift": -0.07418781518936157, "syntactic_distance": 0.0}, {"confidence": [0.018945777788758278, 0.9810541868209839], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17743.gpt3.4", "original_example": {"example_id": "atomic.train.17743", "premise_hypothesis_id": "atomic.train.8257", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "1aJVJ_PPDuBTdIVXODB2Jg==", "AtomicEventRelationId": "9maf4VvEd5V-0GWZOpCwzg==", "AtomicRelationType": "xEffect", "AtomicInference": "forgives"}, "premise": "PersonX spares PersonY life", "hypothesis": "PersonX then forgives", "update": "PersonY is sorry", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17743", "update_paraphrase": "PersonY is apologizing", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22916666666666663, "pred_conf_shift": -0.0035313963890075684, "syntactic_distance": 0.14285714285714285}, {"confidence": [0.022461513057351112, 0.977538526058197], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17743.gpt3.7", "original_example": {"example_id": "atomic.train.17743", "premise_hypothesis_id": "atomic.train.8257", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "1aJVJ_PPDuBTdIVXODB2Jg==", "AtomicEventRelationId": "9maf4VvEd5V-0GWZOpCwzg==", "AtomicRelationType": "xEffect", "AtomicInference": "forgives"}, "premise": "PersonX spares PersonY life", "hypothesis": "PersonX then forgives", "update": "PersonY is sorry", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17743", "update_paraphrase": "PersonY regrets their actions and is apologizing.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5238095238095237, "pred_conf_shift": -0.007047057151794434, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.39237937331199646, 0.6076205968856812], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17743.gpt3.3", "original_example": {"example_id": "atomic.train.17743", "premise_hypothesis_id": "atomic.train.8257", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "1aJVJ_PPDuBTdIVXODB2Jg==", "AtomicEventRelationId": "9maf4VvEd5V-0GWZOpCwzg==", "AtomicRelationType": "xEffect", "AtomicInference": "forgives"}, "premise": "PersonX spares PersonY life", "hypothesis": "PersonX then forgives", "update": "PersonY is sorry", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17743", "update_paraphrase": "PersonY is regretful", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.20238095238095238, "pred_conf_shift": -0.3769649863243103, "syntactic_distance": 0.0}, {"confidence": [0.01628301292657852, 0.9837169647216797], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17743.gpt3.2", "original_example": {"example_id": "atomic.train.17743", "premise_hypothesis_id": "atomic.train.8257", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "1aJVJ_PPDuBTdIVXODB2Jg==", "AtomicEventRelationId": "9maf4VvEd5V-0GWZOpCwzg==", "AtomicRelationType": "xEffect", "AtomicInference": "forgives"}, "premise": "PersonX spares PersonY life", "hypothesis": "PersonX then forgives", "update": "PersonY is sorry", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17743", "update_paraphrase": "PersonY is apologetic", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22777777777777775, "pred_conf_shift": -0.0008686184883117676, "syntactic_distance": 0.0}, {"confidence": [0.0215142872184515, 0.9784857034683228], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17743.gpt3.6", "original_example": {"example_id": "atomic.train.17743", "premise_hypothesis_id": "atomic.train.8257", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "1aJVJ_PPDuBTdIVXODB2Jg==", "AtomicEventRelationId": "9maf4VvEd5V-0GWZOpCwzg==", "AtomicRelationType": "xEffect", "AtomicInference": "forgives"}, "premise": "PersonX spares PersonY life", "hypothesis": "PersonX then forgives", "update": "PersonY is sorry", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17743", "update_paraphrase": "PersonY regrets their actions and is apologetic.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5238095238095237, "pred_conf_shift": -0.006099879741668701, "syntactic_distance": 0.3333333333333333}]}, "atomic.train.17789": {"original_confidence": [0.22957275807857513, 0.7704271674156189], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.5244258046150208, 0.475574254989624], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.17789.gpt3.4", "original_example": {"example_id": "atomic.train.17789", "premise_hypothesis_id": "atomic.train.8279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h694ebsT8Njn1QPdIoPFsA==", "AtomicEventRelationId": "NYHMqSFbciAeV1BsLsqNkg==", "AtomicRelationType": "xNeed", "AtomicInference": "to accuse hom"}, "premise": "PersonX puts PersonY away", "hypothesis": "Before, PersonX needed to accuse hom", "update": "PersonX questioned PersonY about the incident.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17789", "update_paraphrase": "PersonX asked PersonY for more information about what happened.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.46503227766385663, "pred_conf_shift": -0.2948529124259949, "syntactic_distance": 0.0}, {"confidence": [0.8512672781944275, 0.1487327367067337], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.17789.gpt3.7", "original_example": {"example_id": "atomic.train.17789", "premise_hypothesis_id": "atomic.train.8279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h694ebsT8Njn1QPdIoPFsA==", "AtomicEventRelationId": "NYHMqSFbciAeV1BsLsqNkg==", "AtomicRelationType": "xNeed", "AtomicInference": "to accuse hom"}, "premise": "PersonX puts PersonY away", "hypothesis": "Before, PersonX needed to accuse hom", "update": "PersonX questioned PersonY about the incident.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17789", "update_paraphrase": "PersonX inquired PersonY about the event.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.20227920227920232, "pred_conf_shift": -0.6216944307088852, "syntactic_distance": 0.0}, {"confidence": [0.13141076266765594, 0.8685892224311829], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17789.gpt3.0", "original_example": {"example_id": "atomic.train.17789", "premise_hypothesis_id": "atomic.train.8279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h694ebsT8Njn1QPdIoPFsA==", "AtomicEventRelationId": "NYHMqSFbciAeV1BsLsqNkg==", "AtomicRelationType": "xNeed", "AtomicInference": "to accuse hom"}, "premise": "PersonX puts PersonY away", "hypothesis": "Before, PersonX needed to accuse hom", "update": "PersonX questioned PersonY about the incident.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17789", "update_paraphrase": "PersonX interrogated PersonY regarding the event.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3644943807482507, "pred_conf_shift": 0.09816205501556396, "syntactic_distance": 0.05}, {"confidence": [0.11206487566232681, 0.8879351019859314], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17789.gpt3.1", "original_example": {"example_id": "atomic.train.17789", "premise_hypothesis_id": "atomic.train.8279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h694ebsT8Njn1QPdIoPFsA==", "AtomicEventRelationId": "NYHMqSFbciAeV1BsLsqNkg==", "AtomicRelationType": "xNeed", "AtomicInference": "to accuse hom"}, "premise": "PersonX puts PersonY away", "hypothesis": "Before, PersonX needed to accuse hom", "update": "PersonX questioned PersonY about the incident.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17789", "update_paraphrase": "PersonX interrogated PersonY regarding what happened.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.46342475320803495, "pred_conf_shift": 0.1175079345703125, "syntactic_distance": 0.1}, {"confidence": [0.16710016131401062, 0.8328997492790222], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17789.gpt3.3", "original_example": {"example_id": "atomic.train.17789", "premise_hypothesis_id": "atomic.train.8279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h694ebsT8Njn1QPdIoPFsA==", "AtomicEventRelationId": "NYHMqSFbciAeV1BsLsqNkg==", "AtomicRelationType": "xNeed", "AtomicInference": "to accuse hom"}, "premise": "PersonX puts PersonY away", "hypothesis": "Before, PersonX needed to accuse hom", "update": "PersonX questioned PersonY about the incident.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17789", "update_paraphrase": "PersonX wanted to know all the details from PersonY about what happened.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5120419885125768, "pred_conf_shift": 0.06247258186340332, "syntactic_distance": 0.35294117647058826}, {"confidence": [0.13948087394237518, 0.8605191111564636], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17789.gpt3.5", "original_example": {"example_id": "atomic.train.17789", "premise_hypothesis_id": "atomic.train.8279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h694ebsT8Njn1QPdIoPFsA==", "AtomicEventRelationId": "NYHMqSFbciAeV1BsLsqNkg==", "AtomicRelationType": "xNeed", "AtomicInference": "to accuse hom"}, "premise": "PersonX puts PersonY away", "hypothesis": "Before, PersonX needed to accuse hom", "update": "PersonX questioned PersonY about the incident.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17789", "update_paraphrase": "PersonX grilled PersonY about what happened.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3539060068471833, "pred_conf_shift": 0.09009194374084473, "syntactic_distance": 0.05}, {"confidence": [0.16311201453208923, 0.8368880152702332], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17789.gpt3.2", "original_example": {"example_id": "atomic.train.17789", "premise_hypothesis_id": "atomic.train.8279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h694ebsT8Njn1QPdIoPFsA==", "AtomicEventRelationId": "NYHMqSFbciAeV1BsLsqNkg==", "AtomicRelationType": "xNeed", "AtomicInference": "to accuse hom"}, "premise": "PersonX puts PersonY away", "hypothesis": "Before, PersonX needed to accuse hom", "update": "PersonX questioned PersonY about the incident.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17789", "update_paraphrase": "Person X interrogated Person Y about the event.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3326673326673326, "pred_conf_shift": 0.06646084785461426, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.5242463946342468, 0.47575363516807556], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.17789.gpt3.6", "original_example": {"example_id": "atomic.train.17789", "premise_hypothesis_id": "atomic.train.8279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h694ebsT8Njn1QPdIoPFsA==", "AtomicEventRelationId": "NYHMqSFbciAeV1BsLsqNkg==", "AtomicRelationType": "xNeed", "AtomicInference": "to accuse hom"}, "premise": "PersonX puts PersonY away", "hypothesis": "Before, PersonX needed to accuse hom", "update": "PersonX questioned PersonY about the incident.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17789", "update_paraphrase": "PersonX asked PersonY about what happened.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3589985994397759, "pred_conf_shift": -0.29467353224754333, "syntactic_distance": 0.05}]}, "atomic.train.6739": {"original_confidence": [0.9588626027107239, 0.0411374494433403], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.951919674873352, 0.048080217093229294], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.6739.gpt3.4", "original_example": {"example_id": "atomic.train.6739", "premise_hypothesis_id": "atomic.train.3189", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7Ej6wX0k4vre4ruDmUfAlw==", "AtomicEventRelationId": "2xxmF2iNY5CuZKGg-2g07Q==", "AtomicRelationType": "xReact", "AtomicInference": "terrible, ill and weak"}, "premise": "PersonX is knocked unconscious", "hypothesis": "PersonX is seen as terrible, ill and weak", "update": "PersonX is abusive", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6739", "update_paraphrase": "PersonX is abusive and mistreats people.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33333333333333337, "pred_conf_shift": 0.006942767649888992, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.8931572437286377, 0.10684279352426529], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.6739.gpt3.6", "original_example": {"example_id": "atomic.train.6739", "premise_hypothesis_id": "atomic.train.3189", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7Ej6wX0k4vre4ruDmUfAlw==", "AtomicEventRelationId": "2xxmF2iNY5CuZKGg-2g07Q==", "AtomicRelationType": "xReact", "AtomicInference": "terrible, ill and weak"}, "premise": "PersonX is knocked unconscious", "hypothesis": "PersonX is seen as terrible, ill and weak", "update": "PersonX is abusive", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6739", "update_paraphrase": "PersonX is abusive toward others.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.25, "pred_conf_shift": 0.06570534408092499, "syntactic_distance": 0.06666666666666667}, {"confidence": [0.9283314943313599, 0.0716685950756073], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.6739.gpt3.7", "original_example": {"example_id": "atomic.train.6739", "premise_hypothesis_id": "atomic.train.3189", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7Ej6wX0k4vre4ruDmUfAlw==", "AtomicEventRelationId": "2xxmF2iNY5CuZKGg-2g07Q==", "AtomicRelationType": "xReact", "AtomicInference": "terrible, ill and weak"}, "premise": "PersonX is knocked unconscious", "hypothesis": "PersonX is seen as terrible, ill and weak", "update": "PersonX is abusive", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6739", "update_paraphrase": "PersonX is abusive and treats others poorly.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4, "pred_conf_shift": 0.030531145632267, "syntactic_distance": 0.3684210526315789}, {"confidence": [0.7742656469345093, 0.22573424875736237], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.6739.gpt3.5", "original_example": {"example_id": "atomic.train.6739", "premise_hypothesis_id": "atomic.train.3189", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7Ej6wX0k4vre4ruDmUfAlw==", "AtomicEventRelationId": "2xxmF2iNY5CuZKGg-2g07Q==", "AtomicRelationType": "xReact", "AtomicInference": "terrible, ill and weak"}, "premise": "PersonX is knocked unconscious", "hypothesis": "PersonX is seen as terrible, ill and weak", "update": "PersonX is abusive", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6739", "update_paraphrase": "This person mistreats others regularly.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5899621212121212, "pred_conf_shift": 0.18459679931402206, "syntactic_distance": 0.29411764705882354}, {"confidence": [0.964599609375, 0.035400472581386566], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.6739.gpt3.3", "original_example": {"example_id": "atomic.train.6739", "premise_hypothesis_id": "atomic.train.3189", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7Ej6wX0k4vre4ruDmUfAlw==", "AtomicEventRelationId": "2xxmF2iNY5CuZKGg-2g07Q==", "AtomicRelationType": "xReact", "AtomicInference": "terrible, ill and weak"}, "premise": "PersonX is knocked unconscious", "hypothesis": "PersonX is seen as terrible, ill and weak", "update": "PersonX is abusive", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6739", "update_paraphrase": "PersonX is cruel and abusive.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.25, "pred_conf_shift": -0.005736976861953735, "syntactic_distance": 0.125}, {"confidence": [0.9360872507095337, 0.0639127790927887], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.6739.gpt3.1", "original_example": {"example_id": "atomic.train.6739", "premise_hypothesis_id": "atomic.train.3189", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7Ej6wX0k4vre4ruDmUfAlw==", "AtomicEventRelationId": "2xxmF2iNY5CuZKGg-2g07Q==", "AtomicRelationType": "xReact", "AtomicInference": "terrible, ill and weak"}, "premise": "PersonX is knocked unconscious", "hypothesis": "PersonX is seen as terrible, ill and weak", "update": "PersonX is abusive", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6739", "update_paraphrase": "PersonX is abusive and mistreats others.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33333333333333337, "pred_conf_shift": 0.022775329649448395, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.880682110786438, 0.11931794881820679], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.6739.gpt3.0", "original_example": {"example_id": "atomic.train.6739", "premise_hypothesis_id": "atomic.train.3189", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7Ej6wX0k4vre4ruDmUfAlw==", "AtomicEventRelationId": "2xxmF2iNY5CuZKGg-2g07Q==", "AtomicRelationType": "xReact", "AtomicInference": "terrible, ill and weak"}, "premise": "PersonX is knocked unconscious", "hypothesis": "PersonX is seen as terrible, ill and weak", "update": "PersonX is abusive", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6739", "update_paraphrase": "PersonX is abusive, meaning they mistreat or harm those around them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5714285714285714, "pred_conf_shift": 0.07818049937486649, "syntactic_distance": 0.125}, {"confidence": [0.9107264876365662, 0.0892735943198204], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.6739.gpt3.2", "original_example": {"example_id": "atomic.train.6739", "premise_hypothesis_id": "atomic.train.3189", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7Ej6wX0k4vre4ruDmUfAlw==", "AtomicEventRelationId": "2xxmF2iNY5CuZKGg-2g07Q==", "AtomicRelationType": "xReact", "AtomicInference": "terrible, ill and weak"}, "premise": "PersonX is knocked unconscious", "hypothesis": "PersonX is seen as terrible, ill and weak", "update": "PersonX is abusive", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6739", "update_paraphrase": "PersonX is abusive towards others.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.25, "pred_conf_shift": 0.0481361448764801, "syntactic_distance": 0.06666666666666667}]}, "atomic.train.12435": {"original_confidence": [0.4272521734237671, 0.5727478265762329], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.646037757396698, 0.353962242603302], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.12435.gpt3.2", "original_example": {"example_id": "atomic.train.12435", "premise_hypothesis_id": "atomic.train.5842", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DAmuHmgjmj2vgKh0t1fwuw==", "AtomicEventRelationId": "-pZfi5X-nCJBK6BEgdiVLA==", "AtomicRelationType": "xReact", "AtomicInference": "nervous."}, "premise": "PersonX loses in the woods", "hypothesis": "PersonX is seen as nervous.", "update": "They have anxiety meds", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12435", "update_paraphrase": "They have medication for anxiety.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3405483405483405, "pred_conf_shift": -0.2187855839729309, "syntactic_distance": 0.125}, {"confidence": [0.3440326452255249, 0.6559673547744751], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.12435.gpt3.5", "original_example": {"example_id": "atomic.train.12435", "premise_hypothesis_id": "atomic.train.5842", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DAmuHmgjmj2vgKh0t1fwuw==", "AtomicEventRelationId": "-pZfi5X-nCJBK6BEgdiVLA==", "AtomicRelationType": "xReact", "AtomicInference": "nervous."}, "premise": "PersonX loses in the woods", "hypothesis": "PersonX is seen as nervous.", "update": "They have anxiety meds", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12435", "update_paraphrase": "The anxiety medication they take helps them relax.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.556878306878307, "pred_conf_shift": 0.08321952819824219, "syntactic_distance": 0.47619047619047616}, {"confidence": [0.3031875193119049, 0.6968125104904175], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.12435.gpt3.0", "original_example": {"example_id": "atomic.train.12435", "premise_hypothesis_id": "atomic.train.5842", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DAmuHmgjmj2vgKh0t1fwuw==", "AtomicEventRelationId": "-pZfi5X-nCJBK6BEgdiVLA==", "AtomicRelationType": "xReact", "AtomicInference": "nervous."}, "premise": "PersonX loses in the woods", "hypothesis": "PersonX is seen as nervous.", "update": "They have anxiety meds", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12435", "update_paraphrase": "The medication they take helps with their anxiety.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5403439153439153, "pred_conf_shift": 0.12406468391418457, "syntactic_distance": 0.45}, {"confidence": [0.3683234751224518, 0.6316765546798706], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.12435.gpt3.4", "original_example": {"example_id": "atomic.train.12435", "premise_hypothesis_id": "atomic.train.5842", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DAmuHmgjmj2vgKh0t1fwuw==", "AtomicEventRelationId": "-pZfi5X-nCJBK6BEgdiVLA==", "AtomicRelationType": "xReact", "AtomicInference": "nervous."}, "premise": "PersonX loses in the woods", "hypothesis": "PersonX is seen as nervous.", "update": "They have anxiety meds", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12435", "update_paraphrase": "The Anxiety meds are theirs.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.30158730158730157, "pred_conf_shift": 0.058928728103637695, "syntactic_distance": 0.29411764705882354}, {"confidence": [0.49257612228393555, 0.5074238777160645], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.12435.gpt3.3", "original_example": {"example_id": "atomic.train.12435", "premise_hypothesis_id": "atomic.train.5842", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DAmuHmgjmj2vgKh0t1fwuw==", "AtomicEventRelationId": "-pZfi5X-nCJBK6BEgdiVLA==", "AtomicRelationType": "xReact", "AtomicInference": "nervous."}, "premise": "PersonX loses in the woods", "hypothesis": "PersonX is seen as nervous.", "update": "They have anxiety meds", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12435", "update_paraphrase": "They have anxiety medication.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1651785714285714, "pred_conf_shift": -0.06532394886016846, "syntactic_distance": 0.0625}, {"confidence": [0.25066229701042175, 0.7493376135826111], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.12435.gpt3.7", "original_example": {"example_id": "atomic.train.12435", "premise_hypothesis_id": "atomic.train.5842", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DAmuHmgjmj2vgKh0t1fwuw==", "AtomicEventRelationId": "-pZfi5X-nCJBK6BEgdiVLA==", "AtomicRelationType": "xReact", "AtomicInference": "nervous."}, "premise": "PersonX loses in the woods", "hypothesis": "PersonX is seen as nervous.", "update": "They have anxiety meds", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12435", "update_paraphrase": "They have medications to help with anxiety.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.41845730027548206, "pred_conf_shift": 0.17658978700637817, "syntactic_distance": 0.125}, {"confidence": [0.058128152042627335, 0.9418718218803406], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.12435.gpt3.6", "original_example": {"example_id": "atomic.train.12435", "premise_hypothesis_id": "atomic.train.5842", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DAmuHmgjmj2vgKh0t1fwuw==", "AtomicEventRelationId": "-pZfi5X-nCJBK6BEgdiVLA==", "AtomicRelationType": "xReact", "AtomicInference": "nervous."}, "premise": "PersonX loses in the woods", "hypothesis": "PersonX is seen as nervous.", "update": "They have anxiety meds", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12435", "update_paraphrase": "The medications they take are for anxiety.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.483982683982684, "pred_conf_shift": 0.36912399530410767, "syntactic_distance": 0.4}, {"confidence": [0.16875649988651276, 0.8312433958053589], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.12435.gpt3.1", "original_example": {"example_id": "atomic.train.12435", "premise_hypothesis_id": "atomic.train.5842", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DAmuHmgjmj2vgKh0t1fwuw==", "AtomicEventRelationId": "-pZfi5X-nCJBK6BEgdiVLA==", "AtomicRelationType": "xReact", "AtomicInference": "nervous."}, "premise": "PersonX loses in the woods", "hypothesis": "PersonX is seen as nervous.", "update": "They have anxiety meds", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12435", "update_paraphrase": "The medications they take help with their anxiety.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5329365079365078, "pred_conf_shift": 0.258495569229126, "syntactic_distance": 0.4}]}, "atomic.train.18302": {"original_confidence": [0.26181560754776, 0.7381843328475952], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.25290560722351074, 0.7470942735671997], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18302.gpt3.0", "original_example": {"example_id": "atomic.train.18302", "premise_hypothesis_id": "atomic.train.8509", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DizBd1_so1iZKllTL_FRlw==", "AtomicEventRelationId": "U1fjWaYArya9cDWl3duwuQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to visit person Y's home"}, "premise": "PersonX talks to PersonY's neighbor", "hypothesis": "Before, PersonX needed to visit person Y's home", "update": "PersonX and PersonY's neighbor both ran out of groceries on the same day.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18302", "update_paraphrase": "PersonX and PersonY's neighbor both ran out of groceries at the same time.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.18030858030858032, "pred_conf_shift": -0.008910000324249268, "syntactic_distance": 0.0}, {"confidence": [0.2134058177471161, 0.7865940928459167], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18302.gpt3.1", "original_example": {"example_id": "atomic.train.18302", "premise_hypothesis_id": "atomic.train.8509", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DizBd1_so1iZKllTL_FRlw==", "AtomicEventRelationId": "U1fjWaYArya9cDWl3duwuQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to visit person Y's home"}, "premise": "PersonX talks to PersonY's neighbor", "hypothesis": "Before, PersonX needed to visit person Y's home", "update": "PersonX and PersonY's neighbor both ran out of groceries on the same day.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18302", "update_paraphrase": "The neighbors of PersonX and PersonY both ran out of groceries on the same day.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.11400560224089634, "pred_conf_shift": -0.04840978980064392, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.2152070850133896, 0.7847929000854492], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18302.gpt3.4", "original_example": {"example_id": "atomic.train.18302", "premise_hypothesis_id": "atomic.train.8509", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DizBd1_so1iZKllTL_FRlw==", "AtomicEventRelationId": "U1fjWaYArya9cDWl3duwuQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to visit person Y's home"}, "premise": "PersonX talks to PersonY's neighbor", "hypothesis": "Before, PersonX needed to visit person Y's home", "update": "PersonX and PersonY's neighbor both ran out of groceries on the same day.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18302", "update_paraphrase": "Both PersonX and PersonY's neighbor ran out of groceries on the same day.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.038461538461538436, "pred_conf_shift": -0.04660852253437042, "syntactic_distance": 0.08823529411764706}, {"confidence": [0.13596665859222412, 0.8640334010124207], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18302.gpt3.6", "original_example": {"example_id": "atomic.train.18302", "premise_hypothesis_id": "atomic.train.8509", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DizBd1_so1iZKllTL_FRlw==", "AtomicEventRelationId": "U1fjWaYArya9cDWl3duwuQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to visit person Y's home"}, "premise": "PersonX talks to PersonY's neighbor", "hypothesis": "Before, PersonX needed to visit person Y's home", "update": "PersonX and PersonY's neighbor both ran out of groceries on the same day.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18302", "update_paraphrase": "Coincidentally, both PersonX and PersonY's neighbor ran out of food supplies on the same day.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.15336134453781508, "pred_conf_shift": -0.1258489489555359, "syntactic_distance": 0.1388888888888889}, {"confidence": [0.18139579892158508, 0.8186041116714478], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18302.gpt3.3", "original_example": {"example_id": "atomic.train.18302", "premise_hypothesis_id": "atomic.train.8509", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "DizBd1_so1iZKllTL_FRlw==", "AtomicEventRelationId": "U1fjWaYArya9cDWl3duwuQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to visit person Y's home"}, "premise": "PersonX talks to PersonY's neighbor", "hypothesis": "Before, PersonX needed to visit person Y's home", "update": "PersonX and PersonY's neighbor both ran out of groceries on the same day.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18302", "update_paraphrase": "Both of PersonX and PersonY's neighbors ran out of groceries on the same day.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0784313725490196, "pred_conf_shift": -0.08041980862617493, "syntactic_distance": 0.22580645161290322}]}, "atomic.train.322": {"original_confidence": [0.5373740792274475, 0.4626258909702301], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.8157851696014404, 0.1842147558927536], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.322.gpt3.4", "original_example": {"example_id": "atomic.train.322", "premise_hypothesis_id": "atomic.train.153", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xj75nE686JOFccr5lU1KGQ==", "AtomicEventRelationId": "wF0EH89xfOLkBDdDzn1ztg==", "AtomicRelationType": "xWant", "AtomicInference": "to see the wife's reaction"}, "premise": "PersonX surprises PersonY's wife", "hypothesis": "As a result, PersonX wants to see the wife's reaction", "update": "PersonX wishes they weren't working out of town during their wife's birthday.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.322", "update_paraphrase": "PersonX is disappointed that they have to work out of town during their wife's birthday.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.243228582117471, "pred_conf_shift": 0.2784110903739929, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.43777257204055786, 0.5622274279594421], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.322.gpt3.3", "original_example": {"example_id": "atomic.train.322", "premise_hypothesis_id": "atomic.train.153", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xj75nE686JOFccr5lU1KGQ==", "AtomicEventRelationId": "wF0EH89xfOLkBDdDzn1ztg==", "AtomicRelationType": "xWant", "AtomicInference": "to see the wife's reaction"}, "premise": "PersonX surprises PersonY's wife", "hypothesis": "As a result, PersonX wants to see the wife's reaction", "update": "PersonX wishes they weren't working out of town during their wife's birthday.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.322", "update_paraphrase": "PersonX regrets being out of town during their spouse's birthday celebrations.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23614663256606983, "pred_conf_shift": -0.09960150718688965, "syntactic_distance": 0.14285714285714285}, {"confidence": [0.8104476928710938, 0.1895522177219391], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.322.gpt3.5", "original_example": {"example_id": "atomic.train.322", "premise_hypothesis_id": "atomic.train.153", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xj75nE686JOFccr5lU1KGQ==", "AtomicEventRelationId": "wF0EH89xfOLkBDdDzn1ztg==", "AtomicRelationType": "xWant", "AtomicInference": "to see the wife's reaction"}, "premise": "PersonX surprises PersonY's wife", "hypothesis": "As a result, PersonX wants to see the wife's reaction", "update": "PersonX wishes they weren't working out of town during their wife's birthday.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.322", "update_paraphrase": "PersonX is disappointed that they have to work out of town on their wife's birthday.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.283576505798728, "pred_conf_shift": 0.27307361364364624, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.2741064727306366, 0.7258935570716858], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.322.gpt3.6", "original_example": {"example_id": "atomic.train.322", "premise_hypothesis_id": "atomic.train.153", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xj75nE686JOFccr5lU1KGQ==", "AtomicEventRelationId": "wF0EH89xfOLkBDdDzn1ztg==", "AtomicRelationType": "xWant", "AtomicInference": "to see the wife's reaction"}, "premise": "PersonX surprises PersonY's wife", "hypothesis": "As a result, PersonX wants to see the wife's reaction", "update": "PersonX wishes they weren't working out of town during their wife's birthday.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.322", "update_paraphrase": "If PersonX's wife's birthday hadn't fallen during a work trip, they would have been able to celebrate together.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5273004773004774, "pred_conf_shift": -0.2632676064968109, "syntactic_distance": 0.5}, {"confidence": [0.42278313636779785, 0.5772168040275574], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.322.gpt3.2", "original_example": {"example_id": "atomic.train.322", "premise_hypothesis_id": "atomic.train.153", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xj75nE686JOFccr5lU1KGQ==", "AtomicEventRelationId": "wF0EH89xfOLkBDdDzn1ztg==", "AtomicRelationType": "xWant", "AtomicInference": "to see the wife's reaction"}, "premise": "PersonX surprises PersonY's wife", "hypothesis": "As a result, PersonX wants to see the wife's reaction", "update": "PersonX wishes they weren't working out of town during their wife's birthday.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.322", "update_paraphrase": "It's PersonX's wife's birthday, and they wish they weren't out of town for work.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3248057498057498, "pred_conf_shift": -0.11459094285964966, "syntactic_distance": 0.45}, {"confidence": [0.8026694655418396, 0.197330504655838], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.322.gpt3.7", "original_example": {"example_id": "atomic.train.322", "premise_hypothesis_id": "atomic.train.153", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xj75nE686JOFccr5lU1KGQ==", "AtomicEventRelationId": "wF0EH89xfOLkBDdDzn1ztg==", "AtomicRelationType": "xWant", "AtomicInference": "to see the wife's reaction"}, "premise": "PersonX surprises PersonY's wife", "hypothesis": "As a result, PersonX wants to see the wife's reaction", "update": "PersonX wishes they weren't working out of town during their wife's birthday.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.322", "update_paraphrase": "Being away on business during his wife's birthday is something PersonX wishes hadn't happened.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.518065268065268, "pred_conf_shift": 0.2652953863143921, "syntactic_distance": 0.4444444444444444}, {"confidence": [0.7445964813232422, 0.2554035484790802], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.322.gpt3.0", "original_example": {"example_id": "atomic.train.322", "premise_hypothesis_id": "atomic.train.153", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xj75nE686JOFccr5lU1KGQ==", "AtomicEventRelationId": "wF0EH89xfOLkBDdDzn1ztg==", "AtomicRelationType": "xWant", "AtomicInference": "to see the wife's reaction"}, "premise": "PersonX surprises PersonY's wife", "hypothesis": "As a result, PersonX wants to see the wife's reaction", "update": "PersonX wishes they weren't working out of town during their wife's birthday.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.322", "update_paraphrase": "PersonX is upset that they have to work out of town during their wife's birthday.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.237897493453049, "pred_conf_shift": 0.20722240209579468, "syntactic_distance": 0.26666666666666666}]}, "atomic.train.5730": {"original_confidence": [0.7640439867973328, 0.23595599830150604], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.7844898700714111, 0.21551015973091125], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5730.gpt3.6", "original_example": {"example_id": "atomic.train.5730", "premise_hypothesis_id": "atomic.train.2702", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9GTom-eEx2-NNZWT1B9IUQ==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX stops eating fast food", "hypothesis": "PersonX is seen as better", "update": "PersonX's high school friends think this is strange.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5730", "update_paraphrase": "PersonX's high school friends think it's weird that he/she is doing this.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33171134421134424, "pred_conf_shift": 0.02044588327407837, "syntactic_distance": 0.0}, {"confidence": [0.8063092827796936, 0.193690687417984], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5730.gpt3.7", "original_example": {"example_id": "atomic.train.5730", "premise_hypothesis_id": "atomic.train.2702", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9GTom-eEx2-NNZWT1B9IUQ==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX stops eating fast food", "hypothesis": "PersonX is seen as better", "update": "PersonX's high school friends think this is strange.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5730", "update_paraphrase": "PersonX's high school friends are weirded out by this change.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37846628679962013, "pred_conf_shift": 0.04226529598236084, "syntactic_distance": 0.20833333333333334}, {"confidence": [0.6224059462547302, 0.377593994140625], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5730.gpt3.1", "original_example": {"example_id": "atomic.train.5730", "premise_hypothesis_id": "atomic.train.2702", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9GTom-eEx2-NNZWT1B9IUQ==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX stops eating fast food", "hypothesis": "PersonX is seen as better", "update": "PersonX's high school friends think this is strange.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5730", "update_paraphrase": "Person X's high school friends find this situation to be odd.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3629908103592314, "pred_conf_shift": -0.14163804054260254, "syntactic_distance": 0.24}, {"confidence": [0.31311044096946716, 0.6868894696235657], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.5730.gpt3.8", "original_example": {"example_id": "atomic.train.5730", "premise_hypothesis_id": "atomic.train.2702", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9GTom-eEx2-NNZWT1B9IUQ==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX stops eating fast food", "hypothesis": "PersonX is seen as better", "update": "PersonX's high school friends think this is strange.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5730", "update_paraphrase": "It's strange to PersonX's high school friends that this is happening.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2492690058479532, "pred_conf_shift": -0.4509335458278656, "syntactic_distance": 0.4}, {"confidence": [0.7959274649620056, 0.2040724754333496], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5730.gpt3.0", "original_example": {"example_id": "atomic.train.5730", "premise_hypothesis_id": "atomic.train.2702", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9GTom-eEx2-NNZWT1B9IUQ==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX stops eating fast food", "hypothesis": "PersonX is seen as better", "update": "PersonX's high school friends think this is strange.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5730", "update_paraphrase": "PersonX's high school friends find this to be strange behavior.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3418430335097002, "pred_conf_shift": 0.03188347816467285, "syntactic_distance": 0.13043478260869565}, {"confidence": [0.7208887338638306, 0.27911120653152466], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5730.gpt3.4", "original_example": {"example_id": "atomic.train.5730", "premise_hypothesis_id": "atomic.train.2702", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9GTom-eEx2-NNZWT1B9IUQ==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX stops eating fast food", "hypothesis": "PersonX is seen as better", "update": "PersonX's high school friends think this is strange.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5730", "update_paraphrase": "PersonX's high school friends think it is odd that he/she is doing this.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3659155659155659, "pred_conf_shift": -0.0431552529335022, "syntactic_distance": 0.0}]}, "atomic.train.15319": {"original_confidence": [0.32291179895401, 0.6770882606506348], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.0460059829056263, 0.9539941549301147], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15319.gpt3.6", "original_example": {"example_id": "atomic.train.15319", "premise_hypothesis_id": "atomic.train.7146", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "I-TRA65beoH_LTOz5OBWpA==", "AtomicEventRelationId": "ITatbkNCkOflOUQUveTYrw==", "AtomicRelationType": "xIntent", "AtomicInference": "to enjoy the city"}, "premise": "PersonX goes downtown", "hypothesis": "Because PersonX wanted to enjoy the city", "update": "PersonX is a tourist visiting from another country.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15319", "update_paraphrase": "PersonX come from another country and is currently visiting as a tourist.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.38181818181818183, "pred_conf_shift": 0.27690589427948, "syntactic_distance": 0.4}, {"confidence": [0.1127704456448555, 0.8872295618057251], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15319.gpt3.7", "original_example": {"example_id": "atomic.train.15319", "premise_hypothesis_id": "atomic.train.7146", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "I-TRA65beoH_LTOz5OBWpA==", "AtomicEventRelationId": "ITatbkNCkOflOUQUveTYrw==", "AtomicRelationType": "xIntent", "AtomicInference": "to enjoy the city"}, "premise": "PersonX goes downtown", "hypothesis": "Because PersonX wanted to enjoy the city", "update": "PersonX is a tourist visiting from another country.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15319", "update_paraphrase": "PersonX, a foreigner, is currently touring the country.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3591994810744811, "pred_conf_shift": 0.21014130115509033, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.12681260704994202, 0.8731873631477356], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15319.gpt3.8", "original_example": {"example_id": "atomic.train.15319", "premise_hypothesis_id": "atomic.train.7146", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "I-TRA65beoH_LTOz5OBWpA==", "AtomicEventRelationId": "ITatbkNCkOflOUQUveTYrw==", "AtomicRelationType": "xIntent", "AtomicInference": "to enjoy the city"}, "premise": "PersonX goes downtown", "hypothesis": "Because PersonX wanted to enjoy the city", "update": "PersonX is a tourist visiting from another country.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15319", "update_paraphrase": "PersonX is from another country and is here on vacation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4149831649831649, "pred_conf_shift": 0.19609910249710083, "syntactic_distance": 0.35}, {"confidence": [0.2898310422897339, 0.7101688981056213], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15319.gpt3.0", "original_example": {"example_id": "atomic.train.15319", "premise_hypothesis_id": "atomic.train.7146", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "I-TRA65beoH_LTOz5OBWpA==", "AtomicEventRelationId": "ITatbkNCkOflOUQUveTYrw==", "AtomicRelationType": "xIntent", "AtomicInference": "to enjoy the city"}, "premise": "PersonX goes downtown", "hypothesis": "Because PersonX wanted to enjoy the city", "update": "PersonX is a tourist visiting from another country.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15319", "update_paraphrase": "PersonX is a visitor from a different country who is currently touring.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3973412698412698, "pred_conf_shift": 0.03308063745498657, "syntactic_distance": 0.0625}, {"confidence": [0.266594260931015, 0.7334057092666626], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15319.gpt3.1", "original_example": {"example_id": "atomic.train.15319", "premise_hypothesis_id": "atomic.train.7146", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "I-TRA65beoH_LTOz5OBWpA==", "AtomicEventRelationId": "ITatbkNCkOflOUQUveTYrw==", "AtomicRelationType": "xIntent", "AtomicInference": "to enjoy the city"}, "premise": "PersonX goes downtown", "hypothesis": "Because PersonX wanted to enjoy the city", "update": "PersonX is a tourist visiting from another country.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15319", "update_paraphrase": "PersonX is a foreign tourist currently visiting our country.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2886002886002885, "pred_conf_shift": 0.05631744861602783, "syntactic_distance": 0.0}, {"confidence": [0.3231624364852905, 0.6768375635147095], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15319.gpt3.4", "original_example": {"example_id": "atomic.train.15319", "premise_hypothesis_id": "atomic.train.7146", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "I-TRA65beoH_LTOz5OBWpA==", "AtomicEventRelationId": "ITatbkNCkOflOUQUveTYrw==", "AtomicRelationType": "xIntent", "AtomicInference": "to enjoy the city"}, "premise": "PersonX goes downtown", "hypothesis": "Because PersonX wanted to enjoy the city", "update": "PersonX is a tourist visiting from another country.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15319", "update_paraphrase": "PersonX is a tourist visiting the country from another nation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2417027417027417, "pred_conf_shift": -0.00025069713592529297, "syntactic_distance": 0.0}, {"confidence": [0.05432844161987305, 0.945671558380127], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15319.gpt3.5", "original_example": {"example_id": "atomic.train.15319", "premise_hypothesis_id": "atomic.train.7146", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "I-TRA65beoH_LTOz5OBWpA==", "AtomicEventRelationId": "ITatbkNCkOflOUQUveTYrw==", "AtomicRelationType": "xIntent", "AtomicInference": "to enjoy the city"}, "premise": "PersonX goes downtown", "hypothesis": "Because PersonX wanted to enjoy the city", "update": "PersonX is a tourist visiting from another country.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15319", "update_paraphrase": "PersonX is from another country and is visiting as a tourist.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.29665071770334933, "pred_conf_shift": 0.2685832977294922, "syntactic_distance": 0.2631578947368421}, {"confidence": [0.179016575217247, 0.8209834098815918], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15319.gpt3.2", "original_example": {"example_id": "atomic.train.15319", "premise_hypothesis_id": "atomic.train.7146", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "I-TRA65beoH_LTOz5OBWpA==", "AtomicEventRelationId": "ITatbkNCkOflOUQUveTYrw==", "AtomicRelationType": "xIntent", "AtomicInference": "to enjoy the city"}, "premise": "PersonX goes downtown", "hypothesis": "Because PersonX wanted to enjoy the city", "update": "PersonX is a tourist visiting from another country.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15319", "update_paraphrase": "PersonX is a tourist who is visiting from another country.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.11111111111111116, "pred_conf_shift": 0.14389514923095703, "syntactic_distance": 0.0625}, {"confidence": [0.0635332316160202, 0.9364667534828186], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15319.gpt3.3", "original_example": {"example_id": "atomic.train.15319", "premise_hypothesis_id": "atomic.train.7146", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "I-TRA65beoH_LTOz5OBWpA==", "AtomicEventRelationId": "ITatbkNCkOflOUQUveTYrw==", "AtomicRelationType": "xIntent", "AtomicInference": "to enjoy the city"}, "premise": "PersonX goes downtown", "hypothesis": "Because PersonX wanted to enjoy the city", "update": "PersonX is a tourist visiting from another country.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15319", "update_paraphrase": "PersonX is from another country and is currently visiting as a tourist.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3318181818181818, "pred_conf_shift": 0.25937849283218384, "syntactic_distance": 0.3}]}, "atomic.train.14401": {"original_confidence": [0.2643278241157532, 0.7356721758842468], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.14255115389823914, 0.8574488162994385], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.14401.gpt3.2", "original_example": {"example_id": "atomic.train.14401", "premise_hypothesis_id": "atomic.train.6720", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "wFOrqUpMl-Zs2bI-HWi96g==", "AtomicEventRelationId": "1mn5hMxi6firUbJaVJ0E5A==", "AtomicRelationType": "xIntent", "AtomicInference": "discuse matters"}, "premise": "PersonX sees PersonY in person", "hypothesis": "Because PersonX wanted discuse matters", "update": "PersonY just sent PersonX a confusing email.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14401", "update_paraphrase": "PersonY just sent PersonX an email that was confusing.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28235653235653235, "pred_conf_shift": 0.12177664041519165, "syntactic_distance": 0.12}, {"confidence": [0.49940115213394165, 0.5005989074707031], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.14401.gpt3.0", "original_example": {"example_id": "atomic.train.14401", "premise_hypothesis_id": "atomic.train.6720", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "wFOrqUpMl-Zs2bI-HWi96g==", "AtomicEventRelationId": "1mn5hMxi6firUbJaVJ0E5A==", "AtomicRelationType": "xIntent", "AtomicInference": "discuse matters"}, "premise": "PersonX sees PersonY in person", "hypothesis": "Because PersonX wanted discuse matters", "update": "PersonY just sent PersonX a confusing email.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14401", "update_paraphrase": "PersonX is confused by the email PersonY just sent them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.46174548250672814, "pred_conf_shift": -0.2350732684135437, "syntactic_distance": 0.42857142857142855}, {"confidence": [0.18874512612819672, 0.8112549781799316], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.14401.gpt3.5", "original_example": {"example_id": "atomic.train.14401", "premise_hypothesis_id": "atomic.train.6720", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "wFOrqUpMl-Zs2bI-HWi96g==", "AtomicEventRelationId": "1mn5hMxi6firUbJaVJ0E5A==", "AtomicRelationType": "xIntent", "AtomicInference": "discuse matters"}, "premise": "PersonX sees PersonY in person", "hypothesis": "Because PersonX wanted discuse matters", "update": "PersonY just sent PersonX a confusing email.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14401", "update_paraphrase": "The email PersonY just sent to PersonX is confusing.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3125, "pred_conf_shift": 0.07558280229568481, "syntactic_distance": 0.48148148148148145}, {"confidence": [0.18228760361671448, 0.8177124261856079], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.14401.gpt3.3", "original_example": {"example_id": "atomic.train.14401", "premise_hypothesis_id": "atomic.train.6720", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "wFOrqUpMl-Zs2bI-HWi96g==", "AtomicEventRelationId": "1mn5hMxi6firUbJaVJ0E5A==", "AtomicRelationType": "xIntent", "AtomicInference": "discuse matters"}, "premise": "PersonX sees PersonY in person", "hypothesis": "Because PersonX wanted discuse matters", "update": "PersonY just sent PersonX a confusing email.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14401", "update_paraphrase": "PersonX received an email from PersonY that was confusing.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.453125, "pred_conf_shift": 0.08204025030136108, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.3618687093257904, 0.6381312608718872], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.14401.gpt3.4", "original_example": {"example_id": "atomic.train.14401", "premise_hypothesis_id": "atomic.train.6720", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "wFOrqUpMl-Zs2bI-HWi96g==", "AtomicEventRelationId": "1mn5hMxi6firUbJaVJ0E5A==", "AtomicRelationType": "xIntent", "AtomicInference": "discuse matters"}, "premise": "PersonX sees PersonY in person", "hypothesis": "Because PersonX wanted discuse matters", "update": "PersonY just sent PersonX a confusing email.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14401", "update_paraphrase": "PersonY's latest email to PersonX is confusing and hard to understand.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4891534391534393, "pred_conf_shift": -0.09754091501235962, "syntactic_distance": 0.4642857142857143}, {"confidence": [0.21341724693775177, 0.7865826487541199], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.14401.gpt3.1", "original_example": {"example_id": "atomic.train.14401", "premise_hypothesis_id": "atomic.train.6720", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "wFOrqUpMl-Zs2bI-HWi96g==", "AtomicEventRelationId": "1mn5hMxi6firUbJaVJ0E5A==", "AtomicRelationType": "xIntent", "AtomicInference": "discuse matters"}, "premise": "PersonX sees PersonY in person", "hypothesis": "Because PersonX wanted discuse matters", "update": "PersonY just sent PersonX a confusing email.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14401", "update_paraphrase": "The email PersonY sent to PersonX was very confusing and hard to understand.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.46523809523809523, "pred_conf_shift": 0.05091047286987305, "syntactic_distance": 0.38461538461538464}]}, "atomic.train.778": {"original_confidence": [0.7047103047370911, 0.29528963565826416], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.6136937141418457, 0.38630619645118713], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.778.gpt3.3", "original_example": {"example_id": "atomic.train.778", "premise_hypothesis_id": "atomic.train.368", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "cUkvijZxQ2DYYM2HtMU9Pg==", "AtomicEventRelationId": "0PMF1NvF3V2FwjwYyTD-6g==", "AtomicRelationType": "xNeed", "AtomicInference": "to prepare the bedroom: put down tarps, etc"}, "premise": "PersonX paints PersonY's bedroom", "hypothesis": "Before, PersonX needed to prepare the bedroom: put down tarps, etc", "update": "PersonX's room has no carpet.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.778", "update_paraphrase": "The room belonging to PersonX does not have any carpeting.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5218470418470419, "pred_conf_shift": -0.09101659059524536, "syntactic_distance": 0.391304347826087}, {"confidence": [0.3954050540924072, 0.6045950055122375], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.778.gpt3.5", "original_example": {"example_id": "atomic.train.778", "premise_hypothesis_id": "atomic.train.368", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "cUkvijZxQ2DYYM2HtMU9Pg==", "AtomicEventRelationId": "0PMF1NvF3V2FwjwYyTD-6g==", "AtomicRelationType": "xNeed", "AtomicInference": "to prepare the bedroom: put down tarps, etc"}, "premise": "PersonX paints PersonY's bedroom", "hypothesis": "Before, PersonX needed to prepare the bedroom: put down tarps, etc", "update": "PersonX's room has no carpet.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.778", "update_paraphrase": "PersonX's room is not carpeted.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3427705627705628, "pred_conf_shift": -0.30930525064468384, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.579876184463501, 0.4201238751411438], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.778.gpt3.0", "original_example": {"example_id": "atomic.train.778", "premise_hypothesis_id": "atomic.train.368", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "cUkvijZxQ2DYYM2HtMU9Pg==", "AtomicEventRelationId": "0PMF1NvF3V2FwjwYyTD-6g==", "AtomicRelationType": "xNeed", "AtomicInference": "to prepare the bedroom: put down tarps, etc"}, "premise": "PersonX paints PersonY's bedroom", "hypothesis": "Before, PersonX needed to prepare the bedroom: put down tarps, etc", "update": "PersonX's room has no carpet.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.778", "update_paraphrase": "The room that belongs to PersonX does not have any carpeting.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5338744588744588, "pred_conf_shift": -0.12483412027359009, "syntactic_distance": 0.391304347826087}, {"confidence": [0.47677651047706604, 0.5232235193252563], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.778.gpt3.1", "original_example": {"example_id": "atomic.train.778", "premise_hypothesis_id": "atomic.train.368", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "cUkvijZxQ2DYYM2HtMU9Pg==", "AtomicEventRelationId": "0PMF1NvF3V2FwjwYyTD-6g==", "AtomicRelationType": "xNeed", "AtomicInference": "to prepare the bedroom: put down tarps, etc"}, "premise": "PersonX paints PersonY's bedroom", "hypothesis": "Before, PersonX needed to prepare the bedroom: put down tarps, etc", "update": "PersonX's room has no carpet.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.778", "update_paraphrase": "There is no carpeting in PersonX's room.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.44102564102564096, "pred_conf_shift": -0.22793379426002502, "syntactic_distance": 0.25}, {"confidence": [0.7027276754379272, 0.29727238416671753], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.778.gpt3.4", "original_example": {"example_id": "atomic.train.778", "premise_hypothesis_id": "atomic.train.368", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "cUkvijZxQ2DYYM2HtMU9Pg==", "AtomicEventRelationId": "0PMF1NvF3V2FwjwYyTD-6g==", "AtomicRelationType": "xNeed", "AtomicInference": "to prepare the bedroom: put down tarps, etc"}, "premise": "PersonX paints PersonY's bedroom", "hypothesis": "Before, PersonX needed to prepare the bedroom: put down tarps, etc", "update": "PersonX's room has no carpet.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.778", "update_paraphrase": "There is no carpet in PersonX's room.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4076923076923077, "pred_conf_shift": -0.0019826292991638184, "syntactic_distance": 0.25}]}, "atomic.train.30105": {"original_confidence": [0.027472661808133125, 0.972527265548706], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.04781591519713402, 0.9521842002868652], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30105.gpt3.8", "original_example": {"example_id": "atomic.train.30105", "premise_hypothesis_id": "atomic.train.13673", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BL5rTOQOaX-YiJPm9S2CeQ==", "AtomicEventRelationId": "xU3v0O5lHF-Ln5Xh_XECVQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to put it on the oven"}, "premise": "PersonX makes a pizza", "hypothesis": "Before, PersonX needed to put it on the oven", "update": "X preheats the oven.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30105", "update_paraphrase": "Before cooking, X warms up the oven.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39860139860139865, "pred_conf_shift": -0.02034306526184082, "syntactic_distance": 0.4}, {"confidence": [0.02885935641825199, 0.9711406230926514], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30105.gpt3.2", "original_example": {"example_id": "atomic.train.30105", "premise_hypothesis_id": "atomic.train.13673", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BL5rTOQOaX-YiJPm9S2CeQ==", "AtomicEventRelationId": "xU3v0O5lHF-Ln5Xh_XECVQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to put it on the oven"}, "premise": "PersonX makes a pizza", "hypothesis": "Before, PersonX needed to put it on the oven", "update": "X preheats the oven.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30105", "update_paraphrase": "Before baking, X preheats the oven.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19999999999999996, "pred_conf_shift": -0.0013866424560546875, "syntactic_distance": 0.5294117647058824}, {"confidence": [0.025348298251628876, 0.9746517539024353], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30105.gpt3.6", "original_example": {"example_id": "atomic.train.30105", "premise_hypothesis_id": "atomic.train.13673", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BL5rTOQOaX-YiJPm9S2CeQ==", "AtomicEventRelationId": "xU3v0O5lHF-Ln5Xh_XECVQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to put it on the oven"}, "premise": "PersonX makes a pizza", "hypothesis": "Before, PersonX needed to put it on the oven", "update": "X preheats the oven.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30105", "update_paraphrase": "X puts the oven on the preheat setting.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.46388888888888885, "pred_conf_shift": 0.002124488353729248, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.030734561383724213, 0.9692654013633728], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30105.gpt3.1", "original_example": {"example_id": "atomic.train.30105", "premise_hypothesis_id": "atomic.train.13673", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BL5rTOQOaX-YiJPm9S2CeQ==", "AtomicEventRelationId": "xU3v0O5lHF-Ln5Xh_XECVQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to put it on the oven"}, "premise": "PersonX makes a pizza", "hypothesis": "Before, PersonX needed to put it on the oven", "update": "X preheats the oven.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30105", "update_paraphrase": "X puts the oven on to preheat.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4151515151515151, "pred_conf_shift": -0.003261864185333252, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.026143956929445267, 0.9738560318946838], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30105.gpt3.5", "original_example": {"example_id": "atomic.train.30105", "premise_hypothesis_id": "atomic.train.13673", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BL5rTOQOaX-YiJPm9S2CeQ==", "AtomicEventRelationId": "xU3v0O5lHF-Ln5Xh_XECVQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to put it on the oven"}, "premise": "PersonX makes a pizza", "hypothesis": "Before, PersonX needed to put it on the oven", "update": "X preheats the oven.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30105", "update_paraphrase": "Before X starts cooking, they need to preheat the oven.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4380952380952381, "pred_conf_shift": 0.0013287663459777832, "syntactic_distance": 0.631578947368421}, {"confidence": [0.032294612377882004, 0.9677053689956665], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30105.gpt3.0", "original_example": {"example_id": "atomic.train.30105", "premise_hypothesis_id": "atomic.train.13673", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BL5rTOQOaX-YiJPm9S2CeQ==", "AtomicEventRelationId": "xU3v0O5lHF-Ln5Xh_XECVQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to put it on the oven"}, "premise": "PersonX makes a pizza", "hypothesis": "Before, PersonX needed to put it on the oven", "update": "X preheats the oven.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30105", "update_paraphrase": "First, X will preheat the oven.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.21333333333333326, "pred_conf_shift": -0.004821896553039551, "syntactic_distance": 0.5}, {"confidence": [0.026000583544373512, 0.9739994406700134], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30105.gpt3.7", "original_example": {"example_id": "atomic.train.30105", "premise_hypothesis_id": "atomic.train.13673", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BL5rTOQOaX-YiJPm9S2CeQ==", "AtomicEventRelationId": "xU3v0O5lHF-Ln5Xh_XECVQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to put it on the oven"}, "premise": "PersonX makes a pizza", "hypothesis": "Before, PersonX needed to put it on the oven", "update": "X preheats the oven.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30105", "update_paraphrase": "X sets the oven to preheat.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.35666666666666663, "pred_conf_shift": 0.001472175121307373, "syntactic_distance": 0.2857142857142857}, {"confidence": [0.19719524681568146, 0.802804708480835], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30105.gpt3.4", "original_example": {"example_id": "atomic.train.30105", "premise_hypothesis_id": "atomic.train.13673", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BL5rTOQOaX-YiJPm9S2CeQ==", "AtomicEventRelationId": "xU3v0O5lHF-Ln5Xh_XECVQ==", "AtomicRelationType": "xNeed", "AtomicInference": "to put it on the oven"}, "premise": "PersonX makes a pizza", "hypothesis": "Before, PersonX needed to put it on the oven", "update": "X preheats the oven.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30105", "update_paraphrase": "Before baking, X turns on the oven to let it warm up.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5830419580419581, "pred_conf_shift": -0.1697225570678711, "syntactic_distance": 0.5555555555555556}]}, "atomic.train.16786": {"original_confidence": [0.014604165218770504, 0.9853958487510681], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.014430848881602287, 0.9855692386627197], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16786.gpt3.6", "original_example": {"example_id": "atomic.train.16786", "premise_hypothesis_id": "atomic.train.7826", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "O4QLODwH8WvXbBmLE0YyWg==", "AtomicEventRelationId": "oVRgdwOMdenC4X2d-YMK8A==", "AtomicRelationType": "xReact", "AtomicInference": "nervous, unsure, excited"}, "premise": "PersonX touches PersonY's cheek", "hypothesis": "PersonX is seen as nervous, unsure, excited", "update": "PersonX has a crush on PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16786", "update_paraphrase": "PersonX has a major crush on PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.07692307692307687, "pred_conf_shift": -0.0001733163371682167, "syntactic_distance": 0.0}, {"confidence": [0.015680933371186256, 0.9843190312385559], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16786.gpt3.7", "original_example": {"example_id": "atomic.train.16786", "premise_hypothesis_id": "atomic.train.7826", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "O4QLODwH8WvXbBmLE0YyWg==", "AtomicEventRelationId": "oVRgdwOMdenC4X2d-YMK8A==", "AtomicRelationType": "xReact", "AtomicInference": "nervous, unsure, excited"}, "premise": "PersonX touches PersonY's cheek", "hypothesis": "PersonX is seen as nervous, unsure, excited", "update": "PersonX has a crush on PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16786", "update_paraphrase": "PersonX has romantic feelings for PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.36032763532763534, "pred_conf_shift": 0.0010767681524157524, "syntactic_distance": 0.0}, {"confidence": [0.013470220379531384, 0.9865298271179199], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16786.gpt3.5", "original_example": {"example_id": "atomic.train.16786", "premise_hypothesis_id": "atomic.train.7826", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "O4QLODwH8WvXbBmLE0YyWg==", "AtomicEventRelationId": "oVRgdwOMdenC4X2d-YMK8A==", "AtomicRelationType": "xReact", "AtomicInference": "nervous, unsure, excited"}, "premise": "PersonX touches PersonY's cheek", "hypothesis": "PersonX is seen as nervous, unsure, excited", "update": "PersonX has a crush on PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16786", "update_paraphrase": "PersonX harbors romantic feelings for PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.46680911680911685, "pred_conf_shift": -0.0011339448392391205, "syntactic_distance": 0.0}, {"confidence": [0.07018031179904938, 0.929819643497467], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16786.gpt3.0", "original_example": {"example_id": "atomic.train.16786", "premise_hypothesis_id": "atomic.train.7826", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "O4QLODwH8WvXbBmLE0YyWg==", "AtomicEventRelationId": "oVRgdwOMdenC4X2d-YMK8A==", "AtomicRelationType": "xReact", "AtomicInference": "nervous, unsure, excited"}, "premise": "PersonX touches PersonY's cheek", "hypothesis": "PersonX is seen as nervous, unsure, excited", "update": "PersonX has a crush on PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16786", "update_paraphrase": "PersonX is enamored with PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.49725829725829723, "pred_conf_shift": 0.05557614658027887, "syntactic_distance": 0.125}, {"confidence": [0.01644079200923443, 0.983559250831604], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16786.gpt3.4", "original_example": {"example_id": "atomic.train.16786", "premise_hypothesis_id": "atomic.train.7826", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "O4QLODwH8WvXbBmLE0YyWg==", "AtomicEventRelationId": "oVRgdwOMdenC4X2d-YMK8A==", "AtomicRelationType": "xReact", "AtomicInference": "nervous, unsure, excited"}, "premise": "PersonX touches PersonY's cheek", "hypothesis": "PersonX is seen as nervous, unsure, excited", "update": "PersonX has a crush on PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16786", "update_paraphrase": "PersonX has a romantic interest in PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.27772996234534697, "pred_conf_shift": 0.0018366267904639244, "syntactic_distance": 0.0}, {"confidence": [0.024647124111652374, 0.9753528237342834], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16786.gpt3.1", "original_example": {"example_id": "atomic.train.16786", "premise_hypothesis_id": "atomic.train.7826", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "O4QLODwH8WvXbBmLE0YyWg==", "AtomicEventRelationId": "oVRgdwOMdenC4X2d-YMK8A==", "AtomicRelationType": "xReact", "AtomicInference": "nervous, unsure, excited"}, "premise": "PersonX touches PersonY's cheek", "hypothesis": "PersonX is seen as nervous, unsure, excited", "update": "PersonX has a crush on PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16786", "update_paraphrase": "PersonX is attracted to PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.48181818181818187, "pred_conf_shift": 0.01004295889288187, "syntactic_distance": 0.125}, {"confidence": [0.01488556805998087, 0.985114336013794], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16786.gpt3.3", "original_example": {"example_id": "atomic.train.16786", "premise_hypothesis_id": "atomic.train.7826", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "O4QLODwH8WvXbBmLE0YyWg==", "AtomicEventRelationId": "oVRgdwOMdenC4X2d-YMK8A==", "AtomicRelationType": "xReact", "AtomicInference": "nervous, unsure, excited"}, "premise": "PersonX touches PersonY's cheek", "hypothesis": "PersonX is seen as nervous, unsure, excited", "update": "PersonX has a crush on PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16786", "update_paraphrase": "PersonX is attracted to PersonY and would like to pursue a romantic relationship.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5845435266487898, "pred_conf_shift": 0.0002814028412103653, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.015468322671949863, 0.9845317602157593], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16786.gpt3.2", "original_example": {"example_id": "atomic.train.16786", "premise_hypothesis_id": "atomic.train.7826", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "O4QLODwH8WvXbBmLE0YyWg==", "AtomicEventRelationId": "oVRgdwOMdenC4X2d-YMK8A==", "AtomicRelationType": "xReact", "AtomicInference": "nervous, unsure, excited"}, "premise": "PersonX touches PersonY's cheek", "hypothesis": "PersonX is seen as nervous, unsure, excited", "update": "PersonX has a crush on PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16786", "update_paraphrase": "Person X has romantic feelings for Person Y.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4825396825396826, "pred_conf_shift": 0.0008641574531793594, "syntactic_distance": 0.058823529411764705}]}, "atomic.train.5662": {"original_confidence": [0.3605813980102539, 0.6394185423851013], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.515646755695343, 0.48435330390930176], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5662.gpt3.2", "original_example": {"example_id": "atomic.train.5662", "premise_hypothesis_id": "atomic.train.2674", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "tOe1Fq0sczcg5x8ItNpOZg==", "AtomicEventRelationId": "yANm9RlXtb4tOoA81pn3FA==", "AtomicRelationType": "xNeed", "AtomicInference": "to transport themselves to the station"}, "premise": "PersonX meets PersonY at the station", "hypothesis": "Before, PersonX needed to transport themselves to the station", "update": "Person X setup the meeting from the station.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5662", "update_paraphrase": "Person X arranged the meeting to take place at the station.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3734335839598998, "pred_conf_shift": 0.1550653576850891, "syntactic_distance": 0.42857142857142855}, {"confidence": [0.4715128242969513, 0.5284872055053711], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.5662.gpt3.4", "original_example": {"example_id": "atomic.train.5662", "premise_hypothesis_id": "atomic.train.2674", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "tOe1Fq0sczcg5x8ItNpOZg==", "AtomicEventRelationId": "yANm9RlXtb4tOoA81pn3FA==", "AtomicRelationType": "xNeed", "AtomicInference": "to transport themselves to the station"}, "premise": "PersonX meets PersonY at the station", "hypothesis": "Before, PersonX needed to transport themselves to the station", "update": "Person X setup the meeting from the station.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5662", "update_paraphrase": "Person X originally scheduled the meeting to take place at the station.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37797619047619047, "pred_conf_shift": 0.11093142628669739, "syntactic_distance": 0.28}, {"confidence": [0.5274549722671509, 0.4725450873374939], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5662.gpt3.0", "original_example": {"example_id": "atomic.train.5662", "premise_hypothesis_id": "atomic.train.2674", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "tOe1Fq0sczcg5x8ItNpOZg==", "AtomicEventRelationId": "yANm9RlXtb4tOoA81pn3FA==", "AtomicRelationType": "xNeed", "AtomicInference": "to transport themselves to the station"}, "premise": "PersonX meets PersonY at the station", "hypothesis": "Before, PersonX needed to transport themselves to the station", "update": "Person X setup the meeting from the station.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5662", "update_paraphrase": "Person X set up the meeting at the station.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.26213818860877686, "pred_conf_shift": 0.16687357425689697, "syntactic_distance": 0.11538461538461539}, {"confidence": [0.709276020526886, 0.2907239496707916], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5662.gpt3.3", "original_example": {"example_id": "atomic.train.5662", "premise_hypothesis_id": "atomic.train.2674", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "tOe1Fq0sczcg5x8ItNpOZg==", "AtomicEventRelationId": "yANm9RlXtb4tOoA81pn3FA==", "AtomicRelationType": "xNeed", "AtomicInference": "to transport themselves to the station"}, "premise": "PersonX meets PersonY at the station", "hypothesis": "Before, PersonX needed to transport themselves to the station", "update": "Person X setup the meeting from the station.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5662", "update_paraphrase": "The meeting was set up by person X at the station.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.41315789473684206, "pred_conf_shift": 0.3486946225166321, "syntactic_distance": 0.391304347826087}, {"confidence": [0.8951252102851868, 0.10487472265958786], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5662.gpt3.1", "original_example": {"example_id": "atomic.train.5662", "premise_hypothesis_id": "atomic.train.2674", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "tOe1Fq0sczcg5x8ItNpOZg==", "AtomicEventRelationId": "yANm9RlXtb4tOoA81pn3FA==", "AtomicRelationType": "xNeed", "AtomicInference": "to transport themselves to the station"}, "premise": "PersonX meets PersonY at the station", "hypothesis": "Before, PersonX needed to transport themselves to the station", "update": "Person X setup the meeting from the station.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5662", "update_paraphrase": "The person responsible for setting up the meeting did so from the station.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37414965986394555, "pred_conf_shift": 0.5345438122749329, "syntactic_distance": 0.3333333333333333}]}, "atomic.train.38352": {"original_confidence": [0.4957217574119568, 0.504278302192688], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.32013481855392456, 0.6798652410507202], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38352.gpt3.5", "original_example": {"example_id": "atomic.train.38352", "premise_hypothesis_id": "atomic.train.17407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y2qCX-s_lhAnsozDKfokkQ==", "AtomicEventRelationId": "oaiRNf9Whqt2DNn_2EtYWw==", "AtomicRelationType": "xNeed", "AtomicInference": "Contact person Y"}, "premise": "PersonX wants to hang out with PersonY", "hypothesis": "Before, PersonX needed contact person Y", "update": "PersonX lives in the same house as PersonY since they are roommates", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38352", "update_paraphrase": "PersonX shares a residence with PersonY as they are roommates.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3341204250295159, "pred_conf_shift": -0.17558693885803223, "syntactic_distance": 0.12}, {"confidence": [0.4385926425457001, 0.5614073276519775], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38352.gpt3.1", "original_example": {"example_id": "atomic.train.38352", "premise_hypothesis_id": "atomic.train.17407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y2qCX-s_lhAnsozDKfokkQ==", "AtomicEventRelationId": "oaiRNf9Whqt2DNn_2EtYWw==", "AtomicRelationType": "xNeed", "AtomicInference": "Contact person Y"}, "premise": "PersonX wants to hang out with PersonY", "hypothesis": "Before, PersonX needed contact person Y", "update": "PersonX lives in the same house as PersonY since they are roommates", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38352", "update_paraphrase": "PersonX and PersonY are roommates and live together in the same house.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.35433201058201064, "pred_conf_shift": -0.057129114866256714, "syntactic_distance": 0.4}, {"confidence": [0.33564531803131104, 0.6643547415733337], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38352.gpt3.2", "original_example": {"example_id": "atomic.train.38352", "premise_hypothesis_id": "atomic.train.17407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y2qCX-s_lhAnsozDKfokkQ==", "AtomicEventRelationId": "oaiRNf9Whqt2DNn_2EtYWw==", "AtomicRelationType": "xNeed", "AtomicInference": "Contact person Y"}, "premise": "PersonX wants to hang out with PersonY", "hypothesis": "Before, PersonX needed contact person Y", "update": "PersonX lives in the same house as PersonY since they are roommates", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38352", "update_paraphrase": "PersonX and PersonY share a house as roommates", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4361111111111111, "pred_conf_shift": -0.16007643938064575, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.5201631784439087, 0.47983691096305847], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.38352.gpt3.6", "original_example": {"example_id": "atomic.train.38352", "premise_hypothesis_id": "atomic.train.17407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y2qCX-s_lhAnsozDKfokkQ==", "AtomicEventRelationId": "oaiRNf9Whqt2DNn_2EtYWw==", "AtomicRelationType": "xNeed", "AtomicInference": "Contact person Y"}, "premise": "PersonX wants to hang out with PersonY", "hypothesis": "Before, PersonX needed contact person Y", "update": "PersonX lives in the same house as PersonY since they are roommates", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38352", "update_paraphrase": "PersonX lives in the same house as PersonY because they are sharing a living space.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.25423280423280425, "pred_conf_shift": 0.024441421031951904, "syntactic_distance": 0.0}, {"confidence": [0.5521582961082458, 0.44784170389175415], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.38352.gpt3.3", "original_example": {"example_id": "atomic.train.38352", "premise_hypothesis_id": "atomic.train.17407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y2qCX-s_lhAnsozDKfokkQ==", "AtomicEventRelationId": "oaiRNf9Whqt2DNn_2EtYWw==", "AtomicRelationType": "xNeed", "AtomicInference": "Contact person Y"}, "premise": "PersonX wants to hang out with PersonY", "hypothesis": "Before, PersonX needed contact person Y", "update": "PersonX lives in the same house as PersonY since they are roommates", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38352", "update_paraphrase": "PersonX and PersonY are roommates, so they have been living in the same house for a while now.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3958056758056757, "pred_conf_shift": 0.05643653869628906, "syntactic_distance": 0.36}, {"confidence": [0.31112512946128845, 0.6888749599456787], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38352.gpt3.4", "original_example": {"example_id": "atomic.train.38352", "premise_hypothesis_id": "atomic.train.17407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y2qCX-s_lhAnsozDKfokkQ==", "AtomicEventRelationId": "oaiRNf9Whqt2DNn_2EtYWw==", "AtomicRelationType": "xNeed", "AtomicInference": "Contact person Y"}, "premise": "PersonX wants to hang out with PersonY", "hypothesis": "Before, PersonX needed contact person Y", "update": "PersonX lives in the same house as PersonY since they are roommates", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38352", "update_paraphrase": "PersonX and PersonY share a living space because they are roommates.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3304651869869261, "pred_conf_shift": -0.18459662795066833, "syntactic_distance": 0.28}, {"confidence": [0.5582177042961121, 0.4417823255062103], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.38352.gpt3.0", "original_example": {"example_id": "atomic.train.38352", "premise_hypothesis_id": "atomic.train.17407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y2qCX-s_lhAnsozDKfokkQ==", "AtomicEventRelationId": "oaiRNf9Whqt2DNn_2EtYWw==", "AtomicRelationType": "xNeed", "AtomicInference": "Contact person Y"}, "premise": "PersonX wants to hang out with PersonY", "hypothesis": "Before, PersonX needed contact person Y", "update": "PersonX lives in the same house as PersonY since they are roommates", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38352", "update_paraphrase": "PersonX is roommates with PersonY, so they live in the same house.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3697991822991824, "pred_conf_shift": 0.06249594688415527, "syntactic_distance": 0.13636363636363635}]}, "atomic.train.37384": {"original_confidence": [0.18481256067752838, 0.8151874542236328], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.18302342295646667, 0.8169764876365662], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37384.gpt3.2", "original_example": {"example_id": "atomic.train.37384", "premise_hypothesis_id": "atomic.train.16966", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "EjYgLHQPfbZmKCTI198IAg==", "AtomicEventRelationId": "HxoNL2r73OIXA1bl3AlKyw==", "AtomicRelationType": "xReact", "AtomicInference": "may be he achieved something"}, "premise": "PersonX wants to see PersonY", "hypothesis": "PersonX is seen as may be he achieved something", "update": "PersonX has missed PersonY for weeks.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37384", "update_paraphrase": "PersonX has been longing for PersonY for several weeks.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3684981684981685, "pred_conf_shift": -0.0017891377210617065, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.24027284979820251, 0.7597271203994751], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37384.gpt3.5", "original_example": {"example_id": "atomic.train.37384", "premise_hypothesis_id": "atomic.train.16966", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "EjYgLHQPfbZmKCTI198IAg==", "AtomicEventRelationId": "HxoNL2r73OIXA1bl3AlKyw==", "AtomicRelationType": "xReact", "AtomicInference": "may be he achieved something"}, "premise": "PersonX wants to see PersonY", "hypothesis": "PersonX is seen as may be he achieved something", "update": "PersonX has missed PersonY for weeks.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37384", "update_paraphrase": "PersonX hasn't seen PersonY for weeks and really misses them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3916666666666666, "pred_conf_shift": 0.05546028912067413, "syntactic_distance": 0.34782608695652173}, {"confidence": [0.4498201906681061, 0.5501798391342163], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37384.gpt3.1", "original_example": {"example_id": "atomic.train.37384", "premise_hypothesis_id": "atomic.train.16966", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "EjYgLHQPfbZmKCTI198IAg==", "AtomicEventRelationId": "HxoNL2r73OIXA1bl3AlKyw==", "AtomicRelationType": "xReact", "AtomicInference": "may be he achieved something"}, "premise": "PersonX wants to see PersonY", "hypothesis": "PersonX is seen as may be he achieved something", "update": "PersonX has missed PersonY for weeks.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37384", "update_paraphrase": "PersonX has been pining for PersonY for several weeks.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3684981684981685, "pred_conf_shift": 0.2650076299905777, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.18533973395824432, 0.8146603107452393], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37384.gpt3.3", "original_example": {"example_id": "atomic.train.37384", "premise_hypothesis_id": "atomic.train.16966", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "EjYgLHQPfbZmKCTI198IAg==", "AtomicEventRelationId": "HxoNL2r73OIXA1bl3AlKyw==", "AtomicRelationType": "xReact", "AtomicInference": "may be he achieved something"}, "premise": "PersonX wants to see PersonY", "hypothesis": "PersonX is seen as may be he achieved something", "update": "PersonX has missed PersonY for weeks.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37384", "update_paraphrase": "PersonX has been longing for PersonY for weeks.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.24545454545454548, "pred_conf_shift": 0.0005271732807159424, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.3856523334980011, 0.6143475770950317], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37384.gpt3.4", "original_example": {"example_id": "atomic.train.37384", "premise_hypothesis_id": "atomic.train.16966", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "EjYgLHQPfbZmKCTI198IAg==", "AtomicEventRelationId": "HxoNL2r73OIXA1bl3AlKyw==", "AtomicRelationType": "xReact", "AtomicInference": "may be he achieved something"}, "premise": "PersonX wants to see PersonY", "hypothesis": "PersonX is seen as may be he achieved something", "update": "PersonX has missed PersonY for weeks.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37384", "update_paraphrase": "It's been weeks since PersonX has seen PersonY and they miss them dearly.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5450292397660819, "pred_conf_shift": 0.20083977282047272, "syntactic_distance": 0.48}, {"confidence": [0.9758773446083069, 0.024122631177306175], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37384.gpt3.7", "original_example": {"example_id": "atomic.train.37384", "premise_hypothesis_id": "atomic.train.16966", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "EjYgLHQPfbZmKCTI198IAg==", "AtomicEventRelationId": "HxoNL2r73OIXA1bl3AlKyw==", "AtomicRelationType": "xReact", "AtomicInference": "may be he achieved something"}, "premise": "PersonX wants to see PersonY", "hypothesis": "PersonX is seen as may be he achieved something", "update": "PersonX has missed PersonY for weeks.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37384", "update_paraphrase": "It's been weeks since PersonX has seen PersonY and they're feeling pretty down about it.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5863945578231292, "pred_conf_shift": 0.7910647839307785, "syntactic_distance": 0.5}, {"confidence": [0.2139073759317398, 0.7860925197601318], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37384.gpt3.0", "original_example": {"example_id": "atomic.train.37384", "premise_hypothesis_id": "atomic.train.16966", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "EjYgLHQPfbZmKCTI198IAg==", "AtomicEventRelationId": "HxoNL2r73OIXA1bl3AlKyw==", "AtomicRelationType": "xReact", "AtomicInference": "may be he achieved something"}, "premise": "PersonX wants to see PersonY", "hypothesis": "PersonX is seen as may be he achieved something", "update": "PersonX has missed PersonY for weeks.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37384", "update_paraphrase": "PersonX has been longing for PersonY for several weeks now.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.44842657342657344, "pred_conf_shift": 0.029094815254211426, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.17674006521701813, 0.8232598900794983], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37384.gpt3.6", "original_example": {"example_id": "atomic.train.37384", "premise_hypothesis_id": "atomic.train.16966", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "EjYgLHQPfbZmKCTI198IAg==", "AtomicEventRelationId": "HxoNL2r73OIXA1bl3AlKyw==", "AtomicRelationType": "xReact", "AtomicInference": "may be he achieved something"}, "premise": "PersonX wants to see PersonY", "hypothesis": "PersonX is seen as may be he achieved something", "update": "PersonX has missed PersonY for weeks.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37384", "update_paraphrase": "PersonX has been longing to see PersonY again for several weeks now.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.48597081930415265, "pred_conf_shift": -0.008072495460510254, "syntactic_distance": 0.11764705882352941}]}, "atomic.train.14249": {"original_confidence": [0.7758238315582275, 0.22417618334293365], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.21008603274822235, 0.7899139523506165], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.14249.gpt3.3", "original_example": {"example_id": "atomic.train.14249", "premise_hypothesis_id": "atomic.train.6652", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "CsHeRjjh0lkwRzhegn3cHQ==", "AtomicEventRelationId": "23NVHdbXaL_48rX7wLwCfA==", "AtomicRelationType": "xAttr", "AtomicInference": "Experimental"}, "premise": "PersonX bases upon research", "hypothesis": "As a result, PersonX feels experimental", "update": "PersonX wants to disprove the research.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14249", "update_paraphrase": "PersonX would like to find evidence that contradicts the research.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.43888888888888883, "pred_conf_shift": 0.5657377690076828, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.8745662569999695, 0.12543374300003052], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.14249.gpt3.5", "original_example": {"example_id": "atomic.train.14249", "premise_hypothesis_id": "atomic.train.6652", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "CsHeRjjh0lkwRzhegn3cHQ==", "AtomicEventRelationId": "23NVHdbXaL_48rX7wLwCfA==", "AtomicRelationType": "xAttr", "AtomicInference": "Experimental"}, "premise": "PersonX bases upon research", "hypothesis": "As a result, PersonX feels experimental", "update": "PersonX wants to disprove the research.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14249", "update_paraphrase": "PersonX disagrees with the research and wants to disprove it.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33333333333333337, "pred_conf_shift": -0.09874244034290314, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.5057579874992371, 0.49424201250076294], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.14249.gpt3.1", "original_example": {"example_id": "atomic.train.14249", "premise_hypothesis_id": "atomic.train.6652", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "CsHeRjjh0lkwRzhegn3cHQ==", "AtomicEventRelationId": "23NVHdbXaL_48rX7wLwCfA==", "AtomicRelationType": "xAttr", "AtomicInference": "Experimental"}, "premise": "PersonX bases upon research", "hypothesis": "As a result, PersonX feels experimental", "update": "PersonX wants to disprove the research.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14249", "update_paraphrase": "PersonX is determined to show that the research is wrong.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4666666666666666, "pred_conf_shift": 0.2700658291578293, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.9295190572738647, 0.07048090547323227], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.14249.gpt3.8", "original_example": {"example_id": "atomic.train.14249", "premise_hypothesis_id": "atomic.train.6652", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "CsHeRjjh0lkwRzhegn3cHQ==", "AtomicEventRelationId": "23NVHdbXaL_48rX7wLwCfA==", "AtomicRelationType": "xAttr", "AtomicInference": "Experimental"}, "premise": "PersonX bases upon research", "hypothesis": "As a result, PersonX feels experimental", "update": "PersonX wants to disprove the research.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14249", "update_paraphrase": "PersonX is looking to invalidate the research.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.30341880341880345, "pred_conf_shift": -0.15369527786970139, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.45957085490226746, 0.5404291152954102], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.14249.gpt3.6", "original_example": {"example_id": "atomic.train.14249", "premise_hypothesis_id": "atomic.train.6652", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "CsHeRjjh0lkwRzhegn3cHQ==", "AtomicEventRelationId": "23NVHdbXaL_48rX7wLwCfA==", "AtomicRelationType": "xAttr", "AtomicInference": "Experimental"}, "premise": "PersonX bases upon research", "hypothesis": "As a result, PersonX feels experimental", "update": "PersonX wants to disprove the research.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14249", "update_paraphrase": "PersonX wants to show that the research is wrong.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3594612794612794, "pred_conf_shift": 0.3162529319524765, "syntactic_distance": 0.0}, {"confidence": [0.9634891748428345, 0.03651079535484314], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.14249.gpt3.0", "original_example": {"example_id": "atomic.train.14249", "premise_hypothesis_id": "atomic.train.6652", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "CsHeRjjh0lkwRzhegn3cHQ==", "AtomicEventRelationId": "23NVHdbXaL_48rX7wLwCfA==", "AtomicRelationType": "xAttr", "AtomicInference": "Experimental"}, "premise": "PersonX bases upon research", "hypothesis": "As a result, PersonX feels experimental", "update": "PersonX wants to disprove the research.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14249", "update_paraphrase": "PersonX's goal is to discredit the research.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2604180133591897, "pred_conf_shift": -0.18766538798809052, "syntactic_distance": 0.13333333333333333}, {"confidence": [0.6025251150131226, 0.397475004196167], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.14249.gpt3.7", "original_example": {"example_id": "atomic.train.14249", "premise_hypothesis_id": "atomic.train.6652", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "CsHeRjjh0lkwRzhegn3cHQ==", "AtomicEventRelationId": "23NVHdbXaL_48rX7wLwCfA==", "AtomicRelationType": "xAttr", "AtomicInference": "Experimental"}, "premise": "PersonX bases upon research", "hypothesis": "As a result, PersonX feels experimental", "update": "PersonX wants to disprove the research.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14249", "update_paraphrase": "PersonX is looking to disprove the research.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.18681318681318682, "pred_conf_shift": 0.17329882085323334, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.5068949460983276, 0.4931049942970276], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.14249.gpt3.4", "original_example": {"example_id": "atomic.train.14249", "premise_hypothesis_id": "atomic.train.6652", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "CsHeRjjh0lkwRzhegn3cHQ==", "AtomicEventRelationId": "23NVHdbXaL_48rX7wLwCfA==", "AtomicRelationType": "xAttr", "AtomicInference": "Experimental"}, "premise": "PersonX bases upon research", "hypothesis": "As a result, PersonX feels experimental", "update": "PersonX wants to disprove the research.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14249", "update_paraphrase": "PersonX hopes to refute the research.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2758741258741258, "pred_conf_shift": 0.26892881095409393, "syntactic_distance": 0.0}, {"confidence": [0.6704891920089722, 0.3295108377933502], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.14249.gpt3.2", "original_example": {"example_id": "atomic.train.14249", "premise_hypothesis_id": "atomic.train.6652", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "CsHeRjjh0lkwRzhegn3cHQ==", "AtomicEventRelationId": "23NVHdbXaL_48rX7wLwCfA==", "AtomicRelationType": "xAttr", "AtomicInference": "Experimental"}, "premise": "PersonX bases upon research", "hypothesis": "As a result, PersonX feels experimental", "update": "PersonX wants to disprove the research.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14249", "update_paraphrase": "PersonX intends to disprove the research.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1111111111111111, "pred_conf_shift": 0.10533465445041656, "syntactic_distance": 0.0}]}, "atomic.train.7019": {"original_confidence": [0.9750477075576782, 0.02495231293141842], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.9789071679115295, 0.021092845126986504], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7019.gpt3.2", "original_example": {"example_id": "atomic.train.7019", "premise_hypothesis_id": "atomic.train.3315", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "d-GEsVTFv8xNXe-k-V11kQ==", "AtomicEventRelationId": "xDmMv3OO3ARgMCraj-5x5A==", "AtomicRelationType": "xAttr", "AtomicInference": "quick"}, "premise": "PersonX hits the brakes", "hypothesis": "As a result, PersonX feels quick", "update": "PersonX has to slow down to stay under the speed limit.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7019", "update_paraphrase": "Person X needs to drive more slowly in order to stay within the speed limit.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3284113322574861, "pred_conf_shift": -0.0038594678044319153, "syntactic_distance": 0.23809523809523808}, {"confidence": [0.9681777358055115, 0.03182222321629524], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7019.gpt3.6", "original_example": {"example_id": "atomic.train.7019", "premise_hypothesis_id": "atomic.train.3315", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "d-GEsVTFv8xNXe-k-V11kQ==", "AtomicEventRelationId": "xDmMv3OO3ARgMCraj-5x5A==", "AtomicRelationType": "xAttr", "AtomicInference": "quick"}, "premise": "PersonX hits the brakes", "hypothesis": "As a result, PersonX feels quick", "update": "PersonX has to slow down to stay under the speed limit.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7019", "update_paraphrase": "In order to stay within the speed limit, PersonX must drive more slowly.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4121332371332371, "pred_conf_shift": 0.006869910284876823, "syntactic_distance": 0.5454545454545454}, {"confidence": [0.9796347618103027, 0.02036520279943943], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7019.gpt3.3", "original_example": {"example_id": "atomic.train.7019", "premise_hypothesis_id": "atomic.train.3315", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "d-GEsVTFv8xNXe-k-V11kQ==", "AtomicEventRelationId": "xDmMv3OO3ARgMCraj-5x5A==", "AtomicRelationType": "xAttr", "AtomicInference": "quick"}, "premise": "PersonX hits the brakes", "hypothesis": "As a result, PersonX feels quick", "update": "PersonX has to slow down to stay under the speed limit.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7019", "update_paraphrase": "Person X needs to drive more slowly to stay below the speed limit.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.29205840455840454, "pred_conf_shift": -0.004587110131978989, "syntactic_distance": 0.05263157894736842}, {"confidence": [0.9729453921318054, 0.027054591104388237], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7019.gpt3.5", "original_example": {"example_id": "atomic.train.7019", "premise_hypothesis_id": "atomic.train.3315", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "d-GEsVTFv8xNXe-k-V11kQ==", "AtomicEventRelationId": "xDmMv3OO3ARgMCraj-5x5A==", "AtomicRelationType": "xAttr", "AtomicInference": "quick"}, "premise": "PersonX hits the brakes", "hypothesis": "As a result, PersonX feels quick", "update": "PersonX has to slow down to stay under the speed limit.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7019", "update_paraphrase": "PersonX needs to drive more slowly so that they don't exceed the speed limit.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.36714285714285716, "pred_conf_shift": 0.002102278172969818, "syntactic_distance": 0.1875}, {"confidence": [0.9721457362174988, 0.027854254469275475], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7019.gpt3.4", "original_example": {"example_id": "atomic.train.7019", "premise_hypothesis_id": "atomic.train.3315", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "d-GEsVTFv8xNXe-k-V11kQ==", "AtomicEventRelationId": "xDmMv3OO3ARgMCraj-5x5A==", "AtomicRelationType": "xAttr", "AtomicInference": "quick"}, "premise": "PersonX hits the brakes", "hypothesis": "As a result, PersonX feels quick", "update": "PersonX has to slow down to stay under the speed limit.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7019", "update_paraphrase": "To avoid getting a ticket, PersonX has to drive more slowly than the posted speed limit.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3981481481481482, "pred_conf_shift": 0.0029019415378570557, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.9771282076835632, 0.022871803492307663], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7019.gpt3.1", "original_example": {"example_id": "atomic.train.7019", "premise_hypothesis_id": "atomic.train.3315", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "d-GEsVTFv8xNXe-k-V11kQ==", "AtomicEventRelationId": "xDmMv3OO3ARgMCraj-5x5A==", "AtomicRelationType": "xAttr", "AtomicInference": "quick"}, "premise": "PersonX hits the brakes", "hypothesis": "As a result, PersonX feels quick", "update": "PersonX has to slow down to stay under the speed limit.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7019", "update_paraphrase": "PersonX must drive more slowly in order to stay within the speed limit.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.32619047619047614, "pred_conf_shift": -0.002080509439110756, "syntactic_distance": 0.4444444444444444}, {"confidence": [0.9794133901596069, 0.020586464554071426], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7019.gpt3.0", "original_example": {"example_id": "atomic.train.7019", "premise_hypothesis_id": "atomic.train.3315", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "d-GEsVTFv8xNXe-k-V11kQ==", "AtomicEventRelationId": "xDmMv3OO3ARgMCraj-5x5A==", "AtomicRelationType": "xAttr", "AtomicInference": "quick"}, "premise": "PersonX hits the brakes", "hypothesis": "As a result, PersonX feels quick", "update": "PersonX has to slow down to stay under the speed limit.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7019", "update_paraphrase": "PersonX needs to drive more slowly to stay below the speed limit.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2596618357487923, "pred_conf_shift": -0.0043658483773469925, "syntactic_distance": 0.0}, {"confidence": [0.9840404987335205, 0.01595950685441494], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7019.gpt3.8", "original_example": {"example_id": "atomic.train.7019", "premise_hypothesis_id": "atomic.train.3315", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "d-GEsVTFv8xNXe-k-V11kQ==", "AtomicEventRelationId": "xDmMv3OO3ARgMCraj-5x5A==", "AtomicRelationType": "xAttr", "AtomicInference": "quick"}, "premise": "PersonX hits the brakes", "hypothesis": "As a result, PersonX feels quick", "update": "PersonX has to slow down to stay under the speed limit.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7019", "update_paraphrase": "PersonX drives more slowly in order to remain under the speed limit.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3189892233370494, "pred_conf_shift": -0.008992806077003479, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.9712856411933899, 0.028714444488286972], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7019.gpt3.7", "original_example": {"example_id": "atomic.train.7019", "premise_hypothesis_id": "atomic.train.3315", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "d-GEsVTFv8xNXe-k-V11kQ==", "AtomicEventRelationId": "xDmMv3OO3ARgMCraj-5x5A==", "AtomicRelationType": "xAttr", "AtomicInference": "quick"}, "premise": "PersonX hits the brakes", "hypothesis": "As a result, PersonX feels quick", "update": "PersonX has to slow down to stay under the speed limit.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7019", "update_paraphrase": "To stay within the law, PersonX has to drive more slowly.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45328282828282823, "pred_conf_shift": 0.003762131556868553, "syntactic_distance": 0.3333333333333333}]}, "atomic.train.20057": {"original_confidence": [0.9478839635848999, 0.05211600288748741], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.7081620693206787, 0.2918379306793213], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.20057.gpt3.4", "original_example": {"example_id": "atomic.train.20057", "premise_hypothesis_id": "atomic.train.9289", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "R-GAd44NpYHkCm2bw0t1sA==", "AtomicEventRelationId": "TbtElIBwjEmlKRksn7aWkQ==", "AtomicRelationType": "xEffect", "AtomicInference": "went to home"}, "premise": "PersonX does n't say anything", "hypothesis": "PersonX then went to home", "update": "PersonX is being stared at", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20057", "update_paraphrase": "PersonX is receiving stares from others.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4239472648563558, "pred_conf_shift": 0.23972192779183388, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.952700674533844, 0.047299426048994064], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.20057.gpt3.5", "original_example": {"example_id": "atomic.train.20057", "premise_hypothesis_id": "atomic.train.9289", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "R-GAd44NpYHkCm2bw0t1sA==", "AtomicEventRelationId": "TbtElIBwjEmlKRksn7aWkQ==", "AtomicRelationType": "xEffect", "AtomicInference": "went to home"}, "premise": "PersonX does n't say anything", "hypothesis": "PersonX then went to home", "update": "PersonX is being stared at", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20057", "update_paraphrase": "Someone is looking at PersonX with intense focus.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.481825866441251, "pred_conf_shift": -0.004816576838493347, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.9722335934638977, 0.02776632271707058], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.20057.gpt3.3", "original_example": {"example_id": "atomic.train.20057", "premise_hypothesis_id": "atomic.train.9289", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "R-GAd44NpYHkCm2bw0t1sA==", "AtomicEventRelationId": "TbtElIBwjEmlKRksn7aWkQ==", "AtomicRelationType": "xEffect", "AtomicInference": "went to home"}, "premise": "PersonX does n't say anything", "hypothesis": "PersonX then went to home", "update": "PersonX is being stared at", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20057", "update_paraphrase": "PersonX has someone's undivided attention.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5687645687645687, "pred_conf_shift": -0.024349680170416832, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.9544891119003296, 0.0455109067261219], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.20057.gpt3.2", "original_example": {"example_id": "atomic.train.20057", "premise_hypothesis_id": "atomic.train.9289", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "R-GAd44NpYHkCm2bw0t1sA==", "AtomicEventRelationId": "TbtElIBwjEmlKRksn7aWkQ==", "AtomicRelationType": "xEffect", "AtomicInference": "went to home"}, "premise": "PersonX does n't say anything", "hypothesis": "PersonX then went to home", "update": "PersonX is being stared at", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20057", "update_paraphrase": "PersonX is being stared at by someone.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.16666666666666663, "pred_conf_shift": -0.006605096161365509, "syntactic_distance": 0.0}, {"confidence": [0.9416524767875671, 0.058347463607788086], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.20057.gpt3.0", "original_example": {"example_id": "atomic.train.20057", "premise_hypothesis_id": "atomic.train.9289", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "R-GAd44NpYHkCm2bw0t1sA==", "AtomicEventRelationId": "TbtElIBwjEmlKRksn7aWkQ==", "AtomicRelationType": "xEffect", "AtomicInference": "went to home"}, "premise": "PersonX does n't say anything", "hypothesis": "PersonX then went to home", "update": "PersonX is being stared at", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20057", "update_paraphrase": "Person X is the center of attention and everyone is staring at them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5592185592185592, "pred_conf_shift": 0.0062314607203006744, "syntactic_distance": 0.43478260869565216}, {"confidence": [0.949072539806366, 0.050927478820085526], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.20057.gpt3.1", "original_example": {"example_id": "atomic.train.20057", "premise_hypothesis_id": "atomic.train.9289", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "R-GAd44NpYHkCm2bw0t1sA==", "AtomicEventRelationId": "TbtElIBwjEmlKRksn7aWkQ==", "AtomicRelationType": "xEffect", "AtomicInference": "went to home"}, "premise": "PersonX does n't say anything", "hypothesis": "PersonX then went to home", "update": "PersonX is being stared at", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20057", "update_paraphrase": "PersonX is being watched intensely.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3038888888888889, "pred_conf_shift": -0.001188524067401886, "syntactic_distance": 0.0}, {"confidence": [0.9369429349899292, 0.06305702775716782], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.20057.gpt3.6", "original_example": {"example_id": "atomic.train.20057", "premise_hypothesis_id": "atomic.train.9289", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "R-GAd44NpYHkCm2bw0t1sA==", "AtomicEventRelationId": "TbtElIBwjEmlKRksn7aWkQ==", "AtomicRelationType": "xEffect", "AtomicInference": "went to home"}, "premise": "PersonX does n't say anything", "hypothesis": "PersonX then went to home", "update": "PersonX is being stared at", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20057", "update_paraphrase": "There is someone staring at PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3338631065903794, "pred_conf_shift": 0.010941024869680405, "syntactic_distance": 0.1875}]}, "atomic.train.27805": {"original_confidence": [0.5014522671699524, 0.4985477030277252], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.04329126328229904, 0.9567089080810547], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.27805.gpt3.5", "original_example": {"example_id": "atomic.train.27805", "premise_hypothesis_id": "atomic.train.12645", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2Llu--6K2DWpxaZg2hZIqw==", "AtomicEventRelationId": "WJ8pBEE_Sd8Lnn1jAe-r-Q==", "AtomicRelationType": "xAttr", "AtomicInference": "helpful"}, "premise": "PersonX puts PersonY in possession", "hypothesis": "As a result, PersonX feels helpful", "update": "PersonX put PersonY in possession of a car.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27805", "update_paraphrase": "PersonX gave PersonY a car.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37362637362637363, "pred_conf_shift": 0.45816120505332947, "syntactic_distance": 0.15}, {"confidence": [0.038264282047748566, 0.9617356657981873], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.27805.gpt3.4", "original_example": {"example_id": "atomic.train.27805", "premise_hypothesis_id": "atomic.train.12645", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2Llu--6K2DWpxaZg2hZIqw==", "AtomicEventRelationId": "WJ8pBEE_Sd8Lnn1jAe-r-Q==", "AtomicRelationType": "xAttr", "AtomicInference": "helpful"}, "premise": "PersonX puts PersonY in possession", "hypothesis": "As a result, PersonX feels helpful", "update": "PersonX put PersonY in possession of a car.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27805", "update_paraphrase": "PersonX handed PersonY the keys to a car.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3709733893557423, "pred_conf_shift": 0.46318796277046204, "syntactic_distance": 0.2}, {"confidence": [0.03972269967198372, 0.960277259349823], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.27805.gpt3.0", "original_example": {"example_id": "atomic.train.27805", "premise_hypothesis_id": "atomic.train.12645", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2Llu--6K2DWpxaZg2hZIqw==", "AtomicEventRelationId": "WJ8pBEE_Sd8Lnn1jAe-r-Q==", "AtomicRelationType": "xAttr", "AtomicInference": "helpful"}, "premise": "PersonX puts PersonY in possession", "hypothesis": "As a result, PersonX feels helpful", "update": "PersonX put PersonY in possession of a car.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27805", "update_paraphrase": "PersonX gave PersonY a car to use.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3718954248366013, "pred_conf_shift": 0.4617295563220978, "syntactic_distance": 0.15}, {"confidence": [0.06324239820241928, 0.9367576241493225], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.27805.gpt3.3", "original_example": {"example_id": "atomic.train.27805", "premise_hypothesis_id": "atomic.train.12645", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2Llu--6K2DWpxaZg2hZIqw==", "AtomicEventRelationId": "WJ8pBEE_Sd8Lnn1jAe-r-Q==", "AtomicRelationType": "xAttr", "AtomicInference": "helpful"}, "premise": "PersonX puts PersonY in possession", "hypothesis": "As a result, PersonX feels helpful", "update": "PersonX put PersonY in possession of a car.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27805", "update_paraphrase": "PersonX handed over a car to PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3682539682539683, "pred_conf_shift": 0.4382099211215973, "syntactic_distance": 0.13043478260869565}, {"confidence": [0.05636471137404442, 0.9436352252960205], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.27805.gpt3.1", "original_example": {"example_id": "atomic.train.27805", "premise_hypothesis_id": "atomic.train.12645", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2Llu--6K2DWpxaZg2hZIqw==", "AtomicEventRelationId": "WJ8pBEE_Sd8Lnn1jAe-r-Q==", "AtomicRelationType": "xAttr", "AtomicInference": "helpful"}, "premise": "PersonX puts PersonY in possession", "hypothesis": "As a result, PersonX feels helpful", "update": "PersonX put PersonY in possession of a car.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27805", "update_paraphrase": "PersonX tells PersonY that the car is now theirs.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5182072829131652, "pred_conf_shift": 0.4450875222682953, "syntactic_distance": 0.15}, {"confidence": [0.07232582569122314, 0.9276741743087769], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.27805.gpt3.6", "original_example": {"example_id": "atomic.train.27805", "premise_hypothesis_id": "atomic.train.12645", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2Llu--6K2DWpxaZg2hZIqw==", "AtomicEventRelationId": "WJ8pBEE_Sd8Lnn1jAe-r-Q==", "AtomicRelationType": "xAttr", "AtomicInference": "helpful"}, "premise": "PersonX puts PersonY in possession", "hypothesis": "As a result, PersonX feels helpful", "update": "PersonX put PersonY in possession of a car.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27805", "update_paraphrase": "PersonX gave PersonY a car to keep.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3750700280112045, "pred_conf_shift": 0.42912647128105164, "syntactic_distance": 0.15}, {"confidence": [0.034332867711782455, 0.9656670093536377], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.27805.gpt3.2", "original_example": {"example_id": "atomic.train.27805", "premise_hypothesis_id": "atomic.train.12645", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2Llu--6K2DWpxaZg2hZIqw==", "AtomicEventRelationId": "WJ8pBEE_Sd8Lnn1jAe-r-Q==", "AtomicRelationType": "xAttr", "AtomicInference": "helpful"}, "premise": "PersonX puts PersonY in possession", "hypothesis": "As a result, PersonX feels helpful", "update": "PersonX put PersonY in possession of a car.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27805", "update_paraphrase": "PersonX gave PersonY a car to drive.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3750700280112045, "pred_conf_shift": 0.4671193063259125, "syntactic_distance": 0.15}]}, "atomic.train.27011": {"original_confidence": [0.628606915473938, 0.371393084526062], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.5602490901947021, 0.4397510290145874], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.27011.gpt3.0", "original_example": {"example_id": "atomic.train.27011", "premise_hypothesis_id": "atomic.train.12291", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "34sXhxEK7hprKxok_Cm_LQ==", "AtomicEventRelationId": "_mDz2Gx36d8W2Pcu_VNZvw==", "AtomicRelationType": "xNeed", "AtomicInference": "to find out she is pregnant"}, "premise": "PersonX tells PersonY was pregnant", "hypothesis": "Before, PersonX needed to find out she is pregnant", "update": "PersonX just came out of the bathroom", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27011", "update_paraphrase": "PersonX has just come out of the bathroom", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.13666666666666666, "pred_conf_shift": 0.06835794448852539, "syntactic_distance": 0.25}, {"confidence": [0.6415460109710693, 0.3584538996219635], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.27011.gpt3.3", "original_example": {"example_id": "atomic.train.27011", "premise_hypothesis_id": "atomic.train.12291", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "34sXhxEK7hprKxok_Cm_LQ==", "AtomicEventRelationId": "_mDz2Gx36d8W2Pcu_VNZvw==", "AtomicRelationType": "xNeed", "AtomicInference": "to find out she is pregnant"}, "premise": "PersonX tells PersonY was pregnant", "hypothesis": "Before, PersonX needed to find out she is pregnant", "update": "PersonX just came out of the bathroom", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27011", "update_paraphrase": "PersonX just left the bathroom", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.287037037037037, "pred_conf_shift": -0.01293918490409851, "syntactic_distance": 0.15}, {"confidence": [0.7907459139823914, 0.20925414562225342], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.27011.gpt3.1", "original_example": {"example_id": "atomic.train.27011", "premise_hypothesis_id": "atomic.train.12291", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "34sXhxEK7hprKxok_Cm_LQ==", "AtomicEventRelationId": "_mDz2Gx36d8W2Pcu_VNZvw==", "AtomicRelationType": "xNeed", "AtomicInference": "to find out she is pregnant"}, "premise": "PersonX tells PersonY was pregnant", "hypothesis": "Before, PersonX needed to find out she is pregnant", "update": "PersonX just came out of the bathroom", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27011", "update_paraphrase": "PersonX had just finished using the restroom.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.44447278911564625, "pred_conf_shift": -0.1621389389038086, "syntactic_distance": 0.35}, {"confidence": [0.6133548617362976, 0.3866450786590576], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.27011.gpt3.2", "original_example": {"example_id": "atomic.train.27011", "premise_hypothesis_id": "atomic.train.12291", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "34sXhxEK7hprKxok_Cm_LQ==", "AtomicEventRelationId": "_mDz2Gx36d8W2Pcu_VNZvw==", "AtomicRelationType": "xNeed", "AtomicInference": "to find out she is pregnant"}, "premise": "PersonX tells PersonY was pregnant", "hypothesis": "Before, PersonX needed to find out she is pregnant", "update": "PersonX just came out of the bathroom", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27011", "update_paraphrase": "PersonX just exited/left the bathroom", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.300925925925926, "pred_conf_shift": 0.015251994132995605, "syntactic_distance": 0.15}, {"confidence": [0.5617357492446899, 0.4382643699645996], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.27011.gpt3.6", "original_example": {"example_id": "atomic.train.27011", "premise_hypothesis_id": "atomic.train.12291", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "34sXhxEK7hprKxok_Cm_LQ==", "AtomicEventRelationId": "_mDz2Gx36d8W2Pcu_VNZvw==", "AtomicRelationType": "xNeed", "AtomicInference": "to find out she is pregnant"}, "premise": "PersonX tells PersonY was pregnant", "hypothesis": "Before, PersonX needed to find out she is pregnant", "update": "PersonX just came out of the bathroom", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27011", "update_paraphrase": "PersonX exited the bathroom not long ago.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.43644609358895076, "pred_conf_shift": 0.0668712854385376, "syntactic_distance": 0.4090909090909091}, {"confidence": [0.8365694880485535, 0.16343054175376892], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.27011.gpt3.4", "original_example": {"example_id": "atomic.train.27011", "premise_hypothesis_id": "atomic.train.12291", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "34sXhxEK7hprKxok_Cm_LQ==", "AtomicEventRelationId": "_mDz2Gx36d8W2Pcu_VNZvw==", "AtomicRelationType": "xNeed", "AtomicInference": "to find out she is pregnant"}, "premise": "PersonX tells PersonY was pregnant", "hypothesis": "Before, PersonX needed to find out she is pregnant", "update": "PersonX just came out of the bathroom", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27011", "update_paraphrase": "PersonX just finished using the bathroom.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2920579420579421, "pred_conf_shift": -0.2079625427722931, "syntactic_distance": 0.21052631578947367}]}, "atomic.train.3804": {"original_confidence": [0.029646486043930054, 0.9703535437583923], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.032066717743873596, 0.967933177947998], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3804.gpt3.4", "original_example": {"example_id": "atomic.train.3804", "premise_hypothesis_id": "atomic.train.1788", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZXl1vtnpWMTbfB2lyGjyTg==", "AtomicEventRelationId": "PA3T9-dYkxvkPT_5NhE0tw==", "AtomicRelationType": "xAttr", "AtomicInference": "a spendthrift"}, "premise": "PersonX takes PersonX's allowance", "hypothesis": "As a result, PersonX feels a spendthrift", "update": "PersonX then drives to the mall.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3804", "update_paraphrase": "After that, PersonX drives to the mall.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1923076923076923, "pred_conf_shift": 0.0024202316999435425, "syntactic_distance": 0.3684210526315789}, {"confidence": [0.02309182472527027, 0.9769082069396973], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3804.gpt3.6", "original_example": {"example_id": "atomic.train.3804", "premise_hypothesis_id": "atomic.train.1788", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZXl1vtnpWMTbfB2lyGjyTg==", "AtomicEventRelationId": "PA3T9-dYkxvkPT_5NhE0tw==", "AtomicRelationType": "xAttr", "AtomicInference": "a spendthrift"}, "premise": "PersonX takes PersonX's allowance", "hypothesis": "As a result, PersonX feels a spendthrift", "update": "PersonX then drives to the mall.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3804", "update_paraphrase": "Subsequently, PersonX drives to the mall.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.14583333333333331, "pred_conf_shift": -0.006554661318659782, "syntactic_distance": 0.2}, {"confidence": [0.02227966859936714, 0.9777202606201172], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3804.gpt3.2", "original_example": {"example_id": "atomic.train.3804", "premise_hypothesis_id": "atomic.train.1788", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZXl1vtnpWMTbfB2lyGjyTg==", "AtomicEventRelationId": "PA3T9-dYkxvkPT_5NhE0tw==", "AtomicRelationType": "xAttr", "AtomicInference": "a spendthrift"}, "premise": "PersonX takes PersonX's allowance", "hypothesis": "As a result, PersonX feels a spendthrift", "update": "PersonX then drives to the mall.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3804", "update_paraphrase": "PersonX then heads to the mall.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.11072261072261075, "pred_conf_shift": -0.007366817444562912, "syntactic_distance": 0.0}, {"confidence": [0.023678485304117203, 0.9763215780258179], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3804.gpt3.1", "original_example": {"example_id": "atomic.train.3804", "premise_hypothesis_id": "atomic.train.1788", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZXl1vtnpWMTbfB2lyGjyTg==", "AtomicEventRelationId": "PA3T9-dYkxvkPT_5NhE0tw==", "AtomicRelationType": "xAttr", "AtomicInference": "a spendthrift"}, "premise": "PersonX takes PersonX's allowance", "hypothesis": "As a result, PersonX feels a spendthrift", "update": "PersonX then drives to the mall.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3804", "update_paraphrase": "Subsequently, PersonX drives to the shopping center.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3442307692307692, "pred_conf_shift": -0.005968000739812851, "syntactic_distance": 0.2}, {"confidence": [0.02286442555487156, 0.9771355390548706], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3804.gpt3.3", "original_example": {"example_id": "atomic.train.3804", "premise_hypothesis_id": "atomic.train.1788", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZXl1vtnpWMTbfB2lyGjyTg==", "AtomicEventRelationId": "PA3T9-dYkxvkPT_5NhE0tw==", "AtomicRelationType": "xAttr", "AtomicInference": "a spendthrift"}, "premise": "PersonX takes PersonX's allowance", "hypothesis": "As a result, PersonX feels a spendthrift", "update": "PersonX then drives to the mall.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3804", "update_paraphrase": "PersonX gets in the car and heads to the mall.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3451298701298701, "pred_conf_shift": -0.006782060489058495, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.11157303303480148, 0.8884270787239075], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3804.gpt3.0", "original_example": {"example_id": "atomic.train.3804", "premise_hypothesis_id": "atomic.train.1788", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZXl1vtnpWMTbfB2lyGjyTg==", "AtomicEventRelationId": "PA3T9-dYkxvkPT_5NhE0tw==", "AtomicRelationType": "xAttr", "AtomicInference": "a spendthrift"}, "premise": "PersonX takes PersonX's allowance", "hypothesis": "As a result, PersonX feels a spendthrift", "update": "PersonX then drives to the mall.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3804", "update_paraphrase": "After that, PersonX gets behind the wheel and drives to the mall.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3492063492063492, "pred_conf_shift": 0.08192654699087143, "syntactic_distance": 0.45}, {"confidence": [0.025345060974359512, 0.9746549129486084], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3804.gpt3.5", "original_example": {"example_id": "atomic.train.3804", "premise_hypothesis_id": "atomic.train.1788", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZXl1vtnpWMTbfB2lyGjyTg==", "AtomicEventRelationId": "PA3T9-dYkxvkPT_5NhE0tw==", "AtomicRelationType": "xAttr", "AtomicInference": "a spendthrift"}, "premise": "PersonX takes PersonX's allowance", "hypothesis": "As a result, PersonX feels a spendthrift", "update": "PersonX then drives to the mall.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3804", "update_paraphrase": "After that, PersonX heads to the mall.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.283993783993784, "pred_conf_shift": -0.004301425069570541, "syntactic_distance": 0.3684210526315789}]}, "atomic.train.31354": {"original_confidence": [0.3099001944065094, 0.690099835395813], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.12801586091518402, 0.8719842433929443], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31354.gpt3.3", "original_example": {"example_id": "atomic.train.31354", "premise_hypothesis_id": "atomic.train.14242", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "AVUu0EAQh7zsqRhzPsMQKg==", "AtomicEventRelationId": "lh6B6MVW9mzrEbuiGR2QZQ==", "AtomicRelationType": "xEffect", "AtomicInference": "They do math problems"}, "premise": "PersonX loves math", "hypothesis": "Then, they do math problems", "update": "They're still thinking about math while leaving math class to go to English.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31354", "update_paraphrase": "Even though they're leaving math class to go to English, they can't stop thinking about math.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3062944718117132, "pred_conf_shift": -0.18188433349132538, "syntactic_distance": 0.4444444444444444}, {"confidence": [0.17604976892471313, 0.8239502906799316], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31354.gpt3.0", "original_example": {"example_id": "atomic.train.31354", "premise_hypothesis_id": "atomic.train.14242", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "AVUu0EAQh7zsqRhzPsMQKg==", "AtomicEventRelationId": "lh6B6MVW9mzrEbuiGR2QZQ==", "AtomicRelationType": "xEffect", "AtomicInference": "They do math problems"}, "premise": "PersonX loves math", "hypothesis": "Then, they do math problems", "update": "They're still thinking about math while leaving math class to go to English.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31354", "update_paraphrase": "They're still thinking about math while they're walking out of math class to go to English.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1182266009852217, "pred_conf_shift": -0.13385042548179626, "syntactic_distance": 0.0}, {"confidence": [0.08054033666849136, 0.9194596409797668], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31354.gpt3.4", "original_example": {"example_id": "atomic.train.31354", "premise_hypothesis_id": "atomic.train.14242", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "AVUu0EAQh7zsqRhzPsMQKg==", "AtomicEventRelationId": "lh6B6MVW9mzrEbuiGR2QZQ==", "AtomicRelationType": "xEffect", "AtomicInference": "They do math problems"}, "premise": "PersonX loves math", "hypothesis": "Then, they do math problems", "update": "They're still thinking about math while leaving math class to go to English.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31354", "update_paraphrase": "On their way to English class, they're still thinking about math.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.40856481481481477, "pred_conf_shift": -0.22935985773801804, "syntactic_distance": 0.23076923076923078}, {"confidence": [0.1790374368429184, 0.8209626078605652], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31354.gpt3.2", "original_example": {"example_id": "atomic.train.31354", "premise_hypothesis_id": "atomic.train.14242", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "AVUu0EAQh7zsqRhzPsMQKg==", "AtomicEventRelationId": "lh6B6MVW9mzrEbuiGR2QZQ==", "AtomicRelationType": "xEffect", "AtomicInference": "They do math problems"}, "premise": "PersonX loves math", "hypothesis": "Then, they do math problems", "update": "They're still thinking about math while leaving math class to go to English.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31354", "update_paraphrase": "Even though they're now leaving math class to go to English, they're still thinking about math.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28130317957904166, "pred_conf_shift": -0.130862757563591, "syntactic_distance": 0.32142857142857145}, {"confidence": [0.06390015780925751, 0.9360998272895813], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31354.gpt3.6", "original_example": {"example_id": "atomic.train.31354", "premise_hypothesis_id": "atomic.train.14242", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "AVUu0EAQh7zsqRhzPsMQKg==", "AtomicEventRelationId": "lh6B6MVW9mzrEbuiGR2QZQ==", "AtomicRelationType": "xEffect", "AtomicInference": "They do math problems"}, "premise": "PersonX loves math", "hypothesis": "Then, they do math problems", "update": "They're still thinking about math while leaving math class to go to English.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31354", "update_paraphrase": "Even though they're no longer in math class, they're still thinking about the math concepts they learned.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4574107374107374, "pred_conf_shift": -0.2460000365972519, "syntactic_distance": 0.32142857142857145}, {"confidence": [0.3099001944065094, 0.690099835395813], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31354.gpt3.5", "original_example": {"example_id": "atomic.train.31354", "premise_hypothesis_id": "atomic.train.14242", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "AVUu0EAQh7zsqRhzPsMQKg==", "AtomicEventRelationId": "lh6B6MVW9mzrEbuiGR2QZQ==", "AtomicRelationType": "xEffect", "AtomicInference": "They do math problems"}, "premise": "PersonX loves math", "hypothesis": "Then, they do math problems", "update": "They're still thinking about math while leaving math class to go to English.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31354", "update_paraphrase": "They're still thinking about math while leaving math class to go to English.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": 0.0, "syntactic_distance": 0.0}, {"confidence": [0.21973487734794617, 0.7802650928497314], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31354.gpt3.1", "original_example": {"example_id": "atomic.train.31354", "premise_hypothesis_id": "atomic.train.14242", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "AVUu0EAQh7zsqRhzPsMQKg==", "AtomicEventRelationId": "lh6B6MVW9mzrEbuiGR2QZQ==", "AtomicRelationType": "xEffect", "AtomicInference": "They do math problems"}, "premise": "PersonX loves math", "hypothesis": "Then, they do math problems", "update": "They're still thinking about math while leaving math class to go to English.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31354", "update_paraphrase": "Even though they're leaving math class to go to English, they're still thinking about math.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2645640074211503, "pred_conf_shift": -0.09016531705856323, "syntactic_distance": 0.32142857142857145}]}, "atomic.train.26896": {"original_confidence": [0.22713586688041687, 0.772864043712616], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.42706620693206787, 0.5729339122772217], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.26896.gpt3.2", "original_example": {"example_id": "atomic.train.26896", "premise_hypothesis_id": "atomic.train.12247", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "YFpYHBYUdgizDVs2SbHF2A==", "AtomicEventRelationId": "ztYAdYaj5LOiiBwItkLGJA==", "AtomicRelationType": "xReact", "AtomicInference": "depressed"}, "premise": "PersonX loses contact", "hypothesis": "PersonX is seen as depressed", "update": "The other person was toxic", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26896", "update_paraphrase": "The other person was toxic and harmful to be around.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33333333333333337, "pred_conf_shift": 0.199930340051651, "syntactic_distance": 0.10526315789473684}, {"confidence": [0.5874546766281128, 0.4125453233718872], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.26896.gpt3.0", "original_example": {"example_id": "atomic.train.26896", "premise_hypothesis_id": "atomic.train.12247", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "YFpYHBYUdgizDVs2SbHF2A==", "AtomicEventRelationId": "ztYAdYaj5LOiiBwItkLGJA==", "AtomicRelationType": "xReact", "AtomicInference": "depressed"}, "premise": "PersonX loses contact", "hypothesis": "PersonX is seen as depressed", "update": "The other person was toxic", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26896", "update_paraphrase": "The other person was poisonous and harmful.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2928571428571428, "pred_conf_shift": 0.3603188097476959, "syntactic_distance": 0.1}, {"confidence": [0.19367893040180206, 0.8063210248947144], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.26896.gpt3.6", "original_example": {"example_id": "atomic.train.26896", "premise_hypothesis_id": "atomic.train.12247", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "YFpYHBYUdgizDVs2SbHF2A==", "AtomicEventRelationId": "ztYAdYaj5LOiiBwItkLGJA==", "AtomicRelationType": "xReact", "AtomicInference": "depressed"}, "premise": "PersonX loses contact", "hypothesis": "PersonX is seen as depressed", "update": "The other person was toxic", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26896", "update_paraphrase": "The other person was harmful and destructive.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28869047619047616, "pred_conf_shift": -0.03345693647861481, "syntactic_distance": 0.1}, {"confidence": [0.23136462271213531, 0.7686353921890259], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.26896.gpt3.1", "original_example": {"example_id": "atomic.train.26896", "premise_hypothesis_id": "atomic.train.12247", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "YFpYHBYUdgizDVs2SbHF2A==", "AtomicEventRelationId": "ztYAdYaj5LOiiBwItkLGJA==", "AtomicRelationType": "xReact", "AtomicInference": "depressed"}, "premise": "PersonX loses contact", "hypothesis": "PersonX is seen as depressed", "update": "The other person was toxic", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26896", "update_paraphrase": "The other person was very harmful and destructive.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3434065934065934, "pred_conf_shift": 0.004228755831718445, "syntactic_distance": 0.14285714285714285}]}, "atomic.train.8619": {"original_confidence": [0.8117088675498962, 0.18829114735126495], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.6180676817893982, 0.38193225860595703], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8619.gpt3.6", "original_example": {"example_id": "atomic.train.8619", "premise_hypothesis_id": "atomic.train.4065", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "K-xNZDGOeiOnwpypzeADow==", "AtomicEventRelationId": "9Gx0f5QMZ4GNWfoGPZ8x2Q==", "AtomicRelationType": "xReact", "AtomicInference": "accomplished"}, "premise": "PersonX makes a candle", "hypothesis": "PersonX is seen as accomplished", "update": "The candle sells for 20 dollars", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8619", "update_paraphrase": "The price of the candle is twenty dollars.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4306122448979592, "pred_conf_shift": 0.19364111125469208, "syntactic_distance": 0.3181818181818182}, {"confidence": [0.8478007912635803, 0.15219910442829132], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8619.gpt3.3", "original_example": {"example_id": "atomic.train.8619", "premise_hypothesis_id": "atomic.train.4065", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "K-xNZDGOeiOnwpypzeADow==", "AtomicEventRelationId": "9Gx0f5QMZ4GNWfoGPZ8x2Q==", "AtomicRelationType": "xReact", "AtomicInference": "accomplished"}, "premise": "PersonX makes a candle", "hypothesis": "PersonX is seen as accomplished", "update": "The candle sells for 20 dollars", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8619", "update_paraphrase": "The candle costs 20 dollars.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.21363636363636362, "pred_conf_shift": -0.03609204292297363, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.8773560523986816, 0.12264394015073776], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8619.gpt3.4", "original_example": {"example_id": "atomic.train.8619", "premise_hypothesis_id": "atomic.train.4065", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "K-xNZDGOeiOnwpypzeADow==", "AtomicEventRelationId": "9Gx0f5QMZ4GNWfoGPZ8x2Q==", "AtomicRelationType": "xReact", "AtomicInference": "accomplished"}, "premise": "PersonX makes a candle", "hypothesis": "PersonX is seen as accomplished", "update": "The candle sells for 20 dollars", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8619", "update_paraphrase": "The candle is priced at 20 dollars.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.30921855921855923, "pred_conf_shift": -0.06564720720052719, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.8774300813674927, 0.12256992608308792], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8619.gpt3.2", "original_example": {"example_id": "atomic.train.8619", "premise_hypothesis_id": "atomic.train.4065", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "K-xNZDGOeiOnwpypzeADow==", "AtomicEventRelationId": "9Gx0f5QMZ4GNWfoGPZ8x2Q==", "AtomicRelationType": "xReact", "AtomicInference": "accomplished"}, "premise": "PersonX makes a candle", "hypothesis": "PersonX is seen as accomplished", "update": "The candle sells for 20 dollars", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8619", "update_paraphrase": "The candle retails at 20 dollars.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2708333333333333, "pred_conf_shift": -0.06572122126817703, "syntactic_distance": 0.0}, {"confidence": [0.698701024055481, 0.30129891633987427], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8619.gpt3.0", "original_example": {"example_id": "atomic.train.8619", "premise_hypothesis_id": "atomic.train.4065", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "K-xNZDGOeiOnwpypzeADow==", "AtomicEventRelationId": "9Gx0f5QMZ4GNWfoGPZ8x2Q==", "AtomicRelationType": "xReact", "AtomicInference": "accomplished"}, "premise": "PersonX makes a candle", "hypothesis": "PersonX is seen as accomplished", "update": "The candle sells for 20 dollars", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8619", "update_paraphrase": "The price of the candle is 20 dollars.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2877551020408164, "pred_conf_shift": 0.11300776898860931, "syntactic_distance": 0.3181818181818182}, {"confidence": [0.9100831747055054, 0.08991667628288269], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8619.gpt3.7", "original_example": {"example_id": "atomic.train.8619", "premise_hypothesis_id": "atomic.train.4065", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "K-xNZDGOeiOnwpypzeADow==", "AtomicEventRelationId": "9Gx0f5QMZ4GNWfoGPZ8x2Q==", "AtomicRelationType": "xReact", "AtomicInference": "accomplished"}, "premise": "PersonX makes a candle", "hypothesis": "PersonX is seen as accomplished", "update": "The candle sells for 20 dollars", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8619", "update_paraphrase": "The candle is being sold for 20 dollars.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2361111111111111, "pred_conf_shift": -0.09837447106838226, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.812174379825592, 0.18782564997673035], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8619.gpt3.5", "original_example": {"example_id": "atomic.train.8619", "premise_hypothesis_id": "atomic.train.4065", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "K-xNZDGOeiOnwpypzeADow==", "AtomicEventRelationId": "9Gx0f5QMZ4GNWfoGPZ8x2Q==", "AtomicRelationType": "xReact", "AtomicInference": "accomplished"}, "premise": "PersonX makes a candle", "hypothesis": "PersonX is seen as accomplished", "update": "The candle sells for 20 dollars", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8619", "update_paraphrase": "The 20 dollar candle is for sale.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33436648821264203, "pred_conf_shift": -0.00046549737453460693, "syntactic_distance": 0.14285714285714285}, {"confidence": [0.6411368250846863, 0.3588632643222809], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8619.gpt3.1", "original_example": {"example_id": "atomic.train.8619", "premise_hypothesis_id": "atomic.train.4065", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "K-xNZDGOeiOnwpypzeADow==", "AtomicEventRelationId": "9Gx0f5QMZ4GNWfoGPZ8x2Q==", "AtomicRelationType": "xReact", "AtomicInference": "accomplished"}, "premise": "PersonX makes a candle", "hypothesis": "PersonX is seen as accomplished", "update": "The candle sells for 20 dollars", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8619", "update_paraphrase": "The cost of the candle is 20 dollars.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2877551020408164, "pred_conf_shift": 0.17057211697101593, "syntactic_distance": 0.3181818181818182}]}, "atomic.train.32501": {"original_confidence": [0.5703101754188538, 0.42968982458114624], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.3896622657775879, 0.6103377938270569], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.32501.gpt3.1", "original_example": {"example_id": "atomic.train.32501", "premise_hypothesis_id": "atomic.train.14755", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "WsQxgdNQap7vzpqZ3wFhBQ==", "AtomicEventRelationId": "iraxPuBXrIgVCeySvwhKTw==", "AtomicRelationType": "xIntent", "AtomicInference": "to harm another"}, "premise": "PersonX pricks PersonX's finger", "hypothesis": "Because PersonX wanted to harm another", "update": "PersonX is emo", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32501", "update_paraphrase": "PersonX is very emotional.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.30357142857142855, "pred_conf_shift": 0.18064796924591064, "syntactic_distance": 0.06666666666666667}, {"confidence": [0.1203218325972557, 0.8796783089637756], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.32501.gpt3.6", "original_example": {"example_id": "atomic.train.32501", "premise_hypothesis_id": "atomic.train.14755", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "WsQxgdNQap7vzpqZ3wFhBQ==", "AtomicEventRelationId": "iraxPuBXrIgVCeySvwhKTw==", "AtomicRelationType": "xIntent", "AtomicInference": "to harm another"}, "premise": "PersonX pricks PersonX's finger", "hypothesis": "Because PersonX wanted to harm another", "update": "PersonX is emo", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32501", "update_paraphrase": "PersonX is extremely emotional and tends to wear dark, depressing clothing.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6449579831932772, "pred_conf_shift": 0.4499884843826294, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.06046334281563759, 0.9395367503166199], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.32501.gpt3.3", "original_example": {"example_id": "atomic.train.32501", "premise_hypothesis_id": "atomic.train.14755", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "WsQxgdNQap7vzpqZ3wFhBQ==", "AtomicEventRelationId": "iraxPuBXrIgVCeySvwhKTw==", "AtomicRelationType": "xIntent", "AtomicInference": "to harm another"}, "premise": "PersonX pricks PersonX's finger", "hypothesis": "Because PersonX wanted to harm another", "update": "PersonX is emo", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32501", "update_paraphrase": "PersonX is a person who is emotionally unstable.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5120435120435121, "pred_conf_shift": 0.5098469257354736, "syntactic_distance": 0.2}, {"confidence": [0.8423452973365784, 0.1576547473669052], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.32501.gpt3.7", "original_example": {"example_id": "atomic.train.32501", "premise_hypothesis_id": "atomic.train.14755", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "WsQxgdNQap7vzpqZ3wFhBQ==", "AtomicEventRelationId": "iraxPuBXrIgVCeySvwhKTw==", "AtomicRelationType": "xIntent", "AtomicInference": "to harm another"}, "premise": "PersonX pricks PersonX's finger", "hypothesis": "Because PersonX wanted to harm another", "update": "PersonX is emo", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32501", "update_paraphrase": "PersonX is sad and emotional.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.390625, "pred_conf_shift": -0.27203507721424103, "syntactic_distance": 0.125}, {"confidence": [0.7646672129631042, 0.23533280193805695], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.32501.gpt3.0", "original_example": {"example_id": "atomic.train.32501", "premise_hypothesis_id": "atomic.train.14755", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "WsQxgdNQap7vzpqZ3wFhBQ==", "AtomicEventRelationId": "iraxPuBXrIgVCeySvwhKTw==", "AtomicRelationType": "xIntent", "AtomicInference": "to harm another"}, "premise": "PersonX pricks PersonX's finger", "hypothesis": "Because PersonX wanted to harm another", "update": "PersonX is emo", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32501", "update_paraphrase": "Person X is feeling emotional and prone to sadness.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5961538461538461, "pred_conf_shift": -0.1943570226430893, "syntactic_distance": 0.25}, {"confidence": [0.33676397800445557, 0.6632360219955444], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.32501.gpt3.5", "original_example": {"example_id": "atomic.train.32501", "premise_hypothesis_id": "atomic.train.14755", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "WsQxgdNQap7vzpqZ3wFhBQ==", "AtomicEventRelationId": "iraxPuBXrIgVCeySvwhKTw==", "AtomicRelationType": "xIntent", "AtomicInference": "to harm another"}, "premise": "PersonX pricks PersonX's finger", "hypothesis": "Because PersonX wanted to harm another", "update": "PersonX is emo", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32501", "update_paraphrase": "PersonX is gloomy and depressed.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4253472222222222, "pred_conf_shift": 0.2335461974143982, "syntactic_distance": 0.125}, {"confidence": [0.5214653611183167, 0.47853463888168335], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.32501.gpt3.2", "original_example": {"example_id": "atomic.train.32501", "premise_hypothesis_id": "atomic.train.14755", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "WsQxgdNQap7vzpqZ3wFhBQ==", "AtomicEventRelationId": "iraxPuBXrIgVCeySvwhKTw==", "AtomicRelationType": "xIntent", "AtomicInference": "to harm another"}, "premise": "PersonX pricks PersonX's finger", "hypothesis": "Because PersonX wanted to harm another", "update": "PersonX is emo", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32501", "update_paraphrase": "PersonX is melancholy and tends to dwell on negative emotions.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6161616161616161, "pred_conf_shift": 0.04884481430053711, "syntactic_distance": 0.3333333333333333}]}, "atomic.train.4156": {"original_confidence": [0.8793694972991943, 0.12063049525022507], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.886475145816803, 0.1135248988866806], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.4156.gpt3.1", "original_example": {"example_id": "atomic.train.4156", "premise_hypothesis_id": "atomic.train.1957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y04ynBnbU1UdN_uC3AxoQA==", "AtomicEventRelationId": "XRZ0fafZ2yyJPJsk-c3wWw==", "AtomicRelationType": "xEffect", "AtomicInference": "they get out of car"}, "premise": "PersonX drives to work one morning", "hypothesis": "Then, they get out of car", "update": "PersonX works nights and is ordering curbside delivery for breakfast.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4156", "update_paraphrase": "X works the night shift and is ordering breakfast to be delivered to their doorstep.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39993939393939393, "pred_conf_shift": 0.007105648517608643, "syntactic_distance": 0.045454545454545456}, {"confidence": [0.9010410308837891, 0.09895896166563034], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.4156.gpt3.8", "original_example": {"example_id": "atomic.train.4156", "premise_hypothesis_id": "atomic.train.1957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y04ynBnbU1UdN_uC3AxoQA==", "AtomicEventRelationId": "XRZ0fafZ2yyJPJsk-c3wWw==", "AtomicRelationType": "xEffect", "AtomicInference": "they get out of car"}, "premise": "PersonX drives to work one morning", "hypothesis": "Then, they get out of car", "update": "PersonX works nights and is ordering curbside delivery for breakfast.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4156", "update_paraphrase": "PersonX is working the night shift and is ordering curbside delivery for breakfast.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1971892841458059, "pred_conf_shift": 0.021671533584594727, "syntactic_distance": 0.045454545454545456}, {"confidence": [0.8850415349006653, 0.11495848745107651], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.4156.gpt3.4", "original_example": {"example_id": "atomic.train.4156", "premise_hypothesis_id": "atomic.train.1957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y04ynBnbU1UdN_uC3AxoQA==", "AtomicEventRelationId": "XRZ0fafZ2yyJPJsk-c3wWw==", "AtomicRelationType": "xEffect", "AtomicInference": "they get out of car"}, "premise": "PersonX drives to work one morning", "hypothesis": "Then, they get out of car", "update": "PersonX works nights and is ordering curbside delivery for breakfast.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4156", "update_paraphrase": "Currently, PersonX is working the night shift. So, they're ordering breakfast to be delivered to them via curbside service.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5144169893662794, "pred_conf_shift": 0.005672037601470947, "syntactic_distance": 0.36363636363636365}, {"confidence": [0.6091399788856506, 0.39086005091667175], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.4156.gpt3.7", "original_example": {"example_id": "atomic.train.4156", "premise_hypothesis_id": "atomic.train.1957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y04ynBnbU1UdN_uC3AxoQA==", "AtomicEventRelationId": "XRZ0fafZ2yyJPJsk-c3wWw==", "AtomicRelationType": "xEffect", "AtomicInference": "they get out of car"}, "premise": "PersonX drives to work one morning", "hypothesis": "Then, they get out of car", "update": "PersonX works nights and is ordering curbside delivery for breakfast.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4156", "update_paraphrase": "Since PersonX works overnight shifts, they are ordering breakfast to be delivered to them instead of going out to get it.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5685398725246923, "pred_conf_shift": -0.2702295184135437, "syntactic_distance": 0.5}, {"confidence": [0.9017033576965332, 0.0982966274023056], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.4156.gpt3.6", "original_example": {"example_id": "atomic.train.4156", "premise_hypothesis_id": "atomic.train.1957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y04ynBnbU1UdN_uC3AxoQA==", "AtomicEventRelationId": "XRZ0fafZ2yyJPJsk-c3wWw==", "AtomicRelationType": "xEffect", "AtomicInference": "they get out of car"}, "premise": "PersonX drives to work one morning", "hypothesis": "Then, they get out of car", "update": "PersonX works nights and is ordering curbside delivery for breakfast.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4156", "update_paraphrase": "Since PersonX works nights, they're ordering breakfast through curbside delivery.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3246031746031746, "pred_conf_shift": 0.022333860397338867, "syntactic_distance": 0.42105263157894735}, {"confidence": [0.9181522727012634, 0.08184763789176941], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.4156.gpt3.3", "original_example": {"example_id": "atomic.train.4156", "premise_hypothesis_id": "atomic.train.1957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y04ynBnbU1UdN_uC3AxoQA==", "AtomicEventRelationId": "XRZ0fafZ2yyJPJsk-c3wWw==", "AtomicRelationType": "xEffect", "AtomicInference": "they get out of car"}, "premise": "PersonX drives to work one morning", "hypothesis": "Then, they get out of car", "update": "PersonX works nights and is ordering curbside delivery for breakfast.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4156", "update_paraphrase": "Since PersonX works at night, they are ordering breakfast through curbside delivery.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.355883510428965, "pred_conf_shift": 0.03878277540206909, "syntactic_distance": 0.52}, {"confidence": [0.9071710705757141, 0.09282896667718887], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.4156.gpt3.2", "original_example": {"example_id": "atomic.train.4156", "premise_hypothesis_id": "atomic.train.1957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y04ynBnbU1UdN_uC3AxoQA==", "AtomicEventRelationId": "XRZ0fafZ2yyJPJsk-c3wWw==", "AtomicRelationType": "xEffect", "AtomicInference": "they get out of car"}, "premise": "PersonX drives to work one morning", "hypothesis": "Then, they get out of car", "update": "PersonX works nights and is ordering curbside delivery for breakfast.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4156", "update_paraphrase": "PersonX is working the night shift and is ordering breakfast to be delivered to them curbside.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3761232231820466, "pred_conf_shift": 0.027801573276519775, "syntactic_distance": 0.045454545454545456}, {"confidence": [0.85738605260849, 0.14261402189731598], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.4156.gpt3.0", "original_example": {"example_id": "atomic.train.4156", "premise_hypothesis_id": "atomic.train.1957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y04ynBnbU1UdN_uC3AxoQA==", "AtomicEventRelationId": "XRZ0fafZ2yyJPJsk-c3wWw==", "AtomicRelationType": "xEffect", "AtomicInference": "they get out of car"}, "premise": "PersonX drives to work one morning", "hypothesis": "Then, they get out of car", "update": "PersonX works nights and is ordering curbside delivery for breakfast.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4156", "update_paraphrase": "PersonX ordered curbside delivery for breakfast because they work nights.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3111111111111111, "pred_conf_shift": -0.021983444690704346, "syntactic_distance": 0.36363636363636365}]}, "atomic.train.23756": {"original_confidence": [0.6373589634895325, 0.36264100670814514], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.15394628047943115, 0.8460538387298584], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.23756.gpt3.4", "original_example": {"example_id": "atomic.train.23756", "premise_hypothesis_id": "atomic.train.10878", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2y_uM2r7rEtPzCdU1gIX1g==", "AtomicEventRelationId": "s8qrvj_sfXzQOMdeJvEU8Q==", "AtomicRelationType": "xEffect", "AtomicInference": "keeps a secret"}, "premise": "PersonX throws PersonY a surprise party", "hypothesis": "PersonX then keeps a secret", "update": "PersonX went all out for the party.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23756", "update_paraphrase": "PersonX spent a lot of time and effort preparing for the party.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42105263157894735, "pred_conf_shift": -0.4834126830101013, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.38763436675071716, 0.6123656034469604], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.23756.gpt3.5", "original_example": {"example_id": "atomic.train.23756", "premise_hypothesis_id": "atomic.train.10878", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2y_uM2r7rEtPzCdU1gIX1g==", "AtomicEventRelationId": "s8qrvj_sfXzQOMdeJvEU8Q==", "AtomicRelationType": "xEffect", "AtomicInference": "keeps a secret"}, "premise": "PersonX throws PersonY a surprise party", "hypothesis": "PersonX then keeps a secret", "update": "PersonX went all out for the party.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23756", "update_paraphrase": "personX really went all out for the party.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.06666666666666665, "pred_conf_shift": -0.2497245967388153, "syntactic_distance": 0.08333333333333333}, {"confidence": [0.1939745396375656, 0.8060254454612732], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.23756.gpt3.7", "original_example": {"example_id": "atomic.train.23756", "premise_hypothesis_id": "atomic.train.10878", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2y_uM2r7rEtPzCdU1gIX1g==", "AtomicEventRelationId": "s8qrvj_sfXzQOMdeJvEU8Q==", "AtomicRelationType": "xEffect", "AtomicInference": "keeps a secret"}, "premise": "PersonX throws PersonY a surprise party", "hypothesis": "PersonX then keeps a secret", "update": "PersonX went all out for the party.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23756", "update_paraphrase": "PersonX really went above and beyond for the party.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28725961538461536, "pred_conf_shift": -0.44338442385196686, "syntactic_distance": 0.2}, {"confidence": [0.5268166661262512, 0.4731833040714264], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.23756.gpt3.6", "original_example": {"example_id": "atomic.train.23756", "premise_hypothesis_id": "atomic.train.10878", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2y_uM2r7rEtPzCdU1gIX1g==", "AtomicEventRelationId": "s8qrvj_sfXzQOMdeJvEU8Q==", "AtomicRelationType": "xEffect", "AtomicInference": "keeps a secret"}, "premise": "PersonX throws PersonY a surprise party", "hypothesis": "PersonX then keeps a secret", "update": "PersonX went all out for the party.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23756", "update_paraphrase": "PersonX went all out for the party, leaving no detail overlooked.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2222222222222222, "pred_conf_shift": -0.11054229736328125, "syntactic_distance": 0.125}, {"confidence": [0.06469134986400604, 0.9353086948394775], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.23756.gpt3.1", "original_example": {"example_id": "atomic.train.23756", "premise_hypothesis_id": "atomic.train.10878", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2y_uM2r7rEtPzCdU1gIX1g==", "AtomicEventRelationId": "s8qrvj_sfXzQOMdeJvEU8Q==", "AtomicRelationType": "xEffect", "AtomicInference": "keeps a secret"}, "premise": "PersonX throws PersonY a surprise party", "hypothesis": "PersonX then keeps a secret", "update": "PersonX went all out for the party.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23756", "update_paraphrase": "PersonX made an extra effort to make the party special.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4987819370172311, "pred_conf_shift": -0.5726676136255264, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.20780134201049805, 0.792198657989502], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.23756.gpt3.0", "original_example": {"example_id": "atomic.train.23756", "premise_hypothesis_id": "atomic.train.10878", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2y_uM2r7rEtPzCdU1gIX1g==", "AtomicEventRelationId": "s8qrvj_sfXzQOMdeJvEU8Q==", "AtomicRelationType": "xEffect", "AtomicInference": "keeps a secret"}, "premise": "PersonX throws PersonY a surprise party", "hypothesis": "PersonX then keeps a secret", "update": "PersonX went all out for the party.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23756", "update_paraphrase": "PersonX went all-in for the party, pulling out all the stops to make it a success.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5064182194616977, "pred_conf_shift": -0.4295576214790344, "syntactic_distance": 0.21739130434782608}, {"confidence": [0.2876233160495758, 0.7123767137527466], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.23756.gpt3.3", "original_example": {"example_id": "atomic.train.23756", "premise_hypothesis_id": "atomic.train.10878", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2y_uM2r7rEtPzCdU1gIX1g==", "AtomicEventRelationId": "s8qrvj_sfXzQOMdeJvEU8Q==", "AtomicRelationType": "xEffect", "AtomicInference": "keeps a secret"}, "premise": "PersonX throws PersonY a surprise party", "hypothesis": "PersonX then keeps a secret", "update": "PersonX went all out for the party.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23756", "update_paraphrase": "PersonX really went above and beyond to make the party a success.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5038911381016644, "pred_conf_shift": -0.34973564743995667, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.22015851736068726, 0.779841423034668], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.23756.gpt3.2", "original_example": {"example_id": "atomic.train.23756", "premise_hypothesis_id": "atomic.train.10878", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "2y_uM2r7rEtPzCdU1gIX1g==", "AtomicEventRelationId": "s8qrvj_sfXzQOMdeJvEU8Q==", "AtomicRelationType": "xEffect", "AtomicInference": "keeps a secret"}, "premise": "PersonX throws PersonY a surprise party", "hypothesis": "PersonX then keeps a secret", "update": "PersonX went all out for the party.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23756", "update_paraphrase": "PersonX put a lot of effort into making the party a success.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5025062656641605, "pred_conf_shift": -0.4172004461288452, "syntactic_distance": 0.22727272727272727}]}, "atomic.train.19482": {"original_confidence": [0.6806888580322266, 0.3193111717700958], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.5924270153045654, 0.40757304430007935], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19482.gpt3.1", "original_example": {"example_id": "atomic.train.19482", "premise_hypothesis_id": "atomic.train.9035", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "OJgrB97Upli1B0VUrOs3Pg==", "AtomicEventRelationId": "MVvhNNT6g2VEKyfGfWPfrQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to complete things hurriedly"}, "premise": "PersonX spills PersonY's drink", "hypothesis": "Because PersonX wanted to complete things hurriedly", "update": "PersonX is doing it on purpose since PersonY wore a white dress without being the bride", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19482", "update_paraphrase": "PersonX is being deliberately disruptive since PersonY wore a white dress instead of the bride.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2256558537393452, "pred_conf_shift": -0.08826184272766113, "syntactic_distance": 0.10526315789473684}, {"confidence": [0.609565258026123, 0.39043477177619934], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19482.gpt3.3", "original_example": {"example_id": "atomic.train.19482", "premise_hypothesis_id": "atomic.train.9035", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "OJgrB97Upli1B0VUrOs3Pg==", "AtomicEventRelationId": "MVvhNNT6g2VEKyfGfWPfrQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to complete things hurriedly"}, "premise": "PersonX spills PersonY's drink", "hypothesis": "Because PersonX wanted to complete things hurriedly", "update": "PersonX is doing it on purpose since PersonY wore a white dress without being the bride", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19482", "update_paraphrase": "PersonX is doing it out of spite because PersonY wore a white dress even though she wasn't the bride.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.30985522414093847, "pred_conf_shift": -0.07112360000610352, "syntactic_distance": 0.0}, {"confidence": [0.5695322155952454, 0.430467814207077], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19482.gpt3.7", "original_example": {"example_id": "atomic.train.19482", "premise_hypothesis_id": "atomic.train.9035", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "OJgrB97Upli1B0VUrOs3Pg==", "AtomicEventRelationId": "MVvhNNT6g2VEKyfGfWPfrQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to complete things hurriedly"}, "premise": "PersonX spills PersonY's drink", "hypothesis": "Because PersonX wanted to complete things hurriedly", "update": "PersonX is doing it on purpose since PersonY wore a white dress without being the bride", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19482", "update_paraphrase": "Since PersonY wore a white dress without being the bride, PersonX is doing it on purpose.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1875, "pred_conf_shift": -0.1111566424369812, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.6822300553321838, 0.3177699148654938], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19482.gpt3.6", "original_example": {"example_id": "atomic.train.19482", "premise_hypothesis_id": "atomic.train.9035", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "OJgrB97Upli1B0VUrOs3Pg==", "AtomicEventRelationId": "MVvhNNT6g2VEKyfGfWPfrQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to complete things hurriedly"}, "premise": "PersonX spills PersonY's drink", "hypothesis": "Because PersonX wanted to complete things hurriedly", "update": "PersonX is doing it on purpose since PersonY wore a white dress without being the bride", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19482", "update_paraphrase": "PersonX is doing it deliberately because PersonY wore a white dress without being the bride.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.11632179753621874, "pred_conf_shift": 0.0015411972999572754, "syntactic_distance": 0.05}, {"confidence": [0.5571220517158508, 0.44287794828414917], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19482.gpt3.4", "original_example": {"example_id": "atomic.train.19482", "premise_hypothesis_id": "atomic.train.9035", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "OJgrB97Upli1B0VUrOs3Pg==", "AtomicEventRelationId": "MVvhNNT6g2VEKyfGfWPfrQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to complete things hurriedly"}, "premise": "PersonX spills PersonY's drink", "hypothesis": "Because PersonX wanted to complete things hurriedly", "update": "PersonX is doing it on purpose since PersonY wore a white dress without being the bride", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19482", "update_paraphrase": "PersonX is doing it on purpose because PersonY wore a white dress even though she wasn't the bride.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.24908424908424914, "pred_conf_shift": -0.12356680631637573, "syntactic_distance": 0.0}, {"confidence": [0.563296914100647, 0.436703085899353], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19482.gpt3.5", "original_example": {"example_id": "atomic.train.19482", "premise_hypothesis_id": "atomic.train.9035", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "OJgrB97Upli1B0VUrOs3Pg==", "AtomicEventRelationId": "MVvhNNT6g2VEKyfGfWPfrQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to complete things hurriedly"}, "premise": "PersonX spills PersonY's drink", "hypothesis": "Because PersonX wanted to complete things hurriedly", "update": "PersonX is doing it on purpose since PersonY wore a white dress without being the bride", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19482", "update_paraphrase": "PersonX is doing it on purpose to spite PersonY, who wore a white dress even though she wasn't the bride.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28725240808574143, "pred_conf_shift": -0.11739194393157959, "syntactic_distance": 0.05}, {"confidence": [0.7782533764839172, 0.2217465043067932], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19482.gpt3.0", "original_example": {"example_id": "atomic.train.19482", "premise_hypothesis_id": "atomic.train.9035", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "OJgrB97Upli1B0VUrOs3Pg==", "AtomicEventRelationId": "MVvhNNT6g2VEKyfGfWPfrQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to complete things hurriedly"}, "premise": "PersonX spills PersonY's drink", "hypothesis": "Because PersonX wanted to complete things hurriedly", "update": "PersonX is doing it on purpose since PersonY wore a white dress without being the bride", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19482", "update_paraphrase": "PersonX is doing it deliberately since PersonY wore a white dress without being the bride.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.07564610450858328, "pred_conf_shift": 0.09756451845169067, "syntactic_distance": 0.05}, {"confidence": [0.7537638545036316, 0.2462361603975296], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19482.gpt3.2", "original_example": {"example_id": "atomic.train.19482", "premise_hypothesis_id": "atomic.train.9035", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "OJgrB97Upli1B0VUrOs3Pg==", "AtomicEventRelationId": "MVvhNNT6g2VEKyfGfWPfrQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to complete things hurriedly"}, "premise": "PersonX spills PersonY's drink", "hypothesis": "Because PersonX wanted to complete things hurriedly", "update": "PersonX is doing it on purpose since PersonY wore a white dress without being the bride", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19482", "update_paraphrase": "PersonX is being deliberately hostile since PersonY wore a white dress, even though they weren't the bride.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2648423471952884, "pred_conf_shift": 0.07307499647140503, "syntactic_distance": 0.10526315789473684}]}, "atomic.train.1192": {"original_confidence": [0.8553432822227478, 0.14465661346912384], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.34221208095550537, 0.6577878594398499], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1192.gpt3.7", "original_example": {"example_id": "atomic.train.1192", "premise_hypothesis_id": "atomic.train.562", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "46hgB7bya2kC-q8_Snsq7A==", "AtomicEventRelationId": "uyOa6qJ9Sk-VEIPpH6UCAQ==", "AtomicRelationType": "xAttr", "AtomicInference": "athletic"}, "premise": "PersonX is playing tennis", "hypothesis": "As a result, PersonX feels athletic", "update": "PersonX just worked for the first time in a decade.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1192", "update_paraphrase": "The person hadn't worked in a decade, but they took a job recently.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.44431172692042253, "pred_conf_shift": -0.5131312012672424, "syntactic_distance": 0.4444444444444444}, {"confidence": [0.8749536275863647, 0.12504640221595764], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1192.gpt3.5", "original_example": {"example_id": "atomic.train.1192", "premise_hypothesis_id": "atomic.train.562", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "46hgB7bya2kC-q8_Snsq7A==", "AtomicEventRelationId": "uyOa6qJ9Sk-VEIPpH6UCAQ==", "AtomicRelationType": "xAttr", "AtomicInference": "athletic"}, "premise": "PersonX is playing tennis", "hypothesis": "As a result, PersonX feels athletic", "update": "PersonX just worked for the first time in a decade.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1192", "update_paraphrase": "PersonX just worked for the first time in 10 years.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.17412587412587416, "pred_conf_shift": 0.019610345363616943, "syntactic_distance": 0.0}, {"confidence": [0.41089263558387756, 0.5891072750091553], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1192.gpt3.3", "original_example": {"example_id": "atomic.train.1192", "premise_hypothesis_id": "atomic.train.562", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "46hgB7bya2kC-q8_Snsq7A==", "AtomicEventRelationId": "uyOa6qJ9Sk-VEIPpH6UCAQ==", "AtomicRelationType": "xAttr", "AtomicInference": "athletic"}, "premise": "PersonX is playing tennis", "hypothesis": "As a result, PersonX feels athletic", "update": "PersonX just worked for the first time in a decade.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1192", "update_paraphrase": "This person hasn't worked in ten years, but they just got a job.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.44791802400498054, "pred_conf_shift": -0.44445064663887024, "syntactic_distance": 0.42857142857142855}, {"confidence": [0.20543895661830902, 0.7945610284805298], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1192.gpt3.1", "original_example": {"example_id": "atomic.train.1192", "premise_hypothesis_id": "atomic.train.562", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "46hgB7bya2kC-q8_Snsq7A==", "AtomicEventRelationId": "uyOa6qJ9Sk-VEIPpH6UCAQ==", "AtomicRelationType": "xAttr", "AtomicInference": "athletic"}, "premise": "PersonX is playing tennis", "hypothesis": "As a result, PersonX feels athletic", "update": "PersonX just worked for the first time in a decade.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1192", "update_paraphrase": "It's been 10 years since PersonX has worked a day in their life.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5452035886818496, "pred_conf_shift": -0.6499043256044388, "syntactic_distance": 0.42857142857142855}, {"confidence": [0.9299898147583008, 0.07001009583473206], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1192.gpt3.4", "original_example": {"example_id": "atomic.train.1192", "premise_hypothesis_id": "atomic.train.562", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "46hgB7bya2kC-q8_Snsq7A==", "AtomicEventRelationId": "uyOa6qJ9Sk-VEIPpH6UCAQ==", "AtomicRelationType": "xAttr", "AtomicInference": "athletic"}, "premise": "PersonX is playing tennis", "hypothesis": "As a result, PersonX feels athletic", "update": "PersonX just worked for the first time in a decade.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1192", "update_paraphrase": "PersonX just worked for the first time in a decade. This is the first time he has worked in ten years.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3548387096774194, "pred_conf_shift": 0.07464653253555298, "syntactic_distance": 0.25}, {"confidence": [0.94611656665802, 0.05388350784778595], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1192.gpt3.0", "original_example": {"example_id": "atomic.train.1192", "premise_hypothesis_id": "atomic.train.562", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "46hgB7bya2kC-q8_Snsq7A==", "AtomicEventRelationId": "uyOa6qJ9Sk-VEIPpH6UCAQ==", "AtomicRelationType": "xAttr", "AtomicInference": "athletic"}, "premise": "PersonX is playing tennis", "hypothesis": "As a result, PersonX feels athletic", "update": "PersonX just worked for the first time in a decade.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1192", "update_paraphrase": "This was the first time PersonX had worked in a decade.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.29724111866969016, "pred_conf_shift": 0.09077328443527222, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.5583202838897705, 0.4416797459125519], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1192.gpt3.2", "original_example": {"example_id": "atomic.train.1192", "premise_hypothesis_id": "atomic.train.562", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "46hgB7bya2kC-q8_Snsq7A==", "AtomicEventRelationId": "uyOa6qJ9Sk-VEIPpH6UCAQ==", "AtomicRelationType": "xAttr", "AtomicInference": "athletic"}, "premise": "PersonX is playing tennis", "hypothesis": "As a result, PersonX feels athletic", "update": "PersonX just worked for the first time in a decade.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1192", "update_paraphrase": "PersonX just got a job for the first time in ten years.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.26846385937295025, "pred_conf_shift": -0.2970229983329773, "syntactic_distance": 0.13043478260869565}, {"confidence": [0.625754177570343, 0.3742457926273346], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1192.gpt3.6", "original_example": {"example_id": "atomic.train.1192", "premise_hypothesis_id": "atomic.train.562", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "46hgB7bya2kC-q8_Snsq7A==", "AtomicEventRelationId": "uyOa6qJ9Sk-VEIPpH6UCAQ==", "AtomicRelationType": "xAttr", "AtomicInference": "athletic"}, "premise": "PersonX is playing tennis", "hypothesis": "As a result, PersonX feels athletic", "update": "PersonX just worked for the first time in a decade.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1192", "update_paraphrase": "For the first time in ten years, PersonX got a job.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33944891087748236, "pred_conf_shift": -0.22958910465240479, "syntactic_distance": 0.391304347826087}]}, "atomic.train.37755": {"original_confidence": [0.6417705416679382, 0.35822951793670654], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.7900551557540894, 0.20994482934474945], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37755.gpt3.0", "original_example": {"example_id": "atomic.train.37755", "premise_hypothesis_id": "atomic.train.17135", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mGvSshH0zAmPctXVOj_rNA==", "AtomicEventRelationId": "LNxLasmjEBcVu7Ch7eigeA==", "AtomicRelationType": "xReact", "AtomicInference": "neutral"}, "premise": "PersonX asks PersonY to send", "hypothesis": "PersonX is seen as neutral", "update": "PersonX asks PersonY to send their borrowed item back.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37755", "update_paraphrase": "PersonX is requesting that PersonY returns the item they borrowed.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4236889013978797, "pred_conf_shift": -0.1482846885919571, "syntactic_distance": 0.29411764705882354}, {"confidence": [0.7642534971237183, 0.23574648797512054], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37755.gpt3.1", "original_example": {"example_id": "atomic.train.37755", "premise_hypothesis_id": "atomic.train.17135", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mGvSshH0zAmPctXVOj_rNA==", "AtomicEventRelationId": "LNxLasmjEBcVu7Ch7eigeA==", "AtomicRelationType": "xReact", "AtomicInference": "neutral"}, "premise": "PersonX asks PersonY to send", "hypothesis": "PersonX is seen as neutral", "update": "PersonX asks PersonY to send their borrowed item back.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37755", "update_paraphrase": "PersonX requests that PersonY returns the borrowed item.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3983957219251336, "pred_conf_shift": -0.122483029961586, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.7555558085441589, 0.24444419145584106], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37755.gpt3.5", "original_example": {"example_id": "atomic.train.37755", "premise_hypothesis_id": "atomic.train.17135", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mGvSshH0zAmPctXVOj_rNA==", "AtomicEventRelationId": "LNxLasmjEBcVu7Ch7eigeA==", "AtomicRelationType": "xReact", "AtomicInference": "neutral"}, "premise": "PersonX asks PersonY to send", "hypothesis": "PersonX is seen as neutral", "update": "PersonX asks PersonY to send their borrowed item back.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37755", "update_paraphrase": "PersonX requests that PersonY returns the item they had borrowed.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4263499658236501, "pred_conf_shift": -0.11378532648086548, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.7218562364578247, 0.27814367413520813], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37755.gpt3.7", "original_example": {"example_id": "atomic.train.37755", "premise_hypothesis_id": "atomic.train.17135", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mGvSshH0zAmPctXVOj_rNA==", "AtomicEventRelationId": "LNxLasmjEBcVu7Ch7eigeA==", "AtomicRelationType": "xReact", "AtomicInference": "neutral"}, "premise": "PersonX asks PersonY to send", "hypothesis": "PersonX is seen as neutral", "update": "PersonX asks PersonY to send their borrowed item back.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37755", "update_paraphrase": "PersonX is asking PersonY to return the item they borrowed.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3233918128654971, "pred_conf_shift": -0.08008584380149841, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.662760317325592, 0.33723974227905273], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37755.gpt3.4", "original_example": {"example_id": "atomic.train.37755", "premise_hypothesis_id": "atomic.train.17135", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mGvSshH0zAmPctXVOj_rNA==", "AtomicEventRelationId": "LNxLasmjEBcVu7Ch7eigeA==", "AtomicRelationType": "xReact", "AtomicInference": "neutral"}, "premise": "PersonX asks PersonY to send", "hypothesis": "PersonX is seen as neutral", "update": "PersonX asks PersonY to send their borrowed item back.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37755", "update_paraphrase": "PersonX asks PersonY to return the borrowed item.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28351158645276286, "pred_conf_shift": -0.02098977565765381, "syntactic_distance": 0.0}, {"confidence": [0.7459046840667725, 0.2540953755378723], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37755.gpt3.6", "original_example": {"example_id": "atomic.train.37755", "premise_hypothesis_id": "atomic.train.17135", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mGvSshH0zAmPctXVOj_rNA==", "AtomicEventRelationId": "LNxLasmjEBcVu7Ch7eigeA==", "AtomicRelationType": "xReact", "AtomicInference": "neutral"}, "premise": "PersonX asks PersonY to send", "hypothesis": "PersonX is seen as neutral", "update": "PersonX asks PersonY to send their borrowed item back.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37755", "update_paraphrase": "PersonX asks PersonY to return the item they borrowed from them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37207459207459204, "pred_conf_shift": -0.10413414239883423, "syntactic_distance": 0.0}, {"confidence": [0.8097671270370483, 0.19023294746875763], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37755.gpt3.2", "original_example": {"example_id": "atomic.train.37755", "premise_hypothesis_id": "atomic.train.17135", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mGvSshH0zAmPctXVOj_rNA==", "AtomicEventRelationId": "LNxLasmjEBcVu7Ch7eigeA==", "AtomicRelationType": "xReact", "AtomicInference": "neutral"}, "premise": "PersonX asks PersonY to send", "hypothesis": "PersonX is seen as neutral", "update": "PersonX asks PersonY to send their borrowed item back.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37755", "update_paraphrase": "PersonX requests that PersonY return their borrowed item as soon as possible.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39285714285714285, "pred_conf_shift": -0.1679965704679489, "syntactic_distance": 0.23529411764705882}]}, "atomic.train.33228": {"original_confidence": [0.030954912304878235, 0.9690451622009277], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.08035849779844284, 0.9196414947509766], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.33228.gpt3.6", "original_example": {"example_id": "atomic.train.33228", "premise_hypothesis_id": "atomic.train.15088", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-UW9XIeHrbj9r32wLdeuwA==", "AtomicEventRelationId": "mAKt6-4boN0LmdbWlFgcVA==", "AtomicRelationType": "xAttr", "AtomicInference": "ambitious"}, "premise": "PersonX mows my lawn", "hypothesis": "As a result, PersonX feels ambitious", "update": "The lawn is vast and it takes hours.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.33228", "update_paraphrase": "The lawn is large and it takes hours to mow it.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.36319966583124474, "pred_conf_shift": 0.049403585493564606, "syntactic_distance": 0.06451612903225806}, {"confidence": [0.3727400600910187, 0.6272599101066589], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.33228.gpt3.1", "original_example": {"example_id": "atomic.train.33228", "premise_hypothesis_id": "atomic.train.15088", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-UW9XIeHrbj9r32wLdeuwA==", "AtomicEventRelationId": "mAKt6-4boN0LmdbWlFgcVA==", "AtomicRelationType": "xAttr", "AtomicInference": "ambitious"}, "premise": "PersonX mows my lawn", "hypothesis": "As a result, PersonX feels ambitious", "update": "The lawn is vast and it takes hours.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.33228", "update_paraphrase": "The lawn is large and it takes a long time to mow it.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4308767951625095, "pred_conf_shift": 0.34178514778614044, "syntactic_distance": 0.06451612903225806}, {"confidence": [0.9158183932304382, 0.08418156206607819], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.33228.gpt3.0", "original_example": {"example_id": "atomic.train.33228", "premise_hypothesis_id": "atomic.train.15088", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-UW9XIeHrbj9r32wLdeuwA==", "AtomicEventRelationId": "mAKt6-4boN0LmdbWlFgcVA==", "AtomicRelationType": "xAttr", "AtomicInference": "ambitious"}, "premise": "PersonX mows my lawn", "hypothesis": "As a result, PersonX feels ambitious", "update": "The lawn is vast and it takes hours.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.33228", "update_paraphrase": "The lawn is huge and it takes forever to mow.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3408289241622575, "pred_conf_shift": 0.88486348092556, "syntactic_distance": 0.0967741935483871}, {"confidence": [0.4427504539489746, 0.5572495460510254], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.33228.gpt3.5", "original_example": {"example_id": "atomic.train.33228", "premise_hypothesis_id": "atomic.train.15088", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-UW9XIeHrbj9r32wLdeuwA==", "AtomicEventRelationId": "mAKt6-4boN0LmdbWlFgcVA==", "AtomicRelationType": "xAttr", "AtomicInference": "ambitious"}, "premise": "PersonX mows my lawn", "hypothesis": "As a result, PersonX feels ambitious", "update": "The lawn is vast and it takes hours.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.33228", "update_paraphrase": "The lawn is large and it takes a long time to mow.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.40242063492063496, "pred_conf_shift": 0.4117955416440964, "syntactic_distance": 0.06451612903225806}, {"confidence": [0.7549102306365967, 0.2450897991657257], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.33228.gpt3.2", "original_example": {"example_id": "atomic.train.33228", "premise_hypothesis_id": "atomic.train.15088", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-UW9XIeHrbj9r32wLdeuwA==", "AtomicEventRelationId": "mAKt6-4boN0LmdbWlFgcVA==", "AtomicRelationType": "xAttr", "AtomicInference": "ambitious"}, "premise": "PersonX mows my lawn", "hypothesis": "As a result, PersonX feels ambitious", "update": "The lawn is vast and it takes hours.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.33228", "update_paraphrase": "The lawn is large and it usually takes a few hours to mow it.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4242784992784993, "pred_conf_shift": 0.7239553183317184, "syntactic_distance": 0.12121212121212122}, {"confidence": [0.33862394094467163, 0.6613759994506836], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.33228.gpt3.4", "original_example": {"example_id": "atomic.train.33228", "premise_hypothesis_id": "atomic.train.15088", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-UW9XIeHrbj9r32wLdeuwA==", "AtomicEventRelationId": "mAKt6-4boN0LmdbWlFgcVA==", "AtomicRelationType": "xAttr", "AtomicInference": "ambitious"}, "premise": "PersonX mows my lawn", "hypothesis": "As a result, PersonX feels ambitious", "update": "The lawn is vast and it takes hours.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.33228", "update_paraphrase": "The lawn is huge and it takes a long time to mow it.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4080120937263795, "pred_conf_shift": 0.3076690286397934, "syntactic_distance": 0.06451612903225806}, {"confidence": [0.40084779262542725, 0.599152147769928], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.33228.gpt3.3", "original_example": {"example_id": "atomic.train.33228", "premise_hypothesis_id": "atomic.train.15088", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-UW9XIeHrbj9r32wLdeuwA==", "AtomicEventRelationId": "mAKt6-4boN0LmdbWlFgcVA==", "AtomicRelationType": "xAttr", "AtomicInference": "ambitious"}, "premise": "PersonX mows my lawn", "hypothesis": "As a result, PersonX feels ambitious", "update": "The lawn is vast and it takes hours.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.33228", "update_paraphrase": "The lawn is very large and it takes a long time to mow.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42917611489040064, "pred_conf_shift": 0.369892880320549, "syntactic_distance": 0.06451612903225806}]}, "atomic.train.22933": {"original_confidence": [0.6496078968048096, 0.35039210319519043], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.7998268604278564, 0.20017318427562714], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.22933.gpt3.1", "original_example": {"example_id": "atomic.train.22933", "premise_hypothesis_id": "atomic.train.10514", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "iYMg5OyGYXoT-r8dBNiiSQ==", "AtomicEventRelationId": "rmnpGDStwkx8FX_UxYI3ow==", "AtomicRelationType": "xNeed", "AtomicInference": "wipe off the microscope"}, "premise": "PersonX uses PersonY microscope", "hypothesis": "Before, PersonX needed wipe off the microscope", "update": "PersonY was eating chips", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22933", "update_paraphrase": "PersonY was eating potato chips.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.11111111111111116, "pred_conf_shift": -0.1502189189195633, "syntactic_distance": 0.0}, {"confidence": [0.8053602576255798, 0.1946396678686142], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.22933.gpt3.2", "original_example": {"example_id": "atomic.train.22933", "premise_hypothesis_id": "atomic.train.10514", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "iYMg5OyGYXoT-r8dBNiiSQ==", "AtomicEventRelationId": "rmnpGDStwkx8FX_UxYI3ow==", "AtomicRelationType": "xNeed", "AtomicInference": "wipe off the microscope"}, "premise": "PersonX uses PersonY microscope", "hypothesis": "Before, PersonX needed wipe off the microscope", "update": "PersonY was eating chips", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22933", "update_paraphrase": "PersonY was munching on some chips.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3126984126984127, "pred_conf_shift": -0.15575243532657623, "syntactic_distance": 0.0625}, {"confidence": [0.8138582706451416, 0.186141699552536], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.22933.gpt3.0", "original_example": {"example_id": "atomic.train.22933", "premise_hypothesis_id": "atomic.train.10514", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "iYMg5OyGYXoT-r8dBNiiSQ==", "AtomicEventRelationId": "rmnpGDStwkx8FX_UxYI3ow==", "AtomicRelationType": "xNeed", "AtomicInference": "wipe off the microscope"}, "premise": "PersonX uses PersonY microscope", "hypothesis": "Before, PersonX needed wipe off the microscope", "update": "PersonY was eating chips", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22933", "update_paraphrase": "PersonY was munching on chips.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23633156966490293, "pred_conf_shift": -0.16425040364265442, "syntactic_distance": 0.0625}, {"confidence": [0.8260738253593445, 0.1739262044429779], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.22933.gpt3.4", "original_example": {"example_id": "atomic.train.22933", "premise_hypothesis_id": "atomic.train.10514", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "iYMg5OyGYXoT-r8dBNiiSQ==", "AtomicEventRelationId": "rmnpGDStwkx8FX_UxYI3ow==", "AtomicRelationType": "xNeed", "AtomicInference": "wipe off the microscope"}, "premise": "PersonX uses PersonY microscope", "hypothesis": "Before, PersonX needed wipe off the microscope", "update": "PersonY was eating chips", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22933", "update_paraphrase": "The person was eating chips.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1282051282051282, "pred_conf_shift": -0.17646589875221252, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.7874829173088074, 0.2125171571969986], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.22933.gpt3.5", "original_example": {"example_id": "atomic.train.22933", "premise_hypothesis_id": "atomic.train.10514", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "iYMg5OyGYXoT-r8dBNiiSQ==", "AtomicEventRelationId": "rmnpGDStwkx8FX_UxYI3ow==", "AtomicRelationType": "xNeed", "AtomicInference": "wipe off the microscope"}, "premise": "PersonX uses PersonY microscope", "hypothesis": "Before, PersonX needed wipe off the microscope", "update": "PersonY was eating chips", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22933", "update_paraphrase": "PersonY was eating a bag of chips.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2727272727272727, "pred_conf_shift": -0.13787494599819183, "syntactic_distance": 0.0}]}, "atomic.train.10210": {"original_confidence": [0.529716432094574, 0.470283567905426], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.7396513819694519, 0.2603486478328705], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10210.gpt3.4", "original_example": {"example_id": "atomic.train.10210", "premise_hypothesis_id": "atomic.train.4809", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "vEusydFomGTXxWVphXJTyg==", "AtomicEventRelationId": "xa3-x3iWDj1LnVifN6VLLw==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX eats it in secret"}, "premise": "PersonX takes PersonY's lunch", "hypothesis": "PersonX then personX eats it in secret", "update": "PersonX spits some of the food at PersonY just to be mean.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10210", "update_paraphrase": "PersonX deliberately spits some food at PersonY in an act of meanness.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.36167027417027414, "pred_conf_shift": 0.20993494987487793, "syntactic_distance": 0.23333333333333334}, {"confidence": [0.6519853472709656, 0.3480146825313568], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10210.gpt3.2", "original_example": {"example_id": "atomic.train.10210", "premise_hypothesis_id": "atomic.train.4809", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "vEusydFomGTXxWVphXJTyg==", "AtomicEventRelationId": "xa3-x3iWDj1LnVifN6VLLw==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX eats it in secret"}, "premise": "PersonX takes PersonY's lunch", "hypothesis": "PersonX then personX eats it in secret", "update": "PersonX spits some of the food at PersonY just to be mean.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10210", "update_paraphrase": "PersonX purposely sprays some of the food at PersonY to be rude.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.18130827505827507, "pred_conf_shift": 0.1222689151763916, "syntactic_distance": 0.10344827586206896}, {"confidence": [0.728732705116272, 0.27126723527908325], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10210.gpt3.6", "original_example": {"example_id": "atomic.train.10210", "premise_hypothesis_id": "atomic.train.4809", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "vEusydFomGTXxWVphXJTyg==", "AtomicEventRelationId": "xa3-x3iWDj1LnVifN6VLLw==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX eats it in secret"}, "premise": "PersonX takes PersonY's lunch", "hypothesis": "PersonX then personX eats it in secret", "update": "PersonX spits some of the food at PersonY just to be mean.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10210", "update_paraphrase": "PersonX is deliberately rude by spitting some of the food at PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3559600122100123, "pred_conf_shift": 0.199016273021698, "syntactic_distance": 0.28}, {"confidence": [0.6065967082977295, 0.3934033215045929], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10210.gpt3.1", "original_example": {"example_id": "atomic.train.10210", "premise_hypothesis_id": "atomic.train.4809", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "vEusydFomGTXxWVphXJTyg==", "AtomicEventRelationId": "xa3-x3iWDj1LnVifN6VLLw==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX eats it in secret"}, "premise": "PersonX takes PersonY's lunch", "hypothesis": "PersonX then personX eats it in secret", "update": "PersonX spits some of the food at PersonY just to be mean.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10210", "update_paraphrase": "PersonX deliberately spits food at PersonY to be rude.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3078231292517007, "pred_conf_shift": 0.07688027620315552, "syntactic_distance": 0.17857142857142858}, {"confidence": [0.3024684190750122, 0.6975315809249878], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.10210.gpt3.8", "original_example": {"example_id": "atomic.train.10210", "premise_hypothesis_id": "atomic.train.4809", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "vEusydFomGTXxWVphXJTyg==", "AtomicEventRelationId": "xa3-x3iWDj1LnVifN6VLLw==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX eats it in secret"}, "premise": "PersonX takes PersonY's lunch", "hypothesis": "PersonX then personX eats it in secret", "update": "PersonX spits some of the food at PersonY just to be mean.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10210", "update_paraphrase": "PersonX deliberately spits out some of their food at PersonY to be hurtful.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.17872180451127828, "pred_conf_shift": -0.22724801301956177, "syntactic_distance": 0.16129032258064516}, {"confidence": [0.47661852836608887, 0.5233814716339111], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.10210.gpt3.7", "original_example": {"example_id": "atomic.train.10210", "premise_hypothesis_id": "atomic.train.4809", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "vEusydFomGTXxWVphXJTyg==", "AtomicEventRelationId": "xa3-x3iWDj1LnVifN6VLLw==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX eats it in secret"}, "premise": "PersonX takes PersonY's lunch", "hypothesis": "PersonX then personX eats it in secret", "update": "PersonX spits some of the food at PersonY just to be mean.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10210", "update_paraphrase": "PersonX deliberately spits some of the food at PersonY to be rude.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.14583333333333331, "pred_conf_shift": -0.05309790372848511, "syntactic_distance": 0.10344827586206896}, {"confidence": [0.6274213790893555, 0.37257862091064453], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10210.gpt3.3", "original_example": {"example_id": "atomic.train.10210", "premise_hypothesis_id": "atomic.train.4809", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "vEusydFomGTXxWVphXJTyg==", "AtomicEventRelationId": "xa3-x3iWDj1LnVifN6VLLw==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX eats it in secret"}, "premise": "PersonX takes PersonY's lunch", "hypothesis": "PersonX then personX eats it in secret", "update": "PersonX spits some of the food at PersonY just to be mean.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10210", "update_paraphrase": "PersonX deliberately spits some food at PersonY to be rude.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.24837662337662342, "pred_conf_shift": 0.0977049469947815, "syntactic_distance": 0.1724137931034483}, {"confidence": [0.402690589427948, 0.5973094701766968], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.10210.gpt3.0", "original_example": {"example_id": "atomic.train.10210", "premise_hypothesis_id": "atomic.train.4809", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "vEusydFomGTXxWVphXJTyg==", "AtomicEventRelationId": "xa3-x3iWDj1LnVifN6VLLw==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX eats it in secret"}, "premise": "PersonX takes PersonY's lunch", "hypothesis": "PersonX then personX eats it in secret", "update": "PersonX spits some of the food at PersonY just to be mean.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10210", "update_paraphrase": "PersonX purposely spits out some of the food at PersonY to be cruel.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.15325396825396825, "pred_conf_shift": -0.12702584266662598, "syntactic_distance": 0.16129032258064516}, {"confidence": [0.6961489915847778, 0.30385100841522217], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10210.gpt3.5", "original_example": {"example_id": "atomic.train.10210", "premise_hypothesis_id": "atomic.train.4809", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "vEusydFomGTXxWVphXJTyg==", "AtomicEventRelationId": "xa3-x3iWDj1LnVifN6VLLw==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX eats it in secret"}, "premise": "PersonX takes PersonY's lunch", "hypothesis": "PersonX then personX eats it in secret", "update": "PersonX spits some of the food at PersonY just to be mean.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10210", "update_paraphrase": "PersonX intentionally spat some of the food at PersonY in an act of meanness.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.29725274725274725, "pred_conf_shift": 0.16643255949020386, "syntactic_distance": 0.23333333333333334}]}, "atomic.train.7839": {"original_confidence": [0.6971144080162048, 0.30288568139076233], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.9068905711174011, 0.09310948848724365], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7839.gpt3.2", "original_example": {"example_id": "atomic.train.7839", "premise_hypothesis_id": "atomic.train.3692", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ST6lku0u_7xTLJi1m_zX0A==", "AtomicEventRelationId": "1jvW1XmTqLC26kfqP0uaJQ==", "AtomicRelationType": "xNeed", "AtomicInference": "get up"}, "premise": "PersonX lets the dog outside", "hypothesis": "Before, PersonX needed get up", "update": "PersonX was lying on a couch.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7839", "update_paraphrase": "PersonX was stretched out on the couch.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42417582417582417, "pred_conf_shift": -0.20977619290351868, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.8308333158493042, 0.16916672885417938], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7839.gpt3.0", "original_example": {"example_id": "atomic.train.7839", "premise_hypothesis_id": "atomic.train.3692", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ST6lku0u_7xTLJi1m_zX0A==", "AtomicEventRelationId": "1jvW1XmTqLC26kfqP0uaJQ==", "AtomicRelationType": "xNeed", "AtomicInference": "get up"}, "premise": "PersonX lets the dog outside", "hypothesis": "Before, PersonX needed get up", "update": "PersonX was lying on a couch.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7839", "update_paraphrase": "Person X was reclining on a couch.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.15469146238377007, "pred_conf_shift": -0.13371895253658295, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.8937403559684753, 0.10625974833965302], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7839.gpt3.1", "original_example": {"example_id": "atomic.train.7839", "premise_hypothesis_id": "atomic.train.3692", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ST6lku0u_7xTLJi1m_zX0A==", "AtomicEventRelationId": "1jvW1XmTqLC26kfqP0uaJQ==", "AtomicRelationType": "xNeed", "AtomicInference": "get up"}, "premise": "PersonX lets the dog outside", "hypothesis": "Before, PersonX needed get up", "update": "PersonX was lying on a couch.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7839", "update_paraphrase": "PersonX was lounging on a couch.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.10149572649572652, "pred_conf_shift": -0.19662593305110931, "syntactic_distance": 0.0}, {"confidence": [0.8703679442405701, 0.12963207066059113], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7839.gpt3.6", "original_example": {"example_id": "atomic.train.7839", "premise_hypothesis_id": "atomic.train.3692", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ST6lku0u_7xTLJi1m_zX0A==", "AtomicEventRelationId": "1jvW1XmTqLC26kfqP0uaJQ==", "AtomicRelationType": "xNeed", "AtomicInference": "get up"}, "premise": "PersonX lets the dog outside", "hypothesis": "Before, PersonX needed get up", "update": "PersonX was lying on a couch.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7839", "update_paraphrase": "PersonX was stretched out on a couch.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.21538461538461534, "pred_conf_shift": -0.1732536107301712, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.6944810152053833, 0.3055189847946167], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7839.gpt3.5", "original_example": {"example_id": "atomic.train.7839", "premise_hypothesis_id": "atomic.train.3692", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ST6lku0u_7xTLJi1m_zX0A==", "AtomicEventRelationId": "1jvW1XmTqLC26kfqP0uaJQ==", "AtomicRelationType": "xNeed", "AtomicInference": "get up"}, "premise": "PersonX lets the dog outside", "hypothesis": "Before, PersonX needed get up", "update": "PersonX was lying on a couch.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7839", "update_paraphrase": "PersonX was lying down on a couch.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.07692307692307687, "pred_conf_shift": 0.00263330340385437, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.8414247632026672, 0.15857523679733276], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7839.gpt3.3", "original_example": {"example_id": "atomic.train.7839", "premise_hypothesis_id": "atomic.train.3692", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ST6lku0u_7xTLJi1m_zX0A==", "AtomicEventRelationId": "1jvW1XmTqLC26kfqP0uaJQ==", "AtomicRelationType": "xNeed", "AtomicInference": "get up"}, "premise": "PersonX lets the dog outside", "hypothesis": "Before, PersonX needed get up", "update": "PersonX was lying on a couch.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7839", "update_paraphrase": "PersonX was reclining on a couch.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.10515873015873017, "pred_conf_shift": -0.14431044459342957, "syntactic_distance": 0.0}, {"confidence": [0.6519950032234192, 0.3480050265789032], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7839.gpt3.4", "original_example": {"example_id": "atomic.train.7839", "premise_hypothesis_id": "atomic.train.3692", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ST6lku0u_7xTLJi1m_zX0A==", "AtomicEventRelationId": "1jvW1XmTqLC26kfqP0uaJQ==", "AtomicRelationType": "xNeed", "AtomicInference": "get up"}, "premise": "PersonX lets the dog outside", "hypothesis": "Before, PersonX needed get up", "update": "PersonX was lying on a couch.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7839", "update_paraphrase": "PersonX was sprawled out on a couch.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19842209072978306, "pred_conf_shift": 0.04511934518814087, "syntactic_distance": 0.11764705882352941}]}, "atomic.train.9188": {"original_confidence": [0.9860332012176514, 0.013966764323413372], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.9818926453590393, 0.01810736581683159], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9188.gpt3.4", "original_example": {"example_id": "atomic.train.9188", "premise_hypothesis_id": "atomic.train.4332", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "G254W8ZN8LrmBlwM8fBh0g==", "AtomicEventRelationId": "qzFctlBVlG0illHcj0iRCg==", "AtomicRelationType": "xWant", "AtomicInference": "to impart knowledge"}, "premise": "PersonX furthers PersonY's understanding", "hypothesis": "As a result, PersonX wants to impart knowledge", "update": "PersonX teaches illegal things to PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9188", "update_paraphrase": "PersonX provides instruction to PersonY in things that are against the law.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5289241622574956, "pred_conf_shift": -0.0041405558586120605, "syntactic_distance": 0.20833333333333334}, {"confidence": [0.9851377010345459, 0.014862419106066227], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9188.gpt3.3", "original_example": {"example_id": "atomic.train.9188", "premise_hypothesis_id": "atomic.train.4332", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "G254W8ZN8LrmBlwM8fBh0g==", "AtomicEventRelationId": "qzFctlBVlG0illHcj0iRCg==", "AtomicRelationType": "xWant", "AtomicInference": "to impart knowledge"}, "premise": "PersonX furthers PersonY's understanding", "hypothesis": "As a result, PersonX wants to impart knowledge", "update": "PersonX teaches illegal things to PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9188", "update_paraphrase": "PersonX is teaching PersonY things that are against the law.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5063492063492063, "pred_conf_shift": -0.0008955001831054688, "syntactic_distance": 0.2631578947368421}, {"confidence": [0.9788919687271118, 0.021107979118824005], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9188.gpt3.1", "original_example": {"example_id": "atomic.train.9188", "premise_hypothesis_id": "atomic.train.4332", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "G254W8ZN8LrmBlwM8fBh0g==", "AtomicEventRelationId": "qzFctlBVlG0illHcj0iRCg==", "AtomicRelationType": "xWant", "AtomicInference": "to impart knowledge"}, "premise": "PersonX furthers PersonY's understanding", "hypothesis": "As a result, PersonX wants to impart knowledge", "update": "PersonX teaches illegal things to PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9188", "update_paraphrase": "PersonX provides instruction on how to engage in illegal activities to PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45130160326238755, "pred_conf_shift": -0.007141232490539551, "syntactic_distance": 0.2631578947368421}, {"confidence": [0.9838117361068726, 0.016188276931643486], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9188.gpt3.5", "original_example": {"example_id": "atomic.train.9188", "premise_hypothesis_id": "atomic.train.4332", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "G254W8ZN8LrmBlwM8fBh0g==", "AtomicEventRelationId": "qzFctlBVlG0illHcj0iRCg==", "AtomicRelationType": "xWant", "AtomicInference": "to impart knowledge"}, "premise": "PersonX furthers PersonY's understanding", "hypothesis": "As a result, PersonX wants to impart knowledge", "update": "PersonX teaches illegal things to PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9188", "update_paraphrase": "PersonX gives PersonY lessons in things that are against the law.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5236227824463118, "pred_conf_shift": -0.0022214651107788086, "syntactic_distance": 0.0}, {"confidence": [0.9833598136901855, 0.01664019003510475], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9188.gpt3.2", "original_example": {"example_id": "atomic.train.9188", "premise_hypothesis_id": "atomic.train.4332", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "G254W8ZN8LrmBlwM8fBh0g==", "AtomicEventRelationId": "qzFctlBVlG0illHcj0iRCg==", "AtomicRelationType": "xWant", "AtomicInference": "to impart knowledge"}, "premise": "PersonX furthers PersonY's understanding", "hypothesis": "As a result, PersonX wants to impart knowledge", "update": "PersonX teaches illegal things to PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9188", "update_paraphrase": "PersonX breaks the law by teaching PersonY how to do things that are against the law.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5868797868797868, "pred_conf_shift": -0.0026733875274658203, "syntactic_distance": 0.13636363636363635}, {"confidence": [0.9830173850059509, 0.01698264293372631], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9188.gpt3.6", "original_example": {"example_id": "atomic.train.9188", "premise_hypothesis_id": "atomic.train.4332", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "G254W8ZN8LrmBlwM8fBh0g==", "AtomicEventRelationId": "qzFctlBVlG0illHcj0iRCg==", "AtomicRelationType": "xWant", "AtomicInference": "to impart knowledge"}, "premise": "PersonX furthers PersonY's understanding", "hypothesis": "As a result, PersonX wants to impart knowledge", "update": "PersonX teaches illegal things to PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9188", "update_paraphrase": "PersonX teaches PersonY how to do things that are against the law.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.47336860670194003, "pred_conf_shift": -0.0030158162117004395, "syntactic_distance": 0.23809523809523808}, {"confidence": [0.9850629568099976, 0.01493692398071289], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9188.gpt3.0", "original_example": {"example_id": "atomic.train.9188", "premise_hypothesis_id": "atomic.train.4332", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "G254W8ZN8LrmBlwM8fBh0g==", "AtomicEventRelationId": "qzFctlBVlG0illHcj0iRCg==", "AtomicRelationType": "xWant", "AtomicInference": "to impart knowledge"}, "premise": "PersonX furthers PersonY's understanding", "hypothesis": "As a result, PersonX wants to impart knowledge", "update": "PersonX teaches illegal things to PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9188", "update_paraphrase": "PersonX gives PersonY instruction in illicit activities.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4930931938850491, "pred_conf_shift": -0.0009702444076538086, "syntactic_distance": 0.2631578947368421}]}, "atomic.train.10137": {"original_confidence": [0.6284712553024292, 0.371528685092926], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.6482061743736267, 0.3517937958240509], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10137.gpt3.3", "original_example": {"example_id": "atomic.train.10137", "premise_hypothesis_id": "atomic.train.4778", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4sJhn6QpCHprgJQ3jr8zg==", "AtomicEventRelationId": "87Or5IMLgRqZcTf6E8KMBw==", "AtomicRelationType": "xNeed", "AtomicInference": "to pull down their pants"}, "premise": "PersonX pisses like a racehorse", "hypothesis": "Before, PersonX needed to pull down their pants", "update": "PersonX pulls up their pants when finished.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10137", "update_paraphrase": "After finishing, PersonX yanks up their pants.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33370681605975727, "pred_conf_shift": -0.019734889268875122, "syntactic_distance": 0.36}, {"confidence": [0.595808207988739, 0.4041918218135834], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10137.gpt3.2", "original_example": {"example_id": "atomic.train.10137", "premise_hypothesis_id": "atomic.train.4778", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4sJhn6QpCHprgJQ3jr8zg==", "AtomicEventRelationId": "87Or5IMLgRqZcTf6E8KMBw==", "AtomicRelationType": "xNeed", "AtomicInference": "to pull down their pants"}, "premise": "PersonX pisses like a racehorse", "hypothesis": "Before, PersonX needed to pull down their pants", "update": "PersonX pulls up their pants when finished.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10137", "update_paraphrase": "After finishing, PersonX pulls up their pants.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.21942110177404295, "pred_conf_shift": 0.03266313672065735, "syntactic_distance": 0.6842105263157895}, {"confidence": [0.6528499126434326, 0.34715014696121216], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10137.gpt3.0", "original_example": {"example_id": "atomic.train.10137", "premise_hypothesis_id": "atomic.train.4778", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4sJhn6QpCHprgJQ3jr8zg==", "AtomicEventRelationId": "87Or5IMLgRqZcTf6E8KMBw==", "AtomicRelationType": "xNeed", "AtomicInference": "to pull down their pants"}, "premise": "PersonX pisses like a racehorse", "hypothesis": "Before, PersonX needed to pull down their pants", "update": "PersonX pulls up their pants when finished.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10137", "update_paraphrase": "PersonX tugs up their pants once they're done.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33185185185185184, "pred_conf_shift": -0.024378538131713867, "syntactic_distance": 0.038461538461538464}, {"confidence": [0.6544467210769653, 0.3455532491207123], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10137.gpt3.7", "original_example": {"example_id": "atomic.train.10137", "premise_hypothesis_id": "atomic.train.4778", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4sJhn6QpCHprgJQ3jr8zg==", "AtomicEventRelationId": "87Or5IMLgRqZcTf6E8KMBw==", "AtomicRelationType": "xNeed", "AtomicInference": "to pull down their pants"}, "premise": "PersonX pisses like a racehorse", "hypothesis": "Before, PersonX needed to pull down their pants", "update": "PersonX pulls up their pants when finished.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10137", "update_paraphrase": "Once PersonX was finished, they pulled their pants up.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37784090909090906, "pred_conf_shift": -0.025975435972213745, "syntactic_distance": 0.42857142857142855}, {"confidence": [0.4914192855358124, 0.5085806846618652], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.10137.gpt3.4", "original_example": {"example_id": "atomic.train.10137", "premise_hypothesis_id": "atomic.train.4778", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4sJhn6QpCHprgJQ3jr8zg==", "AtomicEventRelationId": "87Or5IMLgRqZcTf6E8KMBw==", "AtomicRelationType": "xNeed", "AtomicInference": "to pull down their pants"}, "premise": "PersonX pisses like a racehorse", "hypothesis": "Before, PersonX needed to pull down their pants", "update": "PersonX pulls up their pants when finished.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10137", "update_paraphrase": "Once PersonX is done, they pull up their pants.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3326388888888889, "pred_conf_shift": 0.1370519995689392, "syntactic_distance": 0.35714285714285715}, {"confidence": [0.3396257758140564, 0.6603741645812988], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.10137.gpt3.1", "original_example": {"example_id": "atomic.train.10137", "premise_hypothesis_id": "atomic.train.4778", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4sJhn6QpCHprgJQ3jr8zg==", "AtomicEventRelationId": "87Or5IMLgRqZcTf6E8KMBw==", "AtomicRelationType": "xNeed", "AtomicInference": "to pull down their pants"}, "premise": "PersonX pisses like a racehorse", "hypothesis": "Before, PersonX needed to pull down their pants", "update": "PersonX pulls up their pants when finished.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10137", "update_paraphrase": "After finishing, PersonX tugs on their pants to pull them up.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.44226579520697173, "pred_conf_shift": 0.2888454794883728, "syntactic_distance": 0.6842105263157895}, {"confidence": [0.5618476271629333, 0.4381524920463562], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10137.gpt3.5", "original_example": {"example_id": "atomic.train.10137", "premise_hypothesis_id": "atomic.train.4778", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4sJhn6QpCHprgJQ3jr8zg==", "AtomicEventRelationId": "87Or5IMLgRqZcTf6E8KMBw==", "AtomicRelationType": "xNeed", "AtomicInference": "to pull down their pants"}, "premise": "PersonX pisses like a racehorse", "hypothesis": "Before, PersonX needed to pull down their pants", "update": "PersonX pulls up their pants when finished.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10137", "update_paraphrase": "After completing the task, PersonX pulls their pants up.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.38255494505494503, "pred_conf_shift": 0.06662380695343018, "syntactic_distance": 0.37037037037037035}, {"confidence": [0.5091435313224792, 0.490856409072876], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10137.gpt3.6", "original_example": {"example_id": "atomic.train.10137", "premise_hypothesis_id": "atomic.train.4778", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4sJhn6QpCHprgJQ3jr8zg==", "AtomicEventRelationId": "87Or5IMLgRqZcTf6E8KMBw==", "AtomicRelationType": "xNeed", "AtomicInference": "to pull down their pants"}, "premise": "PersonX pisses like a racehorse", "hypothesis": "Before, PersonX needed to pull down their pants", "update": "PersonX pulls up their pants when finished.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10137", "update_paraphrase": "Once PersonX is finished, they pull up their pants.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.29513888888888884, "pred_conf_shift": 0.11932772397994995, "syntactic_distance": 0.35714285714285715}, {"confidence": [0.5395452976226807, 0.4604547619819641], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10137.gpt3.8", "original_example": {"example_id": "atomic.train.10137", "premise_hypothesis_id": "atomic.train.4778", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4sJhn6QpCHprgJQ3jr8zg==", "AtomicEventRelationId": "87Or5IMLgRqZcTf6E8KMBw==", "AtomicRelationType": "xNeed", "AtomicInference": "to pull down their pants"}, "premise": "PersonX pisses like a racehorse", "hypothesis": "Before, PersonX needed to pull down their pants", "update": "PersonX pulls up their pants when finished.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10137", "update_paraphrase": "When finished, PersonX pulls up their pants.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.14285714285714285, "pred_conf_shift": 0.08892607688903809, "syntactic_distance": 0.4166666666666667}]}, "atomic.train.36261": {"original_confidence": [0.33868905901908875, 0.6613110303878784], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.11590610444545746, 0.8840938210487366], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.36261.gpt3.0", "original_example": {"example_id": "atomic.train.36261", "premise_hypothesis_id": "atomic.train.16446", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "rO7kFJIWVSV04yGjkgeG6A==", "AtomicEventRelationId": "VtYMIRB7WMX1zmHEEevddA==", "AtomicRelationType": "xNeed", "AtomicInference": "to get tickets"}, "premise": "PersonX makes the trip", "hypothesis": "Before, PersonX needed to get tickets", "update": "Person X is travelling by plane.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36261", "update_paraphrase": "Person X is flying.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.31363636363636366, "pred_conf_shift": 0.22278279066085815, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.109217569231987, 0.8907824158668518], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.36261.gpt3.1", "original_example": {"example_id": "atomic.train.36261", "premise_hypothesis_id": "atomic.train.16446", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "rO7kFJIWVSV04yGjkgeG6A==", "AtomicEventRelationId": "VtYMIRB7WMX1zmHEEevddA==", "AtomicRelationType": "xNeed", "AtomicInference": "to get tickets"}, "premise": "PersonX makes the trip", "hypothesis": "Before, PersonX needed to get tickets", "update": "Person X is travelling by plane.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36261", "update_paraphrase": "Person X is flying to their destination.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42802197802197806, "pred_conf_shift": 0.2294713854789734, "syntactic_distance": 0.0}, {"confidence": [0.15038570761680603, 0.8496143221855164], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.36261.gpt3.5", "original_example": {"example_id": "atomic.train.36261", "premise_hypothesis_id": "atomic.train.16446", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "rO7kFJIWVSV04yGjkgeG6A==", "AtomicEventRelationId": "VtYMIRB7WMX1zmHEEevddA==", "AtomicRelationType": "xNeed", "AtomicInference": "to get tickets"}, "premise": "PersonX makes the trip", "hypothesis": "Before, PersonX needed to get tickets", "update": "Person X is travelling by plane.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36261", "update_paraphrase": "Person X will be flying to their destination.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5347402597402597, "pred_conf_shift": 0.18830329179763794, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.23178185522556305, 0.7682181000709534], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.36261.gpt3.4", "original_example": {"example_id": "atomic.train.36261", "premise_hypothesis_id": "atomic.train.16446", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "rO7kFJIWVSV04yGjkgeG6A==", "AtomicEventRelationId": "VtYMIRB7WMX1zmHEEevddA==", "AtomicRelationType": "xNeed", "AtomicInference": "to get tickets"}, "premise": "PersonX makes the trip", "hypothesis": "Before, PersonX needed to get tickets", "update": "Person X is travelling by plane.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36261", "update_paraphrase": "Person X will be travelling by plane.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.18589743589743585, "pred_conf_shift": 0.10690706968307495, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.10665205866098404, 0.893347978591919], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.36261.gpt3.6", "original_example": {"example_id": "atomic.train.36261", "premise_hypothesis_id": "atomic.train.16446", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "rO7kFJIWVSV04yGjkgeG6A==", "AtomicEventRelationId": "VtYMIRB7WMX1zmHEEevddA==", "AtomicRelationType": "xNeed", "AtomicInference": "to get tickets"}, "premise": "PersonX makes the trip", "hypothesis": "Before, PersonX needed to get tickets", "update": "Person X is travelling by plane.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36261", "update_paraphrase": "Person X is taking a flight.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.38983585858585856, "pred_conf_shift": 0.23203694820404053, "syntactic_distance": 0.05555555555555555}, {"confidence": [0.07595760375261307, 0.9240423440933228], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.36261.gpt3.2", "original_example": {"example_id": "atomic.train.36261", "premise_hypothesis_id": "atomic.train.16446", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "rO7kFJIWVSV04yGjkgeG6A==", "AtomicEventRelationId": "VtYMIRB7WMX1zmHEEevddA==", "AtomicRelationType": "xNeed", "AtomicInference": "to get tickets"}, "premise": "PersonX makes the trip", "hypothesis": "Before, PersonX needed to get tickets", "update": "Person X is travelling by plane.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36261", "update_paraphrase": "Person X is taking a plane trip.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3598484848484848, "pred_conf_shift": 0.26273131370544434, "syntactic_distance": 0.05555555555555555}, {"confidence": [0.15874725580215454, 0.8412527441978455], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.36261.gpt3.3", "original_example": {"example_id": "atomic.train.36261", "premise_hypothesis_id": "atomic.train.16446", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "rO7kFJIWVSV04yGjkgeG6A==", "AtomicEventRelationId": "VtYMIRB7WMX1zmHEEevddA==", "AtomicRelationType": "xNeed", "AtomicInference": "to get tickets"}, "premise": "PersonX makes the trip", "hypothesis": "Before, PersonX needed to get tickets", "update": "Person X is travelling by plane.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36261", "update_paraphrase": "Person X will be taking a flight to their destination.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.578125, "pred_conf_shift": 0.17994171380996704, "syntactic_distance": 0.16666666666666666}]}, "atomic.train.13173": {"original_confidence": [0.29424145817756653, 0.7057585716247559], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.3962561786174774, 0.6037439107894897], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.13173.gpt3.2", "original_example": {"example_id": "atomic.train.13173", "premise_hypothesis_id": "atomic.train.6173", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mMmL8LUaO9l3WuhbeSYhog==", "AtomicEventRelationId": "1Q6I3pA_VPMkRwf8zYxEHw==", "AtomicRelationType": "xReact", "AtomicInference": "hungry"}, "premise": "PersonX does n't know what to eat", "hypothesis": "PersonX is seen as hungry", "update": "PersonX had to pull a twelve-hour shift with no meal break.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13173", "update_paraphrase": "PersonX had to work for twelve hours straight with no break for meals.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.41138791763791765, "pred_conf_shift": -0.10201466083526611, "syntactic_distance": 0.0}, {"confidence": [0.3499813675880432, 0.650018572807312], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.13173.gpt3.0", "original_example": {"example_id": "atomic.train.13173", "premise_hypothesis_id": "atomic.train.6173", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mMmL8LUaO9l3WuhbeSYhog==", "AtomicEventRelationId": "1Q6I3pA_VPMkRwf8zYxEHw==", "AtomicRelationType": "xReact", "AtomicInference": "hungry"}, "premise": "PersonX does n't know what to eat", "hypothesis": "PersonX is seen as hungry", "update": "PersonX had to pull a twelve-hour shift with no meal break.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13173", "update_paraphrase": "Person X was stuck working for twelve hours straight with no time for a break to eat.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.47751613465899184, "pred_conf_shift": -0.05573999881744385, "syntactic_distance": 0.3125}, {"confidence": [0.21220234036445618, 0.7877976894378662], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.13173.gpt3.5", "original_example": {"example_id": "atomic.train.13173", "premise_hypothesis_id": "atomic.train.6173", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mMmL8LUaO9l3WuhbeSYhog==", "AtomicEventRelationId": "1Q6I3pA_VPMkRwf8zYxEHw==", "AtomicRelationType": "xReact", "AtomicInference": "hungry"}, "premise": "PersonX does n't know what to eat", "hypothesis": "PersonX is seen as hungry", "update": "PersonX had to pull a twelve-hour shift with no meal break.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13173", "update_paraphrase": "The person had to work for twelve straight hours without any time for a break to eat.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.46723474937760656, "pred_conf_shift": 0.08203911781311035, "syntactic_distance": 0.13333333333333333}, {"confidence": [0.27704325318336487, 0.722956657409668], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.13173.gpt3.4", "original_example": {"example_id": "atomic.train.13173", "premise_hypothesis_id": "atomic.train.6173", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mMmL8LUaO9l3WuhbeSYhog==", "AtomicEventRelationId": "1Q6I3pA_VPMkRwf8zYxEHw==", "AtomicRelationType": "xReact", "AtomicInference": "hungry"}, "premise": "PersonX does n't know what to eat", "hypothesis": "PersonX is seen as hungry", "update": "PersonX had to pull a twelve-hour shift with no meal break.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13173", "update_paraphrase": "PersonX had to work for twelve hours without a break for food.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4411988977206368, "pred_conf_shift": 0.01719808578491211, "syntactic_distance": 0.0}, {"confidence": [0.2907761335372925, 0.7092238664627075], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.13173.gpt3.1", "original_example": {"example_id": "atomic.train.13173", "premise_hypothesis_id": "atomic.train.6173", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mMmL8LUaO9l3WuhbeSYhog==", "AtomicEventRelationId": "1Q6I3pA_VPMkRwf8zYxEHw==", "AtomicRelationType": "xReact", "AtomicInference": "hungry"}, "premise": "PersonX does n't know what to eat", "hypothesis": "PersonX is seen as hungry", "update": "PersonX had to pull a twelve-hour shift with no meal break.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13173", "update_paraphrase": "Person X had to work for twelve hours straight with no break to eat.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39562881562881563, "pred_conf_shift": 0.00346529483795166, "syntactic_distance": 0.13333333333333333}, {"confidence": [0.42773181200027466, 0.5722682476043701], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.13173.gpt3.8", "original_example": {"example_id": "atomic.train.13173", "premise_hypothesis_id": "atomic.train.6173", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mMmL8LUaO9l3WuhbeSYhog==", "AtomicEventRelationId": "1Q6I3pA_VPMkRwf8zYxEHw==", "AtomicRelationType": "xReact", "AtomicInference": "hungry"}, "premise": "PersonX does n't know what to eat", "hypothesis": "PersonX is seen as hungry", "update": "PersonX had to pull a twelve-hour shift with no meal break.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13173", "update_paraphrase": "PersonX was required to work for twelve hours straight with no opportunity to take a break for a meal.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4809479409479409, "pred_conf_shift": -0.13349032402038574, "syntactic_distance": 0.2}, {"confidence": [0.3809163570404053, 0.6190836429595947], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.13173.gpt3.7", "original_example": {"example_id": "atomic.train.13173", "premise_hypothesis_id": "atomic.train.6173", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mMmL8LUaO9l3WuhbeSYhog==", "AtomicEventRelationId": "1Q6I3pA_VPMkRwf8zYxEHw==", "AtomicRelationType": "xReact", "AtomicInference": "hungry"}, "premise": "PersonX does n't know what to eat", "hypothesis": "PersonX is seen as hungry", "update": "PersonX had to pull a twelve-hour shift with no meal break.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13173", "update_paraphrase": "PersonX had to work a twelve-hour shift without a break for food.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.322266139657444, "pred_conf_shift": -0.08667492866516113, "syntactic_distance": 0.0}, {"confidence": [0.5535426139831543, 0.4464574456214905], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.13173.gpt3.6", "original_example": {"example_id": "atomic.train.13173", "premise_hypothesis_id": "atomic.train.6173", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mMmL8LUaO9l3WuhbeSYhog==", "AtomicEventRelationId": "1Q6I3pA_VPMkRwf8zYxEHw==", "AtomicRelationType": "xReact", "AtomicInference": "hungry"}, "premise": "PersonX does n't know what to eat", "hypothesis": "PersonX is seen as hungry", "update": "PersonX had to pull a twelve-hour shift with no meal break.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13173", "update_paraphrase": "PersonX had to work a twelve-hour shift with no break for eating.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.272463768115942, "pred_conf_shift": -0.2593011260032654, "syntactic_distance": 0.0}, {"confidence": [0.29879724979400635, 0.7012027502059937], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.13173.gpt3.3", "original_example": {"example_id": "atomic.train.13173", "premise_hypothesis_id": "atomic.train.6173", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mMmL8LUaO9l3WuhbeSYhog==", "AtomicEventRelationId": "1Q6I3pA_VPMkRwf8zYxEHw==", "AtomicRelationType": "xReact", "AtomicInference": "hungry"}, "premise": "PersonX does n't know what to eat", "hypothesis": "PersonX is seen as hungry", "update": "PersonX had to pull a twelve-hour shift with no meal break.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13173", "update_paraphrase": "PersonX had to work for twelve hours straight with no break for food.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4451511451511452, "pred_conf_shift": -0.004555821418762207, "syntactic_distance": 0.0}]}, "atomic.train.37057": {"original_confidence": [0.2788214385509491, 0.7211784720420837], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.7055885791778564, 0.29441145062446594], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37057.gpt3.0", "original_example": {"example_id": "atomic.train.37057", "premise_hypothesis_id": "atomic.train.16816", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "0UUtl9lmhIkK_SyhmfOe_w==", "AtomicEventRelationId": "pa2T5VhWC5ezROspB1RCYg==", "AtomicRelationType": "xEffect", "AtomicInference": "Person X breaks his wrist."}, "premise": "PersonX fights hand to hand", "hypothesis": "PersonX then person X breaks his wrist.", "update": "PersonX fought against a bear", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37057", "update_paraphrase": "PersonX put up a fight against a bear.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.31157731157731156, "pred_conf_shift": -0.4267670214176178, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.49821239709854126, 0.5017874836921692], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37057.gpt3.1", "original_example": {"example_id": "atomic.train.37057", "premise_hypothesis_id": "atomic.train.16816", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "0UUtl9lmhIkK_SyhmfOe_w==", "AtomicEventRelationId": "pa2T5VhWC5ezROspB1RCYg==", "AtomicRelationType": "xEffect", "AtomicInference": "Person X breaks his wrist."}, "premise": "PersonX fights hand to hand", "hypothesis": "PersonX then person X breaks his wrist.", "update": "PersonX fought against a bear", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37057", "update_paraphrase": "PersonX was in a physical altercation with a bear.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4793650793650793, "pred_conf_shift": -0.21939098834991455, "syntactic_distance": 0.0625}, {"confidence": [0.11420357972383499, 0.8857964277267456], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37057.gpt3.3", "original_example": {"example_id": "atomic.train.37057", "premise_hypothesis_id": "atomic.train.16816", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "0UUtl9lmhIkK_SyhmfOe_w==", "AtomicEventRelationId": "pa2T5VhWC5ezROspB1RCYg==", "AtomicRelationType": "xEffect", "AtomicInference": "Person X breaks his wrist."}, "premise": "PersonX fights hand to hand", "hypothesis": "PersonX then person X breaks his wrist.", "update": "PersonX fought against a bear", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37057", "update_paraphrase": "PersonX battled fiercely against a bear.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23449883449883457, "pred_conf_shift": 0.16461795568466187, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.9531948566436768, 0.04680519178509712], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37057.gpt3.2", "original_example": {"example_id": "atomic.train.37057", "premise_hypothesis_id": "atomic.train.16816", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "0UUtl9lmhIkK_SyhmfOe_w==", "AtomicEventRelationId": "pa2T5VhWC5ezROspB1RCYg==", "AtomicRelationType": "xEffect", "AtomicInference": "Person X breaks his wrist."}, "premise": "PersonX fights hand to hand", "hypothesis": "PersonX then person X breaks his wrist.", "update": "PersonX fought against a bear", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37057", "update_paraphrase": "In a battle against a bear, personX emerged victorious.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45436507936507936, "pred_conf_shift": -0.6743732802569866, "syntactic_distance": 0.42105263157894735}, {"confidence": [0.204683318734169, 0.7953168153762817], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37057.gpt3.4", "original_example": {"example_id": "atomic.train.37057", "premise_hypothesis_id": "atomic.train.16816", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "0UUtl9lmhIkK_SyhmfOe_w==", "AtomicEventRelationId": "pa2T5VhWC5ezROspB1RCYg==", "AtomicRelationType": "xEffect", "AtomicInference": "Person X breaks his wrist."}, "premise": "PersonX fights hand to hand", "hypothesis": "PersonX then person X breaks his wrist.", "update": "PersonX fought against a bear", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37057", "update_paraphrase": "PersonX battled against a bear", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.16923076923076924, "pred_conf_shift": 0.074138343334198, "syntactic_distance": 0.0}]}, "atomic.train.2578": {"original_confidence": [0.14598959684371948, 0.8540103435516357], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.09134882688522339, 0.9086512327194214], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2578.gpt3.0", "original_example": {"example_id": "atomic.train.2578", "premise_hypothesis_id": "atomic.train.1215", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Lwfmm_pD99QoJJXbXC5gkg==", "AtomicEventRelationId": "euJtyqx3_dw1bhe_fBlg1w==", "AtomicRelationType": "xWant", "AtomicInference": "to go to a store"}, "premise": "PersonX goes from PersonY", "hypothesis": "As a result, PersonX wants to go to a store", "update": "X left his wallet at home.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2578", "update_paraphrase": "He forgot to bring his wallet with him when he left home.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5425925925925926, "pred_conf_shift": -0.054640769958496094, "syntactic_distance": 0.4}, {"confidence": [0.27365267276763916, 0.7263471484184265], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2578.gpt3.4", "original_example": {"example_id": "atomic.train.2578", "premise_hypothesis_id": "atomic.train.1215", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Lwfmm_pD99QoJJXbXC5gkg==", "AtomicEventRelationId": "euJtyqx3_dw1bhe_fBlg1w==", "AtomicRelationType": "xWant", "AtomicInference": "to go to a store"}, "premise": "PersonX goes from PersonY", "hypothesis": "As a result, PersonX wants to go to a store", "update": "X left his wallet at home.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2578", "update_paraphrase": "He didn't bring his wallet with him.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5018315018315018, "pred_conf_shift": 0.12766307592391968, "syntactic_distance": 0.4}, {"confidence": [0.21390940248966217, 0.7860904932022095], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2578.gpt3.1", "original_example": {"example_id": "atomic.train.2578", "premise_hypothesis_id": "atomic.train.1215", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Lwfmm_pD99QoJJXbXC5gkg==", "AtomicEventRelationId": "euJtyqx3_dw1bhe_fBlg1w==", "AtomicRelationType": "xWant", "AtomicInference": "to go to a store"}, "premise": "PersonX goes from PersonY", "hypothesis": "As a result, PersonX wants to go to a store", "update": "X left his wallet at home.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2578", "update_paraphrase": "X forgot to bring his wallet with him.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4139455782312925, "pred_conf_shift": 0.06791980564594269, "syntactic_distance": 0.4375}, {"confidence": [0.18026858568191528, 0.8197314739227295], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2578.gpt3.3", "original_example": {"example_id": "atomic.train.2578", "premise_hypothesis_id": "atomic.train.1215", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Lwfmm_pD99QoJJXbXC5gkg==", "AtomicEventRelationId": "euJtyqx3_dw1bhe_fBlg1w==", "AtomicRelationType": "xWant", "AtomicInference": "to go to a store"}, "premise": "PersonX goes from PersonY", "hypothesis": "As a result, PersonX wants to go to a store", "update": "X left his wallet at home.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2578", "update_paraphrase": "He forgot to bring his wallet with him.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5091836734693878, "pred_conf_shift": 0.0342789888381958, "syntactic_distance": 0.47058823529411764}, {"confidence": [0.04010897874832153, 0.9598910212516785], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2578.gpt3.2", "original_example": {"example_id": "atomic.train.2578", "premise_hypothesis_id": "atomic.train.1215", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Lwfmm_pD99QoJJXbXC5gkg==", "AtomicEventRelationId": "euJtyqx3_dw1bhe_fBlg1w==", "AtomicRelationType": "xWant", "AtomicInference": "to go to a store"}, "premise": "PersonX goes from PersonY", "hypothesis": "As a result, PersonX wants to go to a store", "update": "X left his wallet at home.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2578", "update_paraphrase": "He forgot his wallet at home.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2666666666666666, "pred_conf_shift": -0.10588061809539795, "syntactic_distance": 0.09523809523809523}]}, "atomic.train.14248": {"original_confidence": [0.8899425864219666, 0.11005750298500061], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.8566144108772278, 0.14338555932044983], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.14248.gpt3.0", "original_example": {"example_id": "atomic.train.14248", "premise_hypothesis_id": "atomic.train.6652", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "CsHeRjjh0lkwRzhegn3cHQ==", "AtomicEventRelationId": "23NVHdbXaL_48rX7wLwCfA==", "AtomicRelationType": "xAttr", "AtomicInference": "Experimental"}, "premise": "PersonX bases upon research", "hypothesis": "As a result, PersonX feels experimental", "update": "PersonX trusts the conclusion.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14248", "update_paraphrase": "The person believes the outcome.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4536538262028458, "pred_conf_shift": -0.03332817554473877, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.05131004750728607, 0.9486899971961975], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.14248.gpt3.5", "original_example": {"example_id": "atomic.train.14248", "premise_hypothesis_id": "atomic.train.6652", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "CsHeRjjh0lkwRzhegn3cHQ==", "AtomicEventRelationId": "23NVHdbXaL_48rX7wLwCfA==", "AtomicRelationType": "xAttr", "AtomicInference": "Experimental"}, "premise": "PersonX bases upon research", "hypothesis": "As a result, PersonX feels experimental", "update": "PersonX trusts the conclusion.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14248", "update_paraphrase": "PersonX believes in the outcome.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45470085470085475, "pred_conf_shift": -0.8386325389146805, "syntactic_distance": 0.25}, {"confidence": [0.9162291288375854, 0.08377081900835037], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.14248.gpt3.2", "original_example": {"example_id": "atomic.train.14248", "premise_hypothesis_id": "atomic.train.6652", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "CsHeRjjh0lkwRzhegn3cHQ==", "AtomicEventRelationId": "23NVHdbXaL_48rX7wLwCfA==", "AtomicRelationType": "xAttr", "AtomicInference": "Experimental"}, "premise": "PersonX bases upon research", "hypothesis": "As a result, PersonX feels experimental", "update": "PersonX trusts the conclusion.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14248", "update_paraphrase": "PersonX agrees with the conclusion.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2621082621082621, "pred_conf_shift": 0.026286542415618896, "syntactic_distance": 0.1875}, {"confidence": [0.7378154993057251, 0.2621844708919525], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.14248.gpt3.4", "original_example": {"example_id": "atomic.train.14248", "premise_hypothesis_id": "atomic.train.6652", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "CsHeRjjh0lkwRzhegn3cHQ==", "AtomicEventRelationId": "23NVHdbXaL_48rX7wLwCfA==", "AtomicRelationType": "xAttr", "AtomicInference": "Experimental"}, "premise": "PersonX bases upon research", "hypothesis": "As a result, PersonX feels experimental", "update": "PersonX trusts the conclusion.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14248", "update_paraphrase": "Person X believes that the conclusion is correct.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.44615384615384623, "pred_conf_shift": -0.15212708711624146, "syntactic_distance": 0.29411764705882354}, {"confidence": [0.8535298109054565, 0.14647020399570465], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.14248.gpt3.1", "original_example": {"example_id": "atomic.train.14248", "premise_hypothesis_id": "atomic.train.6652", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "CsHeRjjh0lkwRzhegn3cHQ==", "AtomicEventRelationId": "23NVHdbXaL_48rX7wLwCfA==", "AtomicRelationType": "xAttr", "AtomicInference": "Experimental"}, "premise": "PersonX bases upon research", "hypothesis": "As a result, PersonX feels experimental", "update": "PersonX trusts the conclusion.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14248", "update_paraphrase": "The conclusion is trustworthy according to PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4919786096256684, "pred_conf_shift": -0.03641277551651001, "syntactic_distance": 0.3684210526315789}, {"confidence": [0.8660424947738647, 0.13395750522613525], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.14248.gpt3.3", "original_example": {"example_id": "atomic.train.14248", "premise_hypothesis_id": "atomic.train.6652", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "CsHeRjjh0lkwRzhegn3cHQ==", "AtomicEventRelationId": "23NVHdbXaL_48rX7wLwCfA==", "AtomicRelationType": "xAttr", "AtomicInference": "Experimental"}, "premise": "PersonX bases upon research", "hypothesis": "As a result, PersonX feels experimental", "update": "PersonX trusts the conclusion.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14248", "update_paraphrase": "The conclusion is trustworthy to personX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4411764705882353, "pred_conf_shift": -0.023900091648101807, "syntactic_distance": 0.29411764705882354}]}, "atomic.train.16766": {"original_confidence": [0.3827625811100006, 0.617237389087677], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.07229037582874298, 0.9277095794677734], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16766.gpt3.3", "original_example": {"example_id": "atomic.train.16766", "premise_hypothesis_id": "atomic.train.7816", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "NR4T2ygi-DqQ5wzXbgG9Cg==", "AtomicEventRelationId": "lPDcphr5avnGOsBXMIA6FQ==", "AtomicRelationType": "xAttr", "AtomicInference": "careless"}, "premise": "PersonX burns PersonX's hand", "hypothesis": "As a result, PersonX feels careless", "update": "PersonX is engaging in self-harm", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16766", "update_paraphrase": "PersonX is causing harm to oneself.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4585858585858586, "pred_conf_shift": -0.31047220528125763, "syntactic_distance": 0.0625}, {"confidence": [0.9666205644607544, 0.03337939456105232], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.16766.gpt3.0", "original_example": {"example_id": "atomic.train.16766", "premise_hypothesis_id": "atomic.train.7816", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "NR4T2ygi-DqQ5wzXbgG9Cg==", "AtomicEventRelationId": "lPDcphr5avnGOsBXMIA6FQ==", "AtomicRelationType": "xAttr", "AtomicInference": "careless"}, "premise": "PersonX burns PersonX's hand", "hypothesis": "As a result, PersonX feels careless", "update": "PersonX is engaging in self-harm", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16766", "update_paraphrase": "PersonX is harming themselves physically on purpose.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.49722222222222223, "pred_conf_shift": 0.5838579833507538, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.2152378261089325, 0.7847620844841003], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16766.gpt3.5", "original_example": {"example_id": "atomic.train.16766", "premise_hypothesis_id": "atomic.train.7816", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "NR4T2ygi-DqQ5wzXbgG9Cg==", "AtomicEventRelationId": "lPDcphr5avnGOsBXMIA6FQ==", "AtomicRelationType": "xAttr", "AtomicInference": "careless"}, "premise": "PersonX burns PersonX's hand", "hypothesis": "As a result, PersonX feels careless", "update": "PersonX is engaging in self-harm", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16766", "update_paraphrase": "PersonX is harming themselves physically or emotionally.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5047892166313219, "pred_conf_shift": -0.16752475500106812, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.09721176326274872, 0.9027882218360901], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16766.gpt3.7", "original_example": {"example_id": "atomic.train.16766", "premise_hypothesis_id": "atomic.train.7816", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "NR4T2ygi-DqQ5wzXbgG9Cg==", "AtomicEventRelationId": "lPDcphr5avnGOsBXMIA6FQ==", "AtomicRelationType": "xAttr", "AtomicInference": "careless"}, "premise": "PersonX burns PersonX's hand", "hypothesis": "As a result, PersonX feels careless", "update": "PersonX is engaging in self-harm", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16766", "update_paraphrase": "PersonX is harming themselves.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37407407407407406, "pred_conf_shift": -0.2855508178472519, "syntactic_distance": 0.0625}, {"confidence": [0.9574701189994812, 0.04252979904413223], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.16766.gpt3.4", "original_example": {"example_id": "atomic.train.16766", "premise_hypothesis_id": "atomic.train.7816", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "NR4T2ygi-DqQ5wzXbgG9Cg==", "AtomicEventRelationId": "lPDcphr5avnGOsBXMIA6FQ==", "AtomicRelationType": "xAttr", "AtomicInference": "careless"}, "premise": "PersonX burns PersonX's hand", "hypothesis": "As a result, PersonX feels careless", "update": "PersonX is engaging in self-harm", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16766", "update_paraphrase": "PersonX is harming themselves on purpose.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4515151515151515, "pred_conf_shift": 0.5747075378894806, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.9402079582214355, 0.05979207158088684], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.16766.gpt3.2", "original_example": {"example_id": "atomic.train.16766", "premise_hypothesis_id": "atomic.train.7816", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "NR4T2ygi-DqQ5wzXbgG9Cg==", "AtomicEventRelationId": "lPDcphr5avnGOsBXMIA6FQ==", "AtomicRelationType": "xAttr", "AtomicInference": "careless"}, "premise": "PersonX burns PersonX's hand", "hypothesis": "As a result, PersonX feels careless", "update": "PersonX is engaging in self-harm", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16766", "update_paraphrase": "PersonX is causing themselves intentional harm.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4176729703045492, "pred_conf_shift": 0.5574453771114349, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.9394726157188416, 0.06052729859948158], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.16766.gpt3.1", "original_example": {"example_id": "atomic.train.16766", "premise_hypothesis_id": "atomic.train.7816", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "NR4T2ygi-DqQ5wzXbgG9Cg==", "AtomicEventRelationId": "lPDcphr5avnGOsBXMIA6FQ==", "AtomicRelationType": "xAttr", "AtomicInference": "careless"}, "premise": "PersonX burns PersonX's hand", "hypothesis": "As a result, PersonX feels careless", "update": "PersonX is engaging in self-harm", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16766", "update_paraphrase": "PersonX is hurting themselves on purpose.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4636363636363636, "pred_conf_shift": 0.5567100346088409, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.06555317342281342, 0.9344468116760254], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16766.gpt3.6", "original_example": {"example_id": "atomic.train.16766", "premise_hypothesis_id": "atomic.train.7816", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "NR4T2ygi-DqQ5wzXbgG9Cg==", "AtomicEventRelationId": "lPDcphr5avnGOsBXMIA6FQ==", "AtomicRelationType": "xAttr", "AtomicInference": "careless"}, "premise": "PersonX burns PersonX's hand", "hypothesis": "As a result, PersonX feels careless", "update": "PersonX is engaging in self-harm", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16766", "update_paraphrase": "PersonX is causing themselves harm through their actions.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4910866910866911, "pred_conf_shift": -0.3172094076871872, "syntactic_distance": 0.1111111111111111}]}, "atomic.train.1287": {"original_confidence": [0.16612306237220764, 0.83387690782547], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.0771726667881012, 0.9228273034095764], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1287.gpt3.6", "original_example": {"example_id": "atomic.train.1287", "premise_hypothesis_id": "atomic.train.609", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZHckFqfAohyq-uCST8zg6g==", "AtomicEventRelationId": "Xu0FC80rTmCJ7xu2oRZHmQ==", "AtomicRelationType": "xWant", "AtomicInference": "to send PersonY a reminder"}, "premise": "PersonX gives PersonY a time", "hypothesis": "As a result, PersonX wants to send PersonY a reminder", "update": "PersonX wants to go out with PersonY again.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1287", "update_paraphrase": "PersonX is interested in seeing PersonY again.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.47857142857142854, "pred_conf_shift": 0.08895039558410645, "syntactic_distance": 0.2}, {"confidence": [0.03165708854794502, 0.9683428406715393], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1287.gpt3.3", "original_example": {"example_id": "atomic.train.1287", "premise_hypothesis_id": "atomic.train.609", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZHckFqfAohyq-uCST8zg6g==", "AtomicEventRelationId": "Xu0FC80rTmCJ7xu2oRZHmQ==", "AtomicRelationType": "xWant", "AtomicInference": "to send PersonY a reminder"}, "premise": "PersonX gives PersonY a time", "hypothesis": "As a result, PersonX wants to send PersonY a reminder", "update": "PersonX wants to go out with PersonY again.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1287", "update_paraphrase": "PersonX hopes to go on another date with PersonY in the future.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37920634920634916, "pred_conf_shift": 0.13446593284606934, "syntactic_distance": 0.0}, {"confidence": [0.04789578914642334, 0.9521042108535767], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1287.gpt3.5", "original_example": {"example_id": "atomic.train.1287", "premise_hypothesis_id": "atomic.train.609", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZHckFqfAohyq-uCST8zg6g==", "AtomicEventRelationId": "Xu0FC80rTmCJ7xu2oRZHmQ==", "AtomicRelationType": "xWant", "AtomicInference": "to send PersonY a reminder"}, "premise": "PersonX gives PersonY a time", "hypothesis": "As a result, PersonX wants to send PersonY a reminder", "update": "PersonX wants to go out with PersonY again.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1287", "update_paraphrase": "Person X would like to go on another date with Person Y.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42109890109890113, "pred_conf_shift": 0.11822730302810669, "syntactic_distance": 0.3125}, {"confidence": [0.07412756234407425, 0.9258723855018616], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1287.gpt3.1", "original_example": {"example_id": "atomic.train.1287", "premise_hypothesis_id": "atomic.train.609", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZHckFqfAohyq-uCST8zg6g==", "AtomicEventRelationId": "Xu0FC80rTmCJ7xu2oRZHmQ==", "AtomicRelationType": "xWant", "AtomicInference": "to send PersonY a reminder"}, "premise": "PersonX gives PersonY a time", "hypothesis": "As a result, PersonX wants to send PersonY a reminder", "update": "PersonX wants to go out with PersonY again.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1287", "update_paraphrase": "PersonX would like to date PersonY again.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37370370370370365, "pred_conf_shift": 0.0919954776763916, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.04178227111697197, 0.9582177400588989], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1287.gpt3.4", "original_example": {"example_id": "atomic.train.1287", "premise_hypothesis_id": "atomic.train.609", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZHckFqfAohyq-uCST8zg6g==", "AtomicEventRelationId": "Xu0FC80rTmCJ7xu2oRZHmQ==", "AtomicRelationType": "xWant", "AtomicInference": "to send PersonY a reminder"}, "premise": "PersonX gives PersonY a time", "hypothesis": "As a result, PersonX wants to send PersonY a reminder", "update": "PersonX wants to go out with PersonY again.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1287", "update_paraphrase": "PersonX wishes to have another date with PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.43966450216450215, "pred_conf_shift": 0.12434083223342896, "syntactic_distance": 0.0}, {"confidence": [0.041376177221536636, 0.9586237668991089], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1287.gpt3.2", "original_example": {"example_id": "atomic.train.1287", "premise_hypothesis_id": "atomic.train.609", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZHckFqfAohyq-uCST8zg6g==", "AtomicEventRelationId": "Xu0FC80rTmCJ7xu2oRZHmQ==", "AtomicRelationType": "xWant", "AtomicInference": "to send PersonY a reminder"}, "premise": "PersonX gives PersonY a time", "hypothesis": "As a result, PersonX wants to send PersonY a reminder", "update": "PersonX wants to go out with PersonY again.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1287", "update_paraphrase": "PersonX would like to have another date with PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.40606909430438837, "pred_conf_shift": 0.12474685907363892, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.03897087275981903, 0.9610291123390198], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1287.gpt3.0", "original_example": {"example_id": "atomic.train.1287", "premise_hypothesis_id": "atomic.train.609", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZHckFqfAohyq-uCST8zg6g==", "AtomicEventRelationId": "Xu0FC80rTmCJ7xu2oRZHmQ==", "AtomicRelationType": "xWant", "AtomicInference": "to send PersonY a reminder"}, "premise": "PersonX gives PersonY a time", "hypothesis": "As a result, PersonX wants to send PersonY a reminder", "update": "PersonX wants to go out with PersonY again.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1287", "update_paraphrase": "PersonX would like to date PersonY again in the future.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4871252204585538, "pred_conf_shift": 0.1271522045135498, "syntactic_distance": 0.3333333333333333}]}, "atomic.train.24916": {"original_confidence": [0.6289085745811462, 0.371091365814209], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.5644953846931458, 0.4355045557022095], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.24916.gpt3.0", "original_example": {"example_id": "atomic.train.24916", "premise_hypothesis_id": "atomic.train.11398", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "5C-Ffg9V8Zdag6iTq4kpSw==", "AtomicEventRelationId": "_bcGWwJWxy9purIORrI79A==", "AtomicRelationType": "xReact", "AtomicInference": "nervous"}, "premise": "PersonX passes quickly", "hypothesis": "PersonX is seen as nervous", "update": "They have anxiety meds", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24916", "update_paraphrase": "The anxiety medications they have help them relax.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5029040404040404, "pred_conf_shift": -0.06441318988800049, "syntactic_distance": 0.42857142857142855}, {"confidence": [0.2878918945789337, 0.7121080756187439], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.24916.gpt3.2", "original_example": {"example_id": "atomic.train.24916", "premise_hypothesis_id": "atomic.train.11398", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "5C-Ffg9V8Zdag6iTq4kpSw==", "AtomicEventRelationId": "_bcGWwJWxy9purIORrI79A==", "AtomicRelationType": "xReact", "AtomicInference": "nervous"}, "premise": "PersonX passes quickly", "hypothesis": "PersonX is seen as nervous", "update": "They have anxiety meds", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24916", "update_paraphrase": "The medication they take helps with their anxiety.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5403439153439153, "pred_conf_shift": -0.3410166800022125, "syntactic_distance": 0.45}, {"confidence": [0.565467894077301, 0.43453213572502136], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.24916.gpt3.1", "original_example": {"example_id": "atomic.train.24916", "premise_hypothesis_id": "atomic.train.11398", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "5C-Ffg9V8Zdag6iTq4kpSw==", "AtomicEventRelationId": "_bcGWwJWxy9purIORrI79A==", "AtomicRelationType": "xReact", "AtomicInference": "nervous"}, "premise": "PersonX passes quickly", "hypothesis": "PersonX is seen as nervous", "update": "They have anxiety meds", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24916", "update_paraphrase": "They have medication to treat anxiety.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37633477633477636, "pred_conf_shift": -0.06344068050384521, "syntactic_distance": 0.125}, {"confidence": [0.4859357178211212, 0.514064371585846], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.24916.gpt3.4", "original_example": {"example_id": "atomic.train.24916", "premise_hypothesis_id": "atomic.train.11398", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "5C-Ffg9V8Zdag6iTq4kpSw==", "AtomicEventRelationId": "_bcGWwJWxy9purIORrI79A==", "AtomicRelationType": "xReact", "AtomicInference": "nervous"}, "premise": "PersonX passes quickly", "hypothesis": "PersonX is seen as nervous", "update": "They have anxiety meds", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24916", "update_paraphrase": "They have anxiety medication.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1651785714285714, "pred_conf_shift": -0.14297285676002502, "syntactic_distance": 0.0625}, {"confidence": [0.15620845556259155, 0.8437914848327637], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.24916.gpt3.3", "original_example": {"example_id": "atomic.train.24916", "premise_hypothesis_id": "atomic.train.11398", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "5C-Ffg9V8Zdag6iTq4kpSw==", "AtomicEventRelationId": "_bcGWwJWxy9purIORrI79A==", "AtomicRelationType": "xReact", "AtomicInference": "nervous"}, "premise": "PersonX passes quickly", "hypothesis": "PersonX is seen as nervous", "update": "They have anxiety meds", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24916", "update_paraphrase": "The medications they take help with their anxiety.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5329365079365078, "pred_conf_shift": -0.4727001190185547, "syntactic_distance": 0.4}]}, "atomic.train.28772": {"original_confidence": [0.2074546217918396, 0.7925453782081604], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.8175005316734314, 0.1824994832277298], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.28772.gpt3.3", "original_example": {"example_id": "atomic.train.28772", "premise_hypothesis_id": "atomic.train.13060", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aFgfLsLdBhhrLouS7TlKLQ==", "AtomicEventRelationId": "d0vBjC5jWWWN2c5gbo7TKw==", "AtomicRelationType": "xIntent", "AtomicInference": "to be near PersonY"}, "premise": "PersonX sits with PersonY", "hypothesis": "Because PersonX wanted to be near PersonY", "update": "PersonX is in a waiting room", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.28772", "update_paraphrase": "Person X is waiting in a room for something to happen.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3619909502262443, "pred_conf_shift": 0.6100459098815918, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.22621536254882812, 0.7737846374511719], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.28772.gpt3.4", "original_example": {"example_id": "atomic.train.28772", "premise_hypothesis_id": "atomic.train.13060", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aFgfLsLdBhhrLouS7TlKLQ==", "AtomicEventRelationId": "d0vBjC5jWWWN2c5gbo7TKw==", "AtomicRelationType": "xIntent", "AtomicInference": "to be near PersonY"}, "premise": "PersonX sits with PersonY", "hypothesis": "Because PersonX wanted to be near PersonY", "update": "PersonX is in a waiting room", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.28772", "update_paraphrase": "PersonX is in a room where they are waiting for something.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3773024361259655, "pred_conf_shift": 0.018760740756988525, "syntactic_distance": 0.0}, {"confidence": [0.28764763474464417, 0.7123523354530334], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.28772.gpt3.5", "original_example": {"example_id": "atomic.train.28772", "premise_hypothesis_id": "atomic.train.13060", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aFgfLsLdBhhrLouS7TlKLQ==", "AtomicEventRelationId": "d0vBjC5jWWWN2c5gbo7TKw==", "AtomicRelationType": "xIntent", "AtomicInference": "to be near PersonY"}, "premise": "PersonX sits with PersonY", "hypothesis": "Because PersonX wanted to be near PersonY", "update": "PersonX is in a waiting room", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.28772", "update_paraphrase": "PersonX is sitting in a waiting room, waiting for something to happen.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4285714285714286, "pred_conf_shift": 0.08019301295280457, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.8047784566879272, 0.19522152841091156], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.28772.gpt3.0", "original_example": {"example_id": "atomic.train.28772", "premise_hypothesis_id": "atomic.train.13060", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aFgfLsLdBhhrLouS7TlKLQ==", "AtomicEventRelationId": "d0vBjC5jWWWN2c5gbo7TKw==", "AtomicRelationType": "xIntent", "AtomicInference": "to be near PersonY"}, "premise": "PersonX sits with PersonY", "hypothesis": "Because PersonX wanted to be near PersonY", "update": "PersonX is in a waiting room", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.28772", "update_paraphrase": "PersonX is waiting in a room for something to happen.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3611111111111111, "pred_conf_shift": 0.5973238348960876, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.9414811730384827, 0.058518897742033005], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.28772.gpt3.2", "original_example": {"example_id": "atomic.train.28772", "premise_hypothesis_id": "atomic.train.13060", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aFgfLsLdBhhrLouS7TlKLQ==", "AtomicEventRelationId": "d0vBjC5jWWWN2c5gbo7TKw==", "AtomicRelationType": "xIntent", "AtomicInference": "to be near PersonY"}, "premise": "PersonX sits with PersonY", "hypothesis": "Because PersonX wanted to be near PersonY", "update": "PersonX is in a waiting room", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.28772", "update_paraphrase": "PersonX is in a holding area", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.24648268398268403, "pred_conf_shift": 0.7340265512466431, "syntactic_distance": 0.0}, {"confidence": [0.7589492201805115, 0.2410508245229721], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.28772.gpt3.1", "original_example": {"example_id": "atomic.train.28772", "premise_hypothesis_id": "atomic.train.13060", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aFgfLsLdBhhrLouS7TlKLQ==", "AtomicEventRelationId": "d0vBjC5jWWWN2c5gbo7TKw==", "AtomicRelationType": "xIntent", "AtomicInference": "to be near PersonY"}, "premise": "PersonX sits with PersonY", "hypothesis": "Because PersonX wanted to be near PersonY", "update": "PersonX is in a waiting room", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.28772", "update_paraphrase": "PersonX is sitting in a room, waiting for something to happen.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3949579831932773, "pred_conf_shift": 0.5514945983886719, "syntactic_distance": 0.23529411764705882}]}, "atomic.train.29649": {"original_confidence": [0.463358074426651, 0.5366418957710266], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.5731504559516907, 0.4268495738506317], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29649.gpt3.7", "original_example": {"example_id": "atomic.train.29649", "premise_hypothesis_id": "atomic.train.13455", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "I1oUXuNhzJug8EWOgDkI9Q==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX cuts PersonX's hair short", "hypothesis": "PersonX is seen as better", "update": "PersonX got sick of the long hair.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29649", "update_paraphrase": "PersonX got annoyed with the long hair.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2104256854256854, "pred_conf_shift": -0.1097923219203949, "syntactic_distance": 0.125}, {"confidence": [0.5704426765441895, 0.42955726385116577], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29649.gpt3.4", "original_example": {"example_id": "atomic.train.29649", "premise_hypothesis_id": "atomic.train.13455", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "I1oUXuNhzJug8EWOgDkI9Q==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX cuts PersonX's hair short", "hypothesis": "PersonX is seen as better", "update": "PersonX got sick of the long hair.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29649", "update_paraphrase": "PersonX became frustrated with the long hair.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3414965986394558, "pred_conf_shift": -0.10708463191986084, "syntactic_distance": 0.1875}, {"confidence": [0.4770028591156006, 0.5229971408843994], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.29649.gpt3.8", "original_example": {"example_id": "atomic.train.29649", "premise_hypothesis_id": "atomic.train.13455", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "I1oUXuNhzJug8EWOgDkI9Q==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX cuts PersonX's hair short", "hypothesis": "PersonX is seen as better", "update": "PersonX got sick of the long hair.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29649", "update_paraphrase": "PersonX got tired of having long hair.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22987012987012984, "pred_conf_shift": -0.013644754886627197, "syntactic_distance": 0.0}, {"confidence": [0.5750054121017456, 0.42499464750289917], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29649.gpt3.0", "original_example": {"example_id": "atomic.train.29649", "premise_hypothesis_id": "atomic.train.13455", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "I1oUXuNhzJug8EWOgDkI9Q==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX cuts PersonX's hair short", "hypothesis": "PersonX is seen as better", "update": "PersonX got sick of the long hair.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29649", "update_paraphrase": "PersonX became tired of the long hair.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22499999999999998, "pred_conf_shift": -0.11164724826812744, "syntactic_distance": 0.0}, {"confidence": [0.4751240909099579, 0.524875819683075], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.29649.gpt3.5", "original_example": {"example_id": "atomic.train.29649", "premise_hypothesis_id": "atomic.train.13455", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "I1oUXuNhzJug8EWOgDkI9Q==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX cuts PersonX's hair short", "hypothesis": "PersonX is seen as better", "update": "PersonX got sick of the long hair.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29649", "update_paraphrase": "Sick of the long hair, PersonX decided to chop it all off.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4, "pred_conf_shift": -0.01176607608795166, "syntactic_distance": 0.4444444444444444}, {"confidence": [0.5483186841011047, 0.45168131589889526], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29649.gpt3.6", "original_example": {"example_id": "atomic.train.29649", "premise_hypothesis_id": "atomic.train.13455", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "I1oUXuNhzJug8EWOgDkI9Q==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX cuts PersonX's hair short", "hypothesis": "PersonX is seen as better", "update": "PersonX got sick of the long hair.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29649", "update_paraphrase": "PersonX grew tired of the long hair.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22902494331065765, "pred_conf_shift": -0.08496057987213135, "syntactic_distance": 0.0}, {"confidence": [0.592502772808075, 0.40749722719192505], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29649.gpt3.1", "original_example": {"example_id": "atomic.train.29649", "premise_hypothesis_id": "atomic.train.13455", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "I1oUXuNhzJug8EWOgDkI9Q==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX cuts PersonX's hair short", "hypothesis": "PersonX is seen as better", "update": "PersonX got sick of the long hair.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29649", "update_paraphrase": "PersonX became annoyed with the long hair.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3335600907029479, "pred_conf_shift": -0.12914466857910156, "syntactic_distance": 0.125}, {"confidence": [0.5954504013061523, 0.4045495092868805], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29649.gpt3.3", "original_example": {"example_id": "atomic.train.29649", "premise_hypothesis_id": "atomic.train.13455", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "I1oUXuNhzJug8EWOgDkI9Q==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX cuts PersonX's hair short", "hypothesis": "PersonX is seen as better", "update": "PersonX got sick of the long hair.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29649", "update_paraphrase": "PersonX got tired of the long hair.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.11399711399711399, "pred_conf_shift": -0.13209238648414612, "syntactic_distance": 0.0}, {"confidence": [0.4376622140407562, 0.5623378157615662], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.29649.gpt3.2", "original_example": {"example_id": "atomic.train.29649", "premise_hypothesis_id": "atomic.train.13455", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "I1oUXuNhzJug8EWOgDkI9Q==", "AtomicEventRelationId": "LD6IbQSJUKAdr_FXs_rO4g==", "AtomicRelationType": "xReact", "AtomicInference": "better"}, "premise": "PersonX cuts PersonX's hair short", "hypothesis": "PersonX is seen as better", "update": "PersonX got sick of the long hair.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29649", "update_paraphrase": "PersonX was tired of dealing with long hair.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3628571428571428, "pred_conf_shift": 0.02569591999053955, "syntactic_distance": 0.0625}]}, "atomic.train.27425": {"original_confidence": [0.08100000023841858, 0.918999969959259], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.09805960208177567, 0.9019405245780945], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.27425.gpt3.3", "original_example": {"example_id": "atomic.train.27425", "premise_hypothesis_id": "atomic.train.12476", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "FLX1AT5kemNEogBlo9n1Yw==", "AtomicEventRelationId": "NL8SBZaENNRHT2dZgrLO9Q==", "AtomicRelationType": "xIntent", "AtomicInference": "to drive"}, "premise": "PersonX is in PersonX's car", "hypothesis": "Because PersonX wanted to drive", "update": "PersonX is in the driver's seat.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27425", "update_paraphrase": "PersonX is behind the wheel.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.401010101010101, "pred_conf_shift": -0.01705944538116455, "syntactic_distance": 0.0}]}, "atomic.train.11060": {"original_confidence": [0.19717982411384583, 0.8028202056884766], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.17253714799880981, 0.8274628520011902], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11060.gpt3.1", "original_example": {"example_id": "atomic.train.11060", "premise_hypothesis_id": "atomic.train.5205", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "i44YN0eOHFLf6YXLbsCJSA==", "AtomicEventRelationId": "XgE5GhIraey_UmLj4lGfYA==", "AtomicRelationType": "xIntent", "AtomicInference": "to win the soccer game."}, "premise": "PersonX takes the field", "hypothesis": "Because PersonX wanted to win the soccer game.", "update": "They are wearing a cap and gown", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11060", "update_paraphrase": "They are clothed in a cap and gown.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.13400673400673402, "pred_conf_shift": -0.02464267611503601, "syntactic_distance": 0.125}, {"confidence": [0.06545352190732956, 0.9345464110374451], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11060.gpt3.4", "original_example": {"example_id": "atomic.train.11060", "premise_hypothesis_id": "atomic.train.5205", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "i44YN0eOHFLf6YXLbsCJSA==", "AtomicEventRelationId": "XgE5GhIraey_UmLj4lGfYA==", "AtomicRelationType": "xIntent", "AtomicInference": "to win the soccer game."}, "premise": "PersonX takes the field", "hypothesis": "Because PersonX wanted to win the soccer game.", "update": "They are wearing a cap and gown", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11060", "update_paraphrase": "They are dressed in a cap and gown.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.15824915824915825, "pred_conf_shift": -0.13172630220651627, "syntactic_distance": 0.125}, {"confidence": [0.056536298245191574, 0.9434636235237122], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11060.gpt3.0", "original_example": {"example_id": "atomic.train.11060", "premise_hypothesis_id": "atomic.train.5205", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "i44YN0eOHFLf6YXLbsCJSA==", "AtomicEventRelationId": "XgE5GhIraey_UmLj4lGfYA==", "AtomicRelationType": "xIntent", "AtomicInference": "to win the soccer game."}, "premise": "PersonX takes the field", "hypothesis": "Because PersonX wanted to win the soccer game.", "update": "They are wearing a cap and gown", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11060", "update_paraphrase": "They are clad in a cap and gown.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.17037037037037034, "pred_conf_shift": -0.14064352586865425, "syntactic_distance": 0.125}, {"confidence": [0.19641563296318054, 0.8035843372344971], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11060.gpt3.3", "original_example": {"example_id": "atomic.train.11060", "premise_hypothesis_id": "atomic.train.5205", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "i44YN0eOHFLf6YXLbsCJSA==", "AtomicEventRelationId": "XgE5GhIraey_UmLj4lGfYA==", "AtomicRelationType": "xIntent", "AtomicInference": "to win the soccer game."}, "premise": "PersonX takes the field", "hypothesis": "Because PersonX wanted to win the soccer game.", "update": "They are wearing a cap and gown", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11060", "update_paraphrase": "They are wearing a graduation gown and cap.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22158730158730156, "pred_conf_shift": -0.0007641911506652832, "syntactic_distance": 0.0}]}, "atomic.train.25230": {"original_confidence": [0.8983559012413025, 0.10164400935173035], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.9806411266326904, 0.019358910620212555], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.25230.gpt3.1", "original_example": {"example_id": "atomic.train.25230", "premise_hypothesis_id": "atomic.train.11536", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B1aukSNrm6rTo-d3xwDRfQ==", "AtomicEventRelationId": "Twejy_hMEtcUUP7Q2BCPUw==", "AtomicRelationType": "xAttr", "AtomicInference": "free"}, "premise": "PersonX escapes from PersonX's cage", "hypothesis": "As a result, PersonX feels free", "update": "PersonX is in a locked room with no key.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25230", "update_paraphrase": "PersonX is in a room with no means of escape.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.29226475279106856, "pred_conf_shift": 0.08228522539138794, "syntactic_distance": 0.0}, {"confidence": [0.983489453792572, 0.016510600224137306], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.25230.gpt3.6", "original_example": {"example_id": "atomic.train.25230", "premise_hypothesis_id": "atomic.train.11536", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B1aukSNrm6rTo-d3xwDRfQ==", "AtomicEventRelationId": "Twejy_hMEtcUUP7Q2BCPUw==", "AtomicRelationType": "xAttr", "AtomicInference": "free"}, "premise": "PersonX escapes from PersonX's cage", "hypothesis": "As a result, PersonX feels free", "update": "PersonX is in a locked room with no key.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25230", "update_paraphrase": "PersonX is in a room with no way to get out.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.32348484848484843, "pred_conf_shift": 0.08513355255126953, "syntactic_distance": 0.125}, {"confidence": [0.9830337762832642, 0.016966357827186584], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.25230.gpt3.2", "original_example": {"example_id": "atomic.train.25230", "premise_hypothesis_id": "atomic.train.11536", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B1aukSNrm6rTo-d3xwDRfQ==", "AtomicEventRelationId": "Twejy_hMEtcUUP7Q2BCPUw==", "AtomicRelationType": "xAttr", "AtomicInference": "free"}, "premise": "PersonX escapes from PersonX's cage", "hypothesis": "As a result, PersonX feels free", "update": "PersonX is in a locked room with no key.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25230", "update_paraphrase": "Person X is in a room with no way to get out.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2970085470085469, "pred_conf_shift": 0.08467787504196167, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.9839205741882324, 0.016079526394605637], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.25230.gpt3.4", "original_example": {"example_id": "atomic.train.25230", "premise_hypothesis_id": "atomic.train.11536", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B1aukSNrm6rTo-d3xwDRfQ==", "AtomicEventRelationId": "Twejy_hMEtcUUP7Q2BCPUw==", "AtomicRelationType": "xAttr", "AtomicInference": "free"}, "premise": "PersonX escapes from PersonX's cage", "hypothesis": "As a result, PersonX feels free", "update": "PersonX is in a locked room with no key.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25230", "update_paraphrase": "PersonX is stuck in a room with no way to get out.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.334157905586477, "pred_conf_shift": 0.08556467294692993, "syntactic_distance": 0.1875}, {"confidence": [0.9553841948509216, 0.04461585730314255], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.25230.gpt3.0", "original_example": {"example_id": "atomic.train.25230", "premise_hypothesis_id": "atomic.train.11536", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B1aukSNrm6rTo-d3xwDRfQ==", "AtomicEventRelationId": "Twejy_hMEtcUUP7Q2BCPUw==", "AtomicRelationType": "xAttr", "AtomicInference": "free"}, "premise": "PersonX escapes from PersonX's cage", "hypothesis": "As a result, PersonX feels free", "update": "PersonX is in a locked room with no key.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25230", "update_paraphrase": "In a locked room, PersonX is trapped with no key.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1578947368421053, "pred_conf_shift": 0.05702829360961914, "syntactic_distance": 0.4090909090909091}, {"confidence": [0.8182388544082642, 0.18176108598709106], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.25230.gpt3.5", "original_example": {"example_id": "atomic.train.25230", "premise_hypothesis_id": "atomic.train.11536", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B1aukSNrm6rTo-d3xwDRfQ==", "AtomicEventRelationId": "Twejy_hMEtcUUP7Q2BCPUw==", "AtomicRelationType": "xAttr", "AtomicInference": "free"}, "premise": "PersonX escapes from PersonX's cage", "hypothesis": "As a result, PersonX feels free", "update": "PersonX is in a locked room with no key.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25230", "update_paraphrase": "There is no key for the locked room that PersonX is in.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39024943310657595, "pred_conf_shift": -0.08011704683303833, "syntactic_distance": 0.25}, {"confidence": [0.97967529296875, 0.02032472938299179], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.25230.gpt3.3", "original_example": {"example_id": "atomic.train.25230", "premise_hypothesis_id": "atomic.train.11536", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B1aukSNrm6rTo-d3xwDRfQ==", "AtomicEventRelationId": "Twejy_hMEtcUUP7Q2BCPUw==", "AtomicRelationType": "xAttr", "AtomicInference": "free"}, "premise": "PersonX escapes from PersonX's cage", "hypothesis": "As a result, PersonX feels free", "update": "PersonX is in a locked room with no key.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25230", "update_paraphrase": "PersonX is trapped in a room with no way to escape.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.30238095238095236, "pred_conf_shift": 0.08131939172744751, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.678859531879425, 0.32114043831825256], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.25230.gpt3.7", "original_example": {"example_id": "atomic.train.25230", "premise_hypothesis_id": "atomic.train.11536", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B1aukSNrm6rTo-d3xwDRfQ==", "AtomicEventRelationId": "Twejy_hMEtcUUP7Q2BCPUw==", "AtomicRelationType": "xAttr", "AtomicInference": "free"}, "premise": "PersonX escapes from PersonX's cage", "hypothesis": "As a result, PersonX feels free", "update": "PersonX is in a locked room with no key.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25230", "update_paraphrase": "There is no key to the room where PersonX is locked inside.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45427059712774, "pred_conf_shift": -0.21949636936187744, "syntactic_distance": 0.25}]}, "atomic.train.5100": {"original_confidence": [0.6229310631752014, 0.37706881761550903], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.7285643219947815, 0.2714356780052185], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5100.gpt3.7", "original_example": {"example_id": "atomic.train.5100", "premise_hypothesis_id": "atomic.train.2407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ymD0VMllCDBpoPztCCtdyw==", "AtomicEventRelationId": "uQccsdsCMI42g7Ox4BuYHw==", "AtomicRelationType": "xNeed", "AtomicInference": "to look the other way"}, "premise": "PersonX ignores PersonY's mother", "hypothesis": "Before, PersonX needed to look the other way", "update": "PersonY's mother called PersonX on the telephone.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5100", "update_paraphrase": "PersonY's mother telephoned PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.32599681020733645, "pred_conf_shift": 0.10563325881958008, "syntactic_distance": 0.21052631578947367}, {"confidence": [0.6816980838775635, 0.3183019459247589], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5100.gpt3.4", "original_example": {"example_id": "atomic.train.5100", "premise_hypothesis_id": "atomic.train.2407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ymD0VMllCDBpoPztCCtdyw==", "AtomicEventRelationId": "uQccsdsCMI42g7Ox4BuYHw==", "AtomicRelationType": "xNeed", "AtomicInference": "to look the other way"}, "premise": "PersonX ignores PersonY's mother", "hypothesis": "Before, PersonX needed to look the other way", "update": "PersonY's mother called PersonX on the telephone.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5100", "update_paraphrase": "PersonX received a phone call from PersonY's mother.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.436017316017316, "pred_conf_shift": 0.05876702070236206, "syntactic_distance": 0.13043478260869565}, {"confidence": [0.6936640739440918, 0.3063359558582306], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5100.gpt3.5", "original_example": {"example_id": "atomic.train.5100", "premise_hypothesis_id": "atomic.train.2407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ymD0VMllCDBpoPztCCtdyw==", "AtomicEventRelationId": "uQccsdsCMI42g7Ox4BuYHw==", "AtomicRelationType": "xNeed", "AtomicInference": "to look the other way"}, "premise": "PersonX ignores PersonY's mother", "hypothesis": "Before, PersonX needed to look the other way", "update": "PersonY's mother called PersonX on the telephone.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5100", "update_paraphrase": "PersonX got a call from PersonY's mother on the phone.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28982259570494867, "pred_conf_shift": 0.07073301076889038, "syntactic_distance": 0.2}, {"confidence": [0.6459668874740601, 0.35403308272361755], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5100.gpt3.2", "original_example": {"example_id": "atomic.train.5100", "premise_hypothesis_id": "atomic.train.2407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ymD0VMllCDBpoPztCCtdyw==", "AtomicEventRelationId": "uQccsdsCMI42g7Ox4BuYHw==", "AtomicRelationType": "xNeed", "AtomicInference": "to look the other way"}, "premise": "PersonX ignores PersonY's mother", "hypothesis": "Before, PersonX needed to look the other way", "update": "PersonY's mother called PersonX on the telephone.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5100", "update_paraphrase": "PersonX received a call from PersonY's mother on the telephone.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2739495798319328, "pred_conf_shift": 0.023035824298858643, "syntactic_distance": 0.3}, {"confidence": [0.6578444838523865, 0.3421555459499359], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5100.gpt3.3", "original_example": {"example_id": "atomic.train.5100", "premise_hypothesis_id": "atomic.train.2407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ymD0VMllCDBpoPztCCtdyw==", "AtomicEventRelationId": "uQccsdsCMI42g7Ox4BuYHw==", "AtomicRelationType": "xNeed", "AtomicInference": "to look the other way"}, "premise": "PersonX ignores PersonY's mother", "hypothesis": "Before, PersonX needed to look the other way", "update": "PersonY's mother called PersonX on the telephone.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5100", "update_paraphrase": "PersonX received a call from PersonY's mother.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45030012004801917, "pred_conf_shift": 0.03491342067718506, "syntactic_distance": 0.09090909090909091}, {"confidence": [0.6938310265541077, 0.30616891384124756], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5100.gpt3.8", "original_example": {"example_id": "atomic.train.5100", "premise_hypothesis_id": "atomic.train.2407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ymD0VMllCDBpoPztCCtdyw==", "AtomicEventRelationId": "uQccsdsCMI42g7Ox4BuYHw==", "AtomicRelationType": "xNeed", "AtomicInference": "to look the other way"}, "premise": "PersonX ignores PersonY's mother", "hypothesis": "Before, PersonX needed to look the other way", "update": "PersonY's mother called PersonX on the telephone.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5100", "update_paraphrase": "PersonX got a phone call from PersonY's mother.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42052910052910053, "pred_conf_shift": 0.07089996337890625, "syntactic_distance": 0.13043478260869565}, {"confidence": [0.7181981205940247, 0.28180184960365295], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5100.gpt3.1", "original_example": {"example_id": "atomic.train.5100", "premise_hypothesis_id": "atomic.train.2407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ymD0VMllCDBpoPztCCtdyw==", "AtomicEventRelationId": "uQccsdsCMI42g7Ox4BuYHw==", "AtomicRelationType": "xNeed", "AtomicInference": "to look the other way"}, "premise": "PersonX ignores PersonY's mother", "hypothesis": "Before, PersonX needed to look the other way", "update": "PersonY's mother called PersonX on the telephone.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5100", "update_paraphrase": "PersonY's mother phoned PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.35151515151515145, "pred_conf_shift": 0.09526705741882324, "syntactic_distance": 0.21052631578947367}]}, "atomic.train.18615": {"original_confidence": [0.3331487774848938, 0.6668511629104614], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.10789036750793457, 0.892109751701355], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18615.gpt3.0", "original_example": {"example_id": "atomic.train.18615", "premise_hypothesis_id": "atomic.train.8648", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "TEoFqHgFfzsTZOOchT5h2w==", "AtomicEventRelationId": "Q-FrFTCP-lSkeuDB9qMlxQ==", "AtomicRelationType": "xWant", "AtomicInference": "to eat"}, "premise": "PersonX breaks the fourth wall", "hypothesis": "As a result, PersonX wants to eat", "update": "PersonX is talking about food.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18615", "update_paraphrase": "PersonX is talking about food. This could mean that they are discussing food in general, or perhaps they are discussing a specific food item.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6551724137931034, "pred_conf_shift": 0.22525858879089355, "syntactic_distance": 0.45454545454545453}, {"confidence": [0.43757057189941406, 0.5624294281005859], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18615.gpt3.1", "original_example": {"example_id": "atomic.train.18615", "premise_hypothesis_id": "atomic.train.8648", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "TEoFqHgFfzsTZOOchT5h2w==", "AtomicEventRelationId": "Q-FrFTCP-lSkeuDB9qMlxQ==", "AtomicRelationType": "xWant", "AtomicInference": "to eat"}, "premise": "PersonX breaks the fourth wall", "hypothesis": "As a result, PersonX wants to eat", "update": "PersonX is talking about food.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18615", "update_paraphrase": "PersonX is discussing food.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.275599128540305, "pred_conf_shift": -0.10442173480987549, "syntactic_distance": 0.0625}]}, "atomic.train.37056": {"original_confidence": [0.7545424699783325, 0.2454575151205063], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.4735976755619049, 0.5264022946357727], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37056.gpt3.3", "original_example": {"example_id": "atomic.train.37056", "premise_hypothesis_id": "atomic.train.16816", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "0UUtl9lmhIkK_SyhmfOe_w==", "AtomicEventRelationId": "pa2T5VhWC5ezROspB1RCYg==", "AtomicRelationType": "xEffect", "AtomicInference": "Person X breaks his wrist."}, "premise": "PersonX fights hand to hand", "hypothesis": "PersonX then person X breaks his wrist.", "update": "PersonX is the winner", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37056", "update_paraphrase": "X is the winner.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1875, "pred_conf_shift": -0.2809447944164276, "syntactic_distance": 0.0625}, {"confidence": [0.5882777571678162, 0.41172224283218384], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37056.gpt3.1", "original_example": {"example_id": "atomic.train.37056", "premise_hypothesis_id": "atomic.train.16816", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "0UUtl9lmhIkK_SyhmfOe_w==", "AtomicEventRelationId": "pa2T5VhWC5ezROspB1RCYg==", "AtomicRelationType": "xEffect", "AtomicInference": "Person X breaks his wrist."}, "premise": "PersonX fights hand to hand", "hypothesis": "PersonX then person X breaks his wrist.", "update": "PersonX is the winner", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37056", "update_paraphrase": "PersonX is the triumphant one", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23950617283950615, "pred_conf_shift": -0.16626471281051636, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.6944177150726318, 0.3055822253227234], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37056.gpt3.4", "original_example": {"example_id": "atomic.train.37056", "premise_hypothesis_id": "atomic.train.16816", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "0UUtl9lmhIkK_SyhmfOe_w==", "AtomicEventRelationId": "pa2T5VhWC5ezROspB1RCYg==", "AtomicRelationType": "xEffect", "AtomicInference": "Person X breaks his wrist."}, "premise": "PersonX fights hand to hand", "hypothesis": "PersonX then person X breaks his wrist.", "update": "PersonX is the winner", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37056", "update_paraphrase": "PersonX is the victorious one!", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23950617283950615, "pred_conf_shift": -0.060124754905700684, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.4483376443386078, 0.5516623258590698], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37056.gpt3.0", "original_example": {"example_id": "atomic.train.37056", "premise_hypothesis_id": "atomic.train.16816", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "0UUtl9lmhIkK_SyhmfOe_w==", "AtomicEventRelationId": "pa2T5VhWC5ezROspB1RCYg==", "AtomicRelationType": "xEffect", "AtomicInference": "Person X breaks his wrist."}, "premise": "PersonX fights hand to hand", "hypothesis": "PersonX then person X breaks his wrist.", "update": "PersonX is the winner", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37056", "update_paraphrase": "PersonX is the victor.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.16987179487179488, "pred_conf_shift": -0.30620482563972473, "syntactic_distance": 0.0}, {"confidence": [0.9286770224571228, 0.07132304459810257], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37056.gpt3.2", "original_example": {"example_id": "atomic.train.37056", "premise_hypothesis_id": "atomic.train.16816", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "0UUtl9lmhIkK_SyhmfOe_w==", "AtomicEventRelationId": "pa2T5VhWC5ezROspB1RCYg==", "AtomicRelationType": "xEffect", "AtomicInference": "Person X breaks his wrist."}, "premise": "PersonX fights hand to hand", "hypothesis": "PersonX then person X breaks his wrist.", "update": "PersonX is the winner", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37056", "update_paraphrase": "PersonX is the champion!", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.17582417582417587, "pred_conf_shift": 0.17413455247879028, "syntactic_distance": 0.0}]}, "atomic.train.31623": {"original_confidence": [0.12810935080051422, 0.8718905448913574], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.13399644196033478, 0.8660035729408264], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31623.gpt3.2", "original_example": {"example_id": "atomic.train.31623", "premise_hypothesis_id": "atomic.train.14365", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xmWfrNPdvXt-R5cBdihe-g==", "AtomicEventRelationId": "tBdYQD37LozhIxzgfBNPdg==", "AtomicRelationType": "xIntent", "AtomicInference": "to relieve their frustration"}, "premise": "PersonX looks for a dog to kick", "hypothesis": "Because PersonX wanted to relieve their frustration", "update": "They just got cheated on", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31623", "update_paraphrase": "They just experienced being cheated on.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22979797979797978, "pred_conf_shift": -0.005886971950531006, "syntactic_distance": 0.15789473684210525}, {"confidence": [0.14106322824954987, 0.8589368462562561], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31623.gpt3.7", "original_example": {"example_id": "atomic.train.31623", "premise_hypothesis_id": "atomic.train.14365", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xmWfrNPdvXt-R5cBdihe-g==", "AtomicEventRelationId": "tBdYQD37LozhIxzgfBNPdg==", "AtomicRelationType": "xIntent", "AtomicInference": "to relieve their frustration"}, "premise": "PersonX looks for a dog to kick", "hypothesis": "Because PersonX wanted to relieve their frustration", "update": "They just got cheated on", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31623", "update_paraphrase": "They just got cheated on by their partners.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23076923076923073, "pred_conf_shift": -0.012953698635101318, "syntactic_distance": 0.047619047619047616}, {"confidence": [0.16279558837413788, 0.8372045159339905], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31623.gpt3.5", "original_example": {"example_id": "atomic.train.31623", "premise_hypothesis_id": "atomic.train.14365", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xmWfrNPdvXt-R5cBdihe-g==", "AtomicEventRelationId": "tBdYQD37LozhIxzgfBNPdg==", "AtomicRelationType": "xIntent", "AtomicInference": "to relieve their frustration"}, "premise": "PersonX looks for a dog to kick", "hypothesis": "Because PersonX wanted to relieve their frustration", "update": "They just got cheated on", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31623", "update_paraphrase": "They were just cheated on.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2714285714285714, "pred_conf_shift": -0.03468602895736694, "syntactic_distance": 0.25}, {"confidence": [0.3817668855190277, 0.6182330846786499], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31623.gpt3.1", "original_example": {"example_id": "atomic.train.31623", "premise_hypothesis_id": "atomic.train.14365", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xmWfrNPdvXt-R5cBdihe-g==", "AtomicEventRelationId": "tBdYQD37LozhIxzgfBNPdg==", "AtomicRelationType": "xIntent", "AtomicInference": "to relieve their frustration"}, "premise": "PersonX looks for a dog to kick", "hypothesis": "Because PersonX wanted to relieve their frustration", "update": "They just got cheated on", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31623", "update_paraphrase": "Someone just betrayed them by being unfaithful.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5841029341029341, "pred_conf_shift": -0.2536574602127075, "syntactic_distance": 0.2727272727272727}, {"confidence": [0.12173338234424591, 0.8782665729522705], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31623.gpt3.4", "original_example": {"example_id": "atomic.train.31623", "premise_hypothesis_id": "atomic.train.14365", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xmWfrNPdvXt-R5cBdihe-g==", "AtomicEventRelationId": "tBdYQD37LozhIxzgfBNPdg==", "AtomicRelationType": "xIntent", "AtomicInference": "to relieve their frustration"}, "premise": "PersonX looks for a dog to kick", "hypothesis": "Because PersonX wanted to relieve their frustration", "update": "They just got cheated on", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31623", "update_paraphrase": "They were just cheated on by their partner.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4230769230769231, "pred_conf_shift": 0.006376028060913086, "syntactic_distance": 0.23809523809523808}, {"confidence": [0.2693503201007843, 0.7306496500968933], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31623.gpt3.6", "original_example": {"example_id": "atomic.train.31623", "premise_hypothesis_id": "atomic.train.14365", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xmWfrNPdvXt-R5cBdihe-g==", "AtomicEventRelationId": "tBdYQD37LozhIxzgfBNPdg==", "AtomicRelationType": "xIntent", "AtomicInference": "to relieve their frustration"}, "premise": "PersonX looks for a dog to kick", "hypothesis": "Because PersonX wanted to relieve their frustration", "update": "They just got cheated on", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31623", "update_paraphrase": "Someone just betrayed them by cheating.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.529351961170143, "pred_conf_shift": -0.1412408947944641, "syntactic_distance": 0.2727272727272727}, {"confidence": [0.371246337890625, 0.6287536025047302], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31623.gpt3.3", "original_example": {"example_id": "atomic.train.31623", "premise_hypothesis_id": "atomic.train.14365", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xmWfrNPdvXt-R5cBdihe-g==", "AtomicEventRelationId": "tBdYQD37LozhIxzgfBNPdg==", "AtomicRelationType": "xIntent", "AtomicInference": "to relieve their frustration"}, "premise": "PersonX looks for a dog to kick", "hypothesis": "Because PersonX wanted to relieve their frustration", "update": "They just got cheated on", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31623", "update_paraphrase": "Someone betrayed them by cheating.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.654040404040404, "pred_conf_shift": -0.2431369423866272, "syntactic_distance": 0.4}]}, "atomic.train.29301": {"original_confidence": [0.7108479142189026, 0.2891521453857422], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.8795494437217712, 0.12045050412416458], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29301.gpt3.1", "original_example": {"example_id": "atomic.train.29301", "premise_hypothesis_id": "atomic.train.13297", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "g3opeMnT8Tpk4mLtEen73g==", "AtomicEventRelationId": "xjta_Oi5CFZrCaEn3_EVfg==", "AtomicRelationType": "xAttr", "AtomicInference": "hungry"}, "premise": "PersonX moves into a new apartment", "hypothesis": "As a result, PersonX feels hungry", "update": "PersonX spent all their money on the apartment", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29301", "update_paraphrase": "PersonX forked over all their money for the apartment.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2353946706887884, "pred_conf_shift": -0.1687016412615776, "syntactic_distance": 0.36363636363636365}, {"confidence": [0.6868805289268494, 0.31311947107315063], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29301.gpt3.3", "original_example": {"example_id": "atomic.train.29301", "premise_hypothesis_id": "atomic.train.13297", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "g3opeMnT8Tpk4mLtEen73g==", "AtomicEventRelationId": "xjta_Oi5CFZrCaEn3_EVfg==", "AtomicRelationType": "xAttr", "AtomicInference": "hungry"}, "premise": "PersonX moves into a new apartment", "hypothesis": "As a result, PersonX feels hungry", "update": "PersonX spent all their money on the apartment", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29301", "update_paraphrase": "PersonX spent all of their money on the apartment.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.05882352941176472, "pred_conf_shift": 0.023967325687408447, "syntactic_distance": 0.13043478260869565}, {"confidence": [0.7178278565406799, 0.28217214345932007], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29301.gpt3.4", "original_example": {"example_id": "atomic.train.29301", "premise_hypothesis_id": "atomic.train.13297", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "g3opeMnT8Tpk4mLtEen73g==", "AtomicEventRelationId": "xjta_Oi5CFZrCaEn3_EVfg==", "AtomicRelationType": "xAttr", "AtomicInference": "hungry"}, "premise": "PersonX moves into a new apartment", "hypothesis": "As a result, PersonX feels hungry", "update": "PersonX spent all their money on the apartment", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29301", "update_paraphrase": "Person X spent all of their money on the apartment.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.11965811965811968, "pred_conf_shift": -0.006980001926422119, "syntactic_distance": 0.20833333333333334}, {"confidence": [0.369007408618927, 0.630992591381073], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.29301.gpt3.6", "original_example": {"example_id": "atomic.train.29301", "premise_hypothesis_id": "atomic.train.13297", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "g3opeMnT8Tpk4mLtEen73g==", "AtomicEventRelationId": "xjta_Oi5CFZrCaEn3_EVfg==", "AtomicRelationType": "xAttr", "AtomicInference": "hungry"}, "premise": "PersonX moves into a new apartment", "hypothesis": "As a result, PersonX feels hungry", "update": "PersonX spent all their money on the apartment", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29301", "update_paraphrase": "PersonX blew all their money on the apartment.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0798611111111111, "pred_conf_shift": 0.3418404459953308, "syntactic_distance": 0.0}, {"confidence": [0.6754867434501648, 0.3245132565498352], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29301.gpt3.5", "original_example": {"example_id": "atomic.train.29301", "premise_hypothesis_id": "atomic.train.13297", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "g3opeMnT8Tpk4mLtEen73g==", "AtomicEventRelationId": "xjta_Oi5CFZrCaEn3_EVfg==", "AtomicRelationType": "xAttr", "AtomicInference": "hungry"}, "premise": "PersonX moves into a new apartment", "hypothesis": "As a result, PersonX feels hungry", "update": "PersonX spent all their money on the apartment", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29301", "update_paraphrase": "PersonX used all their money to pay for the apartment.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2561728395061728, "pred_conf_shift": 0.03536111116409302, "syntactic_distance": 0.13043478260869565}, {"confidence": [0.5552968382835388, 0.4447031617164612], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29301.gpt3.2", "original_example": {"example_id": "atomic.train.29301", "premise_hypothesis_id": "atomic.train.13297", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "g3opeMnT8Tpk4mLtEen73g==", "AtomicEventRelationId": "xjta_Oi5CFZrCaEn3_EVfg==", "AtomicRelationType": "xAttr", "AtomicInference": "hungry"}, "premise": "PersonX moves into a new apartment", "hypothesis": "As a result, PersonX feels hungry", "update": "PersonX spent all their money on the apartment", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29301", "update_paraphrase": "PersonX used up all their cash on the apartment.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23673711909006023, "pred_conf_shift": 0.155551016330719, "syntactic_distance": 0.07692307692307693}, {"confidence": [0.7137375473976135, 0.2862623929977417], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29301.gpt3.0", "original_example": {"example_id": "atomic.train.29301", "premise_hypothesis_id": "atomic.train.13297", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "g3opeMnT8Tpk4mLtEen73g==", "AtomicEventRelationId": "xjta_Oi5CFZrCaEn3_EVfg==", "AtomicRelationType": "xAttr", "AtomicInference": "hungry"}, "premise": "PersonX moves into a new apartment", "hypothesis": "As a result, PersonX feels hungry", "update": "PersonX spent all their money on the apartment", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29301", "update_paraphrase": "PersonX used all of their money to purchase the apartment.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2561728395061728, "pred_conf_shift": -0.0028897523880004883, "syntactic_distance": 0.2727272727272727}]}, "atomic.train.37035": {"original_confidence": [0.7671917676925659, 0.2328082174062729], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.7512780427932739, 0.24872201681137085], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37035.gpt3.1", "original_example": {"example_id": "atomic.train.37035", "premise_hypothesis_id": "atomic.train.16806", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "k1YAF81w0jiF8g4ZPRBzFQ==", "AtomicEventRelationId": "dLDIOXWF5h_1xSUmuYNWXw==", "AtomicRelationType": "xEffect", "AtomicInference": "PERSON X GET FEELINGS ABOUT PERSON Y"}, "premise": "PersonX buries PersonY", "hypothesis": "PersonX then pERSON X GET FEELINGS ABOUT PERSON Y", "update": "PersonX realizes PersonX made a mistake.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37035", "update_paraphrase": "PersonX admits PersonX did something wrong.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5044306184012066, "pred_conf_shift": 0.01591379940509796, "syntactic_distance": 0.0}, {"confidence": [0.8688757419586182, 0.13112430274486542], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37035.gpt3.5", "original_example": {"example_id": "atomic.train.37035", "premise_hypothesis_id": "atomic.train.16806", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "k1YAF81w0jiF8g4ZPRBzFQ==", "AtomicEventRelationId": "dLDIOXWF5h_1xSUmuYNWXw==", "AtomicRelationType": "xEffect", "AtomicInference": "PERSON X GET FEELINGS ABOUT PERSON Y"}, "premise": "PersonX buries PersonY", "hypothesis": "PersonX then pERSON X GET FEELINGS ABOUT PERSON Y", "update": "PersonX realizes PersonX made a mistake.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37035", "update_paraphrase": "PersonX understands that PersonX did something wrong.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5251426803463002, "pred_conf_shift": -0.10168391466140747, "syntactic_distance": 0.06666666666666667}, {"confidence": [0.6852983832359314, 0.3147016167640686], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37035.gpt3.2", "original_example": {"example_id": "atomic.train.37035", "premise_hypothesis_id": "atomic.train.16806", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "k1YAF81w0jiF8g4ZPRBzFQ==", "AtomicEventRelationId": "dLDIOXWF5h_1xSUmuYNWXw==", "AtomicRelationType": "xEffect", "AtomicInference": "PERSON X GET FEELINGS ABOUT PERSON Y"}, "premise": "PersonX buries PersonY", "hypothesis": "PersonX then pERSON X GET FEELINGS ABOUT PERSON Y", "update": "PersonX realizes PersonX made a mistake.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37035", "update_paraphrase": "PersonX acknowledges that PersonX made a mistake.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1838056680161943, "pred_conf_shift": 0.08189339935779572, "syntactic_distance": 0.06666666666666667}, {"confidence": [0.8098910450935364, 0.1901090145111084], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37035.gpt3.3", "original_example": {"example_id": "atomic.train.37035", "premise_hypothesis_id": "atomic.train.16806", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "k1YAF81w0jiF8g4ZPRBzFQ==", "AtomicEventRelationId": "dLDIOXWF5h_1xSUmuYNWXw==", "AtomicRelationType": "xEffect", "AtomicInference": "PERSON X GET FEELINGS ABOUT PERSON Y"}, "premise": "PersonX buries PersonY", "hypothesis": "PersonX then pERSON X GET FEELINGS ABOUT PERSON Y", "update": "PersonX realizes PersonX made a mistake.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37035", "update_paraphrase": "PersonX acknowledges that PersonX made an error.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.34638694638694645, "pred_conf_shift": -0.04269920289516449, "syntactic_distance": 0.06666666666666667}, {"confidence": [0.5807961821556091, 0.41920387744903564], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37035.gpt3.6", "original_example": {"example_id": "atomic.train.37035", "premise_hypothesis_id": "atomic.train.16806", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "k1YAF81w0jiF8g4ZPRBzFQ==", "AtomicEventRelationId": "dLDIOXWF5h_1xSUmuYNWXw==", "AtomicRelationType": "xEffect", "AtomicInference": "PERSON X GET FEELINGS ABOUT PERSON Y"}, "premise": "PersonX buries PersonY", "hypothesis": "PersonX then pERSON X GET FEELINGS ABOUT PERSON Y", "update": "PersonX realizes PersonX made a mistake.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37035", "update_paraphrase": "PersonX realizes that he/she made a mistake.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1794871794871794, "pred_conf_shift": 0.18639566004276276, "syntactic_distance": 0.13333333333333333}, {"confidence": [0.9429632425308228, 0.05703681707382202], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37035.gpt3.0", "original_example": {"example_id": "atomic.train.37035", "premise_hypothesis_id": "atomic.train.16806", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "k1YAF81w0jiF8g4ZPRBzFQ==", "AtomicEventRelationId": "dLDIOXWF5h_1xSUmuYNWXw==", "AtomicRelationType": "xEffect", "AtomicInference": "PERSON X GET FEELINGS ABOUT PERSON Y"}, "premise": "PersonX buries PersonY", "hypothesis": "PersonX then pERSON X GET FEELINGS ABOUT PERSON Y", "update": "PersonX realizes PersonX made a mistake.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37035", "update_paraphrase": "PersonX understands that PersonX made an error.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3366253629411524, "pred_conf_shift": -0.17577140033245087, "syntactic_distance": 0.06666666666666667}, {"confidence": [0.8125207424163818, 0.18747924268245697], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37035.gpt3.7", "original_example": {"example_id": "atomic.train.37035", "premise_hypothesis_id": "atomic.train.16806", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "k1YAF81w0jiF8g4ZPRBzFQ==", "AtomicEventRelationId": "dLDIOXWF5h_1xSUmuYNWXw==", "AtomicRelationType": "xEffect", "AtomicInference": "PERSON X GET FEELINGS ABOUT PERSON Y"}, "premise": "PersonX buries PersonY", "hypothesis": "PersonX then pERSON X GET FEELINGS ABOUT PERSON Y", "update": "PersonX realizes PersonX made a mistake.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37035", "update_paraphrase": "PersonX became aware that PersonX had committed a mistake.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.36923076923076925, "pred_conf_shift": -0.04532897472381592, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.7174879312515259, 0.2825120985507965], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37035.gpt3.4", "original_example": {"example_id": "atomic.train.37035", "premise_hypothesis_id": "atomic.train.16806", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "k1YAF81w0jiF8g4ZPRBzFQ==", "AtomicEventRelationId": "dLDIOXWF5h_1xSUmuYNWXw==", "AtomicRelationType": "xEffect", "AtomicInference": "PERSON X GET FEELINGS ABOUT PERSON Y"}, "premise": "PersonX buries PersonY", "hypothesis": "PersonX then pERSON X GET FEELINGS ABOUT PERSON Y", "update": "PersonX realizes PersonX made a mistake.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37035", "update_paraphrase": "PersonX understands that they made a mistake.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2905982905982907, "pred_conf_shift": 0.04970388114452362, "syntactic_distance": 0.13333333333333333}]}, "atomic.train.17948": {"original_confidence": [0.37086597084999084, 0.6291340589523315], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.12403205782175064, 0.8759679794311523], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17948.gpt3.1", "original_example": {"example_id": "atomic.train.17948", "premise_hypothesis_id": "atomic.train.8352", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "N37ZUypdlMDxVNSw2I1R7g==", "AtomicEventRelationId": "-pOSV_YMDbmFJDK3qjsf8A==", "AtomicRelationType": "xEffect", "AtomicInference": "Person x is splashed with water."}, "premise": "PersonX catches two fish", "hypothesis": "PersonX then person x is splashed with water.", "update": "PersonX is fishing from the dock.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17948", "update_paraphrase": "PersonX is casting a line from the dock in hopes of catching a fish.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5311688311688312, "pred_conf_shift": -0.2468339130282402, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.17882585525512695, 0.8211742043495178], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17948.gpt3.3", "original_example": {"example_id": "atomic.train.17948", "premise_hypothesis_id": "atomic.train.8352", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "N37ZUypdlMDxVNSw2I1R7g==", "AtomicEventRelationId": "-pOSV_YMDbmFJDK3qjsf8A==", "AtomicRelationType": "xEffect", "AtomicInference": "Person x is splashed with water."}, "premise": "PersonX catches two fish", "hypothesis": "PersonX then person x is splashed with water.", "update": "PersonX is fishing from the dock.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17948", "update_paraphrase": "PersonX is standing on the dock, fishing.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.32478632478632474, "pred_conf_shift": -0.1920401155948639, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.4255155920982361, 0.5744843482971191], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17948.gpt3.4", "original_example": {"example_id": "atomic.train.17948", "premise_hypothesis_id": "atomic.train.8352", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "N37ZUypdlMDxVNSw2I1R7g==", "AtomicEventRelationId": "-pOSV_YMDbmFJDK3qjsf8A==", "AtomicRelationType": "xEffect", "AtomicInference": "Person x is splashed with water."}, "premise": "PersonX catches two fish", "hypothesis": "PersonX then person x is splashed with water.", "update": "PersonX is fishing from the dock.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17948", "update_paraphrase": "PersonX is fishing from the docks.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.07744107744107742, "pred_conf_shift": 0.05464962124824524, "syntactic_distance": 0.0}, {"confidence": [0.37086597084999084, 0.6291340589523315], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17948.gpt3.5", "original_example": {"example_id": "atomic.train.17948", "premise_hypothesis_id": "atomic.train.8352", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "N37ZUypdlMDxVNSw2I1R7g==", "AtomicEventRelationId": "-pOSV_YMDbmFJDK3qjsf8A==", "AtomicRelationType": "xEffect", "AtomicInference": "Person x is splashed with water."}, "premise": "PersonX catches two fish", "hypothesis": "PersonX then person x is splashed with water.", "update": "PersonX is fishing from the dock.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17948", "update_paraphrase": "PersonX is fishing from the dock.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": 0.0, "syntactic_distance": 0.0}, {"confidence": [0.1741809844970703, 0.8258189558982849], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17948.gpt3.2", "original_example": {"example_id": "atomic.train.17948", "premise_hypothesis_id": "atomic.train.8352", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "N37ZUypdlMDxVNSw2I1R7g==", "AtomicEventRelationId": "-pOSV_YMDbmFJDK3qjsf8A==", "AtomicRelationType": "xEffect", "AtomicInference": "Person x is splashed with water."}, "premise": "PersonX catches two fish", "hypothesis": "PersonX then person x is splashed with water.", "update": "PersonX is fishing from the dock.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17948", "update_paraphrase": "PersonX is fishing off the dock.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.11255411255411257, "pred_conf_shift": -0.19668498635292053, "syntactic_distance": 0.0}, {"confidence": [0.13933028280735016, 0.8606695532798767], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17948.gpt3.0", "original_example": {"example_id": "atomic.train.17948", "premise_hypothesis_id": "atomic.train.8352", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "N37ZUypdlMDxVNSw2I1R7g==", "AtomicEventRelationId": "-pOSV_YMDbmFJDK3qjsf8A==", "AtomicRelationType": "xEffect", "AtomicInference": "Person x is splashed with water."}, "premise": "PersonX catches two fish", "hypothesis": "PersonX then person x is splashed with water.", "update": "PersonX is fishing from the dock.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17948", "update_paraphrase": "PersonX is casting their line from the dock in hopes of catching a fish.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5168831168831168, "pred_conf_shift": -0.23153568804264069, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.3281065821647644, 0.6718934774398804], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17948.gpt3.6", "original_example": {"example_id": "atomic.train.17948", "premise_hypothesis_id": "atomic.train.8352", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "N37ZUypdlMDxVNSw2I1R7g==", "AtomicEventRelationId": "-pOSV_YMDbmFJDK3qjsf8A==", "AtomicRelationType": "xEffect", "AtomicInference": "Person x is splashed with water."}, "premise": "PersonX catches two fish", "hypothesis": "PersonX then person x is splashed with water.", "update": "PersonX is fishing from the dock.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17948", "update_paraphrase": "Person X is fishing from the dock.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.08875739644970415, "pred_conf_shift": -0.04275938868522644, "syntactic_distance": 0.058823529411764705}]}, "atomic.train.9079": {"original_confidence": [0.14834095537662506, 0.8516589403152466], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.39054808020591736, 0.6094518899917603], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9079.gpt3.5", "original_example": {"example_id": "atomic.train.9079", "premise_hypothesis_id": "atomic.train.4279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "imRxIJz-IKXWjeoaygrBhA==", "AtomicEventRelationId": "9IAohk2HP9AlBEhfoMw9Zw==", "AtomicRelationType": "xIntent", "AtomicInference": "to waste time"}, "premise": "PersonX spins around", "hypothesis": "Because PersonX wanted to waste time", "update": "PersonX was unmotivated.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9079", "update_paraphrase": "PersonX was without motivation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.299719887955182, "pred_conf_shift": -0.24220705032348633, "syntactic_distance": 0.2}, {"confidence": [0.07912427186965942, 0.9208758473396301], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9079.gpt3.1", "original_example": {"example_id": "atomic.train.9079", "premise_hypothesis_id": "atomic.train.4279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "imRxIJz-IKXWjeoaygrBhA==", "AtomicEventRelationId": "9IAohk2HP9AlBEhfoMw9Zw==", "AtomicRelationType": "xIntent", "AtomicInference": "to waste time"}, "premise": "PersonX spins around", "hypothesis": "Because PersonX wanted to waste time", "update": "PersonX was unmotivated.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9079", "update_paraphrase": "PersonX was uninterested and unenthused.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39530892448512583, "pred_conf_shift": 0.06921690702438354, "syntactic_distance": 0.125}, {"confidence": [0.3157680034637451, 0.6842320561408997], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9079.gpt3.0", "original_example": {"example_id": "atomic.train.9079", "premise_hypothesis_id": "atomic.train.4279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "imRxIJz-IKXWjeoaygrBhA==", "AtomicEventRelationId": "9IAohk2HP9AlBEhfoMw9Zw==", "AtomicRelationType": "xIntent", "AtomicInference": "to waste time"}, "premise": "PersonX spins around", "hypothesis": "Because PersonX wanted to waste time", "update": "PersonX was unmotivated.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9079", "update_paraphrase": "PersonX didn't have the motivation to do anything.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6904761904761905, "pred_conf_shift": -0.16742688417434692, "syntactic_distance": 0.3125}, {"confidence": [0.25277653336524963, 0.7472234964370728], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9079.gpt3.3", "original_example": {"example_id": "atomic.train.9079", "premise_hypothesis_id": "atomic.train.4279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "imRxIJz-IKXWjeoaygrBhA==", "AtomicEventRelationId": "9IAohk2HP9AlBEhfoMw9Zw==", "AtomicRelationType": "xIntent", "AtomicInference": "to waste time"}, "premise": "PersonX spins around", "hypothesis": "Because PersonX wanted to waste time", "update": "PersonX was unmotivated.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9079", "update_paraphrase": "PersonX didn't have the drive to do anything.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.716991341991342, "pred_conf_shift": -0.10443544387817383, "syntactic_distance": 0.3125}, {"confidence": [0.38438543677330017, 0.6156144738197327], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9079.gpt3.2", "original_example": {"example_id": "atomic.train.9079", "premise_hypothesis_id": "atomic.train.4279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "imRxIJz-IKXWjeoaygrBhA==", "AtomicEventRelationId": "9IAohk2HP9AlBEhfoMw9Zw==", "AtomicRelationType": "xIntent", "AtomicInference": "to waste time"}, "premise": "PersonX spins around", "hypothesis": "Because PersonX wanted to waste time", "update": "PersonX was unmotivated.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9079", "update_paraphrase": "PersonX lacked motivation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4263616557734205, "pred_conf_shift": -0.23604446649551392, "syntactic_distance": 0.21428571428571427}, {"confidence": [0.16414718329906464, 0.8358527421951294], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9079.gpt3.4", "original_example": {"example_id": "atomic.train.9079", "premise_hypothesis_id": "atomic.train.4279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "imRxIJz-IKXWjeoaygrBhA==", "AtomicEventRelationId": "9IAohk2HP9AlBEhfoMw9Zw==", "AtomicRelationType": "xIntent", "AtomicInference": "to waste time"}, "premise": "PersonX spins around", "hypothesis": "Because PersonX wanted to waste time", "update": "PersonX was unmotivated.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9079", "update_paraphrase": "PersonX was not motivated.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2714285714285714, "pred_conf_shift": -0.015806198120117188, "syntactic_distance": 0.2}]}, "atomic.train.9160": {"original_confidence": [0.5277642011642456, 0.47223585844039917], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.17864716053009033, 0.8213528394699097], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9160.gpt3.4", "original_example": {"example_id": "atomic.train.9160", "premise_hypothesis_id": "atomic.train.4319", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "FxYWLmcm1t0nBMMQlY1ZPg==", "AtomicEventRelationId": "3WXH-L2WnuKiyF3Ll1-RKg==", "AtomicRelationType": "xIntent", "AtomicInference": "to get even"}, "premise": "PersonX knocks PersonY out", "hypothesis": "Because PersonX wanted to get even", "update": "PersonY pulls a knife on PersonX.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9160", "update_paraphrase": "PersonY threateningly brandishes a knife at PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3299145299145299, "pred_conf_shift": -0.3491170406341553, "syntactic_distance": 0.08333333333333333}, {"confidence": [0.43446704745292664, 0.5655329823493958], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9160.gpt3.3", "original_example": {"example_id": "atomic.train.9160", "premise_hypothesis_id": "atomic.train.4319", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "FxYWLmcm1t0nBMMQlY1ZPg==", "AtomicEventRelationId": "3WXH-L2WnuKiyF3Ll1-RKg==", "AtomicRelationType": "xIntent", "AtomicInference": "to get even"}, "premise": "PersonX knocks PersonY out", "hypothesis": "Because PersonX wanted to get even", "update": "PersonY pulls a knife on PersonX.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9160", "update_paraphrase": "PersonX is threatened by PersonY who brandishes a knife.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.47492063492063497, "pred_conf_shift": -0.09329715371131897, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.1882130652666092, 0.8117868900299072], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9160.gpt3.0", "original_example": {"example_id": "atomic.train.9160", "premise_hypothesis_id": "atomic.train.4319", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "FxYWLmcm1t0nBMMQlY1ZPg==", "AtomicEventRelationId": "3WXH-L2WnuKiyF3Ll1-RKg==", "AtomicRelationType": "xIntent", "AtomicInference": "to get even"}, "premise": "PersonX knocks PersonY out", "hypothesis": "Because PersonX wanted to get even", "update": "PersonY pulls a knife on PersonX.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9160", "update_paraphrase": "Person Y threatens Person X with a knife.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4775224775224775, "pred_conf_shift": -0.3395511358976364, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.35536491870880127, 0.6446350812911987], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9160.gpt3.2", "original_example": {"example_id": "atomic.train.9160", "premise_hypothesis_id": "atomic.train.4319", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "FxYWLmcm1t0nBMMQlY1ZPg==", "AtomicEventRelationId": "3WXH-L2WnuKiyF3Ll1-RKg==", "AtomicRelationType": "xIntent", "AtomicInference": "to get even"}, "premise": "PersonX knocks PersonY out", "hypothesis": "Because PersonX wanted to get even", "update": "PersonY pulls a knife on PersonX.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9160", "update_paraphrase": "PersonY pulls a knife on PersonX, threatening violence.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1428571428571429, "pred_conf_shift": -0.17239928245544434, "syntactic_distance": 0.09090909090909091}, {"confidence": [0.09665536135435104, 0.9033445715904236], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9160.gpt3.6", "original_example": {"example_id": "atomic.train.9160", "premise_hypothesis_id": "atomic.train.4319", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "FxYWLmcm1t0nBMMQlY1ZPg==", "AtomicEventRelationId": "3WXH-L2WnuKiyF3Ll1-RKg==", "AtomicRelationType": "xIntent", "AtomicInference": "to get even"}, "premise": "PersonX knocks PersonY out", "hypothesis": "Because PersonX wanted to get even", "update": "PersonY pulls a knife on PersonX.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9160", "update_paraphrase": "PersonY threatens PersonX with a knife.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4404040404040404, "pred_conf_shift": -0.43110883980989456, "syntactic_distance": 0.047619047619047616}, {"confidence": [0.5810773968696594, 0.41892263293266296], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9160.gpt3.5", "original_example": {"example_id": "atomic.train.9160", "premise_hypothesis_id": "atomic.train.4319", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "FxYWLmcm1t0nBMMQlY1ZPg==", "AtomicEventRelationId": "3WXH-L2WnuKiyF3Ll1-RKg==", "AtomicRelationType": "xIntent", "AtomicInference": "to get even"}, "premise": "PersonX knocks PersonY out", "hypothesis": "Because PersonX wanted to get even", "update": "PersonY pulls a knife on PersonX.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9160", "update_paraphrase": "Person Y pulls out a knife on person X.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2205128205128204, "pred_conf_shift": 0.05331319570541382, "syntactic_distance": 0.4166666666666667}, {"confidence": [0.19418931007385254, 0.8058106899261475], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9160.gpt3.1", "original_example": {"example_id": "atomic.train.9160", "premise_hypothesis_id": "atomic.train.4319", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "FxYWLmcm1t0nBMMQlY1ZPg==", "AtomicEventRelationId": "3WXH-L2WnuKiyF3Ll1-RKg==", "AtomicRelationType": "xIntent", "AtomicInference": "to get even"}, "premise": "PersonX knocks PersonY out", "hypothesis": "Because PersonX wanted to get even", "update": "PersonY pulls a knife on PersonX.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9160", "update_paraphrase": "PersonY brandishes a knife at PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2916666666666667, "pred_conf_shift": -0.33357489109039307, "syntactic_distance": 0.0}]}, "atomic.train.12724": {"original_confidence": [0.6905087232589722, 0.309491366147995], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.7066856026649475, 0.29331451654434204], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.12724.gpt3.1", "original_example": {"example_id": "atomic.train.12724", "premise_hypothesis_id": "atomic.train.5973", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "yZMnSqX5E16i_AjoxW2mLQ==", "AtomicEventRelationId": "w354Q7FJIa2P5hDZMRjtIQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to be helpful"}, "premise": "PersonX follows the directions", "hypothesis": "Because PersonX wanted to be helpful", "update": "PersonX is an inmate at the local prison.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12724", "update_paraphrase": "PersonX is a prisoner at the local jail.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2613095238095238, "pred_conf_shift": 0.016176879405975342, "syntactic_distance": 0.0}, {"confidence": [0.9047023057937622, 0.095297671854496], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.12724.gpt3.4", "original_example": {"example_id": "atomic.train.12724", "premise_hypothesis_id": "atomic.train.5973", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "yZMnSqX5E16i_AjoxW2mLQ==", "AtomicEventRelationId": "w354Q7FJIa2P5hDZMRjtIQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to be helpful"}, "premise": "PersonX follows the directions", "hypothesis": "Because PersonX wanted to be helpful", "update": "PersonX is an inmate at the local prison.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12724", "update_paraphrase": "PersonX is currently incarcerated at the local prison.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.17440025252525254, "pred_conf_shift": 0.21419358253479004, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.9037840962409973, 0.09621600061655045], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.12724.gpt3.5", "original_example": {"example_id": "atomic.train.12724", "premise_hypothesis_id": "atomic.train.5973", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "yZMnSqX5E16i_AjoxW2mLQ==", "AtomicEventRelationId": "w354Q7FJIa2P5hDZMRjtIQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to be helpful"}, "premise": "PersonX follows the directions", "hypothesis": "Because PersonX wanted to be helpful", "update": "PersonX is an inmate at the local prison.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12724", "update_paraphrase": "PersonX is currently serving time in the local prison.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.26213394448688565, "pred_conf_shift": 0.21327537298202515, "syntactic_distance": 0.21052631578947367}, {"confidence": [0.8868197202682495, 0.11318032443523407], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.12724.gpt3.0", "original_example": {"example_id": "atomic.train.12724", "premise_hypothesis_id": "atomic.train.5973", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "yZMnSqX5E16i_AjoxW2mLQ==", "AtomicEventRelationId": "w354Q7FJIa2P5hDZMRjtIQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to be helpful"}, "premise": "PersonX follows the directions", "hypothesis": "Because PersonX wanted to be helpful", "update": "PersonX is an inmate at the local prison.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12724", "update_paraphrase": "PersonX is currently serving a sentence at the local prison.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2375661375661376, "pred_conf_shift": 0.19631099700927734, "syntactic_distance": 0.21052631578947367}, {"confidence": [0.9152711629867554, 0.08472879230976105], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.12724.gpt3.3", "original_example": {"example_id": "atomic.train.12724", "premise_hypothesis_id": "atomic.train.5973", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "yZMnSqX5E16i_AjoxW2mLQ==", "AtomicEventRelationId": "w354Q7FJIa2P5hDZMRjtIQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to be helpful"}, "premise": "PersonX follows the directions", "hypothesis": "Because PersonX wanted to be helpful", "update": "PersonX is an inmate at the local prison.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12724", "update_paraphrase": "PersonX is currently incarcerated at the nearby prison.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3206845238095238, "pred_conf_shift": 0.2247624397277832, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.8646805286407471, 0.1353195458650589], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.12724.gpt3.2", "original_example": {"example_id": "atomic.train.12724", "premise_hypothesis_id": "atomic.train.5973", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "yZMnSqX5E16i_AjoxW2mLQ==", "AtomicEventRelationId": "w354Q7FJIa2P5hDZMRjtIQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to be helpful"}, "premise": "PersonX follows the directions", "hypothesis": "Because PersonX wanted to be helpful", "update": "PersonX is an inmate at the local prison.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12724", "update_paraphrase": "At the local prison, PersonX is serving time as an inmate.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.368421052631579, "pred_conf_shift": 0.1741718053817749, "syntactic_distance": 0.3181818181818182}, {"confidence": [0.939190685749054, 0.06080932542681694], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.12724.gpt3.6", "original_example": {"example_id": "atomic.train.12724", "premise_hypothesis_id": "atomic.train.5973", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "yZMnSqX5E16i_AjoxW2mLQ==", "AtomicEventRelationId": "w354Q7FJIa2P5hDZMRjtIQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to be helpful"}, "premise": "PersonX follows the directions", "hypothesis": "Because PersonX wanted to be helpful", "update": "PersonX is an inmate at the local prison.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12724", "update_paraphrase": "PersonX is in jail at the local prison.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.16840277777777773, "pred_conf_shift": 0.2486819624900818, "syntactic_distance": 0.2631578947368421}]}, "atomic.train.15684": {"original_confidence": [0.7507146000862122, 0.24928544461727142], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.8812083601951599, 0.11879163980484009], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15684.gpt3.2", "original_example": {"example_id": "atomic.train.15684", "premise_hypothesis_id": "atomic.train.7314", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "AjAd68i9Rj9uHQkBqBuksQ==", "AtomicEventRelationId": "s8vrXvcIq6njt2y5e2K1Tw==", "AtomicRelationType": "xAttr", "AtomicInference": "Determined"}, "premise": "PersonX is within PersonY's power", "hypothesis": "As a result, PersonX feels determined", "update": "PersonX is low ranking", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15684", "update_paraphrase": "PersonX has a low ranking.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.26666666666666666, "pred_conf_shift": 0.13049376010894775, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.9405592083930969, 0.05944075807929039], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15684.gpt3.4", "original_example": {"example_id": "atomic.train.15684", "premise_hypothesis_id": "atomic.train.7314", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "AjAd68i9Rj9uHQkBqBuksQ==", "AtomicEventRelationId": "s8vrXvcIq6njt2y5e2K1Tw==", "AtomicRelationType": "xAttr", "AtomicInference": "Determined"}, "premise": "PersonX is within PersonY's power", "hypothesis": "As a result, PersonX feels determined", "update": "PersonX is low ranking", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15684", "update_paraphrase": "PersonX is not highly ranked.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4001424501424501, "pred_conf_shift": 0.18984460830688477, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.927168071269989, 0.0728318989276886], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15684.gpt3.6", "original_example": {"example_id": "atomic.train.15684", "premise_hypothesis_id": "atomic.train.7314", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "AjAd68i9Rj9uHQkBqBuksQ==", "AtomicEventRelationId": "s8vrXvcIq6njt2y5e2K1Tw==", "AtomicRelationType": "xAttr", "AtomicInference": "Determined"}, "premise": "PersonX is within PersonY's power", "hypothesis": "As a result, PersonX feels determined", "update": "PersonX is low ranking", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15684", "update_paraphrase": "PersonX is not highly ranked or respected.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4995549904640814, "pred_conf_shift": 0.17645347118377686, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.9175578951835632, 0.08244211971759796], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15684.gpt3.3", "original_example": {"example_id": "atomic.train.15684", "premise_hypothesis_id": "atomic.train.7314", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "AjAd68i9Rj9uHQkBqBuksQ==", "AtomicEventRelationId": "s8vrXvcIq6njt2y5e2K1Tw==", "AtomicRelationType": "xAttr", "AtomicInference": "Determined"}, "premise": "PersonX is within PersonY's power", "hypothesis": "As a result, PersonX feels determined", "update": "PersonX is low ranking", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15684", "update_paraphrase": "Person X is not highly ranked or respected.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5158119658119658, "pred_conf_shift": 0.16684329509735107, "syntactic_distance": 0.35}, {"confidence": [0.8865394592285156, 0.11346058547496796], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15684.gpt3.1", "original_example": {"example_id": "atomic.train.15684", "premise_hypothesis_id": "atomic.train.7314", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "AjAd68i9Rj9uHQkBqBuksQ==", "AtomicEventRelationId": "s8vrXvcIq6njt2y5e2K1Tw==", "AtomicRelationType": "xAttr", "AtomicInference": "Determined"}, "premise": "PersonX is within PersonY's power", "hypothesis": "As a result, PersonX feels determined", "update": "PersonX is low ranking", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15684", "update_paraphrase": "PersonX is of low rank or status.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4235537190082644, "pred_conf_shift": 0.13582485914230347, "syntactic_distance": 0.1875}]}, "atomic.train.10936": {"original_confidence": [0.047756537795066833, 0.9522433876991272], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.03294646367430687, 0.9670535326004028], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.10936.gpt3.5", "original_example": {"example_id": "atomic.train.10936", "premise_hypothesis_id": "atomic.train.5147", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "GMtvVquMXLAJnzWp8uiGTA==", "AtomicEventRelationId": "JAgTP2huPJ3AeWfHD6nRLQ==", "AtomicRelationType": "xWant", "AtomicInference": "looks in mirror"}, "premise": "PersonX wears the shirt", "hypothesis": "As a result, PersonX wants looks in mirror", "update": "PersonX is very fat and ashamed", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10936", "update_paraphrase": "PersonX is very overweight and feels ashamed of themselves.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3839153439153438, "pred_conf_shift": -0.014810074120759964, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.03375186771154404, 0.9662482142448425], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.10936.gpt3.3", "original_example": {"example_id": "atomic.train.10936", "premise_hypothesis_id": "atomic.train.5147", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "GMtvVquMXLAJnzWp8uiGTA==", "AtomicEventRelationId": "JAgTP2huPJ3AeWfHD6nRLQ==", "AtomicRelationType": "xWant", "AtomicInference": "looks in mirror"}, "premise": "PersonX wears the shirt", "hypothesis": "As a result, PersonX wants looks in mirror", "update": "PersonX is very fat and ashamed", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10936", "update_paraphrase": "PersonX is overweight and ashamed.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.20070838252656437, "pred_conf_shift": -0.014004670083522797, "syntactic_distance": 0.05263157894736842}, {"confidence": [0.040902674198150635, 0.9590973854064941], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.10936.gpt3.4", "original_example": {"example_id": "atomic.train.10936", "premise_hypothesis_id": "atomic.train.5147", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "GMtvVquMXLAJnzWp8uiGTA==", "AtomicEventRelationId": "JAgTP2huPJ3AeWfHD6nRLQ==", "AtomicRelationType": "xWant", "AtomicInference": "looks in mirror"}, "premise": "PersonX wears the shirt", "hypothesis": "As a result, PersonX wants looks in mirror", "update": "PersonX is very fat and ashamed", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10936", "update_paraphrase": "PersonX is overweight and embarrassed about it.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.43269410328233854, "pred_conf_shift": -0.006853863596916199, "syntactic_distance": 0.15}, {"confidence": [0.02560638077557087, 0.9743936061859131], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.10936.gpt3.0", "original_example": {"example_id": "atomic.train.10936", "premise_hypothesis_id": "atomic.train.5147", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "GMtvVquMXLAJnzWp8uiGTA==", "AtomicEventRelationId": "JAgTP2huPJ3AeWfHD6nRLQ==", "AtomicRelationType": "xWant", "AtomicInference": "looks in mirror"}, "premise": "PersonX wears the shirt", "hypothesis": "As a result, PersonX wants looks in mirror", "update": "PersonX is very fat and ashamed", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10936", "update_paraphrase": "PersonX is obese and feels ashamed.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3470117845117845, "pred_conf_shift": -0.022150157019495964, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.02868831902742386, 0.9713116884231567], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.10936.gpt3.6", "original_example": {"example_id": "atomic.train.10936", "premise_hypothesis_id": "atomic.train.5147", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "GMtvVquMXLAJnzWp8uiGTA==", "AtomicEventRelationId": "JAgTP2huPJ3AeWfHD6nRLQ==", "AtomicRelationType": "xWant", "AtomicInference": "looks in mirror"}, "premise": "PersonX wears the shirt", "hypothesis": "As a result, PersonX wants looks in mirror", "update": "PersonX is very fat and ashamed", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10936", "update_paraphrase": "PersonX is very overweight and feels ashamed.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.24838396897220427, "pred_conf_shift": -0.019068218767642975, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.06355062127113342, 0.936449408531189], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.10936.gpt3.2", "original_example": {"example_id": "atomic.train.10936", "premise_hypothesis_id": "atomic.train.5147", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "GMtvVquMXLAJnzWp8uiGTA==", "AtomicEventRelationId": "JAgTP2huPJ3AeWfHD6nRLQ==", "AtomicRelationType": "xWant", "AtomicInference": "looks in mirror"}, "premise": "PersonX wears the shirt", "hypothesis": "As a result, PersonX wants looks in mirror", "update": "PersonX is very fat and ashamed", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10936", "update_paraphrase": "PersonX is overweight and ashamed of their body.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4466853408029878, "pred_conf_shift": 0.01579408347606659, "syntactic_distance": 0.15789473684210525}, {"confidence": [0.02795933373272419, 0.9720406532287598], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.10936.gpt3.1", "original_example": {"example_id": "atomic.train.10936", "premise_hypothesis_id": "atomic.train.5147", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "GMtvVquMXLAJnzWp8uiGTA==", "AtomicEventRelationId": "JAgTP2huPJ3AeWfHD6nRLQ==", "AtomicRelationType": "xWant", "AtomicInference": "looks in mirror"}, "premise": "PersonX wears the shirt", "hypothesis": "As a result, PersonX wants looks in mirror", "update": "PersonX is very fat and ashamed", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10936", "update_paraphrase": "PersonX is overweight and feels shame.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3308843933843934, "pred_conf_shift": -0.019797204062342644, "syntactic_distance": 0.3333333333333333}]}, "atomic.train.11563": {"original_confidence": [0.40954098105430603, 0.5904589891433716], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.44806045293807983, 0.5519395470619202], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11563.gpt3.1", "original_example": {"example_id": "atomic.train.11563", "premise_hypothesis_id": "atomic.train.5438", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "lP0YlpwV3xXtG906HLcMPA==", "AtomicEventRelationId": "7oQxXDg-RDF2Gv4j8h7jQA==", "AtomicRelationType": "xReact", "AtomicInference": "ashamed"}, "premise": "PersonX loses all of PersonY's money", "hypothesis": "PersonX is seen as ashamed", "update": "PersonX is PersonY's best friend and PersonY did not know that PersonX even took their money.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11563", "update_paraphrase": "PersonX is PersonY's best friend and PersonY was unaware that PersonX had taken their money.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.262467997951869, "pred_conf_shift": -0.038519442081451416, "syntactic_distance": 0.06896551724137931}, {"confidence": [0.8282153010368347, 0.17178462445735931], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11563.gpt3.5", "original_example": {"example_id": "atomic.train.11563", "premise_hypothesis_id": "atomic.train.5438", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "lP0YlpwV3xXtG906HLcMPA==", "AtomicEventRelationId": "7oQxXDg-RDF2Gv4j8h7jQA==", "AtomicRelationType": "xReact", "AtomicInference": "ashamed"}, "premise": "PersonX loses all of PersonY's money", "hypothesis": "PersonX is seen as ashamed", "update": "PersonX is PersonY's best friend and PersonY did not know that PersonX even took their money.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11563", "update_paraphrase": "PersonX took PersonY's money without them knowing and PersonY still considers them their best friend.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4031215200570039, "pred_conf_shift": -0.41867436468601227, "syntactic_distance": 0.25}, {"confidence": [0.09551206231117249, 0.9044878482818604], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11563.gpt3.2", "original_example": {"example_id": "atomic.train.11563", "premise_hypothesis_id": "atomic.train.5438", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "lP0YlpwV3xXtG906HLcMPA==", "AtomicEventRelationId": "7oQxXDg-RDF2Gv4j8h7jQA==", "AtomicRelationType": "xReact", "AtomicInference": "ashamed"}, "premise": "PersonX loses all of PersonY's money", "hypothesis": "PersonX is seen as ashamed", "update": "PersonX is PersonY's best friend and PersonY did not know that PersonX even took their money.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11563", "update_paraphrase": "PersonX is PersonY's best friend, so PersonY was surprised to find out that PersonX had taken their money without them knowing.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.34891820774173715, "pred_conf_shift": 0.31402885913848877, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.287793904542923, 0.7122059464454651], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11563.gpt3.3", "original_example": {"example_id": "atomic.train.11563", "premise_hypothesis_id": "atomic.train.5438", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "lP0YlpwV3xXtG906HLcMPA==", "AtomicEventRelationId": "7oQxXDg-RDF2Gv4j8h7jQA==", "AtomicRelationType": "xReact", "AtomicInference": "ashamed"}, "premise": "PersonX loses all of PersonY's money", "hypothesis": "PersonX is seen as ashamed", "update": "PersonX is PersonY's best friend and PersonY did not know that PersonX even took their money.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11563", "update_paraphrase": "PersonX is PersonY's best friend and PersonY had no idea that PersonX took their money.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19408602150537635, "pred_conf_shift": 0.1217469573020935, "syntactic_distance": 0.06896551724137931}, {"confidence": [0.5848535895347595, 0.41514644026756287], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11563.gpt3.7", "original_example": {"example_id": "atomic.train.11563", "premise_hypothesis_id": "atomic.train.5438", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "lP0YlpwV3xXtG906HLcMPA==", "AtomicEventRelationId": "7oQxXDg-RDF2Gv4j8h7jQA==", "AtomicRelationType": "xReact", "AtomicInference": "ashamed"}, "premise": "PersonX loses all of PersonY's money", "hypothesis": "PersonX is seen as ashamed", "update": "PersonX is PersonY's best friend and PersonY did not know that PersonX even took their money.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11563", "update_paraphrase": "PersonX is PersonY's closest friend, but PersonY was completely unaware that PersonX had stolen their money.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3467428404928405, "pred_conf_shift": -0.17531254887580872, "syntactic_distance": 0.06896551724137931}, {"confidence": [0.0867268443107605, 0.913273274898529], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11563.gpt3.4", "original_example": {"example_id": "atomic.train.11563", "premise_hypothesis_id": "atomic.train.5438", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "lP0YlpwV3xXtG906HLcMPA==", "AtomicEventRelationId": "7oQxXDg-RDF2Gv4j8h7jQA==", "AtomicRelationType": "xReact", "AtomicInference": "ashamed"}, "premise": "PersonX loses all of PersonY's money", "hypothesis": "PersonX is seen as ashamed", "update": "PersonX is PersonY's best friend and PersonY did not know that PersonX even took their money.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11563", "update_paraphrase": "PersonX is personY's best friend, so PersonY was surprised to discover that PersonX had taken their money.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2780904280904281, "pred_conf_shift": 0.32281428575515747, "syntactic_distance": 0.13793103448275862}, {"confidence": [0.1636941134929657, 0.8363058567047119], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11563.gpt3.8", "original_example": {"example_id": "atomic.train.11563", "premise_hypothesis_id": "atomic.train.5438", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "lP0YlpwV3xXtG906HLcMPA==", "AtomicEventRelationId": "7oQxXDg-RDF2Gv4j8h7jQA==", "AtomicRelationType": "xReact", "AtomicInference": "ashamed"}, "premise": "PersonX loses all of PersonY's money", "hypothesis": "PersonX is seen as ashamed", "update": "PersonX is PersonY's best friend and PersonY did not know that PersonX even took their money.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11563", "update_paraphrase": "PersonX is PersonY's bestie, but PersonY had no idea that PersonX would steal from them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3938556067588326, "pred_conf_shift": 0.24584686756134033, "syntactic_distance": 0.06896551724137931}, {"confidence": [0.36126482486724854, 0.6387351155281067], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11563.gpt3.6", "original_example": {"example_id": "atomic.train.11563", "premise_hypothesis_id": "atomic.train.5438", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "lP0YlpwV3xXtG906HLcMPA==", "AtomicEventRelationId": "7oQxXDg-RDF2Gv4j8h7jQA==", "AtomicRelationType": "xReact", "AtomicInference": "ashamed"}, "premise": "PersonX loses all of PersonY's money", "hypothesis": "PersonX is seen as ashamed", "update": "PersonX is PersonY's best friend and PersonY did not know that PersonX even took their money.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11563", "update_paraphrase": "PersonX is PersonY's best friend and PersonY had no idea that PersonX even took their money.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.12646103896103894, "pred_conf_shift": 0.04827612638473511, "syntactic_distance": 0.06896551724137931}, {"confidence": [0.5118769407272339, 0.48812299966812134], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11563.gpt3.0", "original_example": {"example_id": "atomic.train.11563", "premise_hypothesis_id": "atomic.train.5438", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "lP0YlpwV3xXtG906HLcMPA==", "AtomicEventRelationId": "7oQxXDg-RDF2Gv4j8h7jQA==", "AtomicRelationType": "xReact", "AtomicInference": "ashamed"}, "premise": "PersonX loses all of PersonY's money", "hypothesis": "PersonX is seen as ashamed", "update": "PersonX is PersonY's best friend and PersonY did not know that PersonX even took their money.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11563", "update_paraphrase": "PersonX is PersonY's best friend, but PersonY had no idea that PersonX had stolen their money.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28303571428571433, "pred_conf_shift": -0.10233598947525024, "syntactic_distance": 0.06896551724137931}]}, "atomic.train.31865": {"original_confidence": [0.9224465489387512, 0.07755360752344131], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.9605618715286255, 0.039438147097826004], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31865.gpt3.4", "original_example": {"example_id": "atomic.train.31865", "premise_hypothesis_id": "atomic.train.14473", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "feGG3SDt2zAN_U_ve3d2Iw==", "AtomicEventRelationId": "LoBARZ-EcmgBTjx_-oefeg==", "AtomicRelationType": "xAttr", "AtomicInference": "brave"}, "premise": "PersonX ties a narrative bow on something", "hypothesis": "As a result, PersonX feels brave", "update": "PersonX shouldn't even be there", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31865", "update_paraphrase": "PersonX does not belong there.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4153030303030303, "pred_conf_shift": -0.03811546042561531, "syntactic_distance": 0.2}, {"confidence": [0.9759732484817505, 0.02402677945792675], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31865.gpt3.3", "original_example": {"example_id": "atomic.train.31865", "premise_hypothesis_id": "atomic.train.14473", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "feGG3SDt2zAN_U_ve3d2Iw==", "AtomicEventRelationId": "LoBARZ-EcmgBTjx_-oefeg==", "AtomicRelationType": "xAttr", "AtomicInference": "brave"}, "premise": "PersonX ties a narrative bow on something", "hypothesis": "As a result, PersonX feels brave", "update": "PersonX shouldn't even be there", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31865", "update_paraphrase": "PersonX should not be present.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3204545454545454, "pred_conf_shift": -0.053526828065514565, "syntactic_distance": 0.2}, {"confidence": [0.9771012663841248, 0.022898679599165916], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31865.gpt3.1", "original_example": {"example_id": "atomic.train.31865", "premise_hypothesis_id": "atomic.train.14473", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "feGG3SDt2zAN_U_ve3d2Iw==", "AtomicEventRelationId": "LoBARZ-EcmgBTjx_-oefeg==", "AtomicRelationType": "xAttr", "AtomicInference": "brave"}, "premise": "PersonX ties a narrative bow on something", "hypothesis": "As a result, PersonX feels brave", "update": "PersonX shouldn't even be there", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31865", "update_paraphrase": "PersonX being there is a mistake.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5497048406139315, "pred_conf_shift": -0.0546549279242754, "syntactic_distance": 0.4782608695652174}, {"confidence": [0.8496742248535156, 0.1503257155418396], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31865.gpt3.0", "original_example": {"example_id": "atomic.train.31865", "premise_hypothesis_id": "atomic.train.14473", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "feGG3SDt2zAN_U_ve3d2Iw==", "AtomicEventRelationId": "LoBARZ-EcmgBTjx_-oefeg==", "AtomicRelationType": "xAttr", "AtomicInference": "brave"}, "premise": "PersonX ties a narrative bow on something", "hypothesis": "As a result, PersonX feels brave", "update": "PersonX shouldn't even be there", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31865", "update_paraphrase": "There's no reason why PersonX should be at that location.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5021452621452622, "pred_conf_shift": 0.07277210801839828, "syntactic_distance": 0.42105263157894735}, {"confidence": [0.9821851849555969, 0.017814841121435165], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31865.gpt3.2", "original_example": {"example_id": "atomic.train.31865", "premise_hypothesis_id": "atomic.train.14473", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "feGG3SDt2zAN_U_ve3d2Iw==", "AtomicEventRelationId": "LoBARZ-EcmgBTjx_-oefeg==", "AtomicRelationType": "xAttr", "AtomicInference": "brave"}, "premise": "PersonX ties a narrative bow on something", "hypothesis": "As a result, PersonX feels brave", "update": "PersonX shouldn't even be there", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31865", "update_paraphrase": "PersonX's presence isn't welcomed or appreciated.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5935064935064935, "pred_conf_shift": -0.05973876640200615, "syntactic_distance": 0.3181818181818182}, {"confidence": [0.9778030514717102, 0.02219686657190323], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31865.gpt3.6", "original_example": {"example_id": "atomic.train.31865", "premise_hypothesis_id": "atomic.train.14473", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "feGG3SDt2zAN_U_ve3d2Iw==", "AtomicEventRelationId": "LoBARZ-EcmgBTjx_-oefeg==", "AtomicRelationType": "xAttr", "AtomicInference": "brave"}, "premise": "PersonX ties a narrative bow on something", "hypothesis": "As a result, PersonX feels brave", "update": "PersonX shouldn't even be there", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31865", "update_paraphrase": "PersonX's presence is unnecessary and unwelcome.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6412920412920414, "pred_conf_shift": -0.055356740951538086, "syntactic_distance": 0.42857142857142855}, {"confidence": [0.9574370384216309, 0.04256288707256317], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31865.gpt3.5", "original_example": {"example_id": "atomic.train.31865", "premise_hypothesis_id": "atomic.train.14473", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "feGG3SDt2zAN_U_ve3d2Iw==", "AtomicEventRelationId": "LoBARZ-EcmgBTjx_-oefeg==", "AtomicRelationType": "xAttr", "AtomicInference": "brave"}, "premise": "PersonX ties a narrative bow on something", "hypothesis": "As a result, PersonX feels brave", "update": "PersonX shouldn't even be there", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31865", "update_paraphrase": "PersonX has no business being there.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.448051948051948, "pred_conf_shift": -0.03499072045087814, "syntactic_distance": 0.42105263157894735}]}, "atomic.train.4547": {"original_confidence": [0.5288864970207214, 0.47111353278160095], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.18936601281166077, 0.8106339573860168], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4547.gpt3.4", "original_example": {"example_id": "atomic.train.4547", "premise_hypothesis_id": "atomic.train.2141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7auTJKxij8_IKb2P6GRLpw==", "AtomicEventRelationId": "KOXe5e-HFg0p9k4bsAWsWA==", "AtomicRelationType": "xWant", "AtomicInference": "to take a shower"}, "premise": "PersonX is really dirty", "hypothesis": "As a result, PersonX wants to take a shower", "update": "PersonX was walking home and got caked with mud when a car raced through a puddle and spattered them.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4547", "update_paraphrase": "PersonX got completely covered in mud when a car drove through a puddle and splashed them while they were walking home.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3123937908496732, "pred_conf_shift": 0.3395204246044159, "syntactic_distance": 0.25}, {"confidence": [0.28923267126083374, 0.7107672691345215], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4547.gpt3.0", "original_example": {"example_id": "atomic.train.4547", "premise_hypothesis_id": "atomic.train.2141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7auTJKxij8_IKb2P6GRLpw==", "AtomicEventRelationId": "KOXe5e-HFg0p9k4bsAWsWA==", "AtomicRelationType": "xWant", "AtomicInference": "to take a shower"}, "premise": "PersonX is really dirty", "hypothesis": "As a result, PersonX wants to take a shower", "update": "PersonX was walking home and got caked with mud when a car raced through a puddle and spattered them.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4547", "update_paraphrase": "PersonX was walking home when they got hit with a wave of mud after a car drove through a puddle, leaving them completely covered.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.32786670693647446, "pred_conf_shift": 0.23965373635292053, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.24790289998054504, 0.7520970702171326], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4547.gpt3.8", "original_example": {"example_id": "atomic.train.4547", "premise_hypothesis_id": "atomic.train.2141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7auTJKxij8_IKb2P6GRLpw==", "AtomicEventRelationId": "KOXe5e-HFg0p9k4bsAWsWA==", "AtomicRelationType": "xWant", "AtomicInference": "to take a shower"}, "premise": "PersonX is really dirty", "hypothesis": "As a result, PersonX wants to take a shower", "update": "PersonX was walking home and got caked with mud when a car raced through a puddle and spattered them.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4547", "update_paraphrase": "On their way home, PersonX got drenched with mud when a car sped through a puddle, splashing them in the process.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2685286935286936, "pred_conf_shift": 0.2809835374355316, "syntactic_distance": 0.375}, {"confidence": [0.3761464059352875, 0.6238536238670349], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4547.gpt3.7", "original_example": {"example_id": "atomic.train.4547", "premise_hypothesis_id": "atomic.train.2141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7auTJKxij8_IKb2P6GRLpw==", "AtomicEventRelationId": "KOXe5e-HFg0p9k4bsAWsWA==", "AtomicRelationType": "xWant", "AtomicInference": "to take a shower"}, "premise": "PersonX is really dirty", "hypothesis": "As a result, PersonX wants to take a shower", "update": "PersonX was walking home and got caked with mud when a car raced through a puddle and spattered them.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4547", "update_paraphrase": "PersonX was walking home when they were hit with a wave of mud after a car drove through a puddle, splashing them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3289550557843241, "pred_conf_shift": 0.15274009108543396, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.37965643405914307, 0.6203436255455017], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4547.gpt3.5", "original_example": {"example_id": "atomic.train.4547", "premise_hypothesis_id": "atomic.train.2141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7auTJKxij8_IKb2P6GRLpw==", "AtomicEventRelationId": "KOXe5e-HFg0p9k4bsAWsWA==", "AtomicRelationType": "xWant", "AtomicInference": "to take a shower"}, "premise": "PersonX is really dirty", "hypothesis": "As a result, PersonX wants to take a shower", "update": "PersonX was walking home and got caked with mud when a car raced through a puddle and spattered them.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4547", "update_paraphrase": "PersonX was walking home when a car drove though a puddle and splashed mud all over them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22353368309250665, "pred_conf_shift": 0.14923009276390076, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.515453577041626, 0.4845464825630188], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.4547.gpt3.2", "original_example": {"example_id": "atomic.train.4547", "premise_hypothesis_id": "atomic.train.2141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7auTJKxij8_IKb2P6GRLpw==", "AtomicEventRelationId": "KOXe5e-HFg0p9k4bsAWsWA==", "AtomicRelationType": "xWant", "AtomicInference": "to take a shower"}, "premise": "PersonX is really dirty", "hypothesis": "As a result, PersonX wants to take a shower", "update": "PersonX was walking home and got caked with mud when a car raced through a puddle and spattered them.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4547", "update_paraphrase": "PersonX was walking home and got splattered with mud when a car drove through a puddle and hit them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.21454293628808863, "pred_conf_shift": 0.013432949781417847, "syntactic_distance": 0.0}, {"confidence": [0.4988676607608795, 0.5011323690414429], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4547.gpt3.3", "original_example": {"example_id": "atomic.train.4547", "premise_hypothesis_id": "atomic.train.2141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7auTJKxij8_IKb2P6GRLpw==", "AtomicEventRelationId": "KOXe5e-HFg0p9k4bsAWsWA==", "AtomicRelationType": "xWant", "AtomicInference": "to take a shower"}, "premise": "PersonX is really dirty", "hypothesis": "As a result, PersonX wants to take a shower", "update": "PersonX was walking home and got caked with mud when a car raced through a puddle and spattered them.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4547", "update_paraphrase": "PersonX was walking home and got drenched with mud when a car drove through a puddle and splashed them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2118480590616813, "pred_conf_shift": 0.03001883625984192, "syntactic_distance": 0.0}, {"confidence": [0.4444030821323395, 0.5555968880653381], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4547.gpt3.1", "original_example": {"example_id": "atomic.train.4547", "premise_hypothesis_id": "atomic.train.2141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7auTJKxij8_IKb2P6GRLpw==", "AtomicEventRelationId": "KOXe5e-HFg0p9k4bsAWsWA==", "AtomicRelationType": "xWant", "AtomicInference": "to take a shower"}, "premise": "PersonX is really dirty", "hypothesis": "As a result, PersonX wants to take a shower", "update": "PersonX was walking home and got caked with mud when a car raced through a puddle and spattered them.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4547", "update_paraphrase": "PersonX was walking home when a car raced through a puddle and spattered them with mud.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.16858998144712428, "pred_conf_shift": 0.08448335528373718, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.3953273892402649, 0.6046726107597351], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4547.gpt3.6", "original_example": {"example_id": "atomic.train.4547", "premise_hypothesis_id": "atomic.train.2141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7auTJKxij8_IKb2P6GRLpw==", "AtomicEventRelationId": "KOXe5e-HFg0p9k4bsAWsWA==", "AtomicRelationType": "xWant", "AtomicInference": "to take a shower"}, "premise": "PersonX is really dirty", "hypothesis": "As a result, PersonX wants to take a shower", "update": "PersonX was walking home and got caked with mud when a car raced through a puddle and spattered them.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4547", "update_paraphrase": "While PersonX was walking home, a car drove through a puddle and soaked them with muddy water.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.24864718614718612, "pred_conf_shift": 0.13355907797813416, "syntactic_distance": 0.48148148148148145}]}, "atomic.train.29531": {"original_confidence": [0.7057176232337952, 0.2942824363708496], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.9183255434036255, 0.08167444169521332], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29531.gpt3.6", "original_example": {"example_id": "atomic.train.29531", "premise_hypothesis_id": "atomic.train.13400", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "pQ009WW1UinwVbm0njqbBA==", "AtomicEventRelationId": "jDZzEhKjDibHcyz40GyUVg==", "AtomicRelationType": "xWant", "AtomicInference": "buy something nice"}, "premise": "PersonX works so much", "hypothesis": "As a result, PersonX wants buy something nice", "update": "They have tons of recreational income", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29531", "update_paraphrase": "They make a lot of money from recreational activities.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.44798941798941794, "pred_conf_shift": -0.2126079946756363, "syntactic_distance": 0.15789473684210525}, {"confidence": [0.8883556723594666, 0.11164426803588867], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29531.gpt3.1", "original_example": {"example_id": "atomic.train.29531", "premise_hypothesis_id": "atomic.train.13400", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "pQ009WW1UinwVbm0njqbBA==", "AtomicEventRelationId": "jDZzEhKjDibHcyz40GyUVg==", "AtomicRelationType": "xWant", "AtomicInference": "buy something nice"}, "premise": "PersonX works so much", "hypothesis": "As a result, PersonX wants buy something nice", "update": "They have tons of recreational income", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29531", "update_paraphrase": "They have a lot of income from recreational activities.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.40190476190476193, "pred_conf_shift": -0.18263816833496094, "syntactic_distance": 0.0}, {"confidence": [0.8039053082466125, 0.19609466195106506], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29531.gpt3.5", "original_example": {"example_id": "atomic.train.29531", "premise_hypothesis_id": "atomic.train.13400", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "pQ009WW1UinwVbm0njqbBA==", "AtomicEventRelationId": "jDZzEhKjDibHcyz40GyUVg==", "AtomicRelationType": "xWant", "AtomicInference": "buy something nice"}, "premise": "PersonX works so much", "hypothesis": "As a result, PersonX wants buy something nice", "update": "They have tons of recreational income", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29531", "update_paraphrase": "They have a lot of money coming in from recreational activities.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.49234360410830996, "pred_conf_shift": -0.09818777441978455, "syntactic_distance": 0.0625}, {"confidence": [0.9067015647888184, 0.09329842031002045], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29531.gpt3.2", "original_example": {"example_id": "atomic.train.29531", "premise_hypothesis_id": "atomic.train.13400", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "pQ009WW1UinwVbm0njqbBA==", "AtomicEventRelationId": "jDZzEhKjDibHcyz40GyUVg==", "AtomicRelationType": "xWant", "AtomicInference": "buy something nice"}, "premise": "PersonX works so much", "hypothesis": "As a result, PersonX wants buy something nice", "update": "They have tons of recreational income", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29531", "update_paraphrase": "They generate a lot of revenue from recreational activities.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45777777777777784, "pred_conf_shift": -0.20098401606082916, "syntactic_distance": 0.15789473684210525}, {"confidence": [0.921811044216156, 0.07818903028964996], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29531.gpt3.7", "original_example": {"example_id": "atomic.train.29531", "premise_hypothesis_id": "atomic.train.13400", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "pQ009WW1UinwVbm0njqbBA==", "AtomicEventRelationId": "jDZzEhKjDibHcyz40GyUVg==", "AtomicRelationType": "xWant", "AtomicInference": "buy something nice"}, "premise": "PersonX works so much", "hypothesis": "As a result, PersonX wants buy something nice", "update": "They have tons of recreational income", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29531", "update_paraphrase": "They earn a lot of money from recreational activities.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4527513227513227, "pred_conf_shift": -0.21609340608119965, "syntactic_distance": 0.15789473684210525}, {"confidence": [0.9115670919418335, 0.08843287825584412], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29531.gpt3.0", "original_example": {"example_id": "atomic.train.29531", "premise_hypothesis_id": "atomic.train.13400", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "pQ009WW1UinwVbm0njqbBA==", "AtomicEventRelationId": "jDZzEhKjDibHcyz40GyUVg==", "AtomicRelationType": "xWant", "AtomicInference": "buy something nice"}, "premise": "PersonX works so much", "hypothesis": "As a result, PersonX wants buy something nice", "update": "They have tons of recreational income", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29531", "update_paraphrase": "They have a lot of income from recreation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3656771799628943, "pred_conf_shift": -0.2058495581150055, "syntactic_distance": 0.0}, {"confidence": [0.9336403608322144, 0.06635971367359161], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29531.gpt3.4", "original_example": {"example_id": "atomic.train.29531", "premise_hypothesis_id": "atomic.train.13400", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "pQ009WW1UinwVbm0njqbBA==", "AtomicEventRelationId": "jDZzEhKjDibHcyz40GyUVg==", "AtomicRelationType": "xWant", "AtomicInference": "buy something nice"}, "premise": "PersonX works so much", "hypothesis": "As a result, PersonX wants buy something nice", "update": "They have tons of recreational income", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29531", "update_paraphrase": "They generate a lot of revenue from recreation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.43407544836116263, "pred_conf_shift": -0.227922722697258, "syntactic_distance": 0.15789473684210525}]}, "atomic.train.30749": {"original_confidence": [0.9294024705886841, 0.07059752941131592], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.2869838774204254, 0.713016152381897], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30749.gpt3.0", "original_example": {"example_id": "atomic.train.30749", "premise_hypothesis_id": "atomic.train.13961", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "PemJpv04EMS58cGFrSpqRQ==", "AtomicEventRelationId": "V7idsfbqaeqNUBR22o8CSA==", "AtomicRelationType": "xWant", "AtomicInference": "Talks to her"}, "premise": "PersonX goes to PersonY's grandmother 's house", "hypothesis": "As a result, PersonX wants talks to her", "update": "PersonX asked PersonY for a favor.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30749", "update_paraphrase": "PersonX made a request of PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4038359788359788, "pred_conf_shift": 0.642418622970581, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.9488140344619751, 0.05118594318628311], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.30749.gpt3.1", "original_example": {"example_id": "atomic.train.30749", "premise_hypothesis_id": "atomic.train.13961", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "PemJpv04EMS58cGFrSpqRQ==", "AtomicEventRelationId": "V7idsfbqaeqNUBR22o8CSA==", "AtomicRelationType": "xWant", "AtomicInference": "Talks to her"}, "premise": "PersonX goes to PersonY's grandmother 's house", "hypothesis": "As a result, PersonX wants talks to her", "update": "PersonX asked PersonY for a favor.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30749", "update_paraphrase": "PersonX requested a favor from PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.24801587301587302, "pred_conf_shift": -0.019411586225032806, "syntactic_distance": 0.09523809523809523}]}, "atomic.train.2880": {"original_confidence": [0.5170183181762695, 0.48298168182373047], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.8216347694396973, 0.17836523056030273], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2880.gpt3.0", "original_example": {"example_id": "atomic.train.2880", "premise_hypothesis_id": "atomic.train.1356", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "NMNaV6wTblhFvNr3hgM7Cg==", "AtomicEventRelationId": "Gr7h_gs696KgRbBmj8wt3A==", "AtomicRelationType": "xReact", "AtomicInference": "completed"}, "premise": "PersonX uses PersonX's eyes", "hypothesis": "PersonX is seen as completed", "update": "Seeing is a natural thing.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2880", "update_paraphrase": "It's natural to see things.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39151515151515154, "pred_conf_shift": 0.30461645126342773, "syntactic_distance": 0.5555555555555556}, {"confidence": [0.4546511769294739, 0.5453488230705261], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2880.gpt3.2", "original_example": {"example_id": "atomic.train.2880", "premise_hypothesis_id": "atomic.train.1356", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "NMNaV6wTblhFvNr3hgM7Cg==", "AtomicEventRelationId": "Gr7h_gs696KgRbBmj8wt3A==", "AtomicRelationType": "xReact", "AtomicInference": "completed"}, "premise": "PersonX uses PersonX's eyes", "hypothesis": "PersonX is seen as completed", "update": "Seeing is a natural thing.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2880", "update_paraphrase": "The ability to see is a natural thing.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28205128205128205, "pred_conf_shift": -0.062367141246795654, "syntactic_distance": 0.18181818181818182}, {"confidence": [0.6351738572120667, 0.3648260235786438], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2880.gpt3.3", "original_example": {"example_id": "atomic.train.2880", "premise_hypothesis_id": "atomic.train.1356", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "NMNaV6wTblhFvNr3hgM7Cg==", "AtomicEventRelationId": "Gr7h_gs696KgRbBmj8wt3A==", "AtomicRelationType": "xReact", "AtomicInference": "completed"}, "premise": "PersonX uses PersonX's eyes", "hypothesis": "PersonX is seen as completed", "update": "Seeing is a natural thing.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2880", "update_paraphrase": "What we see with our eyes is natural.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5247863247863247, "pred_conf_shift": 0.11815553903579712, "syntactic_distance": 0.38095238095238093}, {"confidence": [0.8162616491317749, 0.18373830616474152], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2880.gpt3.4", "original_example": {"example_id": "atomic.train.2880", "premise_hypothesis_id": "atomic.train.1356", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "NMNaV6wTblhFvNr3hgM7Cg==", "AtomicEventRelationId": "Gr7h_gs696KgRbBmj8wt3A==", "AtomicRelationType": "xReact", "AtomicInference": "completed"}, "premise": "PersonX uses PersonX's eyes", "hypothesis": "PersonX is seen as completed", "update": "Seeing is a natural thing.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2880", "update_paraphrase": "It is natural to see things.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3877410468319559, "pred_conf_shift": 0.29924333095550537, "syntactic_distance": 0.4}, {"confidence": [0.22092847526073456, 0.779071569442749], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2880.gpt3.6", "original_example": {"example_id": "atomic.train.2880", "premise_hypothesis_id": "atomic.train.1356", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "NMNaV6wTblhFvNr3hgM7Cg==", "AtomicEventRelationId": "Gr7h_gs696KgRbBmj8wt3A==", "AtomicRelationType": "xReact", "AtomicInference": "completed"}, "premise": "PersonX uses PersonX's eyes", "hypothesis": "PersonX is seen as completed", "update": "Seeing is a natural thing.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2880", "update_paraphrase": "The ability to see is a natural human ability.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.411904761904762, "pred_conf_shift": -0.296089842915535, "syntactic_distance": 0.21739130434782608}, {"confidence": [0.5875275135040283, 0.4124724566936493], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2880.gpt3.5", "original_example": {"example_id": "atomic.train.2880", "premise_hypothesis_id": "atomic.train.1356", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "NMNaV6wTblhFvNr3hgM7Cg==", "AtomicEventRelationId": "Gr7h_gs696KgRbBmj8wt3A==", "AtomicRelationType": "xReact", "AtomicInference": "completed"}, "premise": "PersonX uses PersonX's eyes", "hypothesis": "PersonX is seen as completed", "update": "Seeing is a natural thing.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2880", "update_paraphrase": "It is natural to see.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45119047619047625, "pred_conf_shift": 0.07050919532775879, "syntactic_distance": 0.4}, {"confidence": [0.4998907148838043, 0.5001092553138733], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2880.gpt3.1", "original_example": {"example_id": "atomic.train.2880", "premise_hypothesis_id": "atomic.train.1356", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "NMNaV6wTblhFvNr3hgM7Cg==", "AtomicEventRelationId": "Gr7h_gs696KgRbBmj8wt3A==", "AtomicRelationType": "xReact", "AtomicInference": "completed"}, "premise": "PersonX uses PersonX's eyes", "hypothesis": "PersonX is seen as completed", "update": "Seeing is a natural thing.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2880", "update_paraphrase": "There's nothing unusual about seeing.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5327561327561328, "pred_conf_shift": -0.01712760329246521, "syntactic_distance": 0.3333333333333333}]}, "atomic.train.6531": {"original_confidence": [0.1642078459262848, 0.8357922434806824], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.14814428985118866, 0.8518556356430054], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.6531.gpt3.6", "original_example": {"example_id": "atomic.train.6531", "premise_hypothesis_id": "atomic.train.3087", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "vQLkkQd-SpmaaJzaWB2PWg==", "AtomicEventRelationId": "tNWd2UeDVupHIvho73GpbQ==", "AtomicRelationType": "xNeed", "AtomicInference": "cut them off"}, "premise": "PersonX keeps PersonY's hands", "hypothesis": "Before, PersonX needed cut them off", "update": "PersonX is a serial killer.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6531", "update_paraphrase": "PersonX is a person who commits multiple murders.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37465952850568235, "pred_conf_shift": 0.016063392162322998, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.17794539034366608, 0.8220545649528503], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.6531.gpt3.3", "original_example": {"example_id": "atomic.train.6531", "premise_hypothesis_id": "atomic.train.3087", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "vQLkkQd-SpmaaJzaWB2PWg==", "AtomicEventRelationId": "tNWd2UeDVupHIvho73GpbQ==", "AtomicRelationType": "xNeed", "AtomicInference": "cut them off"}, "premise": "PersonX keeps PersonY's hands", "hypothesis": "Before, PersonX needed cut them off", "update": "PersonX is a serial killer.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6531", "update_paraphrase": "PersonX is a habitual killer.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.12637362637362637, "pred_conf_shift": -0.013737678527832031, "syntactic_distance": 0.0}, {"confidence": [0.14122791588306427, 0.8587720394134521], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.6531.gpt3.4", "original_example": {"example_id": "atomic.train.6531", "premise_hypothesis_id": "atomic.train.3087", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "vQLkkQd-SpmaaJzaWB2PWg==", "AtomicEventRelationId": "tNWd2UeDVupHIvho73GpbQ==", "AtomicRelationType": "xNeed", "AtomicInference": "cut them off"}, "premise": "PersonX keeps PersonY's hands", "hypothesis": "Before, PersonX needed cut them off", "update": "PersonX is a serial killer.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6531", "update_paraphrase": "PersonX is a habitually murderous individual.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3371212121212121, "pred_conf_shift": 0.022979795932769775, "syntactic_distance": 0.05555555555555555}, {"confidence": [0.18968138098716736, 0.8103185892105103], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.6531.gpt3.0", "original_example": {"example_id": "atomic.train.6531", "premise_hypothesis_id": "atomic.train.3087", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "vQLkkQd-SpmaaJzaWB2PWg==", "AtomicEventRelationId": "tNWd2UeDVupHIvho73GpbQ==", "AtomicRelationType": "xNeed", "AtomicInference": "cut them off"}, "premise": "PersonX keeps PersonY's hands", "hypothesis": "Before, PersonX needed cut them off", "update": "PersonX is a serial killer.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6531", "update_paraphrase": "PersonX is a person who commits murder repeatedly.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37878040762656146, "pred_conf_shift": -0.02547365427017212, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.2203676402568817, 0.7796323299407959], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.6531.gpt3.5", "original_example": {"example_id": "atomic.train.6531", "premise_hypothesis_id": "atomic.train.3087", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "vQLkkQd-SpmaaJzaWB2PWg==", "AtomicEventRelationId": "tNWd2UeDVupHIvho73GpbQ==", "AtomicRelationType": "xNeed", "AtomicInference": "cut them off"}, "premise": "PersonX keeps PersonY's hands", "hypothesis": "Before, PersonX needed cut them off", "update": "PersonX is a serial killer.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6531", "update_paraphrase": "PersonX is a disturbed individual who gets a twisted sense of pleasure from murdering innocent people.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6363498934927506, "pred_conf_shift": -0.056159913539886475, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.17950813472270966, 0.8204918503761292], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.6531.gpt3.8", "original_example": {"example_id": "atomic.train.6531", "premise_hypothesis_id": "atomic.train.3087", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "vQLkkQd-SpmaaJzaWB2PWg==", "AtomicEventRelationId": "tNWd2UeDVupHIvho73GpbQ==", "AtomicRelationType": "xNeed", "AtomicInference": "cut them off"}, "premise": "PersonX keeps PersonY's hands", "hypothesis": "Before, PersonX needed cut them off", "update": "PersonX is a serial killer.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6531", "update_paraphrase": "PersonX is a repeated murderer.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2870879120879122, "pred_conf_shift": -0.015300393104553223, "syntactic_distance": 0.05555555555555555}, {"confidence": [0.09017306566238403, 0.909826934337616], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.6531.gpt3.1", "original_example": {"example_id": "atomic.train.6531", "premise_hypothesis_id": "atomic.train.3087", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "vQLkkQd-SpmaaJzaWB2PWg==", "AtomicEventRelationId": "tNWd2UeDVupHIvho73GpbQ==", "AtomicRelationType": "xNeed", "AtomicInference": "cut them off"}, "premise": "PersonX keeps PersonY's hands", "hypothesis": "Before, PersonX needed cut them off", "update": "PersonX is a serial killer.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6531", "update_paraphrase": "PersonX has committed multiple murders, making them a serial killer.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4114285714285714, "pred_conf_shift": 0.0740346908569336, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.21263574063777924, 0.78736412525177], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.6531.gpt3.2", "original_example": {"example_id": "atomic.train.6531", "premise_hypothesis_id": "atomic.train.3087", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "vQLkkQd-SpmaaJzaWB2PWg==", "AtomicEventRelationId": "tNWd2UeDVupHIvho73GpbQ==", "AtomicRelationType": "xNeed", "AtomicInference": "cut them off"}, "premise": "PersonX keeps PersonY's hands", "hypothesis": "Before, PersonX needed cut them off", "update": "PersonX is a serial killer.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6531", "update_paraphrase": "PersonX is a murderer who preys on innocent people.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4772108843537415, "pred_conf_shift": -0.048428118228912354, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.13638074696063995, 0.8636192083358765], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.6531.gpt3.7", "original_example": {"example_id": "atomic.train.6531", "premise_hypothesis_id": "atomic.train.3087", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "vQLkkQd-SpmaaJzaWB2PWg==", "AtomicEventRelationId": "tNWd2UeDVupHIvho73GpbQ==", "AtomicRelationType": "xNeed", "AtomicInference": "cut them off"}, "premise": "PersonX keeps PersonY's hands", "hypothesis": "Before, PersonX needed cut them off", "update": "PersonX is a serial killer.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6531", "update_paraphrase": "PersonX is a cold-blooded murderer who kills people for sport.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.47139971139971143, "pred_conf_shift": 0.027826964855194092, "syntactic_distance": 0.17647058823529413}]}, "atomic.train.22068": {"original_confidence": [0.5581667423248291, 0.4418332576751709], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.6920320987701416, 0.30796799063682556], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.22068.gpt3.6", "original_example": {"example_id": "atomic.train.22068", "premise_hypothesis_id": "atomic.train.10149", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h5yzQvxySuotaSLeZ-GlKA==", "AtomicEventRelationId": "yGSof7zpSMsbnuwVsNH_1Q==", "AtomicRelationType": "xNeed", "AtomicInference": "to assume PersonX's son's is at fault"}, "premise": "PersonX barks up the wrong tree", "hypothesis": "Before, PersonX needed to assume PersonX's son's is at fault", "update": "PersonX is playing dog charades", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22068", "update_paraphrase": "PersonX is acting out clues for a game of pretend dogs.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5809065934065933, "pred_conf_shift": 0.1338653564453125, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.5810497999191284, 0.4189501404762268], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.22068.gpt3.0", "original_example": {"example_id": "atomic.train.22068", "premise_hypothesis_id": "atomic.train.10149", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h5yzQvxySuotaSLeZ-GlKA==", "AtomicEventRelationId": "yGSof7zpSMsbnuwVsNH_1Q==", "AtomicRelationType": "xNeed", "AtomicInference": "to assume PersonX's son's is at fault"}, "premise": "PersonX barks up the wrong tree", "hypothesis": "Before, PersonX needed to assume PersonX's son's is at fault", "update": "PersonX is playing dog charades", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22068", "update_paraphrase": "PersonX is acting out the behaviors of a dog without using words.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5774591133587673, "pred_conf_shift": 0.022883057594299316, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.714791476726532, 0.285208523273468], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.22068.gpt3.4", "original_example": {"example_id": "atomic.train.22068", "premise_hypothesis_id": "atomic.train.10149", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h5yzQvxySuotaSLeZ-GlKA==", "AtomicEventRelationId": "yGSof7zpSMsbnuwVsNH_1Q==", "AtomicRelationType": "xNeed", "AtomicInference": "to assume PersonX's son's is at fault"}, "premise": "PersonX barks up the wrong tree", "hypothesis": "Before, PersonX needed to assume PersonX's son's is at fault", "update": "PersonX is playing dog charades", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22068", "update_paraphrase": "PersonX is imitating a dog's actions in order to communicate with others.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5947418594477418, "pred_conf_shift": 0.15662473440170288, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.4920313358306885, 0.5079686045646667], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.22068.gpt3.2", "original_example": {"example_id": "atomic.train.22068", "premise_hypothesis_id": "atomic.train.10149", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h5yzQvxySuotaSLeZ-GlKA==", "AtomicEventRelationId": "yGSof7zpSMsbnuwVsNH_1Q==", "AtomicRelationType": "xNeed", "AtomicInference": "to assume PersonX's son's is at fault"}, "premise": "PersonX barks up the wrong tree", "hypothesis": "Before, PersonX needed to assume PersonX's son's is at fault", "update": "PersonX is playing dog charades", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22068", "update_paraphrase": "PersonX is performing charades involving dogs.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.30496562261268145, "pred_conf_shift": -0.06613540649414062, "syntactic_distance": 0.0}, {"confidence": [0.6075065732002258, 0.39249345660209656], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.22068.gpt3.1", "original_example": {"example_id": "atomic.train.22068", "premise_hypothesis_id": "atomic.train.10149", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h5yzQvxySuotaSLeZ-GlKA==", "AtomicEventRelationId": "yGSof7zpSMsbnuwVsNH_1Q==", "AtomicRelationType": "xNeed", "AtomicInference": "to assume PersonX's son's is at fault"}, "premise": "PersonX barks up the wrong tree", "hypothesis": "Before, PersonX needed to assume PersonX's son's is at fault", "update": "PersonX is playing dog charades", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22068", "update_paraphrase": "PersonX is acting out scenes from movies or TV shows involving dogs.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5726626314861609, "pred_conf_shift": 0.04933983087539673, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.557266354560852, 0.44273367524147034], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.22068.gpt3.3", "original_example": {"example_id": "atomic.train.22068", "premise_hypothesis_id": "atomic.train.10149", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h5yzQvxySuotaSLeZ-GlKA==", "AtomicEventRelationId": "yGSof7zpSMsbnuwVsNH_1Q==", "AtomicRelationType": "xNeed", "AtomicInference": "to assume PersonX's son's is at fault"}, "premise": "PersonX barks up the wrong tree", "hypothesis": "Before, PersonX needed to assume PersonX's son's is at fault", "update": "PersonX is playing dog charades", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22068", "update_paraphrase": "PersonX is acting out charades involving dogs.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3856227106227106, "pred_conf_shift": -0.0009003877639770508, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.842827320098877, 0.15717272460460663], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.22068.gpt3.5", "original_example": {"example_id": "atomic.train.22068", "premise_hypothesis_id": "atomic.train.10149", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h5yzQvxySuotaSLeZ-GlKA==", "AtomicEventRelationId": "yGSof7zpSMsbnuwVsNH_1Q==", "AtomicRelationType": "xNeed", "AtomicInference": "to assume PersonX's son's is at fault"}, "premise": "PersonX barks up the wrong tree", "hypothesis": "Before, PersonX needed to assume PersonX's son's is at fault", "update": "PersonX is playing dog charades", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22068", "update_paraphrase": "PersonX is acting out the behaviors of a dog.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5071707704060646, "pred_conf_shift": 0.28466057777404785, "syntactic_distance": 0.058823529411764705}]}, "atomic.train.15705": {"original_confidence": [0.7947822213172913, 0.20521777868270874], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.754174530506134, 0.24582543969154358], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15705.gpt3.6", "original_example": {"example_id": "atomic.train.15705", "premise_hypothesis_id": "atomic.train.7323", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JDNnGzmH6C0qTtCbIgX-Wg==", "AtomicEventRelationId": "qQKLhu1vesOxvOSTdslAhA==", "AtomicRelationType": "xEffect", "AtomicInference": "braided the beard"}, "premise": "PersonX strokes PersonX's beard", "hypothesis": "PersonX then braided the beard", "update": "PersonX is holding their beard with one hand.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15705", "update_paraphrase": "PersonX is using one hand to hold on to their beard.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.35853269537480065, "pred_conf_shift": 0.04060766100883484, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.5697725415229797, 0.43022751808166504], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15705.gpt3.2", "original_example": {"example_id": "atomic.train.15705", "premise_hypothesis_id": "atomic.train.7323", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JDNnGzmH6C0qTtCbIgX-Wg==", "AtomicEventRelationId": "qQKLhu1vesOxvOSTdslAhA==", "AtomicRelationType": "xEffect", "AtomicInference": "braided the beard"}, "premise": "PersonX strokes PersonX's beard", "hypothesis": "PersonX then braided the beard", "update": "PersonX is holding their beard with one hand.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15705", "update_paraphrase": "With one hand, PersonX is gripping/clutching their beard.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2708333333333333, "pred_conf_shift": 0.2250097393989563, "syntactic_distance": 0.2727272727272727}, {"confidence": [0.8507317900657654, 0.14926829934120178], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15705.gpt3.4", "original_example": {"example_id": "atomic.train.15705", "premise_hypothesis_id": "atomic.train.7323", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JDNnGzmH6C0qTtCbIgX-Wg==", "AtomicEventRelationId": "qQKLhu1vesOxvOSTdslAhA==", "AtomicRelationType": "xEffect", "AtomicInference": "braided the beard"}, "premise": "PersonX strokes PersonX's beard", "hypothesis": "PersonX then braided the beard", "update": "PersonX is holding their beard with one hand.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15705", "update_paraphrase": "Person X is gripping their beard with one hand.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1384615384615384, "pred_conf_shift": -0.05594947934150696, "syntactic_distance": 0.05263157894736842}, {"confidence": [0.6222075819969177, 0.3777924180030823], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15705.gpt3.7", "original_example": {"example_id": "atomic.train.15705", "premise_hypothesis_id": "atomic.train.7323", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JDNnGzmH6C0qTtCbIgX-Wg==", "AtomicEventRelationId": "qQKLhu1vesOxvOSTdslAhA==", "AtomicRelationType": "xEffect", "AtomicInference": "braided the beard"}, "premise": "PersonX strokes PersonX's beard", "hypothesis": "PersonX then braided the beard", "update": "PersonX is holding their beard with one hand.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15705", "update_paraphrase": "PersonX is holding their beard in one hand.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.10416666666666669, "pred_conf_shift": 0.17257463932037354, "syntactic_distance": 0.0}, {"confidence": [0.8486220240592957, 0.15137797594070435], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15705.gpt3.0", "original_example": {"example_id": "atomic.train.15705", "premise_hypothesis_id": "atomic.train.7323", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JDNnGzmH6C0qTtCbIgX-Wg==", "AtomicEventRelationId": "qQKLhu1vesOxvOSTdslAhA==", "AtomicRelationType": "xEffect", "AtomicInference": "braided the beard"}, "premise": "PersonX strokes PersonX's beard", "hypothesis": "PersonX then braided the beard", "update": "PersonX is holding their beard with one hand.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15705", "update_paraphrase": "PersonX is gripping their beard with one hand.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.08214285714285713, "pred_conf_shift": -0.053839802742004395, "syntactic_distance": 0.0}, {"confidence": [0.7274348735809326, 0.2725650668144226], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15705.gpt3.1", "original_example": {"example_id": "atomic.train.15705", "premise_hypothesis_id": "atomic.train.7323", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JDNnGzmH6C0qTtCbIgX-Wg==", "AtomicEventRelationId": "qQKLhu1vesOxvOSTdslAhA==", "AtomicRelationType": "xEffect", "AtomicInference": "braided the beard"}, "premise": "PersonX strokes PersonX's beard", "hypothesis": "PersonX then braided the beard", "update": "PersonX is holding their beard with one hand.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15705", "update_paraphrase": "\u3002PersonX is holding their beard with one hand.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.008333333333333304, "pred_conf_shift": 0.06734728813171387, "syntactic_distance": 0.05263157894736842}, {"confidence": [0.7947822213172913, 0.20521777868270874], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15705.gpt3.3", "original_example": {"example_id": "atomic.train.15705", "premise_hypothesis_id": "atomic.train.7323", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JDNnGzmH6C0qTtCbIgX-Wg==", "AtomicEventRelationId": "qQKLhu1vesOxvOSTdslAhA==", "AtomicRelationType": "xEffect", "AtomicInference": "braided the beard"}, "premise": "PersonX strokes PersonX's beard", "hypothesis": "PersonX then braided the beard", "update": "PersonX is holding their beard with one hand.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15705", "update_paraphrase": "PersonX is holding their beard with one hand.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": 0.0, "syntactic_distance": 0.0}, {"confidence": [0.5819950699806213, 0.4180050194263458], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15705.gpt3.5", "original_example": {"example_id": "atomic.train.15705", "premise_hypothesis_id": "atomic.train.7323", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "JDNnGzmH6C0qTtCbIgX-Wg==", "AtomicEventRelationId": "qQKLhu1vesOxvOSTdslAhA==", "AtomicRelationType": "xEffect", "AtomicInference": "braided the beard"}, "premise": "PersonX strokes PersonX's beard", "hypothesis": "PersonX then braided the beard", "update": "PersonX is holding their beard with one hand.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15705", "update_paraphrase": "With one hand, PersonX is gripping their beard.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.26249999999999996, "pred_conf_shift": 0.21278724074363708, "syntactic_distance": 0.2727272727272727}]}, "atomic.train.2782": {"original_confidence": [0.12938424944877625, 0.8706157207489014], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.15815338492393494, 0.8418465256690979], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2782.gpt3.2", "original_example": {"example_id": "atomic.train.2782", "premise_hypothesis_id": "atomic.train.1312", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "nC0OtIZIPZrjudR6x0OhSg==", "AtomicEventRelationId": "t_onAJwCYZr1AfTN1ue9fw==", "AtomicRelationType": "xReact", "AtomicInference": "like he is in a hurry"}, "premise": "PersonX immediately ran", "hypothesis": "PersonX is seen as like he is in a hurry", "update": "Cops are chasing him", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2782", "update_paraphrase": "The police are chasing him.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28888888888888886, "pred_conf_shift": 0.02876913547515869, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.06453435122966766, 0.9354656934738159], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2782.gpt3.3", "original_example": {"example_id": "atomic.train.2782", "premise_hypothesis_id": "atomic.train.1312", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "nC0OtIZIPZrjudR6x0OhSg==", "AtomicEventRelationId": "t_onAJwCYZr1AfTN1ue9fw==", "AtomicRelationType": "xReact", "AtomicInference": "like he is in a hurry"}, "premise": "PersonX immediately ran", "hypothesis": "PersonX is seen as like he is in a hurry", "update": "Cops are chasing him", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2782", "update_paraphrase": "The police are chasing the suspect.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4933333333333334, "pred_conf_shift": -0.06484989821910858, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.07636231929063797, 0.9236377477645874], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2782.gpt3.4", "original_example": {"example_id": "atomic.train.2782", "premise_hypothesis_id": "atomic.train.1312", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "nC0OtIZIPZrjudR6x0OhSg==", "AtomicEventRelationId": "t_onAJwCYZr1AfTN1ue9fw==", "AtomicRelationType": "xReact", "AtomicInference": "like he is in a hurry"}, "premise": "PersonX immediately ran", "hypothesis": "PersonX is seen as like he is in a hurry", "update": "Cops are chasing him", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2782", "update_paraphrase": "The police are in pursuit of him.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.504315886134068, "pred_conf_shift": -0.053021930158138275, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.17387709021568298, 0.8261228203773499], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2782.gpt3.0", "original_example": {"example_id": "atomic.train.2782", "premise_hypothesis_id": "atomic.train.1312", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "nC0OtIZIPZrjudR6x0OhSg==", "AtomicEventRelationId": "t_onAJwCYZr1AfTN1ue9fw==", "AtomicRelationType": "xReact", "AtomicInference": "like he is in a hurry"}, "premise": "PersonX immediately ran", "hypothesis": "PersonX is seen as like he is in a hurry", "update": "Cops are chasing him", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2782", "update_paraphrase": "The cops are chasing him down.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19999999999999996, "pred_conf_shift": 0.04449284076690674, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.18014313280582428, 0.8198569416999817], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2782.gpt3.1", "original_example": {"example_id": "atomic.train.2782", "premise_hypothesis_id": "atomic.train.1312", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "nC0OtIZIPZrjudR6x0OhSg==", "AtomicEventRelationId": "t_onAJwCYZr1AfTN1ue9fw==", "AtomicRelationType": "xReact", "AtomicInference": "like he is in a hurry"}, "premise": "PersonX immediately ran", "hypothesis": "PersonX is seen as like he is in a hurry", "update": "Cops are chasing him", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2782", "update_paraphrase": "The cops are chasing him.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.11111111111111116, "pred_conf_shift": 0.050758883357048035, "syntactic_distance": 0.058823529411764705}]}, "atomic.train.37784": {"original_confidence": [0.12094078958034515, 0.8790592551231384], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.5843732953071594, 0.41562676429748535], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.37784.gpt3.3", "original_example": {"example_id": "atomic.train.37784", "premise_hypothesis_id": "atomic.train.17150", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gQqL7UOu4kO4lzhmFnfjWQ==", "AtomicEventRelationId": "0TrrjYEzqEhj-S4U_Prlcw==", "AtomicRelationType": "xAttr", "AtomicInference": "bad"}, "premise": "PersonX takes PersonY seat", "hypothesis": "As a result, PersonX feels bad", "update": "X is old and disabled.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37784", "update_paraphrase": "Due to his age and disability, X is unable to do much.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5960784313725489, "pred_conf_shift": 0.46343250572681427, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.25008854269981384, 0.7499114871025085], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37784.gpt3.5", "original_example": {"example_id": "atomic.train.37784", "premise_hypothesis_id": "atomic.train.17150", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gQqL7UOu4kO4lzhmFnfjWQ==", "AtomicEventRelationId": "0TrrjYEzqEhj-S4U_Prlcw==", "AtomicRelationType": "xAttr", "AtomicInference": "bad"}, "premise": "PersonX takes PersonY seat", "hypothesis": "As a result, PersonX feels bad", "update": "X is old and disabled.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37784", "update_paraphrase": "X is elderly and unable to move around easily.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.538548752834467, "pred_conf_shift": 0.1291477531194687, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.41632673144340515, 0.5836734175682068], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37784.gpt3.4", "original_example": {"example_id": "atomic.train.37784", "premise_hypothesis_id": "atomic.train.17150", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gQqL7UOu4kO4lzhmFnfjWQ==", "AtomicEventRelationId": "0TrrjYEzqEhj-S4U_Prlcw==", "AtomicRelationType": "xAttr", "AtomicInference": "bad"}, "premise": "PersonX takes PersonY seat", "hypothesis": "As a result, PersonX feels bad", "update": "X is old and disabled.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37784", "update_paraphrase": "X is elderly and physically unable to do much.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5329931972789115, "pred_conf_shift": 0.29538594186306, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.10676237940788269, 0.8932375907897949], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37784.gpt3.1", "original_example": {"example_id": "atomic.train.37784", "premise_hypothesis_id": "atomic.train.17150", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gQqL7UOu4kO4lzhmFnfjWQ==", "AtomicEventRelationId": "0TrrjYEzqEhj-S4U_Prlcw==", "AtomicRelationType": "xAttr", "AtomicInference": "bad"}, "premise": "PersonX takes PersonY seat", "hypothesis": "As a result, PersonX feels bad", "update": "X is old and disabled.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37784", "update_paraphrase": "X is elderly and not able-bodied.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4222222222222222, "pred_conf_shift": -0.014178410172462463, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.3288029134273529, 0.6711971759796143], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37784.gpt3.6", "original_example": {"example_id": "atomic.train.37784", "premise_hypothesis_id": "atomic.train.17150", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gQqL7UOu4kO4lzhmFnfjWQ==", "AtomicEventRelationId": "0TrrjYEzqEhj-S4U_Prlcw==", "AtomicRelationType": "xAttr", "AtomicInference": "bad"}, "premise": "PersonX takes PersonY seat", "hypothesis": "As a result, PersonX feels bad", "update": "X is old and disabled.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37784", "update_paraphrase": "X is elderly and can't move around much.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5264957264957265, "pred_conf_shift": 0.20786212384700775, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.12504619359970093, 0.8749536871910095], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37784.gpt3.2", "original_example": {"example_id": "atomic.train.37784", "premise_hypothesis_id": "atomic.train.17150", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gQqL7UOu4kO4lzhmFnfjWQ==", "AtomicEventRelationId": "0TrrjYEzqEhj-S4U_Prlcw==", "AtomicRelationType": "xAttr", "AtomicInference": "bad"}, "premise": "PersonX takes PersonY seat", "hypothesis": "As a result, PersonX feels bad", "update": "X is old and disabled.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37784", "update_paraphrase": "X is getting up there in age and isn't as mobile as they used to be.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.664021164021164, "pred_conf_shift": 0.004105404019355774, "syntactic_distance": 0.38095238095238093}, {"confidence": [0.2838120758533478, 0.7161879539489746], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.37784.gpt3.0", "original_example": {"example_id": "atomic.train.37784", "premise_hypothesis_id": "atomic.train.17150", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gQqL7UOu4kO4lzhmFnfjWQ==", "AtomicEventRelationId": "0TrrjYEzqEhj-S4U_Prlcw==", "AtomicRelationType": "xAttr", "AtomicInference": "bad"}, "premise": "PersonX takes PersonY seat", "hypothesis": "As a result, PersonX feels bad", "update": "X is old and disabled.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.37784", "update_paraphrase": "X is elderly and physically impaired.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4272727272727273, "pred_conf_shift": 0.16287128627300262, "syntactic_distance": 0.1111111111111111}]}, "atomic.train.7336": {"original_confidence": [0.05216854065656662, 0.9478314518928528], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.11669372767210007, 0.8833062648773193], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.7336.gpt3.7", "original_example": {"example_id": "atomic.train.7336", "premise_hypothesis_id": "atomic.train.3463", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "0rXS_PtfM_hok4GfisREVg==", "AtomicEventRelationId": "MPLf1u_YaIywUgknLBm4rg==", "AtomicRelationType": "xEffect", "AtomicInference": "gets sweaty"}, "premise": "PersonX anxiously awaited", "hypothesis": "PersonX then gets sweaty", "update": "PersonX likes the feeling of a big day.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7336", "update_paraphrase": "PersonX gets excited for big days because they enjoy the feeling.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4921812106022632, "pred_conf_shift": 0.06452518701553345, "syntactic_distance": 0.42857142857142855}, {"confidence": [0.06133054941892624, 0.9386693835258484], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.7336.gpt3.3", "original_example": {"example_id": "atomic.train.7336", "premise_hypothesis_id": "atomic.train.3463", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "0rXS_PtfM_hok4GfisREVg==", "AtomicEventRelationId": "MPLf1u_YaIywUgknLBm4rg==", "AtomicRelationType": "xEffect", "AtomicInference": "gets sweaty"}, "premise": "PersonX anxiously awaited", "hypothesis": "PersonX then gets sweaty", "update": "PersonX likes the feeling of a big day.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7336", "update_paraphrase": "PersonX enjoys feeling accomplished after a big day.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.26241538281979454, "pred_conf_shift": 0.00916200876235962, "syntactic_distance": 0.2}, {"confidence": [0.09340041875839233, 0.9065995812416077], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.7336.gpt3.8", "original_example": {"example_id": "atomic.train.7336", "premise_hypothesis_id": "atomic.train.3463", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "0rXS_PtfM_hok4GfisREVg==", "AtomicEventRelationId": "MPLf1u_YaIywUgknLBm4rg==", "AtomicRelationType": "xEffect", "AtomicInference": "gets sweaty"}, "premise": "PersonX anxiously awaited", "hypothesis": "PersonX then gets sweaty", "update": "PersonX likes the feeling of a big day.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7336", "update_paraphrase": "PersonX enjoys having something to look forward to.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5876893939393939, "pred_conf_shift": 0.041231878101825714, "syntactic_distance": 0.2}, {"confidence": [0.038285307586193085, 0.9617146849632263], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.7336.gpt3.2", "original_example": {"example_id": "atomic.train.7336", "premise_hypothesis_id": "atomic.train.3463", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "0rXS_PtfM_hok4GfisREVg==", "AtomicEventRelationId": "MPLf1u_YaIywUgknLBm4rg==", "AtomicRelationType": "xEffect", "AtomicInference": "gets sweaty"}, "premise": "PersonX anxiously awaited", "hypothesis": "PersonX then gets sweaty", "update": "PersonX likes the feeling of a big day.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7336", "update_paraphrase": "The feeling of excitement and anticipation that comes with a big day is something PersonX enjoys.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.43452380952380953, "pred_conf_shift": -0.013883233070373535, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.08852552622556686, 0.911474347114563], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.7336.gpt3.1", "original_example": {"example_id": "atomic.train.7336", "premise_hypothesis_id": "atomic.train.3463", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "0rXS_PtfM_hok4GfisREVg==", "AtomicEventRelationId": "MPLf1u_YaIywUgknLBm4rg==", "AtomicRelationType": "xEffect", "AtomicInference": "gets sweaty"}, "premise": "PersonX anxiously awaited", "hypothesis": "PersonX then gets sweaty", "update": "PersonX likes the feeling of a big day.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7336", "update_paraphrase": "PersonX enjoys the feeling of having a big day.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19251336898395727, "pred_conf_shift": 0.036356985569000244, "syntactic_distance": 0.0}, {"confidence": [0.10981487482786179, 0.8901850581169128], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.7336.gpt3.4", "original_example": {"example_id": "atomic.train.7336", "premise_hypothesis_id": "atomic.train.3463", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "0rXS_PtfM_hok4GfisREVg==", "AtomicEventRelationId": "MPLf1u_YaIywUgknLBm4rg==", "AtomicRelationType": "xEffect", "AtomicInference": "gets sweaty"}, "premise": "PersonX anxiously awaited", "hypothesis": "PersonX then gets sweaty", "update": "PersonX likes the feeling of a big day.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7336", "update_paraphrase": "PersonX enjoys the feeling of anticipation that comes with a big day.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3118181818181818, "pred_conf_shift": 0.057646334171295166, "syntactic_distance": 0.0625}, {"confidence": [0.06825725734233856, 0.9317426681518555], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.7336.gpt3.6", "original_example": {"example_id": "atomic.train.7336", "premise_hypothesis_id": "atomic.train.3463", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "0rXS_PtfM_hok4GfisREVg==", "AtomicEventRelationId": "MPLf1u_YaIywUgknLBm4rg==", "AtomicRelationType": "xEffect", "AtomicInference": "gets sweaty"}, "premise": "PersonX anxiously awaited", "hypothesis": "PersonX then gets sweaty", "update": "PersonX likes the feeling of a big day.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7336", "update_paraphrase": "PersonX enjoys feeling anticipation for a big day.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2752886002886003, "pred_conf_shift": 0.016088716685771942, "syntactic_distance": 0.2}, {"confidence": [0.29003986716270447, 0.7099601626396179], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.7336.gpt3.5", "original_example": {"example_id": "atomic.train.7336", "premise_hypothesis_id": "atomic.train.3463", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "0rXS_PtfM_hok4GfisREVg==", "AtomicEventRelationId": "MPLf1u_YaIywUgknLBm4rg==", "AtomicRelationType": "xEffect", "AtomicInference": "gets sweaty"}, "premise": "PersonX anxiously awaited", "hypothesis": "PersonX then gets sweaty", "update": "PersonX likes the feeling of a big day.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7336", "update_paraphrase": "PersonX feels good when they have a lot to do in a day.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.48635676492819346, "pred_conf_shift": 0.23787132650613785, "syntactic_distance": 0.3333333333333333}]}, "atomic.train.33654": {"original_confidence": [0.3564518392086029, 0.6435482501983643], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.6536610722541809, 0.3463388979434967], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.33654.gpt3.7", "original_example": {"example_id": "atomic.train.33654", "premise_hypothesis_id": "atomic.train.15278", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4WSYKmdgKs-RbIGncptgA==", "AtomicEventRelationId": "5C9eCpqrHaH_7Y-ymmhB5g==", "AtomicRelationType": "xEffect", "AtomicInference": "reaches for something"}, "premise": "PersonX grabs something", "hypothesis": "PersonX then reaches for something", "update": "PersonX uses a mechanical extender.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.33654", "update_paraphrase": "PersonX uses a machine to help them extend their reach.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.47444755680049794, "pred_conf_shift": 0.297209233045578, "syntactic_distance": 0.15789473684210525}, {"confidence": [0.8369278311729431, 0.1630721241235733], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.33654.gpt3.0", "original_example": {"example_id": "atomic.train.33654", "premise_hypothesis_id": "atomic.train.15278", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4WSYKmdgKs-RbIGncptgA==", "AtomicEventRelationId": "5C9eCpqrHaH_7Y-ymmhB5g==", "AtomicRelationType": "xEffect", "AtomicInference": "reaches for something"}, "premise": "PersonX grabs something", "hypothesis": "PersonX then reaches for something", "update": "PersonX uses a mechanical extender.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.33654", "update_paraphrase": "PersonX uses a device to extend their body mechanically.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4074179788465503, "pred_conf_shift": 0.4804759919643402, "syntactic_distance": 0.21052631578947367}, {"confidence": [0.6914763450622559, 0.30852365493774414], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.33654.gpt3.3", "original_example": {"example_id": "atomic.train.33654", "premise_hypothesis_id": "atomic.train.15278", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4WSYKmdgKs-RbIGncptgA==", "AtomicEventRelationId": "5C9eCpqrHaH_7Y-ymmhB5g==", "AtomicRelationType": "xEffect", "AtomicInference": "reaches for something"}, "premise": "PersonX grabs something", "hypothesis": "PersonX then reaches for something", "update": "PersonX uses a mechanical extender.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.33654", "update_paraphrase": "PersonX has a machine that helps them extend their reach.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5647681294740118, "pred_conf_shift": 0.33502450585365295, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.7465322613716125, 0.2534676790237427], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.33654.gpt3.4", "original_example": {"example_id": "atomic.train.33654", "premise_hypothesis_id": "atomic.train.15278", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4WSYKmdgKs-RbIGncptgA==", "AtomicEventRelationId": "5C9eCpqrHaH_7Y-ymmhB5g==", "AtomicRelationType": "xEffect", "AtomicInference": "reaches for something"}, "premise": "PersonX grabs something", "hypothesis": "PersonX then reaches for something", "update": "PersonX uses a mechanical extender.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.33654", "update_paraphrase": "PersonX relies on a mechanical device to extend their reach.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4865608465608466, "pred_conf_shift": 0.39008042216300964, "syntactic_distance": 0.3684210526315789}, {"confidence": [0.2741655111312866, 0.7258345484733582], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.33654.gpt3.1", "original_example": {"example_id": "atomic.train.33654", "premise_hypothesis_id": "atomic.train.15278", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4WSYKmdgKs-RbIGncptgA==", "AtomicEventRelationId": "5C9eCpqrHaH_7Y-ymmhB5g==", "AtomicRelationType": "xEffect", "AtomicInference": "reaches for something"}, "premise": "PersonX grabs something", "hypothesis": "PersonX then reaches for something", "update": "PersonX uses a mechanical extender.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.33654", "update_paraphrase": "PersonX uses a device to extend their reach.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.399023199023199, "pred_conf_shift": -0.08228632807731628, "syntactic_distance": 0.15789473684210525}, {"confidence": [0.3497735261917114, 0.6502264142036438], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.33654.gpt3.2", "original_example": {"example_id": "atomic.train.33654", "premise_hypothesis_id": "atomic.train.15278", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4WSYKmdgKs-RbIGncptgA==", "AtomicEventRelationId": "5C9eCpqrHaH_7Y-ymmhB5g==", "AtomicRelationType": "xEffect", "AtomicInference": "reaches for something"}, "premise": "PersonX grabs something", "hypothesis": "PersonX then reaches for something", "update": "PersonX uses a mechanical extender.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.33654", "update_paraphrase": "PersonX uses a mechanical device to extend their reach.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3435374149659863, "pred_conf_shift": -0.0066783130168914795, "syntactic_distance": 0.1}, {"confidence": [0.8623717427253723, 0.1376281976699829], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.33654.gpt3.5", "original_example": {"example_id": "atomic.train.33654", "premise_hypothesis_id": "atomic.train.15278", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4WSYKmdgKs-RbIGncptgA==", "AtomicEventRelationId": "5C9eCpqrHaH_7Y-ymmhB5g==", "AtomicRelationType": "xEffect", "AtomicInference": "reaches for something"}, "premise": "PersonX grabs something", "hypothesis": "PersonX then reaches for something", "update": "PersonX uses a mechanical extender.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.33654", "update_paraphrase": "PersonX uses a machine to help them with their reach.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5008211831741243, "pred_conf_shift": 0.5059199035167694, "syntactic_distance": 0.15789473684210525}, {"confidence": [0.8132825493812561, 0.18671734631061554], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.33654.gpt3.6", "original_example": {"example_id": "atomic.train.33654", "premise_hypothesis_id": "atomic.train.15278", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4WSYKmdgKs-RbIGncptgA==", "AtomicEventRelationId": "5C9eCpqrHaH_7Y-ymmhB5g==", "AtomicRelationType": "xEffect", "AtomicInference": "reaches for something"}, "premise": "PersonX grabs something", "hypothesis": "PersonX then reaches for something", "update": "PersonX uses a mechanical extender.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.33654", "update_paraphrase": "PersonX relies on a machine to help them extend their reach.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.584827264239029, "pred_conf_shift": 0.4568307101726532, "syntactic_distance": 0.3157894736842105}]}, "atomic.train.22713": {"original_confidence": [0.30465415120124817, 0.6953458786010742], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.22316285967826843, 0.7768371105194092], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.22713.gpt3.0", "original_example": {"example_id": "atomic.train.22713", "premise_hypothesis_id": "atomic.train.10421", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "erxWB6BQKij1Gv7EVX65FQ==", "AtomicEventRelationId": "vSDDfnI131Bv2LJFcKfKPA==", "AtomicRelationType": "xNeed", "AtomicInference": "to get noisy objects"}, "premise": "PersonX makes loud noises", "hypothesis": "Before, PersonX needed to get noisy objects", "update": "PersonX beats on a drum.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22713", "update_paraphrase": "PersonX hits a drum repeatedly.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3111111111111111, "pred_conf_shift": 0.08149123191833496, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.7692103981971741, 0.23078961670398712], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.22713.gpt3.6", "original_example": {"example_id": "atomic.train.22713", "premise_hypothesis_id": "atomic.train.10421", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "erxWB6BQKij1Gv7EVX65FQ==", "AtomicEventRelationId": "vSDDfnI131Bv2LJFcKfKPA==", "AtomicRelationType": "xNeed", "AtomicInference": "to get noisy objects"}, "premise": "PersonX makes loud noises", "hypothesis": "Before, PersonX needed to get noisy objects", "update": "PersonX beats on a drum.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22713", "update_paraphrase": "PersonX is drumming on a drum.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22251082251082255, "pred_conf_shift": -0.4645562618970871, "syntactic_distance": 0.1875}, {"confidence": [0.5021743774414062, 0.4978255331516266], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.22713.gpt3.2", "original_example": {"example_id": "atomic.train.22713", "premise_hypothesis_id": "atomic.train.10421", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "erxWB6BQKij1Gv7EVX65FQ==", "AtomicEventRelationId": "vSDDfnI131Bv2LJFcKfKPA==", "AtomicRelationType": "xNeed", "AtomicInference": "to get noisy objects"}, "premise": "PersonX makes loud noises", "hypothesis": "Before, PersonX needed to get noisy objects", "update": "PersonX beats on a drum.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22713", "update_paraphrase": "PersonX is pounding on a drum.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2103896103896104, "pred_conf_shift": -0.19752034544944763, "syntactic_distance": 0.1875}, {"confidence": [0.167477548122406, 0.832522451877594], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.22713.gpt3.5", "original_example": {"example_id": "atomic.train.22713", "premise_hypothesis_id": "atomic.train.10421", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "erxWB6BQKij1Gv7EVX65FQ==", "AtomicEventRelationId": "vSDDfnI131Bv2LJFcKfKPA==", "AtomicRelationType": "xNeed", "AtomicInference": "to get noisy objects"}, "premise": "PersonX makes loud noises", "hypothesis": "Before, PersonX needed to get noisy objects", "update": "PersonX beats on a drum.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22713", "update_paraphrase": "PersonX Bangs away on a drum.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.203030303030303, "pred_conf_shift": 0.13717657327651978, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.368482381105423, 0.6315176486968994], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.22713.gpt3.1", "original_example": {"example_id": "atomic.train.22713", "premise_hypothesis_id": "atomic.train.10421", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "erxWB6BQKij1Gv7EVX65FQ==", "AtomicEventRelationId": "vSDDfnI131Bv2LJFcKfKPA==", "AtomicRelationType": "xNeed", "AtomicInference": "to get noisy objects"}, "premise": "PersonX makes loud noises", "hypothesis": "Before, PersonX needed to get noisy objects", "update": "PersonX beats on a drum.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22713", "update_paraphrase": "PersonX hits the drum repeatedly.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4929292929292929, "pred_conf_shift": -0.0638282299041748, "syntactic_distance": 0.2777777777777778}]}, "atomic.train.35902": {"original_confidence": [0.8953195810317993, 0.1046803817152977], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.8953195810317993, 0.1046803817152977], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.35902.gpt3.5", "original_example": {"example_id": "atomic.train.35902", "premise_hypothesis_id": "atomic.train.16280", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "nN2nHoif9tM2a4-qRguKxA==", "AtomicEventRelationId": "cMne149nqzRn44QI5mkzmw==", "AtomicRelationType": "xIntent", "AtomicInference": "to prove dominance"}, "premise": "PersonX beats PersonY's brother", "hypothesis": "Because PersonX wanted to prove dominance", "update": "PersonX is attacked by PersonY's brother.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.35902", "update_paraphrase": "PersonX is attacked by PersonY's brother.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": 0.0, "syntactic_distance": 0.0}, {"confidence": [0.942322850227356, 0.057677093893289566], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.35902.gpt3.1", "original_example": {"example_id": "atomic.train.35902", "premise_hypothesis_id": "atomic.train.16280", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "nN2nHoif9tM2a4-qRguKxA==", "AtomicEventRelationId": "cMne149nqzRn44QI5mkzmw==", "AtomicRelationType": "xIntent", "AtomicInference": "to prove dominance"}, "premise": "PersonX beats PersonY's brother", "hypothesis": "Because PersonX wanted to prove dominance", "update": "PersonX is attacked by PersonY's brother.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.35902", "update_paraphrase": "PersonX is assaulted by PersonY's brother.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.11633986928104578, "pred_conf_shift": 0.04700326919555664, "syntactic_distance": 0.0}, {"confidence": [0.908145010471344, 0.09185485541820526], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.35902.gpt3.2", "original_example": {"example_id": "atomic.train.35902", "premise_hypothesis_id": "atomic.train.16280", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "nN2nHoif9tM2a4-qRguKxA==", "AtomicEventRelationId": "cMne149nqzRn44QI5mkzmw==", "AtomicRelationType": "xIntent", "AtomicInference": "to prove dominance"}, "premise": "PersonX beats PersonY's brother", "hypothesis": "Because PersonX wanted to prove dominance", "update": "PersonX is attacked by PersonY's brother.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.35902", "update_paraphrase": "PersonY's brother attacks PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.38, "pred_conf_shift": 0.012825429439544678, "syntactic_distance": 0.25}, {"confidence": [0.9572237730026245, 0.04277632012963295], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.35902.gpt3.3", "original_example": {"example_id": "atomic.train.35902", "premise_hypothesis_id": "atomic.train.16280", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "nN2nHoif9tM2a4-qRguKxA==", "AtomicEventRelationId": "cMne149nqzRn44QI5mkzmw==", "AtomicRelationType": "xIntent", "AtomicInference": "to prove dominance"}, "premise": "PersonX beats PersonY's brother", "hypothesis": "Because PersonX wanted to prove dominance", "update": "PersonX is attacked by PersonY's brother.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.35902", "update_paraphrase": "PersonX was set upon by PersonY's brother.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.29370629370629375, "pred_conf_shift": 0.061904191970825195, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.8865357041358948, 0.11346433311700821], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.35902.gpt3.4", "original_example": {"example_id": "atomic.train.35902", "premise_hypothesis_id": "atomic.train.16280", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "nN2nHoif9tM2a4-qRguKxA==", "AtomicEventRelationId": "cMne149nqzRn44QI5mkzmw==", "AtomicRelationType": "xIntent", "AtomicInference": "to prove dominance"}, "premise": "PersonX beats PersonY's brother", "hypothesis": "Because PersonX wanted to prove dominance", "update": "PersonX is attacked by PersonY's brother.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.35902", "update_paraphrase": "PersonX is attacked by PersonY's sibling.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.13095238095238093, "pred_conf_shift": -0.008783876895904541, "syntactic_distance": 0.0}, {"confidence": [0.926106870174408, 0.0738932192325592], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.35902.gpt3.0", "original_example": {"example_id": "atomic.train.35902", "premise_hypothesis_id": "atomic.train.16280", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "nN2nHoif9tM2a4-qRguKxA==", "AtomicEventRelationId": "cMne149nqzRn44QI5mkzmw==", "AtomicRelationType": "xIntent", "AtomicInference": "to prove dominance"}, "premise": "PersonX beats PersonY's brother", "hypothesis": "Because PersonX wanted to prove dominance", "update": "PersonX is attacked by PersonY's brother.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.35902", "update_paraphrase": "PersonX was attacked by PersonY's brother.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.11481481481481481, "pred_conf_shift": 0.030787289142608643, "syntactic_distance": 0.0625}, {"confidence": [0.711664080619812, 0.2883358597755432], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.35902.gpt3.6", "original_example": {"example_id": "atomic.train.35902", "premise_hypothesis_id": "atomic.train.16280", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "nN2nHoif9tM2a4-qRguKxA==", "AtomicEventRelationId": "cMne149nqzRn44QI5mkzmw==", "AtomicRelationType": "xIntent", "AtomicInference": "to prove dominance"}, "premise": "PersonX beats PersonY's brother", "hypothesis": "Because PersonX wanted to prove dominance", "update": "PersonX is attacked by PersonY's brother.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.35902", "update_paraphrase": "PersonY's brother launches an attack against PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4647130647130647, "pred_conf_shift": -0.1836555004119873, "syntactic_distance": 0.17647058823529413}]}, "atomic.train.17638": {"original_confidence": [0.38333454728126526, 0.6166654229164124], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.16942007839679718, 0.830579936504364], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17638.gpt3.4", "original_example": {"example_id": "atomic.train.17638", "premise_hypothesis_id": "atomic.train.8211", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mggJ_8Y3wngKFj2sG50pyw==", "AtomicEventRelationId": "hgpsjD80KIFi1D4wO8S3FA==", "AtomicRelationType": "xReact", "AtomicInference": "desperate"}, "premise": "PersonX tries to return it", "hypothesis": "PersonX is seen as desperate", "update": "They have an old library book", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17638", "update_paraphrase": "The book they borrowed from the library is quite old.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5263798701298701, "pred_conf_shift": -0.21391446888446808, "syntactic_distance": 0.45454545454545453}, {"confidence": [0.32956674695014954, 0.6704332232475281], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17638.gpt3.1", "original_example": {"example_id": "atomic.train.17638", "premise_hypothesis_id": "atomic.train.8211", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mggJ_8Y3wngKFj2sG50pyw==", "AtomicEventRelationId": "hgpsjD80KIFi1D4wO8S3FA==", "AtomicRelationType": "xReact", "AtomicInference": "desperate"}, "premise": "PersonX tries to return it", "hypothesis": "PersonX is seen as desperate", "update": "They have an old library book", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17638", "update_paraphrase": "They have an old book from the library.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.21150278293135438, "pred_conf_shift": -0.05376780033111572, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.12364818900823593, 0.8763518333435059], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17638.gpt3.5", "original_example": {"example_id": "atomic.train.17638", "premise_hypothesis_id": "atomic.train.8211", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mggJ_8Y3wngKFj2sG50pyw==", "AtomicEventRelationId": "hgpsjD80KIFi1D4wO8S3FA==", "AtomicRelationType": "xReact", "AtomicInference": "desperate"}, "premise": "PersonX tries to return it", "hypothesis": "PersonX is seen as desperate", "update": "They have an old library book", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17638", "update_paraphrase": "They have a book from the library that is quite old.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4094728800611154, "pred_conf_shift": -0.2596863582730293, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.3567294776439667, 0.6432704329490662], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17638.gpt3.0", "original_example": {"example_id": "atomic.train.17638", "premise_hypothesis_id": "atomic.train.8211", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mggJ_8Y3wngKFj2sG50pyw==", "AtomicEventRelationId": "hgpsjD80KIFi1D4wO8S3FA==", "AtomicRelationType": "xReact", "AtomicInference": "desperate"}, "premise": "PersonX tries to return it", "hypothesis": "PersonX is seen as desperate", "update": "They have an old library book", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17638", "update_paraphrase": "They have an ancient library book.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.16666666666666663, "pred_conf_shift": -0.026605069637298584, "syntactic_distance": 0.0}, {"confidence": [0.14103642106056213, 0.858963668346405], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17638.gpt3.2", "original_example": {"example_id": "atomic.train.17638", "premise_hypothesis_id": "atomic.train.8211", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mggJ_8Y3wngKFj2sG50pyw==", "AtomicEventRelationId": "hgpsjD80KIFi1D4wO8S3FA==", "AtomicRelationType": "xReact", "AtomicInference": "desperate"}, "premise": "PersonX tries to return it", "hypothesis": "PersonX is seen as desperate", "update": "They have an old library book", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17638", "update_paraphrase": "The library book they have is old.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3846153846153846, "pred_conf_shift": -0.24229812622070312, "syntactic_distance": 0.5}, {"confidence": [0.41412585973739624, 0.585874080657959], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17638.gpt3.3", "original_example": {"example_id": "atomic.train.17638", "premise_hypothesis_id": "atomic.train.8211", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mggJ_8Y3wngKFj2sG50pyw==", "AtomicEventRelationId": "hgpsjD80KIFi1D4wO8S3FA==", "AtomicRelationType": "xReact", "AtomicInference": "desperate"}, "premise": "PersonX tries to return it", "hypothesis": "PersonX is seen as desperate", "update": "They have an old library book", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17638", "update_paraphrase": "The library book is old.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3896103896103896, "pred_conf_shift": 0.03079131245613098, "syntactic_distance": 0.42105263157894735}]}, "atomic.train.25742": {"original_confidence": [0.9501675367355347, 0.049832552671432495], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.9626178741455078, 0.0373820960521698], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.25742.gpt3.2", "original_example": {"example_id": "atomic.train.25742", "premise_hypothesis_id": "atomic.train.11757", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B6nxETDDHNpsT_uj_Sehig==", "AtomicEventRelationId": "KKitiIIzgc9n0ZRdORdVXg==", "AtomicRelationType": "xAttr", "AtomicInference": "aggressive"}, "premise": "PersonX holds out PersonY's arms", "hypothesis": "As a result, PersonX feels aggressive", "update": "PersonX is measuring PersonY for a suit", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25742", "update_paraphrase": "PersonX is helping PersonY choose the right size for a suit.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.29497354497354494, "pred_conf_shift": 0.012450337409973145, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.948473334312439, 0.051526669412851334], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.25742.gpt3.3", "original_example": {"example_id": "atomic.train.25742", "premise_hypothesis_id": "atomic.train.11757", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B6nxETDDHNpsT_uj_Sehig==", "AtomicEventRelationId": "KKitiIIzgc9n0ZRdORdVXg==", "AtomicRelationType": "xAttr", "AtomicInference": "aggressive"}, "premise": "PersonX holds out PersonY's arms", "hypothesis": "As a result, PersonX feels aggressive", "update": "PersonX is measuring PersonY for a suit", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25742", "update_paraphrase": "PersonX is taking PersonY's measurements for a suit.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1638095238095238, "pred_conf_shift": -0.0016942024230957031, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.9596429467201233, 0.04035705327987671], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.25742.gpt3.0", "original_example": {"example_id": "atomic.train.25742", "premise_hypothesis_id": "atomic.train.11757", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B6nxETDDHNpsT_uj_Sehig==", "AtomicEventRelationId": "KKitiIIzgc9n0ZRdORdVXg==", "AtomicRelationType": "xAttr", "AtomicInference": "aggressive"}, "premise": "PersonX holds out PersonY's arms", "hypothesis": "As a result, PersonX feels aggressive", "update": "PersonX is measuring PersonY for a suit", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25742", "update_paraphrase": "PersonX is measuring PersonY for a suit.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": 0.009475409984588623, "syntactic_distance": 0.0}, {"confidence": [0.9711562991142273, 0.02884378470480442], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.25742.gpt3.1", "original_example": {"example_id": "atomic.train.25742", "premise_hypothesis_id": "atomic.train.11757", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "B6nxETDDHNpsT_uj_Sehig==", "AtomicEventRelationId": "KKitiIIzgc9n0ZRdORdVXg==", "AtomicRelationType": "xAttr", "AtomicInference": "aggressive"}, "premise": "PersonX holds out PersonY's arms", "hypothesis": "As a result, PersonX feels aggressive", "update": "PersonX is measuring PersonY for a suit", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25742", "update_paraphrase": "PersonX is measuring PersonY to see what size suit they need.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39534662867996206, "pred_conf_shift": 0.020988762378692627, "syntactic_distance": 0.05555555555555555}]}, "atomic.train.1193": {"original_confidence": [0.03513501584529877, 0.9648648500442505], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.04981662333011627, 0.9501832723617554], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1193.gpt3.1", "original_example": {"example_id": "atomic.train.1193", "premise_hypothesis_id": "atomic.train.562", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "46hgB7bya2kC-q8_Snsq7A==", "AtomicEventRelationId": "uyOa6qJ9Sk-VEIPpH6UCAQ==", "AtomicRelationType": "xAttr", "AtomicInference": "athletic"}, "premise": "PersonX is playing tennis", "hypothesis": "As a result, PersonX feels athletic", "update": "PersonX likes to play tennis every day.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1193", "update_paraphrase": "Tennis is a daily activity that PersonX enjoys.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5611177711177712, "pred_conf_shift": -0.014681577682495117, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.027742108330130577, 0.9722579121589661], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1193.gpt3.3", "original_example": {"example_id": "atomic.train.1193", "premise_hypothesis_id": "atomic.train.562", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "46hgB7bya2kC-q8_Snsq7A==", "AtomicEventRelationId": "uyOa6qJ9Sk-VEIPpH6UCAQ==", "AtomicRelationType": "xAttr", "AtomicInference": "athletic"}, "premise": "PersonX is playing tennis", "hypothesis": "As a result, PersonX feels athletic", "update": "PersonX likes to play tennis every day.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1193", "update_paraphrase": "Every day, PersonX enjoys playing tennis.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3706293706293706, "pred_conf_shift": 0.007393062114715576, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.022683605551719666, 0.9773164987564087], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1193.gpt3.4", "original_example": {"example_id": "atomic.train.1193", "premise_hypothesis_id": "atomic.train.562", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "46hgB7bya2kC-q8_Snsq7A==", "AtomicEventRelationId": "uyOa6qJ9Sk-VEIPpH6UCAQ==", "AtomicRelationType": "xAttr", "AtomicInference": "athletic"}, "premise": "PersonX is playing tennis", "hypothesis": "As a result, PersonX feels athletic", "update": "PersonX likes to play tennis every day.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1193", "update_paraphrase": "PersonX loves playing tennis every day.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23489843489843493, "pred_conf_shift": 0.012451648712158203, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.03807704523205757, 0.9619230031967163], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1193.gpt3.0", "original_example": {"example_id": "atomic.train.1193", "premise_hypothesis_id": "atomic.train.562", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "46hgB7bya2kC-q8_Snsq7A==", "AtomicEventRelationId": "uyOa6qJ9Sk-VEIPpH6UCAQ==", "AtomicRelationType": "xAttr", "AtomicInference": "athletic"}, "premise": "PersonX is playing tennis", "hypothesis": "As a result, PersonX feels athletic", "update": "PersonX likes to play tennis every day.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1193", "update_paraphrase": "PersonX tennis every day.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2727272727272727, "pred_conf_shift": -0.0029418468475341797, "syntactic_distance": 0.5}, {"confidence": [0.024105174466967583, 0.9758947491645813], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1193.gpt3.2", "original_example": {"example_id": "atomic.train.1193", "premise_hypothesis_id": "atomic.train.562", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "46hgB7bya2kC-q8_Snsq7A==", "AtomicEventRelationId": "uyOa6qJ9Sk-VEIPpH6UCAQ==", "AtomicRelationType": "xAttr", "AtomicInference": "athletic"}, "premise": "PersonX is playing tennis", "hypothesis": "As a result, PersonX feels athletic", "update": "PersonX likes to play tennis every day.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1193", "update_paraphrase": "PersonX enjoys playing tennis every day.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2558275058275058, "pred_conf_shift": 0.01102989912033081, "syntactic_distance": 0.0}, {"confidence": [0.03037377819418907, 0.9696263074874878], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1193.gpt3.5", "original_example": {"example_id": "atomic.train.1193", "premise_hypothesis_id": "atomic.train.562", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "46hgB7bya2kC-q8_Snsq7A==", "AtomicEventRelationId": "uyOa6qJ9Sk-VEIPpH6UCAQ==", "AtomicRelationType": "xAttr", "AtomicInference": "athletic"}, "premise": "PersonX is playing tennis", "hypothesis": "As a result, PersonX feels athletic", "update": "PersonX likes to play tennis every day.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1193", "update_paraphrase": "PersonX enjoys playing tennis on a daily basis.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4645454545454546, "pred_conf_shift": 0.004761457443237305, "syntactic_distance": 0.0}]}, "atomic.train.10136": {"original_confidence": [0.7995537519454956, 0.2004462331533432], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.7548415660858154, 0.24515844881534576], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10136.gpt3.0", "original_example": {"example_id": "atomic.train.10136", "premise_hypothesis_id": "atomic.train.4778", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4sJhn6QpCHprgJQ3jr8zg==", "AtomicEventRelationId": "87Or5IMLgRqZcTf6E8KMBw==", "AtomicRelationType": "xNeed", "AtomicInference": "to pull down their pants"}, "premise": "PersonX pisses like a racehorse", "hypothesis": "Before, PersonX needed to pull down their pants", "update": "PersonX is in the ocean wearing swim trunks.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10136", "update_paraphrase": "PersonX is in the water wearing swimming shorts.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2922979797979798, "pred_conf_shift": -0.044712185859680176, "syntactic_distance": 0.0}, {"confidence": [0.8398035168647766, 0.16019657254219055], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10136.gpt3.3", "original_example": {"example_id": "atomic.train.10136", "premise_hypothesis_id": "atomic.train.4778", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4sJhn6QpCHprgJQ3jr8zg==", "AtomicEventRelationId": "87Or5IMLgRqZcTf6E8KMBw==", "AtomicRelationType": "xNeed", "AtomicInference": "to pull down their pants"}, "premise": "PersonX pisses like a racehorse", "hypothesis": "Before, PersonX needed to pull down their pants", "update": "PersonX is in the ocean wearing swim trunks.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10136", "update_paraphrase": "PersonX is swimming in the ocean wearing trunks.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.20833333333333331, "pred_conf_shift": 0.040249764919281006, "syntactic_distance": 0.2631578947368421}, {"confidence": [0.7163941860198975, 0.28360581398010254], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10136.gpt3.1", "original_example": {"example_id": "atomic.train.10136", "premise_hypothesis_id": "atomic.train.4778", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4sJhn6QpCHprgJQ3jr8zg==", "AtomicEventRelationId": "87Or5IMLgRqZcTf6E8KMBw==", "AtomicRelationType": "xNeed", "AtomicInference": "to pull down their pants"}, "premise": "PersonX pisses like a racehorse", "hypothesis": "Before, PersonX needed to pull down their pants", "update": "PersonX is in the ocean wearing swim trunks.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10136", "update_paraphrase": "PersonX is in the ocean wearing a swimsuit.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.18134469696969696, "pred_conf_shift": -0.08315956592559814, "syntactic_distance": 0.0}, {"confidence": [0.7092854380607605, 0.29071444272994995], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10136.gpt3.2", "original_example": {"example_id": "atomic.train.10136", "premise_hypothesis_id": "atomic.train.4778", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4sJhn6QpCHprgJQ3jr8zg==", "AtomicEventRelationId": "87Or5IMLgRqZcTf6E8KMBw==", "AtomicRelationType": "xNeed", "AtomicInference": "to pull down their pants"}, "premise": "PersonX pisses like a racehorse", "hypothesis": "Before, PersonX needed to pull down their pants", "update": "PersonX is in the ocean wearing swim trunks.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10136", "update_paraphrase": "PersonX is in the ocean wearing swimwear.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.135042735042735, "pred_conf_shift": -0.09026831388473511, "syntactic_distance": 0.0}, {"confidence": [0.7310594320297241, 0.2689405679702759], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10136.gpt3.6", "original_example": {"example_id": "atomic.train.10136", "premise_hypothesis_id": "atomic.train.4778", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4sJhn6QpCHprgJQ3jr8zg==", "AtomicEventRelationId": "87Or5IMLgRqZcTf6E8KMBw==", "AtomicRelationType": "xNeed", "AtomicInference": "to pull down their pants"}, "premise": "PersonX pisses like a racehorse", "hypothesis": "Before, PersonX needed to pull down their pants", "update": "PersonX is in the ocean wearing swim trunks.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10136", "update_paraphrase": "At the beach, PersonX is wearing swim trunks and enjoying the ocean.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.38, "pred_conf_shift": -0.06849431991577148, "syntactic_distance": 0.391304347826087}, {"confidence": [0.7544512748718262, 0.24554865062236786], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10136.gpt3.5", "original_example": {"example_id": "atomic.train.10136", "premise_hypothesis_id": "atomic.train.4778", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "v4sJhn6QpCHprgJQ3jr8zg==", "AtomicEventRelationId": "87Or5IMLgRqZcTf6E8KMBw==", "AtomicRelationType": "xNeed", "AtomicInference": "to pull down their pants"}, "premise": "PersonX pisses like a racehorse", "hypothesis": "Before, PersonX needed to pull down their pants", "update": "PersonX is in the ocean wearing swim trunks.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10136", "update_paraphrase": "PersonX is wearing swim trunks and swimming in the ocean.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23544973544973546, "pred_conf_shift": -0.045102477073669434, "syntactic_distance": 0.2631578947368421}]}, "atomic.train.18015": {"original_confidence": [0.1128849908709526, 0.8871150612831116], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.1227324977517128, 0.8772674798965454], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18015.gpt3.0", "original_example": {"example_id": "atomic.train.18015", "premise_hypothesis_id": "atomic.train.8381", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "MBUQfif7oHitnEuYAwCXEA==", "AtomicEventRelationId": "BOMILmICesCBQePQIa2ong==", "AtomicRelationType": "xAttr", "AtomicInference": "angry"}, "premise": "PersonX withdraws PersonY's hand", "hypothesis": "As a result, PersonX feels angry", "update": "PersonY was hitting PersonX.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18015", "update_paraphrase": "PersonY was beating up on PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.29841269841269846, "pred_conf_shift": -0.009847581386566162, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.10242298990488052, 0.8975770473480225], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18015.gpt3.2", "original_example": {"example_id": "atomic.train.18015", "premise_hypothesis_id": "atomic.train.8381", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "MBUQfif7oHitnEuYAwCXEA==", "AtomicEventRelationId": "BOMILmICesCBQePQIa2ong==", "AtomicRelationType": "xAttr", "AtomicInference": "angry"}, "premise": "PersonX withdraws PersonY's hand", "hypothesis": "As a result, PersonX feels angry", "update": "PersonY was hitting PersonX.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18015", "update_paraphrase": "PersonY was punching PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1654761904761905, "pred_conf_shift": 0.010461986064910889, "syntactic_distance": 0.0}, {"confidence": [0.1128849908709526, 0.8871150612831116], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18015.gpt3.3", "original_example": {"example_id": "atomic.train.18015", "premise_hypothesis_id": "atomic.train.8381", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "MBUQfif7oHitnEuYAwCXEA==", "AtomicEventRelationId": "BOMILmICesCBQePQIa2ong==", "AtomicRelationType": "xAttr", "AtomicInference": "angry"}, "premise": "PersonX withdraws PersonY's hand", "hypothesis": "As a result, PersonX feels angry", "update": "PersonY was hitting PersonX.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18015", "update_paraphrase": "PersonY was hitting PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": 0.0, "syntactic_distance": 0.0}, {"confidence": [0.1835222691297531, 0.8164776563644409], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18015.gpt3.4", "original_example": {"example_id": "atomic.train.18015", "premise_hypothesis_id": "atomic.train.8381", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "MBUQfif7oHitnEuYAwCXEA==", "AtomicEventRelationId": "BOMILmICesCBQePQIa2ong==", "AtomicRelationType": "xAttr", "AtomicInference": "angry"}, "premise": "PersonX withdraws PersonY's hand", "hypothesis": "As a result, PersonX feels angry", "update": "PersonY was hitting PersonX.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18015", "update_paraphrase": "PersonY was striking PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1654761904761905, "pred_conf_shift": -0.07063740491867065, "syntactic_distance": 0.0625}, {"confidence": [0.130696102976799, 0.8693039417266846], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18015.gpt3.1", "original_example": {"example_id": "atomic.train.18015", "premise_hypothesis_id": "atomic.train.8381", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "MBUQfif7oHitnEuYAwCXEA==", "AtomicEventRelationId": "BOMILmICesCBQePQIa2ong==", "AtomicRelationType": "xAttr", "AtomicInference": "angry"}, "premise": "PersonX withdraws PersonY's hand", "hypothesis": "As a result, PersonX feels angry", "update": "PersonY was hitting PersonX.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18015", "update_paraphrase": "PersonY was attacking PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.15401785714285715, "pred_conf_shift": -0.017811119556427002, "syntactic_distance": 0.0}]}, "atomic.train.3684": {"original_confidence": [0.7917609214782715, 0.2082390934228897], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.6314948797225952, 0.3685050308704376], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3684.gpt3.0", "original_example": {"example_id": "atomic.train.3684", "premise_hypothesis_id": "atomic.train.1731", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "pvH5ePKPpTbpDrzlpIxwvw==", "AtomicEventRelationId": "fLBQk4AN2cmdN2-ACgYV3A==", "AtomicRelationType": "xNeed", "AtomicInference": "to go to PersonY"}, "premise": "PersonX turns PersonY's face", "hypothesis": "Before, PersonX needed to go to PersonY", "update": "PersonX has a picture of PersonY open on a 3d photo shop application.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3684", "update_paraphrase": "There is an image of PersonY open on a 3D photo editing program on PersonX's computer.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3220608993748739, "pred_conf_shift": -0.16026604175567627, "syntactic_distance": 0.125}, {"confidence": [0.34640511870384216, 0.653594970703125], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3684.gpt3.8", "original_example": {"example_id": "atomic.train.3684", "premise_hypothesis_id": "atomic.train.1731", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "pvH5ePKPpTbpDrzlpIxwvw==", "AtomicEventRelationId": "fLBQk4AN2cmdN2-ACgYV3A==", "AtomicRelationType": "xNeed", "AtomicInference": "to go to PersonY"}, "premise": "PersonX turns PersonY's face", "hypothesis": "Before, PersonX needed to go to PersonY", "update": "PersonX has a picture of PersonY open on a 3d photo shop application.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3684", "update_paraphrase": "X has a photograph of Y open on a 3d image editor.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3162086932675168, "pred_conf_shift": -0.4453558027744293, "syntactic_distance": 0.0}, {"confidence": [0.934724748134613, 0.06527528911828995], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3684.gpt3.7", "original_example": {"example_id": "atomic.train.3684", "premise_hypothesis_id": "atomic.train.1731", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "pvH5ePKPpTbpDrzlpIxwvw==", "AtomicEventRelationId": "fLBQk4AN2cmdN2-ACgYV3A==", "AtomicRelationType": "xNeed", "AtomicInference": "to go to PersonY"}, "premise": "PersonX turns PersonY's face", "hypothesis": "Before, PersonX needed to go to PersonY", "update": "PersonX has a picture of PersonY open on a 3d photo shop application.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3684", "update_paraphrase": "PersonX has a picture of PersonY on a 3d photo shop application.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.040000000000000036, "pred_conf_shift": 0.14296382665634155, "syntactic_distance": 0.2631578947368421}, {"confidence": [0.5416246652603149, 0.45837536454200745], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3684.gpt3.2", "original_example": {"example_id": "atomic.train.3684", "premise_hypothesis_id": "atomic.train.1731", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "pvH5ePKPpTbpDrzlpIxwvw==", "AtomicEventRelationId": "fLBQk4AN2cmdN2-ACgYV3A==", "AtomicRelationType": "xNeed", "AtomicInference": "to go to PersonY"}, "premise": "PersonX turns PersonY's face", "hypothesis": "Before, PersonX needed to go to PersonY", "update": "PersonX has a picture of PersonY open on a 3d photo shop application.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3684", "update_paraphrase": "There's an image of PersonY on the 3d photo shop application that PersonX has open.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2860805860805861, "pred_conf_shift": -0.25013625621795654, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.7917609214782715, 0.2082390934228897], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3684.gpt3.1", "original_example": {"example_id": "atomic.train.3684", "premise_hypothesis_id": "atomic.train.1731", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "pvH5ePKPpTbpDrzlpIxwvw==", "AtomicEventRelationId": "fLBQk4AN2cmdN2-ACgYV3A==", "AtomicRelationType": "xNeed", "AtomicInference": "to go to PersonY"}, "premise": "PersonX turns PersonY's face", "hypothesis": "Before, PersonX needed to go to PersonY", "update": "PersonX has a picture of PersonY open on a 3d photo shop application.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3684", "update_paraphrase": "PersonX has a picture of PersonY open on a 3d photo shop application.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": 0.0, "syntactic_distance": 0.0}, {"confidence": [0.9435869455337524, 0.05641299486160278], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3684.gpt3.6", "original_example": {"example_id": "atomic.train.3684", "premise_hypothesis_id": "atomic.train.1731", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "pvH5ePKPpTbpDrzlpIxwvw==", "AtomicEventRelationId": "fLBQk4AN2cmdN2-ACgYV3A==", "AtomicRelationType": "xNeed", "AtomicInference": "to go to PersonY"}, "premise": "PersonX turns PersonY's face", "hypothesis": "Before, PersonX needed to go to PersonY", "update": "PersonX has a picture of PersonY open on a 3d photo shop application.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3684", "update_paraphrase": "PersonX hasPersonY's picture open in a 3D photo shop application.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23015873015873012, "pred_conf_shift": 0.15182602405548096, "syntactic_distance": 0.3888888888888889}, {"confidence": [0.7924773097038269, 0.2075226604938507], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3684.gpt3.5", "original_example": {"example_id": "atomic.train.3684", "premise_hypothesis_id": "atomic.train.1731", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "pvH5ePKPpTbpDrzlpIxwvw==", "AtomicEventRelationId": "fLBQk4AN2cmdN2-ACgYV3A==", "AtomicRelationType": "xNeed", "AtomicInference": "to go to PersonY"}, "premise": "PersonX turns PersonY's face", "hypothesis": "Before, PersonX needed to go to PersonY", "update": "PersonX has a picture of PersonY open on a 3d photo shop application.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3684", "update_paraphrase": "PersonX has a picture of PersonY open in a 3D photo editing program.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.20881895881895884, "pred_conf_shift": 0.0007163882255554199, "syntactic_distance": 0.0}, {"confidence": [0.5518419742584229, 0.44815799593925476], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3684.gpt3.4", "original_example": {"example_id": "atomic.train.3684", "premise_hypothesis_id": "atomic.train.1731", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "pvH5ePKPpTbpDrzlpIxwvw==", "AtomicEventRelationId": "fLBQk4AN2cmdN2-ACgYV3A==", "AtomicRelationType": "xNeed", "AtomicInference": "to go to PersonY"}, "premise": "PersonX turns PersonY's face", "hypothesis": "Before, PersonX needed to go to PersonY", "update": "PersonX has a picture of PersonY open on a 3d photo shop application.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3684", "update_paraphrase": "There is an image of PersonY on the screen in front of PersonX. The image is open in a 3D photo editing program.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4716049382716049, "pred_conf_shift": -0.23991894721984863, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.9586958289146423, 0.04130425676703453], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3684.gpt3.3", "original_example": {"example_id": "atomic.train.3684", "premise_hypothesis_id": "atomic.train.1731", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "pvH5ePKPpTbpDrzlpIxwvw==", "AtomicEventRelationId": "fLBQk4AN2cmdN2-ACgYV3A==", "AtomicRelationType": "xNeed", "AtomicInference": "to go to PersonY"}, "premise": "PersonX turns PersonY's face", "hypothesis": "Before, PersonX needed to go to PersonY", "update": "PersonX has a picture of PersonY open on a 3d photo shop application.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3684", "update_paraphrase": "PersonX is looking at a picture of PersonY in a 3D photo editing program.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28115012559457014, "pred_conf_shift": 0.16693490743637085, "syntactic_distance": 0.23529411764705882}]}, "atomic.train.16797": {"original_confidence": [0.4387836158275604, 0.5612164735794067], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.18931491672992706, 0.8106850385665894], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16797.gpt3.1", "original_example": {"example_id": "atomic.train.16797", "premise_hypothesis_id": "atomic.train.7830", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "31__XpHDjEmgERfSWTgYgQ==", "AtomicEventRelationId": "O2Vai0zVX8PbNq7INMLIig==", "AtomicRelationType": "xReact", "AtomicInference": "friendly"}, "premise": "PersonX stays longer", "hypothesis": "PersonX is seen as friendly", "update": "PersonX stayed to help clean up", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16797", "update_paraphrase": "PersonX lingered to help clean the mess.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.32844932844932845, "pred_conf_shift": 0.24946856498718262, "syntactic_distance": 0.07142857142857142}, {"confidence": [0.028881052508950233, 0.9711189270019531], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16797.gpt3.7", "original_example": {"example_id": "atomic.train.16797", "premise_hypothesis_id": "atomic.train.7830", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "31__XpHDjEmgERfSWTgYgQ==", "AtomicEventRelationId": "O2Vai0zVX8PbNq7INMLIig==", "AtomicRelationType": "xReact", "AtomicInference": "friendly"}, "premise": "PersonX stays longer", "hypothesis": "PersonX is seen as friendly", "update": "PersonX stayed to help clean up", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16797", "update_paraphrase": "PersonX decided to help with the cleanup process.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3827838827838828, "pred_conf_shift": 0.4099024534225464, "syntactic_distance": 0.0}, {"confidence": [0.035832539200782776, 0.9641674160957336], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16797.gpt3.0", "original_example": {"example_id": "atomic.train.16797", "premise_hypothesis_id": "atomic.train.7830", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "31__XpHDjEmgERfSWTgYgQ==", "AtomicEventRelationId": "O2Vai0zVX8PbNq7INMLIig==", "AtomicRelationType": "xReact", "AtomicInference": "friendly"}, "premise": "PersonX stays longer", "hypothesis": "PersonX is seen as friendly", "update": "PersonX stayed to help clean up", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16797", "update_paraphrase": "PersonX hung around to help clean up the mess.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33602693602693595, "pred_conf_shift": 0.4029509425163269, "syntactic_distance": 0.125}, {"confidence": [0.0898779034614563, 0.9101220369338989], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16797.gpt3.8", "original_example": {"example_id": "atomic.train.16797", "premise_hypothesis_id": "atomic.train.7830", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "31__XpHDjEmgERfSWTgYgQ==", "AtomicEventRelationId": "O2Vai0zVX8PbNq7INMLIig==", "AtomicRelationType": "xReact", "AtomicInference": "friendly"}, "premise": "PersonX stays longer", "hypothesis": "PersonX is seen as friendly", "update": "PersonX stayed to help clean up", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16797", "update_paraphrase": "After everyone else had left, PersonX remained to help tidy up.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45090856855562733, "pred_conf_shift": 0.3489055633544922, "syntactic_distance": 0.29411764705882354}, {"confidence": [0.1721584051847458, 0.8278415203094482], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16797.gpt3.5", "original_example": {"example_id": "atomic.train.16797", "premise_hypothesis_id": "atomic.train.7830", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "31__XpHDjEmgERfSWTgYgQ==", "AtomicEventRelationId": "O2Vai0zVX8PbNq7INMLIig==", "AtomicRelationType": "xReact", "AtomicInference": "friendly"}, "premise": "PersonX stays longer", "hypothesis": "PersonX is seen as friendly", "update": "PersonX stayed to help clean up", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16797", "update_paraphrase": "PersonX stayed until the end to help clean up.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19999999999999996, "pred_conf_shift": 0.2666250467300415, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.1163577139377594, 0.8836422562599182], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16797.gpt3.2", "original_example": {"example_id": "atomic.train.16797", "premise_hypothesis_id": "atomic.train.7830", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "31__XpHDjEmgERfSWTgYgQ==", "AtomicEventRelationId": "O2Vai0zVX8PbNq7INMLIig==", "AtomicRelationType": "xReact", "AtomicInference": "friendly"}, "premise": "PersonX stays longer", "hypothesis": "PersonX is seen as friendly", "update": "PersonX stayed to help clean up", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16797", "update_paraphrase": "PersonX remained to assist with the cleaning.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42011834319526625, "pred_conf_shift": 0.3224257826805115, "syntactic_distance": 0.07142857142857142}, {"confidence": [0.03007565438747406, 0.9699243307113647], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16797.gpt3.6", "original_example": {"example_id": "atomic.train.16797", "premise_hypothesis_id": "atomic.train.7830", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "31__XpHDjEmgERfSWTgYgQ==", "AtomicEventRelationId": "O2Vai0zVX8PbNq7INMLIig==", "AtomicRelationType": "xReact", "AtomicInference": "friendly"}, "premise": "PersonX stays longer", "hypothesis": "PersonX is seen as friendly", "update": "PersonX stayed to help clean up", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16797", "update_paraphrase": "Person X decided to stay and help with the cleanup.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4542735042735043, "pred_conf_shift": 0.408707857131958, "syntactic_distance": 0.13333333333333333}, {"confidence": [0.2328835427761078, 0.7671164274215698], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16797.gpt3.3", "original_example": {"example_id": "atomic.train.16797", "premise_hypothesis_id": "atomic.train.7830", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "31__XpHDjEmgERfSWTgYgQ==", "AtomicEventRelationId": "O2Vai0zVX8PbNq7INMLIig==", "AtomicRelationType": "xReact", "AtomicInference": "friendly"}, "premise": "PersonX stays longer", "hypothesis": "PersonX is seen as friendly", "update": "PersonX stayed to help clean up", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16797", "update_paraphrase": "PersonX stayed to help with the cleanup.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28632478632478625, "pred_conf_shift": 0.20589995384216309, "syntactic_distance": 0.0}, {"confidence": [0.10383309423923492, 0.8961669206619263], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.16797.gpt3.4", "original_example": {"example_id": "atomic.train.16797", "premise_hypothesis_id": "atomic.train.7830", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "31__XpHDjEmgERfSWTgYgQ==", "AtomicEventRelationId": "O2Vai0zVX8PbNq7INMLIig==", "AtomicRelationType": "xReact", "AtomicInference": "friendly"}, "premise": "PersonX stays longer", "hypothesis": "PersonX is seen as friendly", "update": "PersonX stayed to help clean up", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.16797", "update_paraphrase": "PersonX chose to stay and help clean up the mess.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3647727272727273, "pred_conf_shift": 0.33495044708251953, "syntactic_distance": 0.0}]}, "atomic.train.3805": {"original_confidence": [0.9360975623130798, 0.06390230357646942], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.8846243619918823, 0.11537563055753708], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3805.gpt3.1", "original_example": {"example_id": "atomic.train.3805", "premise_hypothesis_id": "atomic.train.1788", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZXl1vtnpWMTbfB2lyGjyTg==", "AtomicEventRelationId": "PA3T9-dYkxvkPT_5NhE0tw==", "AtomicRelationType": "xAttr", "AtomicInference": "a spendthrift"}, "premise": "PersonX takes PersonX's allowance", "hypothesis": "As a result, PersonX feels a spendthrift", "update": "PersonX puts the allowance into a savings account.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3805", "update_paraphrase": "After receiving their allowance, PersonX deposited the money into a savings account.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2978021978021978, "pred_conf_shift": 0.05147332698106766, "syntactic_distance": 0.19230769230769232}, {"confidence": [0.9240143299102783, 0.07598564028739929], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3805.gpt3.2", "original_example": {"example_id": "atomic.train.3805", "premise_hypothesis_id": "atomic.train.1788", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZXl1vtnpWMTbfB2lyGjyTg==", "AtomicEventRelationId": "PA3T9-dYkxvkPT_5NhE0tw==", "AtomicRelationType": "xAttr", "AtomicInference": "a spendthrift"}, "premise": "PersonX takes PersonX's allowance", "hypothesis": "As a result, PersonX feels a spendthrift", "update": "PersonX puts the allowance into a savings account.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3805", "update_paraphrase": "PersonX deposits the allowance into a savings account.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.07102272727272729, "pred_conf_shift": 0.01208333671092987, "syntactic_distance": 0.0}, {"confidence": [0.8654359579086304, 0.13456405699253082], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3805.gpt3.4", "original_example": {"example_id": "atomic.train.3805", "premise_hypothesis_id": "atomic.train.1788", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZXl1vtnpWMTbfB2lyGjyTg==", "AtomicEventRelationId": "PA3T9-dYkxvkPT_5NhE0tw==", "AtomicRelationType": "xAttr", "AtomicInference": "a spendthrift"}, "premise": "PersonX takes PersonX's allowance", "hypothesis": "As a result, PersonX feels a spendthrift", "update": "PersonX puts the allowance into a savings account.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3805", "update_paraphrase": "PersonX is saving up their allowance by putting it into a savings account.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3482628482628483, "pred_conf_shift": 0.0706617534160614, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.9422497153282166, 0.05775031819939613], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3805.gpt3.0", "original_example": {"example_id": "atomic.train.3805", "premise_hypothesis_id": "atomic.train.1788", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZXl1vtnpWMTbfB2lyGjyTg==", "AtomicEventRelationId": "PA3T9-dYkxvkPT_5NhE0tw==", "AtomicRelationType": "xAttr", "AtomicInference": "a spendthrift"}, "premise": "PersonX takes PersonX's allowance", "hypothesis": "As a result, PersonX feels a spendthrift", "update": "PersonX puts the allowance into a savings account.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3805", "update_paraphrase": "PersonX saves the allowance money into a savings account.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.20261437908496732, "pred_conf_shift": -0.006151985377073288, "syntactic_distance": 0.043478260869565216}, {"confidence": [0.9479620456695557, 0.052037954330444336], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3805.gpt3.7", "original_example": {"example_id": "atomic.train.3805", "premise_hypothesis_id": "atomic.train.1788", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZXl1vtnpWMTbfB2lyGjyTg==", "AtomicEventRelationId": "PA3T9-dYkxvkPT_5NhE0tw==", "AtomicRelationType": "xAttr", "AtomicInference": "a spendthrift"}, "premise": "PersonX takes PersonX's allowance", "hypothesis": "As a result, PersonX feels a spendthrift", "update": "PersonX puts the allowance into a savings account.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3805", "update_paraphrase": "PersonX saves the allowance money in a special bank account.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.30471380471380477, "pred_conf_shift": -0.011864349246025085, "syntactic_distance": 0.043478260869565216}, {"confidence": [0.9485422968864441, 0.05145774409174919], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3805.gpt3.6", "original_example": {"example_id": "atomic.train.3805", "premise_hypothesis_id": "atomic.train.1788", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZXl1vtnpWMTbfB2lyGjyTg==", "AtomicEventRelationId": "PA3T9-dYkxvkPT_5NhE0tw==", "AtomicRelationType": "xAttr", "AtomicInference": "a spendthrift"}, "premise": "PersonX takes PersonX's allowance", "hypothesis": "As a result, PersonX feels a spendthrift", "update": "PersonX puts the allowance into a savings account.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3805", "update_paraphrase": "PersonX saves their allowance in a bank account.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.25852272727272724, "pred_conf_shift": -0.01244455948472023, "syntactic_distance": 0.045454545454545456}, {"confidence": [0.9180042147636414, 0.08199577033519745], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3805.gpt3.5", "original_example": {"example_id": "atomic.train.3805", "premise_hypothesis_id": "atomic.train.1788", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZXl1vtnpWMTbfB2lyGjyTg==", "AtomicEventRelationId": "PA3T9-dYkxvkPT_5NhE0tw==", "AtomicRelationType": "xAttr", "AtomicInference": "a spendthrift"}, "premise": "PersonX takes PersonX's allowance", "hypothesis": "As a result, PersonX feels a spendthrift", "update": "PersonX puts the allowance into a savings account.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3805", "update_paraphrase": "PersonX puts the money from their allowance into a savings account.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1578947368421053, "pred_conf_shift": 0.018093466758728027, "syntactic_distance": 0.09090909090909091}, {"confidence": [0.947911262512207, 0.052088771015405655], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3805.gpt3.3", "original_example": {"example_id": "atomic.train.3805", "premise_hypothesis_id": "atomic.train.1788", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZXl1vtnpWMTbfB2lyGjyTg==", "AtomicEventRelationId": "PA3T9-dYkxvkPT_5NhE0tw==", "AtomicRelationType": "xAttr", "AtomicInference": "a spendthrift"}, "premise": "PersonX takes PersonX's allowance", "hypothesis": "As a result, PersonX feels a spendthrift", "update": "PersonX puts the allowance into a savings account.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3805", "update_paraphrase": "Person X chooses to save their allowance instead of spending it.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5158134263397421, "pred_conf_shift": -0.011813532561063766, "syntactic_distance": 0.42857142857142855}]}, "atomic.train.3522": {"original_confidence": [0.6724885106086731, 0.3275114893913269], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.5915632247924805, 0.40843671560287476], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3522.gpt3.0", "original_example": {"example_id": "atomic.train.3522", "premise_hypothesis_id": "atomic.train.1655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-GJTjJbuX3f8XPhGcvgVZQ==", "AtomicEventRelationId": "74ALDi7ipHuMOSGxujsQOA==", "AtomicRelationType": "xIntent", "AtomicInference": "to save time"}, "premise": "PersonX makes a long story short", "hypothesis": "Because PersonX wanted to save time", "update": "PersonX is bad at remembering details.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3522", "update_paraphrase": "PersonX is forgetful and has trouble remembering details.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.30952380952380953, "pred_conf_shift": -0.08092528581619263, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.6042211055755615, 0.3957788646221161], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3522.gpt3.1", "original_example": {"example_id": "atomic.train.3522", "premise_hypothesis_id": "atomic.train.1655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-GJTjJbuX3f8XPhGcvgVZQ==", "AtomicEventRelationId": "74ALDi7ipHuMOSGxujsQOA==", "AtomicRelationType": "xIntent", "AtomicInference": "to save time"}, "premise": "PersonX makes a long story short", "hypothesis": "Because PersonX wanted to save time", "update": "PersonX is bad at remembering details.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3522", "update_paraphrase": "PersonX is not good at remembering details.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19340659340659339, "pred_conf_shift": -0.06826740503311157, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.6491220593452454, 0.35087794065475464], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3522.gpt3.3", "original_example": {"example_id": "atomic.train.3522", "premise_hypothesis_id": "atomic.train.1655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-GJTjJbuX3f8XPhGcvgVZQ==", "AtomicEventRelationId": "74ALDi7ipHuMOSGxujsQOA==", "AtomicRelationType": "xIntent", "AtomicInference": "to save time"}, "premise": "PersonX makes a long story short", "hypothesis": "Because PersonX wanted to save time", "update": "PersonX is bad at remembering details.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3522", "update_paraphrase": "PersonX is forgetful and often forgets details.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.38721001221001217, "pred_conf_shift": -0.023366451263427734, "syntactic_distance": 0.38095238095238093}, {"confidence": [0.6348458528518677, 0.36515411734580994], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3522.gpt3.4", "original_example": {"example_id": "atomic.train.3522", "premise_hypothesis_id": "atomic.train.1655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-GJTjJbuX3f8XPhGcvgVZQ==", "AtomicEventRelationId": "74ALDi7ipHuMOSGxujsQOA==", "AtomicRelationType": "xIntent", "AtomicInference": "to save time"}, "premise": "PersonX makes a long story short", "hypothesis": "Because PersonX wanted to save time", "update": "PersonX is bad at remembering details.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3522", "update_paraphrase": "PersonX finds it difficult to remember small details.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4645094880057286, "pred_conf_shift": -0.03764265775680542, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.6774552464485168, 0.32254472374916077], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3522.gpt3.5", "original_example": {"example_id": "atomic.train.3522", "premise_hypothesis_id": "atomic.train.1655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-GJTjJbuX3f8XPhGcvgVZQ==", "AtomicEventRelationId": "74ALDi7ipHuMOSGxujsQOA==", "AtomicRelationType": "xIntent", "AtomicInference": "to save time"}, "premise": "PersonX makes a long story short", "hypothesis": "Because PersonX wanted to save time", "update": "PersonX is bad at remembering details.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3522", "update_paraphrase": "PersonX is poor at recalling specifics.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4270833333333333, "pred_conf_shift": 0.00496673583984375, "syntactic_distance": 0.0}, {"confidence": [0.6838427782058716, 0.3161572515964508], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3522.gpt3.2", "original_example": {"example_id": "atomic.train.3522", "premise_hypothesis_id": "atomic.train.1655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-GJTjJbuX3f8XPhGcvgVZQ==", "AtomicEventRelationId": "74ALDi7ipHuMOSGxujsQOA==", "AtomicRelationType": "xIntent", "AtomicInference": "to save time"}, "premise": "PersonX makes a long story short", "hypothesis": "Because PersonX wanted to save time", "update": "PersonX is bad at remembering details.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3522", "update_paraphrase": "PersonX has trouble remembering details.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3414141414141414, "pred_conf_shift": 0.011354267597198486, "syntactic_distance": 0.1875}, {"confidence": [0.608119010925293, 0.39188095927238464], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3522.gpt3.6", "original_example": {"example_id": "atomic.train.3522", "premise_hypothesis_id": "atomic.train.1655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-GJTjJbuX3f8XPhGcvgVZQ==", "AtomicEventRelationId": "74ALDi7ipHuMOSGxujsQOA==", "AtomicRelationType": "xIntent", "AtomicInference": "to save time"}, "premise": "PersonX makes a long story short", "hypothesis": "Because PersonX wanted to save time", "update": "PersonX is bad at remembering details.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3522", "update_paraphrase": "PersonX tends to forget details.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4551608522196757, "pred_conf_shift": -0.06436949968338013, "syntactic_distance": 0.26666666666666666}]}, "atomic.train.11432": {"original_confidence": [0.9675109386444092, 0.032489001750946045], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.9643422961235046, 0.03565771505236626], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11432.gpt3.0", "original_example": {"example_id": "atomic.train.11432", "premise_hypothesis_id": "atomic.train.5377", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "z-zAlFMM0Y_c8e6j6J9pjg==", "AtomicEventRelationId": "QAQ3fW27Sdwfliu1GrCbPg==", "AtomicRelationType": "xNeed", "AtomicInference": "to receive flattery from persony"}, "premise": "PersonX returns PersonY's attention", "hypothesis": "Before, PersonX needed to receive flattery from persony", "update": "PersonY confused PersonX for someone else.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11432", "update_paraphrase": "PersonY misidentified PersonX as someone else.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.26984126984126977, "pred_conf_shift": -0.003168642520904541, "syntactic_distance": 0.0}, {"confidence": [0.9695496559143066, 0.030450357124209404], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11432.gpt3.2", "original_example": {"example_id": "atomic.train.11432", "premise_hypothesis_id": "atomic.train.5377", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "z-zAlFMM0Y_c8e6j6J9pjg==", "AtomicEventRelationId": "QAQ3fW27Sdwfliu1GrCbPg==", "AtomicRelationType": "xNeed", "AtomicInference": "to receive flattery from persony"}, "premise": "PersonX returns PersonY's attention", "hypothesis": "Before, PersonX needed to receive flattery from persony", "update": "PersonY confused PersonX for someone else.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11432", "update_paraphrase": "PersonY mistook PersonX for someone else.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.13333333333333336, "pred_conf_shift": 0.002038717269897461, "syntactic_distance": 0.0}, {"confidence": [0.9621134400367737, 0.03788648173213005], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11432.gpt3.1", "original_example": {"example_id": "atomic.train.11432", "premise_hypothesis_id": "atomic.train.5377", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "z-zAlFMM0Y_c8e6j6J9pjg==", "AtomicEventRelationId": "QAQ3fW27Sdwfliu1GrCbPg==", "AtomicRelationType": "xNeed", "AtomicInference": "to receive flattery from persony"}, "premise": "PersonX returns PersonY's attention", "hypothesis": "Before, PersonX needed to receive flattery from persony", "update": "PersonY confused PersonX for someone else.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11432", "update_paraphrase": "The individual known as PersonY was confused as to the identity of PersonX and confused them for somebody else entirely.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5641025641025641, "pred_conf_shift": -0.005397498607635498, "syntactic_distance": 0.4642857142857143}, {"confidence": [0.9685077667236328, 0.03149218112230301], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11432.gpt3.3", "original_example": {"example_id": "atomic.train.11432", "premise_hypothesis_id": "atomic.train.5377", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "z-zAlFMM0Y_c8e6j6J9pjg==", "AtomicEventRelationId": "QAQ3fW27Sdwfliu1GrCbPg==", "AtomicRelationType": "xNeed", "AtomicInference": "to receive flattery from persony"}, "premise": "PersonX returns PersonY's attention", "hypothesis": "Before, PersonX needed to receive flattery from persony", "update": "PersonY confused PersonX for someone else.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11432", "update_paraphrase": "PersonY mistook PersonX for another person.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.36269841269841274, "pred_conf_shift": 0.0009968280792236328, "syntactic_distance": 0.0}, {"confidence": [0.950980007648468, 0.049019955098629], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11432.gpt3.4", "original_example": {"example_id": "atomic.train.11432", "premise_hypothesis_id": "atomic.train.5377", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "z-zAlFMM0Y_c8e6j6J9pjg==", "AtomicEventRelationId": "QAQ3fW27Sdwfliu1GrCbPg==", "AtomicRelationType": "xNeed", "AtomicInference": "to receive flattery from persony"}, "premise": "PersonX returns PersonY's attention", "hypothesis": "Before, PersonX needed to receive flattery from persony", "update": "PersonY confused PersonX for someone else.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11432", "update_paraphrase": "PersonX was mistaken for someone else by PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.31745516388373535, "pred_conf_shift": -0.016530930995941162, "syntactic_distance": 0.3157894736842105}]}, "atomic.train.18446": {"original_confidence": [0.2328282594680786, 0.7671718001365662], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.22412914037704468, 0.7758708596229553], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18446.gpt3.8", "original_example": {"example_id": "atomic.train.18446", "premise_hypothesis_id": "atomic.train.8572", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "HVGLTKNgiSAtC41rYgTh3Q==", "AtomicEventRelationId": "eVhNlZSU1qsnv-pezhaS_A==", "AtomicRelationType": "xNeed", "AtomicInference": "shoes"}, "premise": "PersonX meets PersonX's neighbors", "hypothesis": "Before, PersonX needed shoes", "update": "PersonX's neighbors thought that PersonX was strange for walking outside barefoot.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18446", "update_paraphrase": "PersonX's neighbors found it odd that they would walk around outside without any shoes on.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5053079399233245, "pred_conf_shift": -0.008699119091033936, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.25928837060928345, 0.7407115697860718], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18446.gpt3.2", "original_example": {"example_id": "atomic.train.18446", "premise_hypothesis_id": "atomic.train.8572", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "HVGLTKNgiSAtC41rYgTh3Q==", "AtomicEventRelationId": "eVhNlZSU1qsnv-pezhaS_A==", "AtomicRelationType": "xNeed", "AtomicInference": "shoes"}, "premise": "PersonX meets PersonX's neighbors", "hypothesis": "Before, PersonX needed shoes", "update": "PersonX's neighbors thought that PersonX was strange for walking outside barefoot.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18446", "update_paraphrase": "PersonX's neighbors considered PersonX odd for going outside without shoes.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.38323875004547275, "pred_conf_shift": 0.026460111141204834, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.22190694510936737, 0.7780930995941162], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18446.gpt3.0", "original_example": {"example_id": "atomic.train.18446", "premise_hypothesis_id": "atomic.train.8572", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "HVGLTKNgiSAtC41rYgTh3Q==", "AtomicEventRelationId": "eVhNlZSU1qsnv-pezhaS_A==", "AtomicRelationType": "xNeed", "AtomicInference": "shoes"}, "premise": "PersonX meets PersonX's neighbors", "hypothesis": "Before, PersonX needed shoes", "update": "PersonX's neighbors thought that PersonX was strange for walking outside barefoot.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18446", "update_paraphrase": "PersonX's neighbors thought it was odd that they would walk outside barefoot.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.31626199887069456, "pred_conf_shift": -0.010921314358711243, "syntactic_distance": 0.0625}, {"confidence": [0.46236690878868103, 0.5376330018043518], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18446.gpt3.7", "original_example": {"example_id": "atomic.train.18446", "premise_hypothesis_id": "atomic.train.8572", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "HVGLTKNgiSAtC41rYgTh3Q==", "AtomicEventRelationId": "eVhNlZSU1qsnv-pezhaS_A==", "AtomicRelationType": "xNeed", "AtomicInference": "shoes"}, "premise": "PersonX meets PersonX's neighbors", "hypothesis": "Before, PersonX needed shoes", "update": "PersonX's neighbors thought that PersonX was strange for walking outside barefoot.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18446", "update_paraphrase": "PersonX's neighbors thought it was strange that PersonX liked to walk around outside barefoot.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.27335064935064934, "pred_conf_shift": 0.22953864932060242, "syntactic_distance": 0.0}, {"confidence": [0.23699720203876495, 0.7630028128623962], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18446.gpt3.4", "original_example": {"example_id": "atomic.train.18446", "premise_hypothesis_id": "atomic.train.8572", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "HVGLTKNgiSAtC41rYgTh3Q==", "AtomicEventRelationId": "eVhNlZSU1qsnv-pezhaS_A==", "AtomicRelationType": "xNeed", "AtomicInference": "shoes"}, "premise": "PersonX meets PersonX's neighbors", "hypothesis": "Before, PersonX needed shoes", "update": "PersonX's neighbors thought that PersonX was strange for walking outside barefoot.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18446", "update_paraphrase": "PersonX's neighbors thought it was weird that PersonX would walk around outside without shoes on.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39214119214119214, "pred_conf_shift": 0.00416894257068634, "syntactic_distance": 0.0}, {"confidence": [0.3514464199542999, 0.6485536694526672], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18446.gpt3.1", "original_example": {"example_id": "atomic.train.18446", "premise_hypothesis_id": "atomic.train.8572", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "HVGLTKNgiSAtC41rYgTh3Q==", "AtomicEventRelationId": "eVhNlZSU1qsnv-pezhaS_A==", "AtomicRelationType": "xNeed", "AtomicInference": "shoes"}, "premise": "PersonX meets PersonX's neighbors", "hypothesis": "Before, PersonX needed shoes", "update": "PersonX's neighbors thought that PersonX was strange for walking outside barefoot.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18446", "update_paraphrase": "The neighbors thought it was strange that PersonX liked to walk outside without shoes on.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3936704321319706, "pred_conf_shift": 0.11861816048622131, "syntactic_distance": 0.0625}, {"confidence": [0.3403364419937134, 0.6596636176109314], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18446.gpt3.5", "original_example": {"example_id": "atomic.train.18446", "premise_hypothesis_id": "atomic.train.8572", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "HVGLTKNgiSAtC41rYgTh3Q==", "AtomicEventRelationId": "eVhNlZSU1qsnv-pezhaS_A==", "AtomicRelationType": "xNeed", "AtomicInference": "shoes"}, "premise": "PersonX meets PersonX's neighbors", "hypothesis": "Before, PersonX needed shoes", "update": "PersonX's neighbors thought that PersonX was strange for walking outside barefoot.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18446", "update_paraphrase": "PersonX's neighbors were bewildered by the sight of PersonX walking around outside without shoes on.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4838343392999263, "pred_conf_shift": 0.10750818252563477, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.31339386105537415, 0.6866061091423035], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18446.gpt3.3", "original_example": {"example_id": "atomic.train.18446", "premise_hypothesis_id": "atomic.train.8572", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "HVGLTKNgiSAtC41rYgTh3Q==", "AtomicEventRelationId": "eVhNlZSU1qsnv-pezhaS_A==", "AtomicRelationType": "xNeed", "AtomicInference": "shoes"}, "premise": "PersonX meets PersonX's neighbors", "hypothesis": "Before, PersonX needed shoes", "update": "PersonX's neighbors thought that PersonX was strange for walking outside barefoot.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18446", "update_paraphrase": "PersonX's neighbors thought it was strange that PersonX would walk outside barefoot.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.21668548842461888, "pred_conf_shift": 0.08056560158729553, "syntactic_distance": 0.0}, {"confidence": [0.27158841490745544, 0.7284116744995117], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.18446.gpt3.6", "original_example": {"example_id": "atomic.train.18446", "premise_hypothesis_id": "atomic.train.8572", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "HVGLTKNgiSAtC41rYgTh3Q==", "AtomicEventRelationId": "eVhNlZSU1qsnv-pezhaS_A==", "AtomicRelationType": "xNeed", "AtomicInference": "shoes"}, "premise": "PersonX meets PersonX's neighbors", "hypothesis": "Before, PersonX needed shoes", "update": "PersonX's neighbors thought that PersonX was strange for walking outside barefoot.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.18446", "update_paraphrase": "PersonX's neighbors found it weird that PersonX would walk around outside without shoes on.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.43781751581751577, "pred_conf_shift": 0.03876015543937683, "syntactic_distance": 0.2222222222222222}]}, "atomic.train.29108": {"original_confidence": [0.9479442238807678, 0.05205589905381203], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.9424303770065308, 0.057569682598114014], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29108.gpt3.7", "original_example": {"example_id": "atomic.train.29108", "premise_hypothesis_id": "atomic.train.13209", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ubUGHTBUSVmy7r8JrGp_fw==", "AtomicEventRelationId": "9QbcKcMAdQ6i7WNjwNdiIg==", "AtomicRelationType": "xEffect", "AtomicInference": "hits a tree"}, "premise": "PersonX swerves off the road", "hypothesis": "PersonX then hits a tree", "update": "Person X's car shows no damage.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29108", "update_paraphrase": "X's car seems to be undamaged.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.36250000000000004, "pred_conf_shift": -0.0055138468742370605, "syntactic_distance": 0.2631578947368421}, {"confidence": [0.8220263719558716, 0.1779737025499344], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29108.gpt3.8", "original_example": {"example_id": "atomic.train.29108", "premise_hypothesis_id": "atomic.train.13209", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ubUGHTBUSVmy7r8JrGp_fw==", "AtomicEventRelationId": "9QbcKcMAdQ6i7WNjwNdiIg==", "AtomicRelationType": "xEffect", "AtomicInference": "hits a tree"}, "premise": "PersonX swerves off the road", "hypothesis": "PersonX then hits a tree", "update": "Person X's car shows no damage.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29108", "update_paraphrase": "There is no visible damage to Person X's car.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.44761904761904764, "pred_conf_shift": -0.12591785192489624, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.9235536456108093, 0.07644635438919067], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29108.gpt3.4", "original_example": {"example_id": "atomic.train.29108", "premise_hypothesis_id": "atomic.train.13209", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ubUGHTBUSVmy7r8JrGp_fw==", "AtomicEventRelationId": "9QbcKcMAdQ6i7WNjwNdiIg==", "AtomicRelationType": "xEffect", "AtomicInference": "hits a tree"}, "premise": "PersonX swerves off the road", "hypothesis": "PersonX then hits a tree", "update": "Person X's car shows no damage.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29108", "update_paraphrase": "Person X's car is not damaged.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28377918377918376, "pred_conf_shift": -0.024390578269958496, "syntactic_distance": 0.18181818181818182}, {"confidence": [0.8945674300193787, 0.10543259978294373], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29108.gpt3.1", "original_example": {"example_id": "atomic.train.29108", "premise_hypothesis_id": "atomic.train.13209", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ubUGHTBUSVmy7r8JrGp_fw==", "AtomicEventRelationId": "9QbcKcMAdQ6i7WNjwNdiIg==", "AtomicRelationType": "xEffect", "AtomicInference": "hits a tree"}, "premise": "PersonX swerves off the road", "hypothesis": "PersonX then hits a tree", "update": "Person X's car shows no damage.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29108", "update_paraphrase": "Person X's car does not display any outward signs of damage.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.41587301587301584, "pred_conf_shift": -0.05337679386138916, "syntactic_distance": 0.22727272727272727}, {"confidence": [0.9470040798187256, 0.0529959611594677], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29108.gpt3.2", "original_example": {"example_id": "atomic.train.29108", "premise_hypothesis_id": "atomic.train.13209", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ubUGHTBUSVmy7r8JrGp_fw==", "AtomicEventRelationId": "9QbcKcMAdQ6i7WNjwNdiIg==", "AtomicRelationType": "xEffect", "AtomicInference": "hits a tree"}, "premise": "PersonX swerves off the road", "hypothesis": "PersonX then hits a tree", "update": "Person X's car shows no damage.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29108", "update_paraphrase": "Person X's car is undamaged.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.32278630460448643, "pred_conf_shift": -0.0009401440620422363, "syntactic_distance": 0.14285714285714285}, {"confidence": [0.9304643273353577, 0.06953570246696472], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29108.gpt3.0", "original_example": {"example_id": "atomic.train.29108", "premise_hypothesis_id": "atomic.train.13209", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ubUGHTBUSVmy7r8JrGp_fw==", "AtomicEventRelationId": "9QbcKcMAdQ6i7WNjwNdiIg==", "AtomicRelationType": "xEffect", "AtomicInference": "hits a tree"}, "premise": "PersonX swerves off the road", "hypothesis": "PersonX then hits a tree", "update": "Person X's car shows no damage.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29108", "update_paraphrase": "Person X's car was not damaged in any way.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.40290598290598295, "pred_conf_shift": -0.017479896545410156, "syntactic_distance": 0.2727272727272727}, {"confidence": [0.9245030283927917, 0.07549688220024109], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29108.gpt3.5", "original_example": {"example_id": "atomic.train.29108", "premise_hypothesis_id": "atomic.train.13209", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ubUGHTBUSVmy7r8JrGp_fw==", "AtomicEventRelationId": "9QbcKcMAdQ6i7WNjwNdiIg==", "AtomicRelationType": "xEffect", "AtomicInference": "hits a tree"}, "premise": "PersonX swerves off the road", "hypothesis": "PersonX then hits a tree", "update": "Person X's car shows no damage.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29108", "update_paraphrase": "There is no damage evident on Person X's car.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.44761904761904764, "pred_conf_shift": -0.023441195487976074, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.9247024655342102, 0.07529748976230621], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29108.gpt3.3", "original_example": {"example_id": "atomic.train.29108", "premise_hypothesis_id": "atomic.train.13209", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ubUGHTBUSVmy7r8JrGp_fw==", "AtomicEventRelationId": "9QbcKcMAdQ6i7WNjwNdiIg==", "AtomicRelationType": "xEffect", "AtomicInference": "hits a tree"}, "premise": "PersonX swerves off the road", "hypothesis": "PersonX then hits a tree", "update": "Person X's car shows no damage.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29108", "update_paraphrase": "Person X's car is not damaged in any way.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4105250305250305, "pred_conf_shift": -0.023241758346557617, "syntactic_distance": 0.22727272727272727}]}, "atomic.train.31827": {"original_confidence": [0.011952280066907406, 0.9880475401878357], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.01138604711741209, 0.988614022731781], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31827.gpt3.5", "original_example": {"example_id": "atomic.train.31827", "premise_hypothesis_id": "atomic.train.14457", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9kmfnu9QHG7CLOteGTIWjQ==", "AtomicEventRelationId": "ZPQKgHMGsGbzkyTmDUpEPw==", "AtomicRelationType": "xAttr", "AtomicInference": "affectionate"}, "premise": "PersonX loves PersonY enough", "hypothesis": "As a result, PersonX feels affectionate", "update": "PersonX likes the touch of a person.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31827", "update_paraphrase": "PersonX enjoys the physical affection of another person.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.36209716209716203, "pred_conf_shift": 0.0005664825439453125, "syntactic_distance": 0.0}, {"confidence": [0.011449163779616356, 0.9885509014129639], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31827.gpt3.3", "original_example": {"example_id": "atomic.train.31827", "premise_hypothesis_id": "atomic.train.14457", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9kmfnu9QHG7CLOteGTIWjQ==", "AtomicEventRelationId": "ZPQKgHMGsGbzkyTmDUpEPw==", "AtomicRelationType": "xAttr", "AtomicInference": "affectionate"}, "premise": "PersonX loves PersonY enough", "hypothesis": "As a result, PersonX feels affectionate", "update": "PersonX likes the touch of a person.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31827", "update_paraphrase": "PersonX enjoys being touched by another person.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4764069264069264, "pred_conf_shift": 0.0005033612251281738, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.02278999611735344, 0.9772099852561951], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31827.gpt3.0", "original_example": {"example_id": "atomic.train.31827", "premise_hypothesis_id": "atomic.train.14457", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9kmfnu9QHG7CLOteGTIWjQ==", "AtomicEventRelationId": "ZPQKgHMGsGbzkyTmDUpEPw==", "AtomicRelationType": "xAttr", "AtomicInference": "affectionate"}, "premise": "PersonX loves PersonY enough", "hypothesis": "As a result, PersonX feels affectionate", "update": "PersonX likes the touch of a person.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31827", "update_paraphrase": "PersonX enjoys the physical sensation of someone else's touch.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.43719336219336213, "pred_conf_shift": -0.010837554931640625, "syntactic_distance": 0.0}, {"confidence": [0.010576033964753151, 0.9894241094589233], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31827.gpt3.2", "original_example": {"example_id": "atomic.train.31827", "premise_hypothesis_id": "atomic.train.14457", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9kmfnu9QHG7CLOteGTIWjQ==", "AtomicEventRelationId": "ZPQKgHMGsGbzkyTmDUpEPw==", "AtomicRelationType": "xAttr", "AtomicInference": "affectionate"}, "premise": "PersonX loves PersonY enough", "hypothesis": "As a result, PersonX feels affectionate", "update": "PersonX likes the touch of a person.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31827", "update_paraphrase": "PersonX enjoys being physically close to someone else.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6169141969141969, "pred_conf_shift": 0.0013765692710876465, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.0148181626573205, 0.9851818084716797], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31827.gpt3.6", "original_example": {"example_id": "atomic.train.31827", "premise_hypothesis_id": "atomic.train.14457", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9kmfnu9QHG7CLOteGTIWjQ==", "AtomicEventRelationId": "ZPQKgHMGsGbzkyTmDUpEPw==", "AtomicRelationType": "xAttr", "AtomicInference": "affectionate"}, "premise": "PersonX loves PersonY enough", "hypothesis": "As a result, PersonX feels affectionate", "update": "PersonX likes the touch of a person.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31827", "update_paraphrase": "PersonX likes the feeling of another person's skin against their own.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.402024827024827, "pred_conf_shift": -0.002865731716156006, "syntactic_distance": 0.0625}, {"confidence": [0.010852505452930927, 0.9891476035118103], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31827.gpt3.1", "original_example": {"example_id": "atomic.train.31827", "premise_hypothesis_id": "atomic.train.14457", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9kmfnu9QHG7CLOteGTIWjQ==", "AtomicEventRelationId": "ZPQKgHMGsGbzkyTmDUpEPw==", "AtomicRelationType": "xAttr", "AtomicInference": "affectionate"}, "premise": "PersonX loves PersonY enough", "hypothesis": "As a result, PersonX feels affectionate", "update": "PersonX likes the touch of a person.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31827", "update_paraphrase": "Person X enjoys the sensation of another person's touch.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.36148226773226777, "pred_conf_shift": 0.0011000633239746094, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.010381236672401428, 0.989618718624115], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.31827.gpt3.4", "original_example": {"example_id": "atomic.train.31827", "premise_hypothesis_id": "atomic.train.14457", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9kmfnu9QHG7CLOteGTIWjQ==", "AtomicEventRelationId": "ZPQKgHMGsGbzkyTmDUpEPw==", "AtomicRelationType": "xAttr", "AtomicInference": "affectionate"}, "premise": "PersonX loves PersonY enough", "hypothesis": "As a result, PersonX feels affectionate", "update": "PersonX likes the touch of a person.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31827", "update_paraphrase": "PersonX enjoys being physically close to another person.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4963606763606764, "pred_conf_shift": 0.0015711784362792969, "syntactic_distance": 0.2}]}, "atomic.train.5101": {"original_confidence": [0.8788579702377319, 0.12114202231168747], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.8788579702377319, 0.12114202231168747], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5101.gpt3.4", "original_example": {"example_id": "atomic.train.5101", "premise_hypothesis_id": "atomic.train.2407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ymD0VMllCDBpoPztCCtdyw==", "AtomicEventRelationId": "uQccsdsCMI42g7Ox4BuYHw==", "AtomicRelationType": "xNeed", "AtomicInference": "to look the other way"}, "premise": "PersonX ignores PersonY's mother", "hypothesis": "Before, PersonX needed to look the other way", "update": "PersonX and PersonY's mother are in the same room.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5101", "update_paraphrase": "PersonX and PersonY's mother are in the same room.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": 0.0, "syntactic_distance": 0.0}, {"confidence": [0.8855862021446228, 0.1144137904047966], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5101.gpt3.3", "original_example": {"example_id": "atomic.train.5101", "premise_hypothesis_id": "atomic.train.2407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ymD0VMllCDBpoPztCCtdyw==", "AtomicEventRelationId": "uQccsdsCMI42g7Ox4BuYHw==", "AtomicRelationType": "xNeed", "AtomicInference": "to look the other way"}, "premise": "PersonX ignores PersonY's mother", "hypothesis": "Before, PersonX needed to look the other way", "update": "PersonX and PersonY's mother are in the same room.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5101", "update_paraphrase": "PersonX and PersonY's mother are in the same room together.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.052631578947368474, "pred_conf_shift": -0.006728231906890869, "syntactic_distance": 0.07142857142857142}, {"confidence": [0.8848323225975037, 0.11516760289669037], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5101.gpt3.2", "original_example": {"example_id": "atomic.train.5101", "premise_hypothesis_id": "atomic.train.2407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ymD0VMllCDBpoPztCCtdyw==", "AtomicEventRelationId": "uQccsdsCMI42g7Ox4BuYHw==", "AtomicRelationType": "xNeed", "AtomicInference": "to look the other way"}, "premise": "PersonX ignores PersonY's mother", "hypothesis": "Before, PersonX needed to look the other way", "update": "PersonX and PersonY's mother are in the same room.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5101", "update_paraphrase": "PersonX and PersonY's mothers are both in the same room.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1218430692114903, "pred_conf_shift": -0.005974419414997101, "syntactic_distance": 0.19230769230769232}, {"confidence": [0.8603335618972778, 0.13966645300388336], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5101.gpt3.0", "original_example": {"example_id": "atomic.train.5101", "premise_hypothesis_id": "atomic.train.2407", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ymD0VMllCDBpoPztCCtdyw==", "AtomicEventRelationId": "uQccsdsCMI42g7Ox4BuYHw==", "AtomicRelationType": "xNeed", "AtomicInference": "to look the other way"}, "premise": "PersonX ignores PersonY's mother", "hypothesis": "Before, PersonX needed to look the other way", "update": "PersonX and PersonY's mother are in the same room.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5101", "update_paraphrase": "PersonX and PersonY's mother share the same living space.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.26759259259259255, "pred_conf_shift": 0.018524430692195892, "syntactic_distance": 0.17857142857142858}]}, "atomic.train.2795": {"original_confidence": [0.9495747685432434, 0.05042522773146629], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.968789279460907, 0.03121067024767399], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2795.gpt3.4", "original_example": {"example_id": "atomic.train.2795", "premise_hypothesis_id": "atomic.train.1317", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ApSqGP8kwDeaGA-kUWkNSg==", "AtomicEventRelationId": "6vffkqPPDoa43WFgOGhc0g==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gains courage"}, "premise": "PersonX is no longer afraid", "hypothesis": "PersonX then personX gains courage", "update": "personX realizes they have to protect their family first", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2795", "update_paraphrase": "personX understands that their family must be their number one priority.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4910359231411863, "pred_conf_shift": -0.019214557483792305, "syntactic_distance": 0.13333333333333333}, {"confidence": [0.7000777125358582, 0.2999221980571747], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2795.gpt3.5", "original_example": {"example_id": "atomic.train.2795", "premise_hypothesis_id": "atomic.train.1317", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ApSqGP8kwDeaGA-kUWkNSg==", "AtomicEventRelationId": "6vffkqPPDoa43WFgOGhc0g==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gains courage"}, "premise": "PersonX is no longer afraid", "hypothesis": "PersonX then personX gains courage", "update": "personX realizes they have to protect their family first", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2795", "update_paraphrase": "It dawned on personX that their family's safety was their top priority.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5045399045399046, "pred_conf_shift": 0.2494969703257084, "syntactic_distance": 0.3684210526315789}, {"confidence": [0.9352870583534241, 0.06471304595470428], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2795.gpt3.1", "original_example": {"example_id": "atomic.train.2795", "premise_hypothesis_id": "atomic.train.1317", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ApSqGP8kwDeaGA-kUWkNSg==", "AtomicEventRelationId": "6vffkqPPDoa43WFgOGhc0g==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gains courage"}, "premise": "PersonX is no longer afraid", "hypothesis": "PersonX then personX gains courage", "update": "personX realizes they have to protect their family first", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2795", "update_paraphrase": "It dawns on personX that their family must be their top priority when it comes to protection.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5578345736716778, "pred_conf_shift": 0.014287818223237991, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.5462704300880432, 0.45372942090034485], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2795.gpt3.2", "original_example": {"example_id": "atomic.train.2795", "premise_hypothesis_id": "atomic.train.1317", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ApSqGP8kwDeaGA-kUWkNSg==", "AtomicEventRelationId": "6vffkqPPDoa43WFgOGhc0g==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gains courage"}, "premise": "PersonX is no longer afraid", "hypothesis": "PersonX then personX gains courage", "update": "personX realizes they have to protect their family first", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2795", "update_paraphrase": "personX realizes that their family must be protected above all else.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.44416666666666665, "pred_conf_shift": 0.40330419316887856, "syntactic_distance": 0.06666666666666667}, {"confidence": [0.5385617613792419, 0.46143823862075806], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2795.gpt3.7", "original_example": {"example_id": "atomic.train.2795", "premise_hypothesis_id": "atomic.train.1317", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ApSqGP8kwDeaGA-kUWkNSg==", "AtomicEventRelationId": "6vffkqPPDoa43WFgOGhc0g==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gains courage"}, "premise": "PersonX is no longer afraid", "hypothesis": "PersonX then personX gains courage", "update": "personX realizes they have to protect their family first", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2795", "update_paraphrase": "It dawns on personX that their family members need to be safeguarded above all else.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5548941798941799, "pred_conf_shift": 0.41101301088929176, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.9432950615882874, 0.056704893708229065], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2795.gpt3.6", "original_example": {"example_id": "atomic.train.2795", "premise_hypothesis_id": "atomic.train.1317", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ApSqGP8kwDeaGA-kUWkNSg==", "AtomicEventRelationId": "6vffkqPPDoa43WFgOGhc0g==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gains courage"}, "premise": "PersonX is no longer afraid", "hypothesis": "PersonX then personX gains courage", "update": "personX realizes they have to protect their family first", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2795", "update_paraphrase": "personX understands that their family must be their top priority when it comes to protection.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5155244115189936, "pred_conf_shift": 0.006279665976762772, "syntactic_distance": 0.06666666666666667}, {"confidence": [0.5941035747528076, 0.40589645504951477], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2795.gpt3.0", "original_example": {"example_id": "atomic.train.2795", "premise_hypothesis_id": "atomic.train.1317", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ApSqGP8kwDeaGA-kUWkNSg==", "AtomicEventRelationId": "6vffkqPPDoa43WFgOGhc0g==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gains courage"}, "premise": "PersonX is no longer afraid", "hypothesis": "PersonX then personX gains courage", "update": "personX realizes they have to protect their family first", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2795", "update_paraphrase": "Person X understands that their family must be protected above all else.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5032672493198809, "pred_conf_shift": 0.3554712273180485, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.763060450553894, 0.23693951964378357], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2795.gpt3.3", "original_example": {"example_id": "atomic.train.2795", "premise_hypothesis_id": "atomic.train.1317", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ApSqGP8kwDeaGA-kUWkNSg==", "AtomicEventRelationId": "6vffkqPPDoa43WFgOGhc0g==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gains courage"}, "premise": "PersonX is no longer afraid", "hypothesis": "PersonX then personX gains courage", "update": "personX realizes they have to protect their family first", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2795", "update_paraphrase": "personX understands that their family's safety is the top priority.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4377204820418117, "pred_conf_shift": 0.18651429191231728, "syntactic_distance": 0.06666666666666667}, {"confidence": [0.01902252808213234, 0.9809773564338684], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2795.gpt3.8", "original_example": {"example_id": "atomic.train.2795", "premise_hypothesis_id": "atomic.train.1317", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ApSqGP8kwDeaGA-kUWkNSg==", "AtomicEventRelationId": "6vffkqPPDoa43WFgOGhc0g==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gains courage"}, "premise": "PersonX is no longer afraid", "hypothesis": "PersonX then personX gains courage", "update": "personX realizes they have to protect their family first", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2795", "update_paraphrase": "It dawned on personX that their family must be protected at all cost.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5169847828938738, "pred_conf_shift": 0.9305521287024021, "syntactic_distance": 0.3684210526315789}]}, "atomic.train.2355": {"original_confidence": [0.4041821360588074, 0.5958178639411926], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.3619961738586426, 0.638003945350647], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2355.gpt3.4", "original_example": {"example_id": "atomic.train.2355", "premise_hypothesis_id": "atomic.train.1108", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "XYO2a6NASdXONDyC_LJA0A==", "AtomicEventRelationId": "2Q-Vwx2FH2LkVqzCQuVWTw==", "AtomicRelationType": "xEffect", "AtomicInference": "puts to sleep"}, "premise": "PersonX takes PersonY's lives", "hypothesis": "PersonX then puts to sleep", "update": "PersoX did not like PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2355", "update_paraphrase": "PersonX had no fondness for PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.413986013986014, "pred_conf_shift": 0.042186081409454346, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.6117435693740845, 0.3882564306259155], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2355.gpt3.0", "original_example": {"example_id": "atomic.train.2355", "premise_hypothesis_id": "atomic.train.1108", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "XYO2a6NASdXONDyC_LJA0A==", "AtomicEventRelationId": "2Q-Vwx2FH2LkVqzCQuVWTw==", "AtomicRelationType": "xEffect", "AtomicInference": "puts to sleep"}, "premise": "PersonX takes PersonY's lives", "hypothesis": "PersonX then puts to sleep", "update": "PersoX did not like PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2355", "update_paraphrase": "There was no love lost between PersonX and PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5557109557109556, "pred_conf_shift": -0.2075614333152771, "syntactic_distance": 0.29411764705882354}, {"confidence": [0.35238584876060486, 0.6476142406463623], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2355.gpt3.2", "original_example": {"example_id": "atomic.train.2355", "premise_hypothesis_id": "atomic.train.1108", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "XYO2a6NASdXONDyC_LJA0A==", "AtomicEventRelationId": "2Q-Vwx2FH2LkVqzCQuVWTw==", "AtomicRelationType": "xEffect", "AtomicInference": "puts to sleep"}, "premise": "PersonX takes PersonY's lives", "hypothesis": "PersonX then puts to sleep", "update": "PersoX did not like PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2355", "update_paraphrase": "PersonX had no liking for PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33519813519813524, "pred_conf_shift": 0.05179637670516968, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.6074350476264954, 0.39256495237350464], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2355.gpt3.1", "original_example": {"example_id": "atomic.train.2355", "premise_hypothesis_id": "atomic.train.1108", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "XYO2a6NASdXONDyC_LJA0A==", "AtomicEventRelationId": "2Q-Vwx2FH2LkVqzCQuVWTw==", "AtomicRelationType": "xEffect", "AtomicInference": "puts to sleep"}, "premise": "PersonX takes PersonY's lives", "hypothesis": "PersonX then puts to sleep", "update": "PersoX did not like PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2355", "update_paraphrase": "There was no love lost between PersoX and PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5502164502164502, "pred_conf_shift": -0.203252911567688, "syntactic_distance": 0.29411764705882354}, {"confidence": [0.6484910845756531, 0.3515089154243469], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2355.gpt3.3", "original_example": {"example_id": "atomic.train.2355", "premise_hypothesis_id": "atomic.train.1108", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "XYO2a6NASdXONDyC_LJA0A==", "AtomicEventRelationId": "2Q-Vwx2FH2LkVqzCQuVWTw==", "AtomicRelationType": "xEffect", "AtomicInference": "puts to sleep"}, "premise": "PersonX takes PersonY's lives", "hypothesis": "PersonX then puts to sleep", "update": "PersoX did not like PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2355", "update_paraphrase": "PersonX did not appreciate PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.15824175824175823, "pred_conf_shift": -0.2443089485168457, "syntactic_distance": 0.0}, {"confidence": [0.4026319086551666, 0.597368061542511], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2355.gpt3.5", "original_example": {"example_id": "atomic.train.2355", "premise_hypothesis_id": "atomic.train.1108", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "XYO2a6NASdXONDyC_LJA0A==", "AtomicEventRelationId": "2Q-Vwx2FH2LkVqzCQuVWTw==", "AtomicRelationType": "xEffect", "AtomicInference": "puts to sleep"}, "premise": "PersonX takes PersonY's lives", "hypothesis": "PersonX then puts to sleep", "update": "PersoX did not like PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2355", "update_paraphrase": "PersonX did not have any positive feelings towards PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.391941391941392, "pred_conf_shift": 0.0015501976013183594, "syntactic_distance": 0.0}]}, "atomic.train.36260": {"original_confidence": [0.7955024242401123, 0.2044975608587265], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.7955024242401123, 0.2044975608587265], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.36260.gpt3.2", "original_example": {"example_id": "atomic.train.36260", "premise_hypothesis_id": "atomic.train.16446", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "rO7kFJIWVSV04yGjkgeG6A==", "AtomicEventRelationId": "VtYMIRB7WMX1zmHEEevddA==", "AtomicRelationType": "xNeed", "AtomicInference": "to get tickets"}, "premise": "PersonX makes the trip", "hypothesis": "Before, PersonX needed to get tickets", "update": "Person X is travelling by car.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36260", "update_paraphrase": "Person X is travelling by car.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": 0.0, "syntactic_distance": 0.0}, {"confidence": [0.19917032122612, 0.8008295893669128], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.36260.gpt3.3", "original_example": {"example_id": "atomic.train.36260", "premise_hypothesis_id": "atomic.train.16446", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "rO7kFJIWVSV04yGjkgeG6A==", "AtomicEventRelationId": "VtYMIRB7WMX1zmHEEevddA==", "AtomicRelationType": "xNeed", "AtomicInference": "to get tickets"}, "premise": "PersonX makes the trip", "hypothesis": "Before, PersonX needed to get tickets", "update": "Person X is travelling by car.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36260", "update_paraphrase": "Person X is driving a car to travel.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42445054945054944, "pred_conf_shift": -0.5963321030139923, "syntactic_distance": 0.10526315789473684}, {"confidence": [0.8643501400947571, 0.13564981520175934], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.36260.gpt3.4", "original_example": {"example_id": "atomic.train.36260", "premise_hypothesis_id": "atomic.train.16446", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "rO7kFJIWVSV04yGjkgeG6A==", "AtomicEventRelationId": "VtYMIRB7WMX1zmHEEevddA==", "AtomicRelationType": "xNeed", "AtomicInference": "to get tickets"}, "premise": "PersonX makes the trip", "hypothesis": "Before, PersonX needed to get tickets", "update": "Person X is travelling by car.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36260", "update_paraphrase": "Person X is driving to their destination.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42833523942121227, "pred_conf_shift": 0.06884771585464478, "syntactic_distance": 0.0}, {"confidence": [0.8070762753486633, 0.19292372465133667], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.36260.gpt3.0", "original_example": {"example_id": "atomic.train.36260", "premise_hypothesis_id": "atomic.train.16446", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "rO7kFJIWVSV04yGjkgeG6A==", "AtomicEventRelationId": "VtYMIRB7WMX1zmHEEevddA==", "AtomicRelationType": "xNeed", "AtomicInference": "to get tickets"}, "premise": "PersonX makes the trip", "hypothesis": "Before, PersonX needed to get tickets", "update": "Person X is travelling by car.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36260", "update_paraphrase": "Person X is traveling by car.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.06688596491228066, "pred_conf_shift": 0.011573851108551025, "syntactic_distance": 0.0}]}, "atomic.train.21125": {"original_confidence": [0.9599732756614685, 0.04002665355801582], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.9487946629524231, 0.051205337047576904], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.21125.gpt3.0", "original_example": {"example_id": "atomic.train.21125", "premise_hypothesis_id": "atomic.train.9747", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "WMp8AU5dH0BipCshFindLg==", "AtomicEventRelationId": "_VR3xklcuGLJ5vC98C_iXQ==", "AtomicRelationType": "xReact", "AtomicInference": "like they are getting something from someone"}, "premise": "PersonX drives PersonY up the wall", "hypothesis": "PersonX is seen as like they are getting something from someone", "update": "PersonX hates PersonY", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21125", "update_paraphrase": "PersonX cannot stand PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4270833333333333, "pred_conf_shift": 0.011178683489561081, "syntactic_distance": 0.3125}, {"confidence": [0.9595442414283752, 0.04045575484633446], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.21125.gpt3.6", "original_example": {"example_id": "atomic.train.21125", "premise_hypothesis_id": "atomic.train.9747", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "WMp8AU5dH0BipCshFindLg==", "AtomicEventRelationId": "_VR3xklcuGLJ5vC98C_iXQ==", "AtomicRelationType": "xReact", "AtomicInference": "like they are getting something from someone"}, "premise": "PersonX drives PersonY up the wall", "hypothesis": "PersonX is seen as like they are getting something from someone", "update": "PersonX hates PersonY", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21125", "update_paraphrase": "PersonX detests PersonY", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19444444444444442, "pred_conf_shift": 0.00042910128831863403, "syntactic_distance": 0.07142857142857142}, {"confidence": [0.9705647826194763, 0.029435278847813606], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.21125.gpt3.5", "original_example": {"example_id": "atomic.train.21125", "premise_hypothesis_id": "atomic.train.9747", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "WMp8AU5dH0BipCshFindLg==", "AtomicEventRelationId": "_VR3xklcuGLJ5vC98C_iXQ==", "AtomicRelationType": "xReact", "AtomicInference": "like they are getting something from someone"}, "premise": "PersonX drives PersonY up the wall", "hypothesis": "PersonX is seen as like they are getting something from someone", "update": "PersonX hates PersonY", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21125", "update_paraphrase": "PersonX can't stand PersonY", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3174603174603174, "pred_conf_shift": -0.010591374710202217, "syntactic_distance": 0.3125}, {"confidence": [0.75852370262146, 0.24147622287273407], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.21125.gpt3.4", "original_example": {"example_id": "atomic.train.21125", "premise_hypothesis_id": "atomic.train.9747", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "WMp8AU5dH0BipCshFindLg==", "AtomicEventRelationId": "_VR3xklcuGLJ5vC98C_iXQ==", "AtomicRelationType": "xReact", "AtomicInference": "like they are getting something from someone"}, "premise": "PersonX drives PersonY up the wall", "hypothesis": "PersonX is seen as like they are getting something from someone", "update": "PersonX hates PersonY", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21125", "update_paraphrase": "PersonX has a strong dislike for PersonY", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4788461538461538, "pred_conf_shift": 0.20144956931471825, "syntactic_distance": 0.13333333333333333}, {"confidence": [0.7809439897537231, 0.21905608475208282], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.21125.gpt3.3", "original_example": {"example_id": "atomic.train.21125", "premise_hypothesis_id": "atomic.train.9747", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "WMp8AU5dH0BipCshFindLg==", "AtomicEventRelationId": "_VR3xklcuGLJ5vC98C_iXQ==", "AtomicRelationType": "xReact", "AtomicInference": "like they are getting something from someone"}, "premise": "PersonX drives PersonY up the wall", "hypothesis": "PersonX is seen as like they are getting something from someone", "update": "PersonX hates PersonY", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21125", "update_paraphrase": "PersonX has intense feelings of dislike towards PersonY", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5422077922077922, "pred_conf_shift": 0.179029431194067, "syntactic_distance": 0.13333333333333333}, {"confidence": [0.4884693920612335, 0.5115306973457336], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.21125.gpt3.2", "original_example": {"example_id": "atomic.train.21125", "premise_hypothesis_id": "atomic.train.9747", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "WMp8AU5dH0BipCshFindLg==", "AtomicEventRelationId": "_VR3xklcuGLJ5vC98C_iXQ==", "AtomicRelationType": "xReact", "AtomicInference": "like they are getting something from someone"}, "premise": "PersonX drives PersonY up the wall", "hypothesis": "PersonX is seen as like they are getting something from someone", "update": "PersonX hates PersonY", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21125", "update_paraphrase": "PersonX has intense feelings of dislike or hostility towards PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6126373626373627, "pred_conf_shift": 0.4715040437877178, "syntactic_distance": 0.13333333333333333}, {"confidence": [0.6286182999610901, 0.3713817000389099], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.21125.gpt3.1", "original_example": {"example_id": "atomic.train.21125", "premise_hypothesis_id": "atomic.train.9747", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "WMp8AU5dH0BipCshFindLg==", "AtomicEventRelationId": "_VR3xklcuGLJ5vC98C_iXQ==", "AtomicRelationType": "xReact", "AtomicInference": "like they are getting something from someone"}, "premise": "PersonX drives PersonY up the wall", "hypothesis": "PersonX is seen as like they are getting something from someone", "update": "PersonX hates PersonY", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21125", "update_paraphrase": "There is no love lost between PersonX and PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6125, "pred_conf_shift": 0.3313550464808941, "syntactic_distance": 0.2}]}, "atomic.train.1274": {"original_confidence": [0.9697010517120361, 0.03029893897473812], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.9763739109039307, 0.023626120761036873], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1274.gpt3.2", "original_example": {"example_id": "atomic.train.1274", "premise_hypothesis_id": "atomic.train.603", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_bV_2H3aJ3urNfdI6qNGSw==", "AtomicEventRelationId": "o--5DJ6IP2Tw6ABXDNSlVA==", "AtomicRelationType": "xNeed", "AtomicInference": "a reason for the meeting"}, "premise": "PersonX calls PersonY into the office", "hypothesis": "Before, PersonX needed a reason for the meeting", "update": "PersonX just wanted to say \"hello\" to PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1274", "update_paraphrase": "PersonX just wanted to greet PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.24149659863945577, "pred_conf_shift": 0.006672859191894531, "syntactic_distance": 0.0}, {"confidence": [0.9697010517120361, 0.03029893897473812], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1274.gpt3.3", "original_example": {"example_id": "atomic.train.1274", "premise_hypothesis_id": "atomic.train.603", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_bV_2H3aJ3urNfdI6qNGSw==", "AtomicEventRelationId": "o--5DJ6IP2Tw6ABXDNSlVA==", "AtomicRelationType": "xNeed", "AtomicInference": "a reason for the meeting"}, "premise": "PersonX calls PersonY into the office", "hypothesis": "Before, PersonX needed a reason for the meeting", "update": "PersonX just wanted to say \"hello\" to PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1274", "update_paraphrase": "PersonX just wanted to say \"hello\" to PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": 0.0, "syntactic_distance": 0.0}, {"confidence": [0.976154088973999, 0.02384602278470993], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1274.gpt3.0", "original_example": {"example_id": "atomic.train.1274", "premise_hypothesis_id": "atomic.train.603", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_bV_2H3aJ3urNfdI6qNGSw==", "AtomicEventRelationId": "o--5DJ6IP2Tw6ABXDNSlVA==", "AtomicRelationType": "xNeed", "AtomicInference": "a reason for the meeting"}, "premise": "PersonX calls PersonY into the office", "hypothesis": "Before, PersonX needed a reason for the meeting", "update": "PersonX just wanted to say \"hello\" to PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1274", "update_paraphrase": "Person X merely wanted to greet Person Y.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42953921078921087, "pred_conf_shift": 0.006453037261962891, "syntactic_distance": 0.05263157894736842}, {"confidence": [0.9764597415924072, 0.02354036457836628], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.1274.gpt3.1", "original_example": {"example_id": "atomic.train.1274", "premise_hypothesis_id": "atomic.train.603", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_bV_2H3aJ3urNfdI6qNGSw==", "AtomicEventRelationId": "o--5DJ6IP2Tw6ABXDNSlVA==", "AtomicRelationType": "xNeed", "AtomicInference": "a reason for the meeting"}, "premise": "PersonX calls PersonY into the office", "hypothesis": "Before, PersonX needed a reason for the meeting", "update": "PersonX just wanted to say \"hello\" to PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1274", "update_paraphrase": "PersonX merely wanted to greet PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3692022263450835, "pred_conf_shift": 0.006758689880371094, "syntactic_distance": 0.0}]}, "atomic.train.19397": {"original_confidence": [0.5670238137245178, 0.4329761862754822], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.595504105091095, 0.4044959247112274], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19397.gpt3.6", "original_example": {"example_id": "atomic.train.19397", "premise_hypothesis_id": "atomic.train.8995", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eUyqP6QgYSGgCuHwAUFCLg==", "AtomicEventRelationId": "wCs77LrgvxyRFU50wIJaPw==", "AtomicRelationType": "xAttr", "AtomicInference": "finished"}, "premise": "PersonX leaves the room", "hypothesis": "As a result, PersonX feels finished", "update": "X goes on to his next chore.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19397", "update_paraphrase": "After completing his current task, X moves on to the next thing on his to-do list.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5020703933747412, "pred_conf_shift": -0.02848026156425476, "syntactic_distance": 0.20833333333333334}, {"confidence": [0.30330613255500793, 0.6966938376426697], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.19397.gpt3.4", "original_example": {"example_id": "atomic.train.19397", "premise_hypothesis_id": "atomic.train.8995", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eUyqP6QgYSGgCuHwAUFCLg==", "AtomicEventRelationId": "wCs77LrgvxyRFU50wIJaPw==", "AtomicRelationType": "xAttr", "AtomicInference": "finished"}, "premise": "PersonX leaves the room", "hypothesis": "As a result, PersonX feels finished", "update": "X goes on to his next chore.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19397", "update_paraphrase": "X moves on to his next task.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19047619047619047, "pred_conf_shift": 0.2637176513671875, "syntactic_distance": 0.0}, {"confidence": [0.3260202407836914, 0.6739797592163086], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.19397.gpt3.7", "original_example": {"example_id": "atomic.train.19397", "premise_hypothesis_id": "atomic.train.8995", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eUyqP6QgYSGgCuHwAUFCLg==", "AtomicEventRelationId": "wCs77LrgvxyRFU50wIJaPw==", "AtomicRelationType": "xAttr", "AtomicInference": "finished"}, "premise": "PersonX leaves the room", "hypothesis": "As a result, PersonX feels finished", "update": "X goes on to his next chore.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19397", "update_paraphrase": "Then, X moved on to the next task on his to-do list.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42063492063492064, "pred_conf_shift": 0.24100357294082642, "syntactic_distance": 0.18181818181818182}, {"confidence": [0.7333753108978271, 0.26662468910217285], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19397.gpt3.2", "original_example": {"example_id": "atomic.train.19397", "premise_hypothesis_id": "atomic.train.8995", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eUyqP6QgYSGgCuHwAUFCLg==", "AtomicEventRelationId": "wCs77LrgvxyRFU50wIJaPw==", "AtomicRelationType": "xAttr", "AtomicInference": "finished"}, "premise": "PersonX leaves the room", "hypothesis": "As a result, PersonX feels finished", "update": "X goes on to his next chore.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19397", "update_paraphrase": "X proceeds with his next task.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39316239316239315, "pred_conf_shift": -0.16635149717330933, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.8053887486457825, 0.19461126625537872], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19397.gpt3.1", "original_example": {"example_id": "atomic.train.19397", "premise_hypothesis_id": "atomic.train.8995", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eUyqP6QgYSGgCuHwAUFCLg==", "AtomicEventRelationId": "wCs77LrgvxyRFU50wIJaPw==", "AtomicRelationType": "xAttr", "AtomicInference": "finished"}, "premise": "PersonX leaves the room", "hypothesis": "As a result, PersonX feels finished", "update": "X goes on to his next chore.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19397", "update_paraphrase": "X continues with his next task.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3990795529257068, "pred_conf_shift": -0.23836492002010345, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.44645175337791443, 0.5535482168197632], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.19397.gpt3.8", "original_example": {"example_id": "atomic.train.19397", "premise_hypothesis_id": "atomic.train.8995", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eUyqP6QgYSGgCuHwAUFCLg==", "AtomicEventRelationId": "wCs77LrgvxyRFU50wIJaPw==", "AtomicRelationType": "xAttr", "AtomicInference": "finished"}, "premise": "PersonX leaves the room", "hypothesis": "As a result, PersonX feels finished", "update": "X goes on to his next chore.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19397", "update_paraphrase": "After finishing his current task, X moved on to his next one.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.36758563074352546, "pred_conf_shift": 0.120572030544281, "syntactic_distance": 0.2608695652173913}, {"confidence": [0.4500785768032074, 0.5499213337898254], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.19397.gpt3.3", "original_example": {"example_id": "atomic.train.19397", "premise_hypothesis_id": "atomic.train.8995", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eUyqP6QgYSGgCuHwAUFCLg==", "AtomicEventRelationId": "wCs77LrgvxyRFU50wIJaPw==", "AtomicRelationType": "xAttr", "AtomicInference": "finished"}, "premise": "PersonX leaves the room", "hypothesis": "As a result, PersonX feels finished", "update": "X goes on to his next chore.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19397", "update_paraphrase": "Next, X moved on to his next task.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2592592592592593, "pred_conf_shift": 0.11694514751434326, "syntactic_distance": 0.14285714285714285}, {"confidence": [0.3220372498035431, 0.6779628396034241], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.19397.gpt3.5", "original_example": {"example_id": "atomic.train.19397", "premise_hypothesis_id": "atomic.train.8995", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eUyqP6QgYSGgCuHwAUFCLg==", "AtomicEventRelationId": "wCs77LrgvxyRFU50wIJaPw==", "AtomicRelationType": "xAttr", "AtomicInference": "finished"}, "premise": "PersonX leaves the room", "hypothesis": "As a result, PersonX feels finished", "update": "X goes on to his next chore.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19397", "update_paraphrase": "X moves on to the next task on his list.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.34313725490196073, "pred_conf_shift": 0.2449866533279419, "syntactic_distance": 0.05}, {"confidence": [0.6378561854362488, 0.362143874168396], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19397.gpt3.0", "original_example": {"example_id": "atomic.train.19397", "premise_hypothesis_id": "atomic.train.8995", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eUyqP6QgYSGgCuHwAUFCLg==", "AtomicEventRelationId": "wCs77LrgvxyRFU50wIJaPw==", "AtomicRelationType": "xAttr", "AtomicInference": "finished"}, "premise": "PersonX leaves the room", "hypothesis": "As a result, PersonX feels finished", "update": "X goes on to his next chore.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19397", "update_paraphrase": "X proceeds to his next task.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.30325443786982254, "pred_conf_shift": -0.07083231210708618, "syntactic_distance": 0.23529411764705882}]}, "atomic.train.13172": {"original_confidence": [0.24293901026248932, 0.7570609450340271], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.5962755680084229, 0.40372440218925476], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.13172.gpt3.0", "original_example": {"example_id": "atomic.train.13172", "premise_hypothesis_id": "atomic.train.6173", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mMmL8LUaO9l3WuhbeSYhog==", "AtomicEventRelationId": "1Q6I3pA_VPMkRwf8zYxEHw==", "AtomicRelationType": "xReact", "AtomicInference": "hungry"}, "premise": "PersonX does n't know what to eat", "hypothesis": "PersonX is seen as hungry", "update": "PersonX wants to eat something they haven't already eaten toady, but can't find anything.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13172", "update_paraphrase": "PersonX would like to consume something new, but can't seem to find anything they haven't already eaten today.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.34489889705882354, "pred_conf_shift": 0.35333655774593353, "syntactic_distance": 0.08333333333333333}, {"confidence": [0.6733989119529724, 0.32660111784935], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.13172.gpt3.1", "original_example": {"example_id": "atomic.train.13172", "premise_hypothesis_id": "atomic.train.6173", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mMmL8LUaO9l3WuhbeSYhog==", "AtomicEventRelationId": "1Q6I3pA_VPMkRwf8zYxEHw==", "AtomicRelationType": "xReact", "AtomicInference": "hungry"}, "premise": "PersonX does n't know what to eat", "hypothesis": "PersonX is seen as hungry", "update": "PersonX wants to eat something they haven't already eaten toady, but can't find anything.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13172", "update_paraphrase": "PersonX wants to try something new for their meal, but can't find anything they haven't already eaten today.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.27012211134453784, "pred_conf_shift": 0.4304599016904831, "syntactic_distance": 0.0}, {"confidence": [0.684113621711731, 0.31588637828826904], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.13172.gpt3.6", "original_example": {"example_id": "atomic.train.13172", "premise_hypothesis_id": "atomic.train.6173", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mMmL8LUaO9l3WuhbeSYhog==", "AtomicEventRelationId": "1Q6I3pA_VPMkRwf8zYxEHw==", "AtomicRelationType": "xReact", "AtomicInference": "hungry"}, "premise": "PersonX does n't know what to eat", "hypothesis": "PersonX is seen as hungry", "update": "PersonX wants to eat something they haven't already eaten toady, but can't find anything.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13172", "update_paraphrase": "PersonX wants to eat something new, but can't find anything they haven't already eaten today.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.15139090118806142, "pred_conf_shift": 0.44117461144924164, "syntactic_distance": 0.0}, {"confidence": [0.1286081075668335, 0.8713918924331665], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.13172.gpt3.3", "original_example": {"example_id": "atomic.train.13172", "premise_hypothesis_id": "atomic.train.6173", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mMmL8LUaO9l3WuhbeSYhog==", "AtomicEventRelationId": "1Q6I3pA_VPMkRwf8zYxEHw==", "AtomicRelationType": "xReact", "AtomicInference": "hungry"}, "premise": "PersonX does n't know what to eat", "hypothesis": "PersonX is seen as hungry", "update": "PersonX wants to eat something they haven't already eaten toady, but can't find anything.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13172", "update_paraphrase": "PersonX would like to try something new for their meal, but can't find anything that meets their criteria.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.43179563492063494, "pred_conf_shift": -0.11433090269565582, "syntactic_distance": 0.08333333333333333}, {"confidence": [0.7492827773094177, 0.2507171332836151], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.13172.gpt3.4", "original_example": {"example_id": "atomic.train.13172", "premise_hypothesis_id": "atomic.train.6173", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mMmL8LUaO9l3WuhbeSYhog==", "AtomicEventRelationId": "1Q6I3pA_VPMkRwf8zYxEHw==", "AtomicRelationType": "xReact", "AtomicInference": "hungry"}, "premise": "PersonX does n't know what to eat", "hypothesis": "PersonX is seen as hungry", "update": "PersonX wants to eat something they haven't already eaten toady, but can't find anything.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13172", "update_paraphrase": "PersonX is looking for something new to eat, but can't find anything they haven't already had today.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3355177554892926, "pred_conf_shift": 0.5063437670469284, "syntactic_distance": 0.041666666666666664}, {"confidence": [0.10920550674200058, 0.8907943964004517], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.13172.gpt3.5", "original_example": {"example_id": "atomic.train.13172", "premise_hypothesis_id": "atomic.train.6173", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mMmL8LUaO9l3WuhbeSYhog==", "AtomicEventRelationId": "1Q6I3pA_VPMkRwf8zYxEHw==", "AtomicRelationType": "xReact", "AtomicInference": "hungry"}, "premise": "PersonX does n't know what to eat", "hypothesis": "PersonX is seen as hungry", "update": "PersonX wants to eat something they haven't already eaten toady, but can't find anything.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13172", "update_paraphrase": "X would like to try something new for their meal, but can't find anything that meets their criteria.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4474206349206349, "pred_conf_shift": -0.13373350352048874, "syntactic_distance": 0.125}, {"confidence": [0.1783696413040161, 0.8216303586959839], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.13172.gpt3.2", "original_example": {"example_id": "atomic.train.13172", "premise_hypothesis_id": "atomic.train.6173", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "mMmL8LUaO9l3WuhbeSYhog==", "AtomicEventRelationId": "1Q6I3pA_VPMkRwf8zYxEHw==", "AtomicRelationType": "xReact", "AtomicInference": "hungry"}, "premise": "PersonX does n't know what to eat", "hypothesis": "PersonX is seen as hungry", "update": "PersonX wants to eat something they haven't already eaten toady, but can't find anything.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13172", "update_paraphrase": "PersonX would like to have something different for their meal, but can't find anything new to eat.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39226365032816646, "pred_conf_shift": -0.0645693689584732, "syntactic_distance": 0.08333333333333333}]}, "atomic.train.15985": {"original_confidence": [0.18495289981365204, 0.815047025680542], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.04604966193437576, 0.9539502263069153], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15985.gpt3.0", "original_example": {"example_id": "atomic.train.15985", "premise_hypothesis_id": "atomic.train.7447", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "83vm77Qxr7CokcIpUj6SAA==", "AtomicEventRelationId": "1HXl6W0dCCTlPJYDnjilbA==", "AtomicRelationType": "xEffect", "AtomicInference": "shakes new boss's hand"}, "premise": "PersonX is offered a new job", "hypothesis": "PersonX then shakes new boss's hand", "update": "PersonX is a new grad", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15985", "update_paraphrase": "PersonX is a recent graduate.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2911111111111111, "pred_conf_shift": 0.1389032006263733, "syntactic_distance": 0.0}, {"confidence": [0.043645765632390976, 0.9563543200492859], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15985.gpt3.1", "original_example": {"example_id": "atomic.train.15985", "premise_hypothesis_id": "atomic.train.7447", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "83vm77Qxr7CokcIpUj6SAA==", "AtomicEventRelationId": "1HXl6W0dCCTlPJYDnjilbA==", "AtomicRelationType": "xEffect", "AtomicInference": "shakes new boss's hand"}, "premise": "PersonX is offered a new job", "hypothesis": "PersonX then shakes new boss's hand", "update": "PersonX is a new grad", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15985", "update_paraphrase": "Person X is a recent graduate.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.30691530691530694, "pred_conf_shift": 0.1413072943687439, "syntactic_distance": 0.05263157894736842}, {"confidence": [0.02797948569059372, 0.9720204472541809], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15985.gpt3.2", "original_example": {"example_id": "atomic.train.15985", "premise_hypothesis_id": "atomic.train.7447", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "83vm77Qxr7CokcIpUj6SAA==", "AtomicEventRelationId": "1HXl6W0dCCTlPJYDnjilbA==", "AtomicRelationType": "xEffect", "AtomicInference": "shakes new boss's hand"}, "premise": "PersonX is offered a new job", "hypothesis": "PersonX then shakes new boss's hand", "update": "PersonX is a new grad", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15985", "update_paraphrase": "PersonX is a freshly graduated individual", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3392940392940393, "pred_conf_shift": 0.15697342157363892, "syntactic_distance": 0.05555555555555555}, {"confidence": [0.17382602393627167, 0.8261739015579224], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15985.gpt3.4", "original_example": {"example_id": "atomic.train.15985", "premise_hypothesis_id": "atomic.train.7447", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "83vm77Qxr7CokcIpUj6SAA==", "AtomicEventRelationId": "1HXl6W0dCCTlPJYDnjilbA==", "AtomicRelationType": "xEffect", "AtomicInference": "shakes new boss's hand"}, "premise": "PersonX is offered a new job", "hypothesis": "PersonX then shakes new boss's hand", "update": "PersonX is a new grad", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15985", "update_paraphrase": "PersonX is a new graduate.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.11515151515151517, "pred_conf_shift": 0.011126875877380371, "syntactic_distance": 0.0}, {"confidence": [0.06614422798156738, 0.9338557720184326], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15985.gpt3.3", "original_example": {"example_id": "atomic.train.15985", "premise_hypothesis_id": "atomic.train.7447", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "83vm77Qxr7CokcIpUj6SAA==", "AtomicEventRelationId": "1HXl6W0dCCTlPJYDnjilbA==", "AtomicRelationType": "xEffect", "AtomicInference": "shakes new boss's hand"}, "premise": "PersonX is offered a new job", "hypothesis": "PersonX then shakes new boss's hand", "update": "PersonX is a new grad", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15985", "update_paraphrase": "PersonX has just graduated from college.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5834498834498835, "pred_conf_shift": 0.11880874633789062, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.3615635335445404, 0.638436496257782], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15985.gpt3.5", "original_example": {"example_id": "atomic.train.15985", "premise_hypothesis_id": "atomic.train.7447", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "83vm77Qxr7CokcIpUj6SAA==", "AtomicEventRelationId": "1HXl6W0dCCTlPJYDnjilbA==", "AtomicRelationType": "xEffect", "AtomicInference": "shakes new boss's hand"}, "premise": "PersonX is offered a new job", "hypothesis": "PersonX then shakes new boss's hand", "update": "PersonX is a new grad", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15985", "update_paraphrase": "PersonX has just graduated.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5365622032288699, "pred_conf_shift": -0.17661052942276, "syntactic_distance": 0.3333333333333333}]}, "atomic.train.19106": {"original_confidence": [0.05985860154032707, 0.9401413202285767], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.04866940528154373, 0.9513306021690369], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.19106.gpt3.1", "original_example": {"example_id": "atomic.train.19106", "premise_hypothesis_id": "atomic.train.8864", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aDXPLg6e-ZMXuytXpal3rQ==", "AtomicEventRelationId": "Hzlrk0vD5ajeOAjO8K7gWA==", "AtomicRelationType": "xWant", "AtomicInference": "to apologize"}, "premise": "PersonX plays old harry", "hypothesis": "As a result, PersonX wants to apologize", "update": "Old Harry bullied PersonX", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19106", "update_paraphrase": "Old Harry was a bully to PersonX", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.35757575757575755, "pred_conf_shift": -0.01118919625878334, "syntactic_distance": 0.5333333333333333}, {"confidence": [0.08887985348701477, 0.9111201763153076], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.19106.gpt3.8", "original_example": {"example_id": "atomic.train.19106", "premise_hypothesis_id": "atomic.train.8864", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aDXPLg6e-ZMXuytXpal3rQ==", "AtomicEventRelationId": "Hzlrk0vD5ajeOAjO8K7gWA==", "AtomicRelationType": "xWant", "AtomicInference": "to apologize"}, "premise": "PersonX plays old harry", "hypothesis": "As a result, PersonX wants to apologize", "update": "Old Harry bullied PersonX", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19106", "update_paraphrase": "Harry, the old man, bullied PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.27499999999999997, "pred_conf_shift": 0.0290212519466877, "syntactic_distance": 0.5833333333333334}, {"confidence": [0.0997939258813858, 0.9002060294151306], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.19106.gpt3.5", "original_example": {"example_id": "atomic.train.19106", "premise_hypothesis_id": "atomic.train.8864", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aDXPLg6e-ZMXuytXpal3rQ==", "AtomicEventRelationId": "Hzlrk0vD5ajeOAjO8K7gWA==", "AtomicRelationType": "xWant", "AtomicInference": "to apologize"}, "premise": "PersonX plays old harry", "hypothesis": "As a result, PersonX wants to apologize", "update": "Old Harry bullied PersonX", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19106", "update_paraphrase": "Person X was always being bullied by Old Harry.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5443786982248521, "pred_conf_shift": 0.03993532434105873, "syntactic_distance": 0.6470588235294118}, {"confidence": [0.04526405408978462, 0.9547359943389893], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.19106.gpt3.3", "original_example": {"example_id": "atomic.train.19106", "premise_hypothesis_id": "atomic.train.8864", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aDXPLg6e-ZMXuytXpal3rQ==", "AtomicEventRelationId": "Hzlrk0vD5ajeOAjO8K7gWA==", "AtomicRelationType": "xWant", "AtomicInference": "to apologize"}, "premise": "PersonX plays old harry", "hypothesis": "As a result, PersonX wants to apologize", "update": "Old Harry bullied PersonX", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19106", "update_paraphrase": "PersonX was bullied mercilessly by Old Harry.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45454545454545453, "pred_conf_shift": -0.01459454745054245, "syntactic_distance": 0.6}, {"confidence": [0.049772314727306366, 0.950227677822113], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.19106.gpt3.0", "original_example": {"example_id": "atomic.train.19106", "premise_hypothesis_id": "atomic.train.8864", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aDXPLg6e-ZMXuytXpal3rQ==", "AtomicEventRelationId": "Hzlrk0vD5ajeOAjO8K7gWA==", "AtomicRelationType": "xWant", "AtomicInference": "to apologize"}, "premise": "PersonX plays old harry", "hypothesis": "As a result, PersonX wants to apologize", "update": "Old Harry bullied PersonX", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19106", "update_paraphrase": "PersonX was bullied relentlessly by Old Harry.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45454545454545453, "pred_conf_shift": -0.010086286813020706, "syntactic_distance": 0.6}, {"confidence": [0.04320657253265381, 0.9567934274673462], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.19106.gpt3.7", "original_example": {"example_id": "atomic.train.19106", "premise_hypothesis_id": "atomic.train.8864", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aDXPLg6e-ZMXuytXpal3rQ==", "AtomicEventRelationId": "Hzlrk0vD5ajeOAjO8K7gWA==", "AtomicRelationType": "xWant", "AtomicInference": "to apologize"}, "premise": "PersonX plays old harry", "hypothesis": "As a result, PersonX wants to apologize", "update": "Old Harry bullied PersonX", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19106", "update_paraphrase": "PersonX was constantly bullied by Old Harry.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45454545454545453, "pred_conf_shift": -0.016652029007673264, "syntactic_distance": 0.625}, {"confidence": [0.07004518806934357, 0.9299547076225281], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.19106.gpt3.2", "original_example": {"example_id": "atomic.train.19106", "premise_hypothesis_id": "atomic.train.8864", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aDXPLg6e-ZMXuytXpal3rQ==", "AtomicEventRelationId": "Hzlrk0vD5ajeOAjO8K7gWA==", "AtomicRelationType": "xWant", "AtomicInference": "to apologize"}, "premise": "PersonX plays old harry", "hypothesis": "As a result, PersonX wants to apologize", "update": "Old Harry bullied PersonX", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19106", "update_paraphrase": "PersonX was always getting picked on by Old Harry.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5798816568047337, "pred_conf_shift": 0.010186586529016495, "syntactic_distance": 0.6875}, {"confidence": [0.07399798929691315, 0.9260019659996033], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.19106.gpt3.4", "original_example": {"example_id": "atomic.train.19106", "premise_hypothesis_id": "atomic.train.8864", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aDXPLg6e-ZMXuytXpal3rQ==", "AtomicEventRelationId": "Hzlrk0vD5ajeOAjO8K7gWA==", "AtomicRelationType": "xWant", "AtomicInference": "to apologize"}, "premise": "PersonX plays old harry", "hypothesis": "As a result, PersonX wants to apologize", "update": "Old Harry bullied PersonX", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19106", "update_paraphrase": "Old Harry was mean to PersonX", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.34181818181818185, "pred_conf_shift": 0.014139387756586075, "syntactic_distance": 0.5333333333333333}, {"confidence": [0.06974423676729202, 0.9302557110786438], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.19106.gpt3.6", "original_example": {"example_id": "atomic.train.19106", "premise_hypothesis_id": "atomic.train.8864", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aDXPLg6e-ZMXuytXpal3rQ==", "AtomicEventRelationId": "Hzlrk0vD5ajeOAjO8K7gWA==", "AtomicRelationType": "xWant", "AtomicInference": "to apologize"}, "premise": "PersonX plays old harry", "hypothesis": "As a result, PersonX wants to apologize", "update": "Old Harry bullied PersonX", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19106", "update_paraphrase": "PersonX was always being picked on by Old Harry.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5798816568047337, "pred_conf_shift": 0.00988563522696495, "syntactic_distance": 0.6875}]}, "atomic.train.29388": {"original_confidence": [0.34240368008613586, 0.6575964093208313], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.45439615845680237, 0.54560387134552], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.29388.gpt3.0", "original_example": {"example_id": "atomic.train.29388", "premise_hypothesis_id": "atomic.train.13337", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eMOeMLOa36nmwM03ccVdEg==", "AtomicEventRelationId": "7Am-PeBmYC3pZAPSx6iPzA==", "AtomicRelationType": "xNeed", "AtomicInference": "pack clothes"}, "premise": "PersonX leaves for college", "hypothesis": "Before, PersonX needed pack clothes", "update": "PersonX has ordered new clothes to be sent to the school.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29388", "update_paraphrase": "PersonX has instructed for new clothes to be delivered to the school.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19719302436693747, "pred_conf_shift": 0.1119924783706665, "syntactic_distance": 0.0625}, {"confidence": [0.35072776675224304, 0.6492722034454346], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.29388.gpt3.4", "original_example": {"example_id": "atomic.train.29388", "premise_hypothesis_id": "atomic.train.13337", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eMOeMLOa36nmwM03ccVdEg==", "AtomicEventRelationId": "7Am-PeBmYC3pZAPSx6iPzA==", "AtomicRelationType": "xNeed", "AtomicInference": "pack clothes"}, "premise": "PersonX leaves for college", "hypothesis": "Before, PersonX needed pack clothes", "update": "PersonX has ordered new clothes to be sent to the school.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29388", "update_paraphrase": "PersonX has requested new clothes to be sent to the school.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.05519480519480513, "pred_conf_shift": 0.008324086666107178, "syntactic_distance": 0.0625}, {"confidence": [0.6426241397857666, 0.3573758900165558], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29388.gpt3.8", "original_example": {"example_id": "atomic.train.29388", "premise_hypothesis_id": "atomic.train.13337", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eMOeMLOa36nmwM03ccVdEg==", "AtomicEventRelationId": "7Am-PeBmYC3pZAPSx6iPzA==", "AtomicRelationType": "xNeed", "AtomicInference": "pack clothes"}, "premise": "PersonX leaves for college", "hypothesis": "Before, PersonX needed pack clothes", "update": "PersonX has ordered new clothes to be sent to the school.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29388", "update_paraphrase": "PersonX has arranged for new clothes to be sent to the school.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.09565217391304354, "pred_conf_shift": 0.30022045969963074, "syntactic_distance": 0.0625}, {"confidence": [0.48386314511299133, 0.5161368250846863], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.29388.gpt3.6", "original_example": {"example_id": "atomic.train.29388", "premise_hypothesis_id": "atomic.train.13337", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eMOeMLOa36nmwM03ccVdEg==", "AtomicEventRelationId": "7Am-PeBmYC3pZAPSx6iPzA==", "AtomicRelationType": "xNeed", "AtomicInference": "pack clothes"}, "premise": "PersonX leaves for college", "hypothesis": "Before, PersonX needed pack clothes", "update": "PersonX has ordered new clothes to be sent to the school.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29388", "update_paraphrase": "PersonX has ordered new clothes to be shipped to the school.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.05785123966942152, "pred_conf_shift": 0.14145946502685547, "syntactic_distance": 0.0625}, {"confidence": [0.3612211346626282, 0.638778805732727], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.29388.gpt3.7", "original_example": {"example_id": "atomic.train.29388", "premise_hypothesis_id": "atomic.train.13337", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eMOeMLOa36nmwM03ccVdEg==", "AtomicEventRelationId": "7Am-PeBmYC3pZAPSx6iPzA==", "AtomicRelationType": "xNeed", "AtomicInference": "pack clothes"}, "premise": "PersonX leaves for college", "hypothesis": "Before, PersonX needed pack clothes", "update": "PersonX has ordered new clothes to be sent to the school.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29388", "update_paraphrase": "PersonX requested that new clothes be delivered to the school.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22837519623233904, "pred_conf_shift": 0.01881745457649231, "syntactic_distance": 0.25}, {"confidence": [0.3685949146747589, 0.6314049959182739], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.29388.gpt3.1", "original_example": {"example_id": "atomic.train.29388", "premise_hypothesis_id": "atomic.train.13337", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eMOeMLOa36nmwM03ccVdEg==", "AtomicEventRelationId": "7Am-PeBmYC3pZAPSx6iPzA==", "AtomicRelationType": "xNeed", "AtomicInference": "pack clothes"}, "premise": "PersonX leaves for college", "hypothesis": "Before, PersonX needed pack clothes", "update": "PersonX has ordered new clothes to be sent to the school.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29388", "update_paraphrase": "PersonX has ordered new clothes to be delivered to the school.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.06738715829624925, "pred_conf_shift": 0.026191234588623047, "syntactic_distance": 0.0625}, {"confidence": [0.5068349838256836, 0.4931650161743164], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.29388.gpt3.2", "original_example": {"example_id": "atomic.train.29388", "premise_hypothesis_id": "atomic.train.13337", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eMOeMLOa36nmwM03ccVdEg==", "AtomicEventRelationId": "7Am-PeBmYC3pZAPSx6iPzA==", "AtomicRelationType": "xNeed", "AtomicInference": "pack clothes"}, "premise": "PersonX leaves for college", "hypothesis": "Before, PersonX needed pack clothes", "update": "PersonX has ordered new clothes to be sent to the school.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29388", "update_paraphrase": "PersonX has arranged for new clothes to be delivered to the school.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19746376811594213, "pred_conf_shift": 0.16443130373954773, "syntactic_distance": 0.0625}, {"confidence": [0.3403483033180237, 0.6596517562866211], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.29388.gpt3.3", "original_example": {"example_id": "atomic.train.29388", "premise_hypothesis_id": "atomic.train.13337", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eMOeMLOa36nmwM03ccVdEg==", "AtomicEventRelationId": "7Am-PeBmYC3pZAPSx6iPzA==", "AtomicRelationType": "xNeed", "AtomicInference": "pack clothes"}, "premise": "PersonX leaves for college", "hypothesis": "Before, PersonX needed pack clothes", "update": "PersonX has ordered new clothes to be sent to the school.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29388", "update_paraphrase": "PersonX has requested new clothes to be delivered to the school.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.16215034965034963, "pred_conf_shift": -0.0020553767681121826, "syntactic_distance": 0.0625}, {"confidence": [0.3457016050815582, 0.6542984247207642], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.29388.gpt3.5", "original_example": {"example_id": "atomic.train.29388", "premise_hypothesis_id": "atomic.train.13337", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "eMOeMLOa36nmwM03ccVdEg==", "AtomicEventRelationId": "7Am-PeBmYC3pZAPSx6iPzA==", "AtomicRelationType": "xNeed", "AtomicInference": "pack clothes"}, "premise": "PersonX leaves for college", "hypothesis": "Before, PersonX needed pack clothes", "update": "PersonX has ordered new clothes to be sent to the school.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.29388", "update_paraphrase": "PersonX arranged for new clothes to be delivered to the school.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.20272038567493106, "pred_conf_shift": 0.0032979249954223633, "syntactic_distance": 0.1875}]}, "atomic.train.31826": {"original_confidence": [0.987686276435852, 0.012313577346503735], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.9838659167289734, 0.01613403484225273], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31826.gpt3.6", "original_example": {"example_id": "atomic.train.31826", "premise_hypothesis_id": "atomic.train.14457", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9kmfnu9QHG7CLOteGTIWjQ==", "AtomicEventRelationId": "ZPQKgHMGsGbzkyTmDUpEPw==", "AtomicRelationType": "xAttr", "AtomicInference": "affectionate"}, "premise": "PersonX loves PersonY enough", "hypothesis": "As a result, PersonX feels affectionate", "update": "PersonX is a cold personality.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31826", "update_paraphrase": "PersonX is a very aloof person.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28625622743269796, "pred_conf_shift": -0.003820359706878662, "syntactic_distance": 0.05555555555555555}, {"confidence": [0.9828994870185852, 0.017100472003221512], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31826.gpt3.5", "original_example": {"example_id": "atomic.train.31826", "premise_hypothesis_id": "atomic.train.14457", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9kmfnu9QHG7CLOteGTIWjQ==", "AtomicEventRelationId": "ZPQKgHMGsGbzkyTmDUpEPw==", "AtomicRelationType": "xAttr", "AtomicInference": "affectionate"}, "premise": "PersonX loves PersonY enough", "hypothesis": "As a result, PersonX feels affectionate", "update": "PersonX is a cold personality.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31826", "update_paraphrase": "PersonX is unemotional and detached.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4045454545454545, "pred_conf_shift": -0.004786789417266846, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.9627538323402405, 0.03724617511034012], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31826.gpt3.8", "original_example": {"example_id": "atomic.train.31826", "premise_hypothesis_id": "atomic.train.14457", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9kmfnu9QHG7CLOteGTIWjQ==", "AtomicEventRelationId": "ZPQKgHMGsGbzkyTmDUpEPw==", "AtomicRelationType": "xAttr", "AtomicInference": "affectionate"}, "premise": "PersonX loves PersonY enough", "hypothesis": "As a result, PersonX feels affectionate", "update": "PersonX is a cold personality.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31826", "update_paraphrase": "PersonX is an unemotional person.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.36941176470588233, "pred_conf_shift": -0.024932444095611572, "syntactic_distance": 0.0}, {"confidence": [0.9849725365638733, 0.015027432702481747], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31826.gpt3.0", "original_example": {"example_id": "atomic.train.31826", "premise_hypothesis_id": "atomic.train.14457", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9kmfnu9QHG7CLOteGTIWjQ==", "AtomicEventRelationId": "ZPQKgHMGsGbzkyTmDUpEPw==", "AtomicRelationType": "xAttr", "AtomicInference": "affectionate"}, "premise": "PersonX loves PersonY enough", "hypothesis": "As a result, PersonX feels affectionate", "update": "PersonX is a cold personality.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31826", "update_paraphrase": "PersonX is unemotional and indifferent.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42030303030303023, "pred_conf_shift": -0.0027137398719787598, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.9861590266227722, 0.013841107487678528], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31826.gpt3.2", "original_example": {"example_id": "atomic.train.31826", "premise_hypothesis_id": "atomic.train.14457", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9kmfnu9QHG7CLOteGTIWjQ==", "AtomicEventRelationId": "ZPQKgHMGsGbzkyTmDUpEPw==", "AtomicRelationType": "xAttr", "AtomicInference": "affectionate"}, "premise": "PersonX loves PersonY enough", "hypothesis": "As a result, PersonX feels affectionate", "update": "PersonX is a cold personality.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31826", "update_paraphrase": "PersonX is an aloof personality.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.29292929292929293, "pred_conf_shift": -0.001527249813079834, "syntactic_distance": 0.0}, {"confidence": [0.9881060123443604, 0.011894039809703827], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31826.gpt3.1", "original_example": {"example_id": "atomic.train.31826", "premise_hypothesis_id": "atomic.train.14457", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9kmfnu9QHG7CLOteGTIWjQ==", "AtomicEventRelationId": "ZPQKgHMGsGbzkyTmDUpEPw==", "AtomicRelationType": "xAttr", "AtomicInference": "affectionate"}, "premise": "PersonX loves PersonY enough", "hypothesis": "As a result, PersonX feels affectionate", "update": "PersonX is a cold personality.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31826", "update_paraphrase": "PersonX is indifferent and unfriendly.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.43190476190476185, "pred_conf_shift": 0.0004197359085083008, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.9871351718902588, 0.012864859774708748], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31826.gpt3.3", "original_example": {"example_id": "atomic.train.31826", "premise_hypothesis_id": "atomic.train.14457", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9kmfnu9QHG7CLOteGTIWjQ==", "AtomicEventRelationId": "ZPQKgHMGsGbzkyTmDUpEPw==", "AtomicRelationType": "xAttr", "AtomicInference": "affectionate"}, "premise": "PersonX loves PersonY enough", "hypothesis": "As a result, PersonX feels affectionate", "update": "PersonX is a cold personality.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31826", "update_paraphrase": "PersonX is distant and unemotional.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4196969696969697, "pred_conf_shift": -0.0005511045455932617, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.9781720042228699, 0.021828075870871544], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31826.gpt3.7", "original_example": {"example_id": "atomic.train.31826", "premise_hypothesis_id": "atomic.train.14457", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9kmfnu9QHG7CLOteGTIWjQ==", "AtomicEventRelationId": "ZPQKgHMGsGbzkyTmDUpEPw==", "AtomicRelationType": "xAttr", "AtomicInference": "affectionate"}, "premise": "PersonX loves PersonY enough", "hypothesis": "As a result, PersonX feels affectionate", "update": "PersonX is a cold personality.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31826", "update_paraphrase": "Person X seems unemotional and is not very outgoing.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5877051519908663, "pred_conf_shift": -0.009514272212982178, "syntactic_distance": 0.36363636363636365}, {"confidence": [0.9880972504615784, 0.011902629397809505], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31826.gpt3.4", "original_example": {"example_id": "atomic.train.31826", "premise_hypothesis_id": "atomic.train.14457", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9kmfnu9QHG7CLOteGTIWjQ==", "AtomicEventRelationId": "ZPQKgHMGsGbzkyTmDUpEPw==", "AtomicRelationType": "xAttr", "AtomicInference": "affectionate"}, "premise": "PersonX loves PersonY enough", "hypothesis": "As a result, PersonX feels affectionate", "update": "PersonX is a cold personality.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31826", "update_paraphrase": "PersonX is unapproachable and unfriendly.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42301587301587296, "pred_conf_shift": 0.00041097402572631836, "syntactic_distance": 0.2222222222222222}]}, "atomic.train.21421": {"original_confidence": [0.18518999218940735, 0.814810037612915], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.12603454291820526, 0.8739655017852783], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.21421.gpt3.1", "original_example": {"example_id": "atomic.train.21421", "premise_hypothesis_id": "atomic.train.9873", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8oBDwS2qBnjvIoC18aaNoA==", "AtomicEventRelationId": "X-OihNMi_kGeQWhZmwSYiA==", "AtomicRelationType": "xWant", "AtomicInference": "nothing"}, "premise": "PersonX poses PersonY threat", "hypothesis": "As a result, PersonX wants nothing", "update": "PersonX runs away from the threat.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21421", "update_paraphrase": "PersonX escapes the danger by running away.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4594482440636287, "pred_conf_shift": 0.05915546417236328, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.18163631856441498, 0.818363606929779], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.21421.gpt3.6", "original_example": {"example_id": "atomic.train.21421", "premise_hypothesis_id": "atomic.train.9873", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8oBDwS2qBnjvIoC18aaNoA==", "AtomicEventRelationId": "X-OihNMi_kGeQWhZmwSYiA==", "AtomicRelationType": "xWant", "AtomicInference": "nothing"}, "premise": "PersonX poses PersonY threat", "hypothesis": "As a result, PersonX wants nothing", "update": "PersonX runs away from the threat.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21421", "update_paraphrase": "PersonX chose to flee rather than confront the threat.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.49037037037037035, "pred_conf_shift": 0.0035535693168640137, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.15295495092868805, 0.8470450043678284], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.21421.gpt3.2", "original_example": {"example_id": "atomic.train.21421", "premise_hypothesis_id": "atomic.train.9873", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8oBDwS2qBnjvIoC18aaNoA==", "AtomicEventRelationId": "X-OihNMi_kGeQWhZmwSYiA==", "AtomicRelationType": "xWant", "AtomicInference": "nothing"}, "premise": "PersonX poses PersonY threat", "hypothesis": "As a result, PersonX wants nothing", "update": "PersonX runs away from the threat.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21421", "update_paraphrase": "PersonX takes off from the scene to avoid the danger.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5347222222222222, "pred_conf_shift": 0.03223496675491333, "syntactic_distance": 0.35}, {"confidence": [0.2098834365606308, 0.790116548538208], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.21421.gpt3.5", "original_example": {"example_id": "atomic.train.21421", "premise_hypothesis_id": "atomic.train.9873", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8oBDwS2qBnjvIoC18aaNoA==", "AtomicEventRelationId": "X-OihNMi_kGeQWhZmwSYiA==", "AtomicRelationType": "xWant", "AtomicInference": "nothing"}, "premise": "PersonX poses PersonY threat", "hypothesis": "As a result, PersonX wants nothing", "update": "PersonX runs away from the threat.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21421", "update_paraphrase": "PersonX flees from the danger.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3831037649219467, "pred_conf_shift": -0.02469348907470703, "syntactic_distance": 0.25}, {"confidence": [0.3394731283187866, 0.6605268716812134], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.21421.gpt3.4", "original_example": {"example_id": "atomic.train.21421", "premise_hypothesis_id": "atomic.train.9873", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8oBDwS2qBnjvIoC18aaNoA==", "AtomicEventRelationId": "X-OihNMi_kGeQWhZmwSYiA==", "AtomicRelationType": "xWant", "AtomicInference": "nothing"}, "premise": "PersonX poses PersonY threat", "hypothesis": "As a result, PersonX wants nothing", "update": "PersonX runs away from the threat.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21421", "update_paraphrase": "Person X fled the scene when they saw the threat approaching.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5437836673130791, "pred_conf_shift": -0.15428316593170166, "syntactic_distance": 0.4}, {"confidence": [0.24352219700813293, 0.7564778327941895], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.21421.gpt3.0", "original_example": {"example_id": "atomic.train.21421", "premise_hypothesis_id": "atomic.train.9873", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8oBDwS2qBnjvIoC18aaNoA==", "AtomicEventRelationId": "X-OihNMi_kGeQWhZmwSYiA==", "AtomicRelationType": "xWant", "AtomicInference": "nothing"}, "premise": "PersonX poses PersonY threat", "hypothesis": "As a result, PersonX wants nothing", "update": "PersonX runs away from the threat.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21421", "update_paraphrase": "PersonX flees the scene to avoid the danger.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5476190476190476, "pred_conf_shift": -0.058332204818725586, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.5044471621513367, 0.4955528676509857], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.21421.gpt3.3", "original_example": {"example_id": "atomic.train.21421", "premise_hypothesis_id": "atomic.train.9873", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8oBDwS2qBnjvIoC18aaNoA==", "AtomicEventRelationId": "X-OihNMi_kGeQWhZmwSYiA==", "AtomicRelationType": "xWant", "AtomicInference": "nothing"}, "premise": "PersonX poses PersonY threat", "hypothesis": "As a result, PersonX wants nothing", "update": "PersonX runs away from the threat.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21421", "update_paraphrase": "PersonX chooses to flee from the looming threat.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4666048237476809, "pred_conf_shift": -0.3192571699619293, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.20806783437728882, 0.7919321656227112], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.21421.gpt3.7", "original_example": {"example_id": "atomic.train.21421", "premise_hypothesis_id": "atomic.train.9873", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "8oBDwS2qBnjvIoC18aaNoA==", "AtomicEventRelationId": "X-OihNMi_kGeQWhZmwSYiA==", "AtomicRelationType": "xWant", "AtomicInference": "nothing"}, "premise": "PersonX poses PersonY threat", "hypothesis": "As a result, PersonX wants nothing", "update": "PersonX runs away from the threat.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.21421", "update_paraphrase": "PersonX avoids the danger by running away from it.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39675990675990686, "pred_conf_shift": -0.022877871990203857, "syntactic_distance": 0.3684210526315789}]}, "atomic.train.20568": {"original_confidence": [0.31823840737342834, 0.6817615628242493], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.1594967097043991, 0.8405033349990845], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.20568.gpt3.6", "original_example": {"example_id": "atomic.train.20568", "premise_hypothesis_id": "atomic.train.9509", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "5Prwu4JJGjTqELkAkWGIhg==", "AtomicEventRelationId": "_DwAM8gX9aruJFo5z_BzTQ==", "AtomicRelationType": "xWant", "AtomicInference": "to get even"}, "premise": "PersonX stabs PersonY in the back", "hypothesis": "As a result, PersonX wants to get even", "update": "PersonX was being blackmailed by someone else.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20568", "update_paraphrase": "Someone was blackmailing PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4161490683229814, "pred_conf_shift": -0.15874169766902924, "syntactic_distance": 0.0625}, {"confidence": [0.3418959975242615, 0.6581039428710938], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.20568.gpt3.0", "original_example": {"example_id": "atomic.train.20568", "premise_hypothesis_id": "atomic.train.9509", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "5Prwu4JJGjTqELkAkWGIhg==", "AtomicEventRelationId": "_DwAM8gX9aruJFo5z_BzTQ==", "AtomicRelationType": "xWant", "AtomicInference": "to get even"}, "premise": "PersonX stabs PersonY in the back", "hypothesis": "As a result, PersonX wants to get even", "update": "PersonX was being blackmailed by someone else.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20568", "update_paraphrase": "PersonX was being threatened by another person to keep something private.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4373643331976665, "pred_conf_shift": 0.02365759015083313, "syntactic_distance": 0.0}, {"confidence": [0.2519974410533905, 0.7480025887489319], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.20568.gpt3.2", "original_example": {"example_id": "atomic.train.20568", "premise_hypothesis_id": "atomic.train.9509", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "5Prwu4JJGjTqELkAkWGIhg==", "AtomicEventRelationId": "_DwAM8gX9aruJFo5z_BzTQ==", "AtomicRelationType": "xWant", "AtomicInference": "to get even"}, "premise": "PersonX stabs PersonY in the back", "hypothesis": "As a result, PersonX wants to get even", "update": "PersonX was being blackmailed by someone else.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20568", "update_paraphrase": "PersonX was being blackmailed by another person.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.18571428571428567, "pred_conf_shift": -0.06624096632003784, "syntactic_distance": 0.0}, {"confidence": [0.5191789865493774, 0.48082101345062256], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.20568.gpt3.3", "original_example": {"example_id": "atomic.train.20568", "premise_hypothesis_id": "atomic.train.9509", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "5Prwu4JJGjTqELkAkWGIhg==", "AtomicEventRelationId": "_DwAM8gX9aruJFo5z_BzTQ==", "AtomicRelationType": "xWant", "AtomicInference": "to get even"}, "premise": "PersonX stabs PersonY in the back", "hypothesis": "As a result, PersonX wants to get even", "update": "PersonX was being blackmailed by someone else.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20568", "update_paraphrase": "PersonX was receiving blackmail threats from another individual.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4886580086580086, "pred_conf_shift": 0.2009405791759491, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.30243489146232605, 0.6975650787353516], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.20568.gpt3.1", "original_example": {"example_id": "atomic.train.20568", "premise_hypothesis_id": "atomic.train.9509", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "5Prwu4JJGjTqELkAkWGIhg==", "AtomicEventRelationId": "_DwAM8gX9aruJFo5z_BzTQ==", "AtomicRelationType": "xWant", "AtomicInference": "to get even"}, "premise": "PersonX stabs PersonY in the back", "hypothesis": "As a result, PersonX wants to get even", "update": "PersonX was being blackmailed by someone else.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20568", "update_paraphrase": "PersonX was being extorted by another person.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3678004535147392, "pred_conf_shift": -0.015803515911102295, "syntactic_distance": 0.0}, {"confidence": [0.31823840737342834, 0.6817615628242493], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.20568.gpt3.4", "original_example": {"example_id": "atomic.train.20568", "premise_hypothesis_id": "atomic.train.9509", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "5Prwu4JJGjTqELkAkWGIhg==", "AtomicEventRelationId": "_DwAM8gX9aruJFo5z_BzTQ==", "AtomicRelationType": "xWant", "AtomicInference": "to get even"}, "premise": "PersonX stabs PersonY in the back", "hypothesis": "As a result, PersonX wants to get even", "update": "PersonX was being blackmailed by someone else.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20568", "update_paraphrase": "PersonX was being blackmailed by someone else.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": 0.0, "syntactic_distance": 0.0}, {"confidence": [0.5252849459648132, 0.47471505403518677], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.20568.gpt3.7", "original_example": {"example_id": "atomic.train.20568", "premise_hypothesis_id": "atomic.train.9509", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "5Prwu4JJGjTqELkAkWGIhg==", "AtomicEventRelationId": "_DwAM8gX9aruJFo5z_BzTQ==", "AtomicRelationType": "xWant", "AtomicInference": "to get even"}, "premise": "PersonX stabs PersonY in the back", "hypothesis": "As a result, PersonX wants to get even", "update": "PersonX was being blackmailed by someone else.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.20568", "update_paraphrase": "PersonX was receiving blackmail threats from another person.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.48213120213120214, "pred_conf_shift": 0.2070465385913849, "syntactic_distance": 0.11764705882352941}]}, "atomic.train.27424": {"original_confidence": [0.4786354899406433, 0.5213644504547119], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.13748513162136078, 0.862514853477478], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.27424.gpt3.2", "original_example": {"example_id": "atomic.train.27424", "premise_hypothesis_id": "atomic.train.12476", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "FLX1AT5kemNEogBlo9n1Yw==", "AtomicEventRelationId": "NL8SBZaENNRHT2dZgrLO9Q==", "AtomicRelationType": "xIntent", "AtomicInference": "to drive"}, "premise": "PersonX is in PersonX's car", "hypothesis": "Because PersonX wanted to drive", "update": "PersonX is in the back seat.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27424", "update_paraphrase": "Person X is seated in the back.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1810650887573964, "pred_conf_shift": -0.34115035831928253, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.29750382900238037, 0.7024961709976196], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.27424.gpt3.1", "original_example": {"example_id": "atomic.train.27424", "premise_hypothesis_id": "atomic.train.12476", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "FLX1AT5kemNEogBlo9n1Yw==", "AtomicEventRelationId": "NL8SBZaENNRHT2dZgrLO9Q==", "AtomicRelationType": "xIntent", "AtomicInference": "to drive"}, "premise": "PersonX is in PersonX's car", "hypothesis": "Because PersonX wanted to drive", "update": "PersonX is in the back seat.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27424", "update_paraphrase": "PersonX is sitting in the back seat.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.07692307692307687, "pred_conf_shift": -0.18113166093826294, "syntactic_distance": 0.1875}, {"confidence": [0.5071836709976196, 0.4928164780139923], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.27424.gpt3.3", "original_example": {"example_id": "atomic.train.27424", "premise_hypothesis_id": "atomic.train.12476", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "FLX1AT5kemNEogBlo9n1Yw==", "AtomicEventRelationId": "NL8SBZaENNRHT2dZgrLO9Q==", "AtomicRelationType": "xIntent", "AtomicInference": "to drive"}, "premise": "PersonX is in PersonX's car", "hypothesis": "Because PersonX wanted to drive", "update": "PersonX is in the back seat.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27424", "update_paraphrase": "PersonX is in the backseat.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1955922865013774, "pred_conf_shift": 0.02854818105697632, "syntactic_distance": 0.0}, {"confidence": [0.5002180337905884, 0.49978190660476685], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.27424.gpt3.0", "original_example": {"example_id": "atomic.train.27424", "premise_hypothesis_id": "atomic.train.12476", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "FLX1AT5kemNEogBlo9n1Yw==", "AtomicEventRelationId": "NL8SBZaENNRHT2dZgrLO9Q==", "AtomicRelationType": "xIntent", "AtomicInference": "to drive"}, "premise": "PersonX is in PersonX's car", "hypothesis": "Because PersonX wanted to drive", "update": "PersonX is in the back seat.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27424", "update_paraphrase": "PersonX is in the back seat of the car.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19999999999999996, "pred_conf_shift": 0.02158254384994507, "syntactic_distance": 0.0}]}, "atomic.train.11588": {"original_confidence": [0.2898785173892975, 0.7101214528083801], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.11552824079990387, 0.8844717144966125], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11588.gpt3.2", "original_example": {"example_id": "atomic.train.11588", "premise_hypothesis_id": "atomic.train.5451", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "XBw-T1Dt-q9F_dOV7YTTSA==", "AtomicEventRelationId": "jrWLssoj-DO2rFvXtL0rMA==", "AtomicRelationType": "xEffect", "AtomicInference": "wonder what they got"}, "premise": "PersonX gets mail", "hypothesis": "PersonX then wonder what they got", "update": "The package is transparent", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11588", "update_paraphrase": "The package is see-through.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1785714285714286, "pred_conf_shift": -0.17435027658939362, "syntactic_distance": 0.0}, {"confidence": [0.1506582498550415, 0.8493417501449585], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11588.gpt3.1", "original_example": {"example_id": "atomic.train.11588", "premise_hypothesis_id": "atomic.train.5451", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "XBw-T1Dt-q9F_dOV7YTTSA==", "AtomicEventRelationId": "jrWLssoj-DO2rFvXtL0rMA==", "AtomicRelationType": "xEffect", "AtomicInference": "wonder what they got"}, "premise": "PersonX gets mail", "hypothesis": "PersonX then wonder what they got", "update": "The package is transparent", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11588", "update_paraphrase": "The package is clear/see-through.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.17582417582417587, "pred_conf_shift": -0.13922026753425598, "syntactic_distance": 0.0}, {"confidence": [0.21781979501247406, 0.7821801900863647], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11588.gpt3.3", "original_example": {"example_id": "atomic.train.11588", "premise_hypothesis_id": "atomic.train.5451", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "XBw-T1Dt-q9F_dOV7YTTSA==", "AtomicEventRelationId": "jrWLssoj-DO2rFvXtL0rMA==", "AtomicRelationType": "xEffect", "AtomicInference": "wonder what they got"}, "premise": "PersonX gets mail", "hypothesis": "PersonX then wonder what they got", "update": "The package is transparent", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11588", "update_paraphrase": "You can see through the package.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5314285714285714, "pred_conf_shift": -0.07205872237682343, "syntactic_distance": 0.375}, {"confidence": [0.9539406895637512, 0.046059366315603256], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11588.gpt3.0", "original_example": {"example_id": "atomic.train.11588", "premise_hypothesis_id": "atomic.train.5451", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "XBw-T1Dt-q9F_dOV7YTTSA==", "AtomicEventRelationId": "jrWLssoj-DO2rFvXtL0rMA==", "AtomicRelationType": "xEffect", "AtomicInference": "wonder what they got"}, "premise": "PersonX gets mail", "hypothesis": "PersonX then wonder what they got", "update": "The package is transparent", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11588", "update_paraphrase": "The package is clear", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1830357142857143, "pred_conf_shift": 0.6640621721744537, "syntactic_distance": 0.0}]}, "atomic.train.23565": {"original_confidence": [0.482774019241333, 0.5172259211540222], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.3544588088989258, 0.645541250705719], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.23565.gpt3.0", "original_example": {"example_id": "atomic.train.23565", "premise_hypothesis_id": "atomic.train.10798", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "J3ESxh1fdgRZf_EtXbbu8Q==", "AtomicEventRelationId": "aaVmgCUZIvCa7_d0KSg3cA==", "AtomicRelationType": "xNeed", "AtomicInference": "pick up the phone"}, "premise": "PersonX calls the store", "hypothesis": "Before, PersonX needed pick up the phone", "update": "PersonX calls on a cell phone.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23565", "update_paraphrase": "PersonX is calling on a cell phone.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.16239316239316237, "pred_conf_shift": 0.12831532955169678, "syntactic_distance": 0.1875}, {"confidence": [0.1296030879020691, 0.8703968524932861], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.23565.gpt3.3", "original_example": {"example_id": "atomic.train.23565", "premise_hypothesis_id": "atomic.train.10798", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "J3ESxh1fdgRZf_EtXbbu8Q==", "AtomicEventRelationId": "aaVmgCUZIvCa7_d0KSg3cA==", "AtomicRelationType": "xNeed", "AtomicInference": "pick up the phone"}, "premise": "PersonX calls the store", "hypothesis": "Before, PersonX needed pick up the phone", "update": "PersonX calls on a cell phone.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23565", "update_paraphrase": "On a cell phone, PersonX makes a call.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.29365079365079366, "pred_conf_shift": 0.3531709313392639, "syntactic_distance": 0.3888888888888889}, {"confidence": [0.43769630789756775, 0.5623036026954651], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.23565.gpt3.6", "original_example": {"example_id": "atomic.train.23565", "premise_hypothesis_id": "atomic.train.10798", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "J3ESxh1fdgRZf_EtXbbu8Q==", "AtomicEventRelationId": "aaVmgCUZIvCa7_d0KSg3cA==", "AtomicRelationType": "xNeed", "AtomicInference": "pick up the phone"}, "premise": "PersonX calls the store", "hypothesis": "Before, PersonX needed pick up the phone", "update": "PersonX calls on a cell phone.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23565", "update_paraphrase": "Person X makes a call using a cell phone.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.32030932030932036, "pred_conf_shift": 0.04507768154144287, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.3339187502861023, 0.6660811901092529], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.23565.gpt3.7", "original_example": {"example_id": "atomic.train.23565", "premise_hypothesis_id": "atomic.train.10798", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "J3ESxh1fdgRZf_EtXbbu8Q==", "AtomicEventRelationId": "aaVmgCUZIvCa7_d0KSg3cA==", "AtomicRelationType": "xNeed", "AtomicInference": "pick up the phone"}, "premise": "PersonX calls the store", "hypothesis": "Before, PersonX needed pick up the phone", "update": "PersonX calls on a cell phone.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23565", "update_paraphrase": "Person X is calling on a cell phone.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.20146520146520153, "pred_conf_shift": 0.1488552689552307, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.10037370026111603, 0.8996262550354004], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.23565.gpt3.2", "original_example": {"example_id": "atomic.train.23565", "premise_hypothesis_id": "atomic.train.10798", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "J3ESxh1fdgRZf_EtXbbu8Q==", "AtomicEventRelationId": "aaVmgCUZIvCa7_d0KSg3cA==", "AtomicRelationType": "xNeed", "AtomicInference": "pick up the phone"}, "premise": "PersonX calls the store", "hypothesis": "Before, PersonX needed pick up the phone", "update": "PersonX calls on a cell phone.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23565", "update_paraphrase": "PersonX is using a cell phone to make a call.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3931051587301587, "pred_conf_shift": 0.3824003338813782, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.5105695724487305, 0.4894304573535919], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.23565.gpt3.5", "original_example": {"example_id": "atomic.train.23565", "premise_hypothesis_id": "atomic.train.10798", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "J3ESxh1fdgRZf_EtXbbu8Q==", "AtomicEventRelationId": "aaVmgCUZIvCa7_d0KSg3cA==", "AtomicRelationType": "xNeed", "AtomicInference": "pick up the phone"}, "premise": "PersonX calls the store", "hypothesis": "Before, PersonX needed pick up the phone", "update": "PersonX calls on a cell phone.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23565", "update_paraphrase": "PersonX makes a call on a cell phone.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19841269841269837, "pred_conf_shift": -0.027795463800430298, "syntactic_distance": 0.15789473684210525}, {"confidence": [0.2103184014558792, 0.789681613445282], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.23565.gpt3.1", "original_example": {"example_id": "atomic.train.23565", "premise_hypothesis_id": "atomic.train.10798", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "J3ESxh1fdgRZf_EtXbbu8Q==", "AtomicEventRelationId": "aaVmgCUZIvCa7_d0KSg3cA==", "AtomicRelationType": "xNeed", "AtomicInference": "pick up the phone"}, "premise": "PersonX calls the store", "hypothesis": "Before, PersonX needed pick up the phone", "update": "PersonX calls on a cell phone.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23565", "update_paraphrase": "PersonX makes a phone call using their cell phone.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3243386243386243, "pred_conf_shift": 0.27245569229125977, "syntactic_distance": 0.3684210526315789}, {"confidence": [0.19897328317165375, 0.8010267019271851], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.23565.gpt3.4", "original_example": {"example_id": "atomic.train.23565", "premise_hypothesis_id": "atomic.train.10798", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "J3ESxh1fdgRZf_EtXbbu8Q==", "AtomicEventRelationId": "aaVmgCUZIvCa7_d0KSg3cA==", "AtomicRelationType": "xNeed", "AtomicInference": "pick up the phone"}, "premise": "PersonX calls the store", "hypothesis": "Before, PersonX needed pick up the phone", "update": "PersonX calls on a cell phone.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23565", "update_paraphrase": "There was a ring as PersonX called on a cell phone.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3262032085561497, "pred_conf_shift": 0.28380078077316284, "syntactic_distance": 0.3684210526315789}]}, "atomic.train.15308": {"original_confidence": [0.41598132252693176, 0.5840187072753906], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.33542418479919434, 0.6645758748054504], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15308.gpt3.3", "original_example": {"example_id": "atomic.train.15308", "premise_hypothesis_id": "atomic.train.7141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "R3Se22z4GwOpmfJR2jTQGw==", "AtomicEventRelationId": "_eSDX-9U6IygtOTXXmuU8Q==", "AtomicRelationType": "xNeed", "AtomicInference": "approach the cat"}, "premise": "PersonX is playing with PersonY's cat", "hypothesis": "Before, PersonX needed approach the cat", "update": "The cat mostly likely playing chase.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15308", "update_paraphrase": "The cat likely enjoyed playing chase.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.20584045584045585, "pred_conf_shift": -0.08055713772773743, "syntactic_distance": 0.2857142857142857}, {"confidence": [0.301087886095047, 0.6989122033119202], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15308.gpt3.1", "original_example": {"example_id": "atomic.train.15308", "premise_hypothesis_id": "atomic.train.7141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "R3Se22z4GwOpmfJR2jTQGw==", "AtomicEventRelationId": "_eSDX-9U6IygtOTXXmuU8Q==", "AtomicRelationType": "xNeed", "AtomicInference": "approach the cat"}, "premise": "PersonX is playing with PersonY's cat", "hypothesis": "Before, PersonX needed approach the cat", "update": "The cat mostly likely playing chase.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15308", "update_paraphrase": "The cat is probably playing chase.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.25826719576719576, "pred_conf_shift": -0.11489343643188477, "syntactic_distance": 0.18181818181818182}, {"confidence": [0.38982751965522766, 0.6101725101470947], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15308.gpt3.5", "original_example": {"example_id": "atomic.train.15308", "premise_hypothesis_id": "atomic.train.7141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "R3Se22z4GwOpmfJR2jTQGw==", "AtomicEventRelationId": "_eSDX-9U6IygtOTXXmuU8Q==", "AtomicRelationType": "xNeed", "AtomicInference": "approach the cat"}, "premise": "PersonX is playing with PersonY's cat", "hypothesis": "Before, PersonX needed approach the cat", "update": "The cat mostly likely playing chase.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15308", "update_paraphrase": "It's probable that the cat was playing chase.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3764172335600907, "pred_conf_shift": -0.0261538028717041, "syntactic_distance": 0.5294117647058824}, {"confidence": [0.25239524245262146, 0.7476047277450562], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15308.gpt3.0", "original_example": {"example_id": "atomic.train.15308", "premise_hypothesis_id": "atomic.train.7141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "R3Se22z4GwOpmfJR2jTQGw==", "AtomicEventRelationId": "_eSDX-9U6IygtOTXXmuU8Q==", "AtomicRelationType": "xNeed", "AtomicInference": "approach the cat"}, "premise": "PersonX is playing with PersonY's cat", "hypothesis": "Before, PersonX needed approach the cat", "update": "The cat mostly likely playing chase.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15308", "update_paraphrase": "It's highly probable that the cat was playing chase.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3994708994708995, "pred_conf_shift": -0.1635860800743103, "syntactic_distance": 0.4}, {"confidence": [0.3303116261959076, 0.6696882843971252], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15308.gpt3.2", "original_example": {"example_id": "atomic.train.15308", "premise_hypothesis_id": "atomic.train.7141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "R3Se22z4GwOpmfJR2jTQGw==", "AtomicEventRelationId": "_eSDX-9U6IygtOTXXmuU8Q==", "AtomicRelationType": "xNeed", "AtomicInference": "approach the cat"}, "premise": "PersonX is playing with PersonY's cat", "hypothesis": "Before, PersonX needed approach the cat", "update": "The cat mostly likely playing chase.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15308", "update_paraphrase": "The cat was most likely playing a game of chase.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37916666666666665, "pred_conf_shift": -0.08566969633102417, "syntactic_distance": 0.21739130434782608}, {"confidence": [0.4480690360069275, 0.5519309043884277], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15308.gpt3.4", "original_example": {"example_id": "atomic.train.15308", "premise_hypothesis_id": "atomic.train.7141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "R3Se22z4GwOpmfJR2jTQGw==", "AtomicEventRelationId": "_eSDX-9U6IygtOTXXmuU8Q==", "AtomicRelationType": "xNeed", "AtomicInference": "approach the cat"}, "premise": "PersonX is playing with PersonY's cat", "hypothesis": "Before, PersonX needed approach the cat", "update": "The cat mostly likely playing chase.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15308", "update_paraphrase": "The cat was probably playing chase.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2724867724867725, "pred_conf_shift": 0.03208771347999573, "syntactic_distance": 0.18181818181818182}, {"confidence": [0.48612338304519653, 0.5138766169548035], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15308.gpt3.6", "original_example": {"example_id": "atomic.train.15308", "premise_hypothesis_id": "atomic.train.7141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "R3Se22z4GwOpmfJR2jTQGw==", "AtomicEventRelationId": "_eSDX-9U6IygtOTXXmuU8Q==", "AtomicRelationType": "xNeed", "AtomicInference": "approach the cat"}, "premise": "PersonX is playing with PersonY's cat", "hypothesis": "Before, PersonX needed approach the cat", "update": "The cat mostly likely playing chase.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15308", "update_paraphrase": "Given that the cat was chasing something, it is likely that it was playing.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.54, "pred_conf_shift": 0.07014206051826477, "syntactic_distance": 0.6111111111111112}, {"confidence": [0.3212224543094635, 0.6787775158882141], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.15308.gpt3.7", "original_example": {"example_id": "atomic.train.15308", "premise_hypothesis_id": "atomic.train.7141", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "R3Se22z4GwOpmfJR2jTQGw==", "AtomicEventRelationId": "_eSDX-9U6IygtOTXXmuU8Q==", "AtomicRelationType": "xNeed", "AtomicInference": "approach the cat"}, "premise": "PersonX is playing with PersonY's cat", "hypothesis": "Before, PersonX needed approach the cat", "update": "The cat mostly likely playing chase.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15308", "update_paraphrase": "The chances are good that the cat was playing chase.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3958333333333333, "pred_conf_shift": -0.09475886821746826, "syntactic_distance": 0.3181818181818182}]}, "atomic.train.13564": {"original_confidence": [0.6387840509414673, 0.36121588945388794], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.607262909412384, 0.39273717999458313], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.13564.gpt3.3", "original_example": {"example_id": "atomic.train.13564", "premise_hypothesis_id": "atomic.train.6348", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "o6Apg9tmphyeKGsp4f0E-w==", "AtomicEventRelationId": "0A_B8G90Rc6YPkATxktRsA==", "AtomicRelationType": "xIntent", "AtomicInference": "to meet them"}, "premise": "PersonX sees PersonX's old friend", "hypothesis": "Because PersonX wanted to meet them", "update": "PersonX runs into their old friend in a grocery store.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13564", "update_paraphrase": "PersonX bumped into an old friend in the grocery store.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2009848484848485, "pred_conf_shift": -0.03152114152908325, "syntactic_distance": 0.2631578947368421}, {"confidence": [0.22065472602844238, 0.7793452143669128], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.13564.gpt3.8", "original_example": {"example_id": "atomic.train.13564", "premise_hypothesis_id": "atomic.train.6348", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "o6Apg9tmphyeKGsp4f0E-w==", "AtomicEventRelationId": "0A_B8G90Rc6YPkATxktRsA==", "AtomicRelationType": "xIntent", "AtomicInference": "to meet them"}, "premise": "PersonX sees PersonX's old friend", "hypothesis": "Because PersonX wanted to meet them", "update": "PersonX runs into their old friend in a grocery store.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13564", "update_paraphrase": "PersonX reconnects with an old acquaintance at the grocery store.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3443181818181819, "pred_conf_shift": -0.4181293249130249, "syntactic_distance": 0.21052631578947367}, {"confidence": [0.5143177509307861, 0.48568224906921387], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.13564.gpt3.4", "original_example": {"example_id": "atomic.train.13564", "premise_hypothesis_id": "atomic.train.6348", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "o6Apg9tmphyeKGsp4f0E-w==", "AtomicEventRelationId": "0A_B8G90Rc6YPkATxktRsA==", "AtomicRelationType": "xIntent", "AtomicInference": "to meet them"}, "premise": "PersonX sees PersonX's old friend", "hypothesis": "Because PersonX wanted to meet them", "update": "PersonX runs into their old friend in a grocery store.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13564", "update_paraphrase": "Person X bumped into an old friend while they were shopping for groceries.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45617136486701704, "pred_conf_shift": -0.12446630001068115, "syntactic_distance": 0.17391304347826086}, {"confidence": [0.11455618590116501, 0.8854438066482544], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.13564.gpt3.0", "original_example": {"example_id": "atomic.train.13564", "premise_hypothesis_id": "atomic.train.6348", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "o6Apg9tmphyeKGsp4f0E-w==", "AtomicEventRelationId": "0A_B8G90Rc6YPkATxktRsA==", "AtomicRelationType": "xIntent", "AtomicInference": "to meet them"}, "premise": "PersonX sees PersonX's old friend", "hypothesis": "Because PersonX wanted to meet them", "update": "PersonX runs into their old friend in a grocery store.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13564", "update_paraphrase": "Person X was pleasantly surprised when they bumped into their old friend in the grocery store.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3476331360946746, "pred_conf_shift": -0.5242278650403023, "syntactic_distance": 0.34782608695652173}, {"confidence": [0.2888867259025574, 0.7111132144927979], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.13564.gpt3.1", "original_example": {"example_id": "atomic.train.13564", "premise_hypothesis_id": "atomic.train.6348", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "o6Apg9tmphyeKGsp4f0E-w==", "AtomicEventRelationId": "0A_B8G90Rc6YPkATxktRsA==", "AtomicRelationType": "xIntent", "AtomicInference": "to meet them"}, "premise": "PersonX sees PersonX's old friend", "hypothesis": "Because PersonX wanted to meet them", "update": "PersonX runs into their old friend in a grocery store.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13564", "update_paraphrase": "Person X ran into an old friend while they were both at the grocery store.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3656776556776557, "pred_conf_shift": -0.3498973250389099, "syntactic_distance": 0.17391304347826086}, {"confidence": [0.4202885329723358, 0.5797114372253418], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.13564.gpt3.5", "original_example": {"example_id": "atomic.train.13564", "premise_hypothesis_id": "atomic.train.6348", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "o6Apg9tmphyeKGsp4f0E-w==", "AtomicEventRelationId": "0A_B8G90Rc6YPkATxktRsA==", "AtomicRelationType": "xIntent", "AtomicInference": "to meet them"}, "premise": "PersonX sees PersonX's old friend", "hypothesis": "Because PersonX wanted to meet them", "update": "PersonX runs into their old friend in a grocery store.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13564", "update_paraphrase": "PersonX bumped into their old friend while they were both shopping in the grocery store.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33769230769230774, "pred_conf_shift": -0.21849551796913147, "syntactic_distance": 0.18181818181818182}, {"confidence": [0.39182594418525696, 0.6081740260124207], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.13564.gpt3.6", "original_example": {"example_id": "atomic.train.13564", "premise_hypothesis_id": "atomic.train.6348", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "o6Apg9tmphyeKGsp4f0E-w==", "AtomicEventRelationId": "0A_B8G90Rc6YPkATxktRsA==", "AtomicRelationType": "xIntent", "AtomicInference": "to meet them"}, "premise": "PersonX sees PersonX's old friend", "hypothesis": "Because PersonX wanted to meet them", "update": "PersonX runs into their old friend in a grocery store.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13564", "update_paraphrase": "PersonX ran into an old friend while they were grocery shopping.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.35207860922146633, "pred_conf_shift": -0.24695810675621033, "syntactic_distance": 0.18181818181818182}, {"confidence": [0.451506108045578, 0.5484939813613892], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.13564.gpt3.2", "original_example": {"example_id": "atomic.train.13564", "premise_hypothesis_id": "atomic.train.6348", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "o6Apg9tmphyeKGsp4f0E-w==", "AtomicEventRelationId": "0A_B8G90Rc6YPkATxktRsA==", "AtomicRelationType": "xIntent", "AtomicInference": "to meet them"}, "premise": "PersonX sees PersonX's old friend", "hypothesis": "Because PersonX wanted to meet them", "update": "PersonX runs into their old friend in a grocery store.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13564", "update_paraphrase": "In the grocery store, PersonX ran into their old friend.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.29285714285714287, "pred_conf_shift": -0.18727794289588928, "syntactic_distance": 0.4}]}, "atomic.train.34761": {"original_confidence": [0.8464120030403137, 0.15358808636665344], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.3186491131782532, 0.6813509464263916], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34761.gpt3.6", "original_example": {"example_id": "atomic.train.34761", "premise_hypothesis_id": "atomic.train.15762", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oO6p-qLhCXgyVtAxN8yCeg==", "AtomicEventRelationId": "bJXWQ1Gtry3xmmTMO8GmGw==", "AtomicRelationType": "xReact", "AtomicInference": "satisfied"}, "premise": "PersonX wants to get rid of PersonY", "hypothesis": "PersonX is seen as satisfied", "update": "PersonX is sick of PersonY's behavior.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34761", "update_paraphrase": "PersonX has had enough of PersonY's bad behavior.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4428571428571428, "pred_conf_shift": 0.5277628600597382, "syntactic_distance": 0.1875}, {"confidence": [0.4679267406463623, 0.5320731401443481], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34761.gpt3.8", "original_example": {"example_id": "atomic.train.34761", "premise_hypothesis_id": "atomic.train.15762", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oO6p-qLhCXgyVtAxN8yCeg==", "AtomicEventRelationId": "bJXWQ1Gtry3xmmTMO8GmGw==", "AtomicRelationType": "xReact", "AtomicInference": "satisfied"}, "premise": "PersonX wants to get rid of PersonY", "hypothesis": "PersonX is seen as satisfied", "update": "PersonX is sick of PersonY's behavior.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34761", "update_paraphrase": "PersonX has grown tired of PersonY's antics.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3928148774302621, "pred_conf_shift": 0.3784850537776947, "syntactic_distance": 0.1875}, {"confidence": [0.7249164581298828, 0.27508342266082764], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34761.gpt3.2", "original_example": {"example_id": "atomic.train.34761", "premise_hypothesis_id": "atomic.train.15762", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oO6p-qLhCXgyVtAxN8yCeg==", "AtomicEventRelationId": "bJXWQ1Gtry3xmmTMO8GmGw==", "AtomicRelationType": "xReact", "AtomicInference": "satisfied"}, "premise": "PersonX wants to get rid of PersonY", "hypothesis": "PersonX is seen as satisfied", "update": "PersonX is sick of PersonY's behavior.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34761", "update_paraphrase": "PersonX is fed up with PersonY's behavior.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2918803418803419, "pred_conf_shift": 0.1214953362941742, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.5074453353881836, 0.4925546944141388], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34761.gpt3.5", "original_example": {"example_id": "atomic.train.34761", "premise_hypothesis_id": "atomic.train.15762", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oO6p-qLhCXgyVtAxN8yCeg==", "AtomicEventRelationId": "bJXWQ1Gtry3xmmTMO8GmGw==", "AtomicRelationType": "xReact", "AtomicInference": "satisfied"}, "premise": "PersonX wants to get rid of PersonY", "hypothesis": "PersonX is seen as satisfied", "update": "PersonX is sick of PersonY's behavior.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34761", "update_paraphrase": "PersonX has had enough of PersonY's behavior.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.32307692307692304, "pred_conf_shift": 0.33896660804748535, "syntactic_distance": 0.1875}, {"confidence": [0.64670729637146, 0.3532925844192505], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34761.gpt3.0", "original_example": {"example_id": "atomic.train.34761", "premise_hypothesis_id": "atomic.train.15762", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oO6p-qLhCXgyVtAxN8yCeg==", "AtomicEventRelationId": "bJXWQ1Gtry3xmmTMO8GmGw==", "AtomicRelationType": "xReact", "AtomicInference": "satisfied"}, "premise": "PersonX wants to get rid of PersonY", "hypothesis": "PersonX is seen as satisfied", "update": "PersonX is sick of PersonY's behavior.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34761", "update_paraphrase": "PersonX has grown tired of PersonY's behavior.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2763125763125764, "pred_conf_shift": 0.19970449805259705, "syntactic_distance": 0.1875}, {"confidence": [0.936363697052002, 0.06363627314567566], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34761.gpt3.7", "original_example": {"example_id": "atomic.train.34761", "premise_hypothesis_id": "atomic.train.15762", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oO6p-qLhCXgyVtAxN8yCeg==", "AtomicEventRelationId": "bJXWQ1Gtry3xmmTMO8GmGw==", "AtomicRelationType": "xReact", "AtomicInference": "satisfied"}, "premise": "PersonX wants to get rid of PersonY", "hypothesis": "PersonX is seen as satisfied", "update": "PersonX is sick of PersonY's behavior.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34761", "update_paraphrase": "PersonX is getting fed up with PersonY's actions.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.478968253968254, "pred_conf_shift": -0.08995181322097778, "syntactic_distance": 0.1875}, {"confidence": [0.3035459816455841, 0.696453869342804], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34761.gpt3.1", "original_example": {"example_id": "atomic.train.34761", "premise_hypothesis_id": "atomic.train.15762", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oO6p-qLhCXgyVtAxN8yCeg==", "AtomicEventRelationId": "bJXWQ1Gtry3xmmTMO8GmGw==", "AtomicRelationType": "xReact", "AtomicInference": "satisfied"}, "premise": "PersonX wants to get rid of PersonY", "hypothesis": "PersonX is seen as satisfied", "update": "PersonX is sick of PersonY's behavior.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34761", "update_paraphrase": "PersonX has had enough of PersonY's antics.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.41818181818181815, "pred_conf_shift": 0.5428657829761505, "syntactic_distance": 0.1875}, {"confidence": [0.7265302538871765, 0.27346959710121155], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.34761.gpt3.3", "original_example": {"example_id": "atomic.train.34761", "premise_hypothesis_id": "atomic.train.15762", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oO6p-qLhCXgyVtAxN8yCeg==", "AtomicEventRelationId": "bJXWQ1Gtry3xmmTMO8GmGw==", "AtomicRelationType": "xReact", "AtomicInference": "satisfied"}, "premise": "PersonX wants to get rid of PersonY", "hypothesis": "PersonX is seen as satisfied", "update": "PersonX is sick of PersonY's behavior.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34761", "update_paraphrase": "PersonX is tired of PersonY's antics.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3299145299145299, "pred_conf_shift": 0.1198815107345581, "syntactic_distance": 0.0}, {"confidence": [0.19918076694011688, 0.8008192181587219], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34761.gpt3.4", "original_example": {"example_id": "atomic.train.34761", "premise_hypothesis_id": "atomic.train.15762", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oO6p-qLhCXgyVtAxN8yCeg==", "AtomicEventRelationId": "bJXWQ1Gtry3xmmTMO8GmGw==", "AtomicRelationType": "xReact", "AtomicInference": "satisfied"}, "premise": "PersonX wants to get rid of PersonY", "hypothesis": "PersonX is seen as satisfied", "update": "PersonX is sick of PersonY's behavior.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34761", "update_paraphrase": "PersonX has had enough of PersonY's bad habits.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.460760667903525, "pred_conf_shift": 0.6472311317920685, "syntactic_distance": 0.1875}]}, "atomic.train.3523": {"original_confidence": [0.023787308484315872, 0.9762126803398132], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.028307544067502022, 0.9716923236846924], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3523.gpt3.1", "original_example": {"example_id": "atomic.train.3523", "premise_hypothesis_id": "atomic.train.1655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-GJTjJbuX3f8XPhGcvgVZQ==", "AtomicEventRelationId": "74ALDi7ipHuMOSGxujsQOA==", "AtomicRelationType": "xIntent", "AtomicInference": "to save time"}, "premise": "PersonX makes a long story short", "hypothesis": "Because PersonX wanted to save time", "update": "PersonX likes to be efficient.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3523", "update_paraphrase": "PersonX is a stickler for efficiency.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5214580740896531, "pred_conf_shift": -0.00452035665512085, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.021309744566679, 0.9786903858184814], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3523.gpt3.5", "original_example": {"example_id": "atomic.train.3523", "premise_hypothesis_id": "atomic.train.1655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-GJTjJbuX3f8XPhGcvgVZQ==", "AtomicEventRelationId": "74ALDi7ipHuMOSGxujsQOA==", "AtomicRelationType": "xIntent", "AtomicInference": "to save time"}, "premise": "PersonX makes a long story short", "hypothesis": "Because PersonX wanted to save time", "update": "PersonX likes to be efficient.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3523", "update_paraphrase": "PersonX prefers to be efficient.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.13333333333333341, "pred_conf_shift": 0.002477705478668213, "syntactic_distance": 0.0}, {"confidence": [0.10085652023553848, 0.8991435170173645], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3523.gpt3.0", "original_example": {"example_id": "atomic.train.3523", "premise_hypothesis_id": "atomic.train.1655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-GJTjJbuX3f8XPhGcvgVZQ==", "AtomicEventRelationId": "74ALDi7ipHuMOSGxujsQOA==", "AtomicRelationType": "xIntent", "AtomicInference": "to save time"}, "premise": "PersonX makes a long story short", "hypothesis": "Because PersonX wanted to save time", "update": "PersonX likes to be efficient.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3523", "update_paraphrase": "PersonX is organized and likes to get things done quickly.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5122222222222222, "pred_conf_shift": -0.07706916332244873, "syntactic_distance": 0.3888888888888889}, {"confidence": [0.033925484865903854, 0.966074526309967], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3523.gpt3.8", "original_example": {"example_id": "atomic.train.3523", "premise_hypothesis_id": "atomic.train.1655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-GJTjJbuX3f8XPhGcvgVZQ==", "AtomicEventRelationId": "74ALDi7ipHuMOSGxujsQOA==", "AtomicRelationType": "xIntent", "AtomicInference": "to save time"}, "premise": "PersonX makes a long story short", "hypothesis": "Because PersonX wanted to save time", "update": "PersonX likes to be efficient.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3523", "update_paraphrase": "PersonX is always looking for ways to work more efficiently.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5517364117364116, "pred_conf_shift": -0.010138154029846191, "syntactic_distance": 0.35294117647058826}, {"confidence": [0.03162641450762749, 0.9683735966682434], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3523.gpt3.4", "original_example": {"example_id": "atomic.train.3523", "premise_hypothesis_id": "atomic.train.1655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-GJTjJbuX3f8XPhGcvgVZQ==", "AtomicEventRelationId": "74ALDi7ipHuMOSGxujsQOA==", "AtomicRelationType": "xIntent", "AtomicInference": "to save time"}, "premise": "PersonX makes a long story short", "hypothesis": "Because PersonX wanted to save time", "update": "PersonX likes to be efficient.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3523", "update_paraphrase": "PersonX likes to work efficiently and get things done quickly.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4668686868686868, "pred_conf_shift": -0.007839083671569824, "syntactic_distance": 0.0}, {"confidence": [0.4238327741622925, 0.5761672854423523], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3523.gpt3.6", "original_example": {"example_id": "atomic.train.3523", "premise_hypothesis_id": "atomic.train.1655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-GJTjJbuX3f8XPhGcvgVZQ==", "AtomicEventRelationId": "74ALDi7ipHuMOSGxujsQOA==", "AtomicRelationType": "xIntent", "AtomicInference": "to save time"}, "premise": "PersonX makes a long story short", "hypothesis": "Because PersonX wanted to save time", "update": "PersonX likes to be efficient.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3523", "update_paraphrase": "PersonX is very efficient and organized.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5434868162140889, "pred_conf_shift": -0.40004539489746094, "syntactic_distance": 0.35294117647058826}, {"confidence": [0.31474387645721436, 0.6852562427520752], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3523.gpt3.3", "original_example": {"example_id": "atomic.train.3523", "premise_hypothesis_id": "atomic.train.1655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-GJTjJbuX3f8XPhGcvgVZQ==", "AtomicEventRelationId": "74ALDi7ipHuMOSGxujsQOA==", "AtomicRelationType": "xIntent", "AtomicInference": "to save time"}, "premise": "PersonX makes a long story short", "hypothesis": "Because PersonX wanted to save time", "update": "PersonX likes to be efficient.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3523", "update_paraphrase": "PersonX enjoys being productive and efficient.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.47490085671903853, "pred_conf_shift": -0.29095643758773804, "syntactic_distance": 0.0}, {"confidence": [0.024021970108151436, 0.9759780168533325], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3523.gpt3.2", "original_example": {"example_id": "atomic.train.3523", "premise_hypothesis_id": "atomic.train.1655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-GJTjJbuX3f8XPhGcvgVZQ==", "AtomicEventRelationId": "74ALDi7ipHuMOSGxujsQOA==", "AtomicRelationType": "xIntent", "AtomicInference": "to save time"}, "premise": "PersonX makes a long story short", "hypothesis": "Because PersonX wanted to save time", "update": "PersonX likes to be efficient.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3523", "update_paraphrase": "PersonX is all about efficiency.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.544360902255639, "pred_conf_shift": -0.0002346634864807129, "syntactic_distance": 0.3125}, {"confidence": [0.036627624183893204, 0.9633723497390747], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3523.gpt3.7", "original_example": {"example_id": "atomic.train.3523", "premise_hypothesis_id": "atomic.train.1655", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-GJTjJbuX3f8XPhGcvgVZQ==", "AtomicEventRelationId": "74ALDi7ipHuMOSGxujsQOA==", "AtomicRelationType": "xIntent", "AtomicInference": "to save time"}, "premise": "PersonX makes a long story short", "hypothesis": "Because PersonX wanted to save time", "update": "PersonX likes to be efficient.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3523", "update_paraphrase": "PersonX likes to be productive and efficient.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.16666666666666663, "pred_conf_shift": -0.012840330600738525, "syntactic_distance": 0.0}]}, "atomic.train.1007": {"original_confidence": [0.02024458348751068, 0.9797554612159729], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.02295609749853611, 0.9770439863204956], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1007.gpt3.3", "original_example": {"example_id": "atomic.train.1007", "premise_hypothesis_id": "atomic.train.474", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "kXS6_YwS2_Cd177zc1BnVg==", "AtomicEventRelationId": "nsDj2yHeaQXyW-waYUtY5A==", "AtomicRelationType": "xIntent", "AtomicInference": "they are aggressive, go getters"}, "premise": "PersonX gets PersonX's way", "hypothesis": "Because they are aggressive, go getters", "update": "Person X started their own business from scratch.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1007", "update_paraphrase": "Person X created their business from the ground up.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.35368814192343606, "pred_conf_shift": -0.002711474895477295, "syntactic_distance": 0.04}, {"confidence": [0.026583056896924973, 0.9734168648719788], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1007.gpt3.4", "original_example": {"example_id": "atomic.train.1007", "premise_hypothesis_id": "atomic.train.474", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "kXS6_YwS2_Cd177zc1BnVg==", "AtomicEventRelationId": "nsDj2yHeaQXyW-waYUtY5A==", "AtomicRelationType": "xIntent", "AtomicInference": "they are aggressive, go getters"}, "premise": "PersonX gets PersonX's way", "hypothesis": "Because they are aggressive, go getters", "update": "Person X started their own business from scratch.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1007", "update_paraphrase": "Person X create their business from the ground up.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3575666163901458, "pred_conf_shift": -0.006338596343994141, "syntactic_distance": 0.16}, {"confidence": [0.020687034353613853, 0.9793128967285156], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1007.gpt3.2", "original_example": {"example_id": "atomic.train.1007", "premise_hypothesis_id": "atomic.train.474", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "kXS6_YwS2_Cd177zc1BnVg==", "AtomicEventRelationId": "nsDj2yHeaQXyW-waYUtY5A==", "AtomicRelationType": "xIntent", "AtomicInference": "they are aggressive, go getters"}, "premise": "PersonX gets PersonX's way", "hypothesis": "Because they are aggressive, go getters", "update": "Person X started their own business from scratch.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1007", "update_paraphrase": "Person X founded their business from the ground up.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.38600876247935073, "pred_conf_shift": -0.0004425644874572754, "syntactic_distance": 0.07692307692307693}, {"confidence": [0.020120907574892044, 0.9798790216445923], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1007.gpt3.5", "original_example": {"example_id": "atomic.train.1007", "premise_hypothesis_id": "atomic.train.474", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "kXS6_YwS2_Cd177zc1BnVg==", "AtomicEventRelationId": "nsDj2yHeaQXyW-waYUtY5A==", "AtomicRelationType": "xIntent", "AtomicInference": "they are aggressive, go getters"}, "premise": "PersonX gets PersonX's way", "hypothesis": "Because they are aggressive, go getters", "update": "Person X started their own business from scratch.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1007", "update_paraphrase": "Person X created their own business from the ground up.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.30317460317460315, "pred_conf_shift": 0.00012356042861938477, "syntactic_distance": 0.0}, {"confidence": [0.019526978954672813, 0.9804728031158447], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1007.gpt3.0", "original_example": {"example_id": "atomic.train.1007", "premise_hypothesis_id": "atomic.train.474", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "kXS6_YwS2_Cd177zc1BnVg==", "AtomicEventRelationId": "nsDj2yHeaQXyW-waYUtY5A==", "AtomicRelationType": "xIntent", "AtomicInference": "they are aggressive, go getters"}, "premise": "PersonX gets PersonX's way", "hypothesis": "Because they are aggressive, go getters", "update": "Person X started their own business from scratch.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1007", "update_paraphrase": "Person X founded their own business from the ground up.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33247863247863246, "pred_conf_shift": 0.0007173418998718262, "syntactic_distance": 0.0}, {"confidence": [0.02750045247375965, 0.9724995493888855], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1007.gpt3.6", "original_example": {"example_id": "atomic.train.1007", "premise_hypothesis_id": "atomic.train.474", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "kXS6_YwS2_Cd177zc1BnVg==", "AtomicEventRelationId": "nsDj2yHeaQXyW-waYUtY5A==", "AtomicRelationType": "xIntent", "AtomicInference": "they are aggressive, go getters"}, "premise": "PersonX gets PersonX's way", "hypothesis": "Because they are aggressive, go getters", "update": "Person X started their own business from scratch.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1007", "update_paraphrase": "With no prior experience, Person X started their own business from the ground up.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.32727272727272727, "pred_conf_shift": -0.007255911827087402, "syntactic_distance": 0.1875}, {"confidence": [0.08480065315961838, 0.9151992797851562], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.1007.gpt3.1", "original_example": {"example_id": "atomic.train.1007", "premise_hypothesis_id": "atomic.train.474", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "kXS6_YwS2_Cd177zc1BnVg==", "AtomicEventRelationId": "nsDj2yHeaQXyW-waYUtY5A==", "AtomicRelationType": "xIntent", "AtomicInference": "they are aggressive, go getters"}, "premise": "PersonX gets PersonX's way", "hypothesis": "Because they are aggressive, go getters", "update": "Person X started their own business from scratch.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.1007", "update_paraphrase": "Person X created their business from nothing.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.29714285714285715, "pred_conf_shift": -0.06455618143081665, "syntactic_distance": 0.04}]}, "atomic.train.9025": {"original_confidence": [0.27645719051361084, 0.7235427498817444], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.3135347366333008, 0.6864652037620544], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9025.gpt3.4", "original_example": {"example_id": "atomic.train.9025", "premise_hypothesis_id": "atomic.train.4255", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "11cyxbI7jBbJKZT-g6kr2Q==", "AtomicEventRelationId": "JOKqMkIk98DdOH3NUy2MbA==", "AtomicRelationType": "xNeed", "AtomicInference": "to have multiple friendships."}, "premise": "PersonX likes PersonY more", "hypothesis": "Before, PersonX needed to have multiple friendships.", "update": "PersonX buys a gift for PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9025", "update_paraphrase": "PersonX buys a present for PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1515151515151515, "pred_conf_shift": -0.03707754611968994, "syntactic_distance": 0.0}, {"confidence": [0.41613203287124634, 0.5838680267333984], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9025.gpt3.1", "original_example": {"example_id": "atomic.train.9025", "premise_hypothesis_id": "atomic.train.4255", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "11cyxbI7jBbJKZT-g6kr2Q==", "AtomicEventRelationId": "JOKqMkIk98DdOH3NUy2MbA==", "AtomicRelationType": "xNeed", "AtomicInference": "to have multiple friendships."}, "premise": "PersonX likes PersonY more", "hypothesis": "Before, PersonX needed to have multiple friendships.", "update": "PersonX buys a gift for PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9025", "update_paraphrase": "PersonX purchased a present for PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.26689976689976685, "pred_conf_shift": -0.13967472314834595, "syntactic_distance": 0.0625}, {"confidence": [0.263737291097641, 0.7362626791000366], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9025.gpt3.5", "original_example": {"example_id": "atomic.train.9025", "premise_hypothesis_id": "atomic.train.4255", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "11cyxbI7jBbJKZT-g6kr2Q==", "AtomicEventRelationId": "JOKqMkIk98DdOH3NUy2MbA==", "AtomicRelationType": "xNeed", "AtomicInference": "to have multiple friendships."}, "premise": "PersonX likes PersonY more", "hypothesis": "Before, PersonX needed to have multiple friendships.", "update": "PersonX buys a gift for PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9025", "update_paraphrase": "PersonX purchases a gift for PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1258741258741259, "pred_conf_shift": 0.012719929218292236, "syntactic_distance": 0.0}, {"confidence": [0.2842341363430023, 0.7157658338546753], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9025.gpt3.0", "original_example": {"example_id": "atomic.train.9025", "premise_hypothesis_id": "atomic.train.4255", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "11cyxbI7jBbJKZT-g6kr2Q==", "AtomicEventRelationId": "JOKqMkIk98DdOH3NUy2MbA==", "AtomicRelationType": "xNeed", "AtomicInference": "to have multiple friendships."}, "premise": "PersonX likes PersonY more", "hypothesis": "Before, PersonX needed to have multiple friendships.", "update": "PersonX buys a gift for PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9025", "update_paraphrase": "PersonX purchases a present for PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.26689976689976685, "pred_conf_shift": -0.007776916027069092, "syntactic_distance": 0.0}, {"confidence": [0.46016305685043335, 0.5398369431495667], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9025.gpt3.2", "original_example": {"example_id": "atomic.train.9025", "premise_hypothesis_id": "atomic.train.4255", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "11cyxbI7jBbJKZT-g6kr2Q==", "AtomicEventRelationId": "JOKqMkIk98DdOH3NUy2MbA==", "AtomicRelationType": "xNeed", "AtomicInference": "to have multiple friendships."}, "premise": "PersonX likes PersonY more", "hypothesis": "Before, PersonX needed to have multiple friendships.", "update": "PersonX buys a gift for PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9025", "update_paraphrase": "PersonX decides to purchase a present for PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.336734693877551, "pred_conf_shift": -0.18370580673217773, "syntactic_distance": 0.2}]}, "atomic.train.6650": {"original_confidence": [0.09572513401508331, 0.9042748212814331], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.06215456873178482, 0.9378454685211182], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.6650.gpt3.2", "original_example": {"example_id": "atomic.train.6650", "premise_hypothesis_id": "atomic.train.3146", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ffNS9HyeWxpU1kQr_WtNhg==", "AtomicEventRelationId": "mxST_4i1muyBEvh1yUY51g==", "AtomicRelationType": "xEffect", "AtomicInference": "they win"}, "premise": "PersonX plays chess with PersonY", "hypothesis": "Then, they win", "update": "PersonX hears PersonY yell \"checkmate\"", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6650", "update_paraphrase": "PersonX hears PersonY call out \"checkmate\"", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.20909090909090905, "pred_conf_shift": -0.03357056528329849, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.06790294498205185, 0.9320970177650452], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.6650.gpt3.1", "original_example": {"example_id": "atomic.train.6650", "premise_hypothesis_id": "atomic.train.3146", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ffNS9HyeWxpU1kQr_WtNhg==", "AtomicEventRelationId": "mxST_4i1muyBEvh1yUY51g==", "AtomicRelationType": "xEffect", "AtomicInference": "they win"}, "premise": "PersonX plays chess with PersonY", "hypothesis": "Then, they win", "update": "PersonX hears PersonY yell \"checkmate\"", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6650", "update_paraphrase": "PersonY's shouts of \"checkmate\" reach PersonX's ears.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4696969696969697, "pred_conf_shift": -0.027822189033031464, "syntactic_distance": 0.47619047619047616}, {"confidence": [0.22458355128765106, 0.7754164338111877], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.6650.gpt3.5", "original_example": {"example_id": "atomic.train.6650", "premise_hypothesis_id": "atomic.train.3146", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ffNS9HyeWxpU1kQr_WtNhg==", "AtomicEventRelationId": "mxST_4i1muyBEvh1yUY51g==", "AtomicRelationType": "xEffect", "AtomicInference": "they win"}, "premise": "PersonX plays chess with PersonY", "hypothesis": "Then, they win", "update": "PersonX hears PersonY yell \"checkmate\"", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6650", "update_paraphrase": "PersonX overhears PersonY exclaim \"checkmate\"", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2207792207792208, "pred_conf_shift": 0.12885841727256775, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.15674692392349243, 0.8432530760765076], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.6650.gpt3.0", "original_example": {"example_id": "atomic.train.6650", "premise_hypothesis_id": "atomic.train.3146", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ffNS9HyeWxpU1kQr_WtNhg==", "AtomicEventRelationId": "mxST_4i1muyBEvh1yUY51g==", "AtomicRelationType": "xEffect", "AtomicInference": "they win"}, "premise": "PersonX plays chess with PersonY", "hypothesis": "Then, they win", "update": "PersonX hears PersonY yell \"checkmate\"", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6650", "update_paraphrase": "PersonX hears PersonY shout \"checkmate.\"", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.18181818181818182, "pred_conf_shift": 0.06102178990840912, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.4689115285873413, 0.5310884118080139], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.6650.gpt3.3", "original_example": {"example_id": "atomic.train.6650", "premise_hypothesis_id": "atomic.train.3146", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ffNS9HyeWxpU1kQr_WtNhg==", "AtomicEventRelationId": "mxST_4i1muyBEvh1yUY51g==", "AtomicRelationType": "xEffect", "AtomicInference": "they win"}, "premise": "PersonX plays chess with PersonY", "hypothesis": "Then, they win", "update": "PersonX hears PersonY yell \"checkmate\"", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.6650", "update_paraphrase": "PersonX hears PersonY yell \"checkmate!\"", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": 0.373186394572258, "syntactic_distance": 0.0}]}, "atomic.train.7333": {"original_confidence": [0.7296773791313171, 0.2703225314617157], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.5920898914337158, 0.4079101085662842], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7333.gpt3.1", "original_example": {"example_id": "atomic.train.7333", "premise_hypothesis_id": "atomic.train.3461", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9x6hpYPhc2vJQmCgEJQWHw==", "AtomicEventRelationId": "9_5fOT4UJn1uNsqcHJS08w==", "AtomicRelationType": "xNeed", "AtomicInference": "to get up"}, "premise": "PersonX looks behind", "hypothesis": "Before, PersonX needed to get up", "update": "Person X is seated in a crowded stadium.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7333", "update_paraphrase": "Person X is sitting in a busy stadium.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.312366452991453, "pred_conf_shift": 0.13758757710456848, "syntactic_distance": 0.05555555555555555}, {"confidence": [0.6345195770263672, 0.3654804229736328], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7333.gpt3.5", "original_example": {"example_id": "atomic.train.7333", "premise_hypothesis_id": "atomic.train.3461", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9x6hpYPhc2vJQmCgEJQWHw==", "AtomicEventRelationId": "9_5fOT4UJn1uNsqcHJS08w==", "AtomicRelationType": "xNeed", "AtomicInference": "to get up"}, "premise": "PersonX looks behind", "hypothesis": "Before, PersonX needed to get up", "update": "Person X is seated in a crowded stadium.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7333", "update_paraphrase": "Person X is sitting in a crowded stadium.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0953525641025641, "pred_conf_shift": 0.09515789151191711, "syntactic_distance": 0.05555555555555555}, {"confidence": [0.4422098398208618, 0.557790219783783], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.7333.gpt3.4", "original_example": {"example_id": "atomic.train.7333", "premise_hypothesis_id": "atomic.train.3461", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9x6hpYPhc2vJQmCgEJQWHw==", "AtomicEventRelationId": "9_5fOT4UJn1uNsqcHJS08w==", "AtomicRelationType": "xNeed", "AtomicInference": "to get up"}, "premise": "PersonX looks behind", "hypothesis": "Before, PersonX needed to get up", "update": "Person X is seated in a crowded stadium.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7333", "update_paraphrase": "Person X is surrounded by other people in a tightly packed stadium.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37058823529411766, "pred_conf_shift": 0.28746768832206726, "syntactic_distance": 0.05263157894736842}, {"confidence": [0.7142928838729858, 0.28570717573165894], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7333.gpt3.6", "original_example": {"example_id": "atomic.train.7333", "premise_hypothesis_id": "atomic.train.3461", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9x6hpYPhc2vJQmCgEJQWHw==", "AtomicEventRelationId": "9_5fOT4UJn1uNsqcHJS08w==", "AtomicRelationType": "xNeed", "AtomicInference": "to get up"}, "premise": "PersonX looks behind", "hypothesis": "Before, PersonX needed to get up", "update": "Person X is seated in a crowded stadium.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7333", "update_paraphrase": "Person X is sitting in a stadium that is full of people.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42615384615384616, "pred_conf_shift": 0.015384644269943237, "syntactic_distance": 0.05555555555555555}, {"confidence": [0.46932753920555115, 0.5306724309921265], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.7333.gpt3.2", "original_example": {"example_id": "atomic.train.7333", "premise_hypothesis_id": "atomic.train.3461", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9x6hpYPhc2vJQmCgEJQWHw==", "AtomicEventRelationId": "9_5fOT4UJn1uNsqcHJS08w==", "AtomicRelationType": "xNeed", "AtomicInference": "to get up"}, "premise": "PersonX looks behind", "hypothesis": "Before, PersonX needed to get up", "update": "Person X is seated in a crowded stadium.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7333", "update_paraphrase": "There is a sea of people around Person X in the stadium.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4320745920745921, "pred_conf_shift": 0.26034989953041077, "syntactic_distance": 0.43478260869565216}, {"confidence": [0.49339720606803894, 0.5066028237342834], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.7333.gpt3.0", "original_example": {"example_id": "atomic.train.7333", "premise_hypothesis_id": "atomic.train.3461", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9x6hpYPhc2vJQmCgEJQWHw==", "AtomicEventRelationId": "9_5fOT4UJn1uNsqcHJS08w==", "AtomicRelationType": "xNeed", "AtomicInference": "to get up"}, "premise": "PersonX looks behind", "hypothesis": "Before, PersonX needed to get up", "update": "Person X is seated in a crowded stadium.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7333", "update_paraphrase": "Person X was one of many people crammed into the stadium.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.46785553627658893, "pred_conf_shift": 0.23628029227256775, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.7614838480949402, 0.2385161817073822], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7333.gpt3.3", "original_example": {"example_id": "atomic.train.7333", "premise_hypothesis_id": "atomic.train.3461", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "9x6hpYPhc2vJQmCgEJQWHw==", "AtomicEventRelationId": "9_5fOT4UJn1uNsqcHJS08w==", "AtomicRelationType": "xNeed", "AtomicInference": "to get up"}, "premise": "PersonX looks behind", "hypothesis": "Before, PersonX needed to get up", "update": "Person X is seated in a crowded stadium.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7333", "update_paraphrase": "Person X is sitting in a packed stadium.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28352029914529914, "pred_conf_shift": -0.031806349754333496, "syntactic_distance": 0.05555555555555555}]}, "atomic.train.17742": {"original_confidence": [0.9725939035415649, 0.027406036853790283], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.9744530320167542, 0.025546949356794357], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.17742.gpt3.2", "original_example": {"example_id": "atomic.train.17742", "premise_hypothesis_id": "atomic.train.8257", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "1aJVJ_PPDuBTdIVXODB2Jg==", "AtomicEventRelationId": "9maf4VvEd5V-0GWZOpCwzg==", "AtomicRelationType": "xEffect", "AtomicInference": "forgives"}, "premise": "PersonX spares PersonY life", "hypothesis": "PersonX then forgives", "update": "PersonY tries to kill them again", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17742", "update_paraphrase": "Person Y attempts to kill them once more.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3418803418803419, "pred_conf_shift": 0.001859128475189209, "syntactic_distance": 0.125}, {"confidence": [0.9742026329040527, 0.025797292590141296], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.17742.gpt3.4", "original_example": {"example_id": "atomic.train.17742", "premise_hypothesis_id": "atomic.train.8257", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "1aJVJ_PPDuBTdIVXODB2Jg==", "AtomicEventRelationId": "9maf4VvEd5V-0GWZOpCwzg==", "AtomicRelationType": "xEffect", "AtomicInference": "forgives"}, "premise": "PersonX spares PersonY life", "hypothesis": "PersonX then forgives", "update": "PersonY tries to kill them again", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17742", "update_paraphrase": "PersonY makes another attempt to kill them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.27692307692307694, "pred_conf_shift": 0.001608729362487793, "syntactic_distance": 0.25}, {"confidence": [0.9758877754211426, 0.024112217128276825], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.17742.gpt3.0", "original_example": {"example_id": "atomic.train.17742", "premise_hypothesis_id": "atomic.train.8257", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "1aJVJ_PPDuBTdIVXODB2Jg==", "AtomicEventRelationId": "9maf4VvEd5V-0GWZOpCwzg==", "AtomicRelationType": "xEffect", "AtomicInference": "forgives"}, "premise": "PersonX spares PersonY life", "hypothesis": "PersonX then forgives", "update": "PersonY tries to kill them again", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17742", "update_paraphrase": "PersonY makes another attempt at killing them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3958041958041958, "pred_conf_shift": 0.0032938718795776367, "syntactic_distance": 0.2}, {"confidence": [0.9726885557174683, 0.027311507612466812], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.17742.gpt3.1", "original_example": {"example_id": "atomic.train.17742", "premise_hypothesis_id": "atomic.train.8257", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "1aJVJ_PPDuBTdIVXODB2Jg==", "AtomicEventRelationId": "9maf4VvEd5V-0GWZOpCwzg==", "AtomicRelationType": "xEffect", "AtomicInference": "forgives"}, "premise": "PersonX spares PersonY life", "hypothesis": "PersonX then forgives", "update": "PersonY tries to kill them again", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17742", "update_paraphrase": "PersonY makes another attempt on their life.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5384615384615384, "pred_conf_shift": 9.465217590332031e-05, "syntactic_distance": 0.2}, {"confidence": [0.9736683964729309, 0.026331642642617226], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.17742.gpt3.5", "original_example": {"example_id": "atomic.train.17742", "premise_hypothesis_id": "atomic.train.8257", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "1aJVJ_PPDuBTdIVXODB2Jg==", "AtomicEventRelationId": "9maf4VvEd5V-0GWZOpCwzg==", "AtomicRelationType": "xEffect", "AtomicInference": "forgives"}, "premise": "PersonX spares PersonY life", "hypothesis": "PersonX then forgives", "update": "PersonY tries to kill them again", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17742", "update_paraphrase": "PersonY makes another attempt to murder them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.41647241647241645, "pred_conf_shift": 0.0010744929313659668, "syntactic_distance": 0.25}, {"confidence": [0.9769895076751709, 0.023010417819023132], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.17742.gpt3.3", "original_example": {"example_id": "atomic.train.17742", "premise_hypothesis_id": "atomic.train.8257", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "1aJVJ_PPDuBTdIVXODB2Jg==", "AtomicEventRelationId": "9maf4VvEd5V-0GWZOpCwzg==", "AtomicRelationType": "xEffect", "AtomicInference": "forgives"}, "premise": "PersonX spares PersonY life", "hypothesis": "PersonX then forgives", "update": "PersonY tries to kill them again", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17742", "update_paraphrase": "PersonY brazenly attempts to murder them once more.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4491452991452991, "pred_conf_shift": 0.004395604133605957, "syntactic_distance": 0.125}, {"confidence": [0.9753158092498779, 0.024684211239218712], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.17742.gpt3.6", "original_example": {"example_id": "atomic.train.17742", "premise_hypothesis_id": "atomic.train.8257", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "1aJVJ_PPDuBTdIVXODB2Jg==", "AtomicEventRelationId": "9maf4VvEd5V-0GWZOpCwzg==", "AtomicRelationType": "xEffect", "AtomicInference": "forgives"}, "premise": "PersonX spares PersonY life", "hypothesis": "PersonX then forgives", "update": "PersonY tries to kill them again", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17742", "update_paraphrase": "PersonY makes another attempt at murdering them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.48389217619986846, "pred_conf_shift": 0.0027219057083129883, "syntactic_distance": 0.2}]}, "atomic.train.23195": {"original_confidence": [0.3199402689933777, 0.6800597906112671], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.7808852791786194, 0.2191147357225418], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.23195.gpt3.0", "original_example": {"example_id": "atomic.train.23195", "premise_hypothesis_id": "atomic.train.10634", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-azbkh5idQ5W8ZDR-Nnw-Q==", "AtomicEventRelationId": "q5X8Pq4nH2waLWiPeJvY5A==", "AtomicRelationType": "xAttr", "AtomicInference": "tired"}, "premise": "PersonX lets out a sigh of relief", "hypothesis": "As a result, PersonX feels tired", "update": "PersonX is dangling over a cliff", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23195", "update_paraphrase": "PersonX is at risk of falling off a cliff.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.35555555555555557, "pred_conf_shift": -0.4609450548887253, "syntactic_distance": 0.1875}, {"confidence": [0.6032899618148804, 0.39671003818511963], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.23195.gpt3.1", "original_example": {"example_id": "atomic.train.23195", "premise_hypothesis_id": "atomic.train.10634", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-azbkh5idQ5W8ZDR-Nnw-Q==", "AtomicEventRelationId": "q5X8Pq4nH2waLWiPeJvY5A==", "AtomicRelationType": "xAttr", "AtomicInference": "tired"}, "premise": "PersonX lets out a sigh of relief", "hypothesis": "As a result, PersonX feels tired", "update": "PersonX is dangling over a cliff", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23195", "update_paraphrase": "PersonX is hanging precariously over a cliff.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.136842105263158, "pred_conf_shift": -0.28334975242614746, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.8398191928863525, 0.16018076241016388], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.23195.gpt3.3", "original_example": {"example_id": "atomic.train.23195", "premise_hypothesis_id": "atomic.train.10634", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-azbkh5idQ5W8ZDR-Nnw-Q==", "AtomicEventRelationId": "q5X8Pq4nH2waLWiPeJvY5A==", "AtomicRelationType": "xAttr", "AtomicInference": "tired"}, "premise": "PersonX lets out a sigh of relief", "hypothesis": "As a result, PersonX feels tired", "update": "PersonX is dangling over a cliff", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23195", "update_paraphrase": "Person X is in danger of falling off a cliff.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3834249084249084, "pred_conf_shift": -0.5198790282011032, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.8408445119857788, 0.1591554433107376], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.23195.gpt3.2", "original_example": {"example_id": "atomic.train.23195", "premise_hypothesis_id": "atomic.train.10634", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-azbkh5idQ5W8ZDR-Nnw-Q==", "AtomicEventRelationId": "q5X8Pq4nH2waLWiPeJvY5A==", "AtomicRelationType": "xAttr", "AtomicInference": "tired"}, "premise": "PersonX lets out a sigh of relief", "hypothesis": "As a result, PersonX feels tired", "update": "PersonX is dangling over a cliff", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23195", "update_paraphrase": "PersonX is in danger of falling off a cliff.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3602279202279202, "pred_conf_shift": -0.5209043473005295, "syntactic_distance": 0.1875}]}, "atomic.train.36295": {"original_confidence": [0.3707748353481293, 0.6292251348495483], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.691344141960144, 0.30865588784217834], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.36295.gpt3.3", "original_example": {"example_id": "atomic.train.36295", "premise_hypothesis_id": "atomic.train.16460", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BOSpkW5tUEV-BmXeJFYuwg==", "AtomicEventRelationId": "pqgdkLqR6bCHLoFvc2NMqQ==", "AtomicRelationType": "xNeed", "AtomicInference": "To have time to spend at beach"}, "premise": "PersonX spends the day at the beach", "hypothesis": "Before, PersonX needed to have time to spend at beach", "update": "X used vacation time.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36295", "update_paraphrase": "X used their vacation time to take a break from work.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5833333333333333, "pred_conf_shift": -0.32056924700737, "syntactic_distance": 0.5333333333333333}, {"confidence": [0.4528418481349945, 0.5471581220626831], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.36295.gpt3.1", "original_example": {"example_id": "atomic.train.36295", "premise_hypothesis_id": "atomic.train.16460", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BOSpkW5tUEV-BmXeJFYuwg==", "AtomicEventRelationId": "pqgdkLqR6bCHLoFvc2NMqQ==", "AtomicRelationType": "xNeed", "AtomicInference": "To have time to spend at beach"}, "premise": "PersonX spends the day at the beach", "hypothesis": "Before, PersonX needed to have time to spend at beach", "update": "X used vacation time.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36295", "update_paraphrase": "X used some of their vacation time.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2727272727272727, "pred_conf_shift": -0.08206701278686523, "syntactic_distance": 0.5833333333333334}, {"confidence": [0.12084908038377762, 0.8791510462760925], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.36295.gpt3.4", "original_example": {"example_id": "atomic.train.36295", "premise_hypothesis_id": "atomic.train.16460", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BOSpkW5tUEV-BmXeJFYuwg==", "AtomicEventRelationId": "pqgdkLqR6bCHLoFvc2NMqQ==", "AtomicRelationType": "xNeed", "AtomicInference": "To have time to spend at beach"}, "premise": "PersonX spends the day at the beach", "hypothesis": "Before, PersonX needed to have time to spend at beach", "update": "X used vacation time.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36295", "update_paraphrase": "X took some time off from work for a vacation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5714285714285714, "pred_conf_shift": 0.2499259114265442, "syntactic_distance": 0.6842105263157895}, {"confidence": [0.10789254307746887, 0.8921074867248535], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.36295.gpt3.0", "original_example": {"example_id": "atomic.train.36295", "premise_hypothesis_id": "atomic.train.16460", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BOSpkW5tUEV-BmXeJFYuwg==", "AtomicEventRelationId": "pqgdkLqR6bCHLoFvc2NMqQ==", "AtomicRelationType": "xNeed", "AtomicInference": "To have time to spend at beach"}, "premise": "PersonX spends the day at the beach", "hypothesis": "Before, PersonX needed to have time to spend at beach", "update": "X used vacation time.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36295", "update_paraphrase": "X took some time off from work for vacation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5384615384615385, "pred_conf_shift": 0.2628823518753052, "syntactic_distance": 0.6842105263157895}, {"confidence": [0.14915400743484497, 0.8508458733558655], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.36295.gpt3.6", "original_example": {"example_id": "atomic.train.36295", "premise_hypothesis_id": "atomic.train.16460", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BOSpkW5tUEV-BmXeJFYuwg==", "AtomicEventRelationId": "pqgdkLqR6bCHLoFvc2NMqQ==", "AtomicRelationType": "xNeed", "AtomicInference": "To have time to spend at beach"}, "premise": "PersonX spends the day at the beach", "hypothesis": "Before, PersonX needed to have time to spend at beach", "update": "X used vacation time.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36295", "update_paraphrase": "X took a vacation day.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.49603174603174605, "pred_conf_shift": 0.22162073850631714, "syntactic_distance": 0.46153846153846156}, {"confidence": [0.4613203704357147, 0.5386795997619629], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.36295.gpt3.7", "original_example": {"example_id": "atomic.train.36295", "premise_hypothesis_id": "atomic.train.16460", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BOSpkW5tUEV-BmXeJFYuwg==", "AtomicEventRelationId": "pqgdkLqR6bCHLoFvc2NMqQ==", "AtomicRelationType": "xNeed", "AtomicInference": "To have time to spend at beach"}, "premise": "PersonX spends the day at the beach", "hypothesis": "Before, PersonX needed to have time to spend at beach", "update": "X used vacation time.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36295", "update_paraphrase": "X used up his or her vacation days.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5317460317460319, "pred_conf_shift": -0.09054553508758545, "syntactic_distance": 0.6470588235294118}, {"confidence": [0.9532819390296936, 0.04671811684966087], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.36295.gpt3.2", "original_example": {"example_id": "atomic.train.36295", "premise_hypothesis_id": "atomic.train.16460", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BOSpkW5tUEV-BmXeJFYuwg==", "AtomicEventRelationId": "pqgdkLqR6bCHLoFvc2NMqQ==", "AtomicRelationType": "xNeed", "AtomicInference": "To have time to spend at beach"}, "premise": "PersonX spends the day at the beach", "hypothesis": "Before, PersonX needed to have time to spend at beach", "update": "X used vacation time.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36295", "update_paraphrase": "X used vacation time to travel.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19999999999999996, "pred_conf_shift": -0.5825070179998875, "syntactic_distance": 0.35714285714285715}, {"confidence": [0.14860299229621887, 0.8513970375061035], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.36295.gpt3.5", "original_example": {"example_id": "atomic.train.36295", "premise_hypothesis_id": "atomic.train.16460", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "BOSpkW5tUEV-BmXeJFYuwg==", "AtomicEventRelationId": "pqgdkLqR6bCHLoFvc2NMqQ==", "AtomicRelationType": "xNeed", "AtomicInference": "To have time to spend at beach"}, "premise": "PersonX spends the day at the beach", "hypothesis": "Before, PersonX needed to have time to spend at beach", "update": "X used vacation time.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36295", "update_paraphrase": "X took a vacation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5520833333333333, "pred_conf_shift": 0.22217190265655518, "syntactic_distance": 0.5}]}, "atomic.train.24195": {"original_confidence": [0.22016040980815887, 0.7798395156860352], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.17824332416057587, 0.8217566609382629], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.24195.gpt3.4", "original_example": {"example_id": "atomic.train.24195", "premise_hypothesis_id": "atomic.train.11071", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7AOW6ybFPIfkmv4Z8Qj_Ig==", "AtomicEventRelationId": "7l4hWPY3H6Vj0HF3ZgoJQw==", "AtomicRelationType": "xIntent", "AtomicInference": "to throw out something"}, "premise": "PersonX gets rid altogether", "hypothesis": "Because PersonX wanted to throw out something", "update": "They hate clutter", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24195", "update_paraphrase": "They can't stand having a lot of stuff around.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.7041666666666666, "pred_conf_shift": 0.04191714525222778, "syntactic_distance": 0.3125}, {"confidence": [0.2705761194229126, 0.7294238209724426], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.24195.gpt3.8", "original_example": {"example_id": "atomic.train.24195", "premise_hypothesis_id": "atomic.train.11071", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7AOW6ybFPIfkmv4Z8Qj_Ig==", "AtomicEventRelationId": "7l4hWPY3H6Vj0HF3ZgoJQw==", "AtomicRelationType": "xIntent", "AtomicInference": "to throw out something"}, "premise": "PersonX gets rid altogether", "hypothesis": "Because PersonX wanted to throw out something", "update": "They hate clutter", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24195", "update_paraphrase": "They detest being surrounded by clutter.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4666666666666667, "pred_conf_shift": -0.05041569471359253, "syntactic_distance": 0.14285714285714285}, {"confidence": [0.22074469923973083, 0.779255211353302], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.24195.gpt3.5", "original_example": {"example_id": "atomic.train.24195", "premise_hypothesis_id": "atomic.train.11071", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7AOW6ybFPIfkmv4Z8Qj_Ig==", "AtomicEventRelationId": "7l4hWPY3H6Vj0HF3ZgoJQw==", "AtomicRelationType": "xIntent", "AtomicInference": "to throw out something"}, "premise": "PersonX gets rid altogether", "hypothesis": "Because PersonX wanted to throw out something", "update": "They hate clutter", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24195", "update_paraphrase": "They cannot stand having a lot of stuff around them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.736734693877551, "pred_conf_shift": -0.0005843043327331543, "syntactic_distance": 0.3125}, {"confidence": [0.23517195880413055, 0.764828085899353], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.24195.gpt3.0", "original_example": {"example_id": "atomic.train.24195", "premise_hypothesis_id": "atomic.train.11071", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7AOW6ybFPIfkmv4Z8Qj_Ig==", "AtomicEventRelationId": "7l4hWPY3H6Vj0HF3ZgoJQw==", "AtomicRelationType": "xIntent", "AtomicInference": "to throw out something"}, "premise": "PersonX gets rid altogether", "hypothesis": "Because PersonX wanted to throw out something", "update": "They hate clutter", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24195", "update_paraphrase": "To them, clutter is a hated thing.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5527777777777778, "pred_conf_shift": -0.015011429786682129, "syntactic_distance": 0.35}, {"confidence": [0.26197734475135803, 0.7380226850509644], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.24195.gpt3.7", "original_example": {"example_id": "atomic.train.24195", "premise_hypothesis_id": "atomic.train.11071", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7AOW6ybFPIfkmv4Z8Qj_Ig==", "AtomicEventRelationId": "7l4hWPY3H6Vj0HF3ZgoJQw==", "AtomicRelationType": "xIntent", "AtomicInference": "to throw out something"}, "premise": "PersonX gets rid altogether", "hypothesis": "Because PersonX wanted to throw out something", "update": "They hate clutter", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24195", "update_paraphrase": "They hate messes and disorganization.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45576923076923076, "pred_conf_shift": -0.0418168306350708, "syntactic_distance": 0.125}, {"confidence": [0.09576275944709778, 0.9042372107505798], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.24195.gpt3.6", "original_example": {"example_id": "atomic.train.24195", "premise_hypothesis_id": "atomic.train.11071", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7AOW6ybFPIfkmv4Z8Qj_Ig==", "AtomicEventRelationId": "7l4hWPY3H6Vj0HF3ZgoJQw==", "AtomicRelationType": "xIntent", "AtomicInference": "to throw out something"}, "premise": "PersonX gets rid altogether", "hypothesis": "Because PersonX wanted to throw out something", "update": "They hate clutter", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24195", "update_paraphrase": "They have a strong dislike of messiness and being surrounded by too many things.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.7671945701357465, "pred_conf_shift": 0.12439769506454468, "syntactic_distance": 0.13333333333333333}, {"confidence": [0.3006134629249573, 0.6993865966796875], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.24195.gpt3.1", "original_example": {"example_id": "atomic.train.24195", "premise_hypothesis_id": "atomic.train.11071", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7AOW6ybFPIfkmv4Z8Qj_Ig==", "AtomicEventRelationId": "7l4hWPY3H6Vj0HF3ZgoJQw==", "AtomicRelationType": "xIntent", "AtomicInference": "to throw out something"}, "premise": "PersonX gets rid altogether", "hypothesis": "Because PersonX wanted to throw out something", "update": "They hate clutter", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24195", "update_paraphrase": "They detest clutter.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.18333333333333335, "pred_conf_shift": -0.08045291900634766, "syntactic_distance": 0.0}, {"confidence": [0.09443416446447372, 0.9055658578872681], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.24195.gpt3.2", "original_example": {"example_id": "atomic.train.24195", "premise_hypothesis_id": "atomic.train.11071", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7AOW6ybFPIfkmv4Z8Qj_Ig==", "AtomicEventRelationId": "7l4hWPY3H6Vj0HF3ZgoJQw==", "AtomicRelationType": "xIntent", "AtomicInference": "to throw out something"}, "premise": "PersonX gets rid altogether", "hypothesis": "Because PersonX wanted to throw out something", "update": "They hate clutter", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24195", "update_paraphrase": "They can't stand when their space is messy and cluttered.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6549145299145299, "pred_conf_shift": 0.1257263422012329, "syntactic_distance": 0.3125}, {"confidence": [0.14107784628868103, 0.8589221239089966], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.24195.gpt3.3", "original_example": {"example_id": "atomic.train.24195", "premise_hypothesis_id": "atomic.train.11071", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7AOW6ybFPIfkmv4Z8Qj_Ig==", "AtomicEventRelationId": "7l4hWPY3H6Vj0HF3ZgoJQw==", "AtomicRelationType": "xIntent", "AtomicInference": "to throw out something"}, "premise": "PersonX gets rid altogether", "hypothesis": "Because PersonX wanted to throw out something", "update": "They hate clutter", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24195", "update_paraphrase": "They detest having a lot of things around that are not organized.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.7133333333333333, "pred_conf_shift": 0.07908260822296143, "syntactic_distance": 0.14285714285714285}]}, "atomic.train.7145": {"original_confidence": [0.8793820142745972, 0.12061796337366104], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.8793820142745972, 0.12061796337366104], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7145.gpt3.5", "original_example": {"example_id": "atomic.train.7145", "premise_hypothesis_id": "atomic.train.3372", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "KxcNu4qYMawOzPXEjX-1CQ==", "AtomicEventRelationId": "80eyn3XKc7_67e5Wlh9LxQ==", "AtomicRelationType": "xWant", "AtomicInference": "hold PersonY  down"}, "premise": "PersonX takes PersonY down", "hypothesis": "As a result, PersonX wants hold PersonY  down", "update": "PersonX was playing football against PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7145", "update_paraphrase": "PersonX was playing football against PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": 0.0, "syntactic_distance": 0.0}, {"confidence": [0.8162439465522766, 0.18375597894191742], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7145.gpt3.2", "original_example": {"example_id": "atomic.train.7145", "premise_hypothesis_id": "atomic.train.3372", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "KxcNu4qYMawOzPXEjX-1CQ==", "AtomicEventRelationId": "80eyn3XKc7_67e5Wlh9LxQ==", "AtomicRelationType": "xWant", "AtomicInference": "hold PersonY  down"}, "premise": "PersonX takes PersonY down", "hypothesis": "As a result, PersonX wants hold PersonY  down", "update": "PersonX was playing football against PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7145", "update_paraphrase": "PersonX and PersonY were playing football against each other.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.30158730158730157, "pred_conf_shift": 0.06313801556825638, "syntactic_distance": 0.1}, {"confidence": [0.8409557938575745, 0.15904423594474792], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7145.gpt3.4", "original_example": {"example_id": "atomic.train.7145", "premise_hypothesis_id": "atomic.train.3372", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "KxcNu4qYMawOzPXEjX-1CQ==", "AtomicEventRelationId": "80eyn3XKc7_67e5Wlh9LxQ==", "AtomicRelationType": "xWant", "AtomicInference": "hold PersonY  down"}, "premise": "PersonX takes PersonY down", "hypothesis": "As a result, PersonX wants hold PersonY  down", "update": "PersonX was playing football against PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7145", "update_paraphrase": "PersonX was playing football with PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.12445887445887444, "pred_conf_shift": 0.038426272571086884, "syntactic_distance": 0.0}, {"confidence": [0.6934146881103516, 0.30658531188964844], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7145.gpt3.1", "original_example": {"example_id": "atomic.train.7145", "premise_hypothesis_id": "atomic.train.3372", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "KxcNu4qYMawOzPXEjX-1CQ==", "AtomicEventRelationId": "80eyn3XKc7_67e5Wlh9LxQ==", "AtomicRelationType": "xWant", "AtomicInference": "hold PersonY  down"}, "premise": "PersonX takes PersonY down", "hypothesis": "As a result, PersonX wants hold PersonY  down", "update": "PersonX was playing football against PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7145", "update_paraphrase": "PersonX was competing against PersonY in a game of football.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37256493506493504, "pred_conf_shift": 0.1859673485159874, "syntactic_distance": 0.05555555555555555}, {"confidence": [0.8302209377288818, 0.16977910697460175], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7145.gpt3.3", "original_example": {"example_id": "atomic.train.7145", "premise_hypothesis_id": "atomic.train.3372", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "KxcNu4qYMawOzPXEjX-1CQ==", "AtomicEventRelationId": "80eyn3XKc7_67e5Wlh9LxQ==", "AtomicRelationType": "xWant", "AtomicInference": "hold PersonY  down"}, "premise": "PersonX takes PersonY down", "hypothesis": "As a result, PersonX wants hold PersonY  down", "update": "PersonX was playing football against PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7145", "update_paraphrase": "PersonX was playing against PersonY in a game of football.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.34131493506493504, "pred_conf_shift": 0.049161143600940704, "syntactic_distance": 0.05555555555555555}, {"confidence": [0.7739331126213074, 0.22606685757637024], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.7145.gpt3.0", "original_example": {"example_id": "atomic.train.7145", "premise_hypothesis_id": "atomic.train.3372", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "KxcNu4qYMawOzPXEjX-1CQ==", "AtomicEventRelationId": "80eyn3XKc7_67e5Wlh9LxQ==", "AtomicRelationType": "xWant", "AtomicInference": "hold PersonY  down"}, "premise": "PersonX takes PersonY down", "hypothesis": "As a result, PersonX wants hold PersonY  down", "update": "PersonX was playing football against PersonY.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.7145", "update_paraphrase": "PersonX was pitted against PersonY in a game of football.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37603715728715725, "pred_conf_shift": 0.1054488942027092, "syntactic_distance": 0.1111111111111111}]}, "atomic.train.4157": {"original_confidence": [0.10259213298559189, 0.8974079489707947], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.1456446349620819, 0.8543553352355957], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4157.gpt3.3", "original_example": {"example_id": "atomic.train.4157", "premise_hypothesis_id": "atomic.train.1957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y04ynBnbU1UdN_uC3AxoQA==", "AtomicEventRelationId": "XRZ0fafZ2yyJPJsk-c3wWw==", "AtomicRelationType": "xEffect", "AtomicInference": "they get out of car"}, "premise": "PersonX drives to work one morning", "hypothesis": "Then, they get out of car", "update": "PersonX spots bird droppings on the outside of their car window.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4157", "update_paraphrase": "PersonX finds bird poop on their car window.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.340016708437761, "pred_conf_shift": -0.043052613735198975, "syntactic_distance": 0.045454545454545456}, {"confidence": [0.14931648969650269, 0.8506835103034973], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4157.gpt3.0", "original_example": {"example_id": "atomic.train.4157", "premise_hypothesis_id": "atomic.train.1957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y04ynBnbU1UdN_uC3AxoQA==", "AtomicEventRelationId": "XRZ0fafZ2yyJPJsk-c3wWw==", "AtomicRelationType": "xEffect", "AtomicInference": "they get out of car"}, "premise": "PersonX drives to work one morning", "hypothesis": "Then, they get out of car", "update": "PersonX spots bird droppings on the outside of their car window.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4157", "update_paraphrase": "PersonX sees bird poop on their car window.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33758639021796916, "pred_conf_shift": -0.04672443866729736, "syntactic_distance": 0.045454545454545456}, {"confidence": [0.10318117588758469, 0.8968186974525452], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4157.gpt3.1", "original_example": {"example_id": "atomic.train.4157", "premise_hypothesis_id": "atomic.train.1957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y04ynBnbU1UdN_uC3AxoQA==", "AtomicEventRelationId": "XRZ0fafZ2yyJPJsk-c3wWw==", "AtomicRelationType": "xEffect", "AtomicInference": "they get out of car"}, "premise": "PersonX drives to work one morning", "hypothesis": "Then, they get out of car", "update": "PersonX spots bird droppings on the outside of their car window.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4157", "update_paraphrase": "PersonX saw that there were bird droppings on the outside of their car window.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.17545454545454547, "pred_conf_shift": -0.0005892515182495117, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.1268649846315384, 0.8731350302696228], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4157.gpt3.7", "original_example": {"example_id": "atomic.train.4157", "premise_hypothesis_id": "atomic.train.1957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y04ynBnbU1UdN_uC3AxoQA==", "AtomicEventRelationId": "XRZ0fafZ2yyJPJsk-c3wWw==", "AtomicRelationType": "xEffect", "AtomicInference": "they get out of car"}, "premise": "PersonX drives to work one morning", "hypothesis": "Then, they get out of car", "update": "PersonX spots bird droppings on the outside of their car window.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4157", "update_paraphrase": "The personX sees bird poop on the exterior of their car window.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.20995912300260128, "pred_conf_shift": -0.024272918701171875, "syntactic_distance": 0.13043478260869565}, {"confidence": [0.10109639912843704, 0.8989036083221436], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4157.gpt3.6", "original_example": {"example_id": "atomic.train.4157", "premise_hypothesis_id": "atomic.train.1957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y04ynBnbU1UdN_uC3AxoQA==", "AtomicEventRelationId": "XRZ0fafZ2yyJPJsk-c3wWw==", "AtomicRelationType": "xEffect", "AtomicInference": "they get out of car"}, "premise": "PersonX drives to work one morning", "hypothesis": "Then, they get out of car", "update": "PersonX spots bird droppings on the outside of their car window.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4157", "update_paraphrase": "PersonX noticed bird droppings on the outside of their car window.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.06060606060606055, "pred_conf_shift": 0.001495659351348877, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.15107978880405426, 0.8489203453063965], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4157.gpt3.2", "original_example": {"example_id": "atomic.train.4157", "premise_hypothesis_id": "atomic.train.1957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y04ynBnbU1UdN_uC3AxoQA==", "AtomicEventRelationId": "XRZ0fafZ2yyJPJsk-c3wWw==", "AtomicRelationType": "xEffect", "AtomicInference": "they get out of car"}, "premise": "PersonX drives to work one morning", "hypothesis": "Then, they get out of car", "update": "PersonX spots bird droppings on the outside of their car window.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4157", "update_paraphrase": "X notices bird poop on the exterior of their car window.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23520335873277054, "pred_conf_shift": -0.04848760366439819, "syntactic_distance": 0.4444444444444444}, {"confidence": [0.11509605497121811, 0.8849039673805237], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4157.gpt3.4", "original_example": {"example_id": "atomic.train.4157", "premise_hypothesis_id": "atomic.train.1957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y04ynBnbU1UdN_uC3AxoQA==", "AtomicEventRelationId": "XRZ0fafZ2yyJPJsk-c3wWw==", "AtomicRelationType": "xEffect", "AtomicInference": "they get out of car"}, "premise": "PersonX drives to work one morning", "hypothesis": "Then, they get out of car", "update": "PersonX spots bird droppings on the outside of their car window.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4157", "update_paraphrase": "PersonX notices bird droppings on their car windows.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2634470792365529, "pred_conf_shift": -0.012503981590270996, "syntactic_distance": 0.2631578947368421}, {"confidence": [0.15426017343997955, 0.8457399606704712], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.4157.gpt3.5", "original_example": {"example_id": "atomic.train.4157", "premise_hypothesis_id": "atomic.train.1957", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y04ynBnbU1UdN_uC3AxoQA==", "AtomicEventRelationId": "XRZ0fafZ2yyJPJsk-c3wWw==", "AtomicRelationType": "xEffect", "AtomicInference": "they get out of car"}, "premise": "PersonX drives to work one morning", "hypothesis": "Then, they get out of car", "update": "PersonX spots bird droppings on the outside of their car window.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.4157", "update_paraphrase": "PersonX sees bird poop on the outside of their car window.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.12742812742812742, "pred_conf_shift": -0.051667988300323486, "syntactic_distance": 0.045454545454545456}]}, "atomic.train.25605": {"original_confidence": [0.25694870948791504, 0.7430512309074402], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.021322693675756454, 0.9786773324012756], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25605.gpt3.6", "original_example": {"example_id": "atomic.train.25605", "premise_hypothesis_id": "atomic.train.11698", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "e03JK2x1a__6lyRvkOv4wg==", "AtomicEventRelationId": "cJ3nvR3hy-g27y3QjLxRgQ==", "AtomicRelationType": "xWant", "AtomicInference": "satisfaction"}, "premise": "PersonX is very kind to PersonY", "hypothesis": "As a result, PersonX wants satisfaction", "update": "PersonX expects something in return.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25605", "update_paraphrase": "PersonX anticipates receiving something in return for their actions.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4277210884353741, "pred_conf_shift": 0.23562610149383545, "syntactic_distance": 0.29411764705882354}, {"confidence": [0.02114587277173996, 0.978854238986969], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25605.gpt3.8", "original_example": {"example_id": "atomic.train.25605", "premise_hypothesis_id": "atomic.train.11698", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "e03JK2x1a__6lyRvkOv4wg==", "AtomicEventRelationId": "cJ3nvR3hy-g27y3QjLxRgQ==", "AtomicRelationType": "xWant", "AtomicInference": "satisfaction"}, "premise": "PersonX is very kind to PersonY", "hypothesis": "As a result, PersonX wants satisfaction", "update": "PersonX expects something in return.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25605", "update_paraphrase": "PersonX anticipates receiving something in return.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.21212121212121204, "pred_conf_shift": 0.2358030080795288, "syntactic_distance": 0.29411764705882354}, {"confidence": [0.29412296414375305, 0.7058770656585693], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25605.gpt3.5", "original_example": {"example_id": "atomic.train.25605", "premise_hypothesis_id": "atomic.train.11698", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "e03JK2x1a__6lyRvkOv4wg==", "AtomicEventRelationId": "cJ3nvR3hy-g27y3QjLxRgQ==", "AtomicRelationType": "xWant", "AtomicInference": "satisfaction"}, "premise": "PersonX is very kind to PersonY", "hypothesis": "As a result, PersonX wants satisfaction", "update": "PersonX expects something in return.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25605", "update_paraphrase": "PersonX wants something in return for their help.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.40792540792540793, "pred_conf_shift": -0.03717416524887085, "syntactic_distance": 0.0}, {"confidence": [0.3216218054294586, 0.6783781051635742], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25605.gpt3.3", "original_example": {"example_id": "atomic.train.25605", "premise_hypothesis_id": "atomic.train.11698", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "e03JK2x1a__6lyRvkOv4wg==", "AtomicEventRelationId": "cJ3nvR3hy-g27y3QjLxRgQ==", "AtomicRelationType": "xWant", "AtomicInference": "satisfaction"}, "premise": "PersonX is very kind to PersonY", "hypothesis": "As a result, PersonX wants satisfaction", "update": "PersonX expects something in return.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25605", "update_paraphrase": "PersonX wants something in exchange for their actions.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45188145188145185, "pred_conf_shift": -0.06467312574386597, "syntactic_distance": 0.0}, {"confidence": [0.08591226488351822, 0.9140877723693848], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25605.gpt3.1", "original_example": {"example_id": "atomic.train.25605", "premise_hypothesis_id": "atomic.train.11698", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "e03JK2x1a__6lyRvkOv4wg==", "AtomicEventRelationId": "cJ3nvR3hy-g27y3QjLxRgQ==", "AtomicRelationType": "xWant", "AtomicInference": "satisfaction"}, "premise": "PersonX is very kind to PersonY", "hypothesis": "As a result, PersonX wants satisfaction", "update": "PersonX expects something in return.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25605", "update_paraphrase": "PersonX wants something in return for their actions.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4029304029304029, "pred_conf_shift": 0.17103654146194458, "syntactic_distance": 0.0}, {"confidence": [0.4641284644603729, 0.5358715653419495], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25605.gpt3.2", "original_example": {"example_id": "atomic.train.25605", "premise_hypothesis_id": "atomic.train.11698", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "e03JK2x1a__6lyRvkOv4wg==", "AtomicEventRelationId": "cJ3nvR3hy-g27y3QjLxRgQ==", "AtomicRelationType": "xWant", "AtomicInference": "satisfaction"}, "premise": "PersonX is very kind to PersonY", "hypothesis": "As a result, PersonX wants satisfaction", "update": "PersonX expects something in return.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25605", "update_paraphrase": "In return for something, PersonX expects something.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3333333333333333, "pred_conf_shift": -0.20717966556549072, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.278399258852005, 0.7216007113456726], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25605.gpt3.7", "original_example": {"example_id": "atomic.train.25605", "premise_hypothesis_id": "atomic.train.11698", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "e03JK2x1a__6lyRvkOv4wg==", "AtomicEventRelationId": "cJ3nvR3hy-g27y3QjLxRgQ==", "AtomicRelationType": "xWant", "AtomicInference": "satisfaction"}, "premise": "PersonX is very kind to PersonY", "hypothesis": "As a result, PersonX wants satisfaction", "update": "PersonX expects something in return.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25605", "update_paraphrase": "Sentence: PersonX is expecting something in return.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.20833333333333337, "pred_conf_shift": -0.021450519561767578, "syntactic_distance": 0.35}, {"confidence": [0.19838303327560425, 0.8016170263290405], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25605.gpt3.0", "original_example": {"example_id": "atomic.train.25605", "premise_hypothesis_id": "atomic.train.11698", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "e03JK2x1a__6lyRvkOv4wg==", "AtomicEventRelationId": "cJ3nvR3hy-g27y3QjLxRgQ==", "AtomicRelationType": "xWant", "AtomicInference": "satisfaction"}, "premise": "PersonX is very kind to PersonY", "hypothesis": "As a result, PersonX wants satisfaction", "update": "PersonX expects something in return.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25605", "update_paraphrase": "PersonX is hoping to get something back in return for their actions.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5213962508080154, "pred_conf_shift": 0.05856579542160034, "syntactic_distance": 0.3333333333333333}]}, "atomic.train.12204": {"original_confidence": [0.878584623336792, 0.12141545116901398], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.8849273324012756, 0.11507269740104675], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.12204.gpt3.2", "original_example": {"example_id": "atomic.train.12204", "premise_hypothesis_id": "atomic.train.5738", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "tZojb_L_nt1aRsJa39l7mQ==", "AtomicEventRelationId": "icF_yQM5Cws6ZeM-NQUMpQ==", "AtomicRelationType": "xEffect", "AtomicInference": "becomes angry with PersonY"}, "premise": "PersonX makes PersonY sick", "hypothesis": "PersonX then becomes angry with PersonY", "update": "PersonY gave PersonX a common cold.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12204", "update_paraphrase": "PersonX contracted a cold from PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3476190476190476, "pred_conf_shift": 0.006342709064483643, "syntactic_distance": 0.2727272727272727}, {"confidence": [0.7717735767364502, 0.228226438164711], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.12204.gpt3.5", "original_example": {"example_id": "atomic.train.12204", "premise_hypothesis_id": "atomic.train.5738", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "tZojb_L_nt1aRsJa39l7mQ==", "AtomicEventRelationId": "icF_yQM5Cws6ZeM-NQUMpQ==", "AtomicRelationType": "xEffect", "AtomicInference": "becomes angry with PersonY"}, "premise": "PersonX makes PersonY sick", "hypothesis": "PersonX then becomes angry with PersonY", "update": "PersonY gave PersonX a common cold.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12204", "update_paraphrase": "PersonX caught a cold from PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.36190476190476195, "pred_conf_shift": -0.1068110466003418, "syntactic_distance": 0.2727272727272727}, {"confidence": [0.6695490479469299, 0.33045095205307007], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.12204.gpt3.1", "original_example": {"example_id": "atomic.train.12204", "premise_hypothesis_id": "atomic.train.5738", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "tZojb_L_nt1aRsJa39l7mQ==", "AtomicEventRelationId": "icF_yQM5Cws6ZeM-NQUMpQ==", "AtomicRelationType": "xEffect", "AtomicInference": "becomes angry with PersonY"}, "premise": "PersonX makes PersonY sick", "hypothesis": "PersonX then becomes angry with PersonY", "update": "PersonY gave PersonX a common cold.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12204", "update_paraphrase": "PersonX caught a cold after being around PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.44036281179138326, "pred_conf_shift": -0.20903557538986206, "syntactic_distance": 0.2727272727272727}, {"confidence": [0.561726987361908, 0.43827304244041443], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.12204.gpt3.3", "original_example": {"example_id": "atomic.train.12204", "premise_hypothesis_id": "atomic.train.5738", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "tZojb_L_nt1aRsJa39l7mQ==", "AtomicEventRelationId": "icF_yQM5Cws6ZeM-NQUMpQ==", "AtomicRelationType": "xEffect", "AtomicInference": "becomes angry with PersonY"}, "premise": "PersonX makes PersonY sick", "hypothesis": "PersonX then becomes angry with PersonY", "update": "PersonY gave PersonX a common cold.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12204", "update_paraphrase": "PersonY gave PersonX a cold.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.09090909090909094, "pred_conf_shift": -0.31685763597488403, "syntactic_distance": 0.047619047619047616}, {"confidence": [0.40205076336860657, 0.597949206829071], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.12204.gpt3.4", "original_example": {"example_id": "atomic.train.12204", "premise_hypothesis_id": "atomic.train.5738", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "tZojb_L_nt1aRsJa39l7mQ==", "AtomicEventRelationId": "icF_yQM5Cws6ZeM-NQUMpQ==", "AtomicRelationType": "xEffect", "AtomicInference": "becomes angry with PersonY"}, "premise": "PersonX makes PersonY sick", "hypothesis": "PersonX then becomes angry with PersonY", "update": "PersonY gave PersonX a common cold.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12204", "update_paraphrase": "PersonY transmitted a cold virus to PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.44743589743589746, "pred_conf_shift": -0.4765338599681854, "syntactic_distance": 0.21739130434782608}, {"confidence": [0.7516636848449707, 0.24833622574806213], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.12204.gpt3.0", "original_example": {"example_id": "atomic.train.12204", "premise_hypothesis_id": "atomic.train.5738", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "tZojb_L_nt1aRsJa39l7mQ==", "AtomicEventRelationId": "icF_yQM5Cws6ZeM-NQUMpQ==", "AtomicRelationType": "xEffect", "AtomicInference": "becomes angry with PersonY"}, "premise": "PersonX makes PersonY sick", "hypothesis": "PersonX then becomes angry with PersonY", "update": "PersonY gave PersonX a common cold.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12204", "update_paraphrase": "PersonY transmitted a common cold virus to PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3904761904761905, "pred_conf_shift": -0.1269209384918213, "syntactic_distance": 0.25}, {"confidence": [0.45745670795440674, 0.542543351650238], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.12204.gpt3.6", "original_example": {"example_id": "atomic.train.12204", "premise_hypothesis_id": "atomic.train.5738", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "tZojb_L_nt1aRsJa39l7mQ==", "AtomicEventRelationId": "icF_yQM5Cws6ZeM-NQUMpQ==", "AtomicRelationType": "xEffect", "AtomicInference": "becomes angry with PersonY"}, "premise": "PersonX makes PersonY sick", "hypothesis": "PersonX then becomes angry with PersonY", "update": "PersonY gave PersonX a common cold.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.12204", "update_paraphrase": "PersonY passed the common cold virus on to PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5219047619047619, "pred_conf_shift": -0.42112791538238525, "syntactic_distance": 0.28}]}, "atomic.train.32816": {"original_confidence": [0.6870577335357666, 0.3129422962665558], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.7828232049942017, 0.21717673540115356], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.32816.gpt3.1", "original_example": {"example_id": "atomic.train.32816", "premise_hypothesis_id": "atomic.train.14900", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "X4An66UT9v7N0RfQOP5ApA==", "AtomicEventRelationId": "x62haQRJHADFPl2VvSrm0Q==", "AtomicRelationType": "xNeed", "AtomicInference": "nothing to do at home"}, "premise": "PersonX is really bored", "hypothesis": "Before, PersonX needed nothing to do at home", "update": "PersonX works a reception desk", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32816", "update_paraphrase": "PersonX works at a reception desk.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.09090909090909094, "pred_conf_shift": 0.09576547145843506, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.8086220026016235, 0.19137787818908691], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.32816.gpt3.3", "original_example": {"example_id": "atomic.train.32816", "premise_hypothesis_id": "atomic.train.14900", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "X4An66UT9v7N0RfQOP5ApA==", "AtomicEventRelationId": "x62haQRJHADFPl2VvSrm0Q==", "AtomicRelationType": "xNeed", "AtomicInference": "nothing to do at home"}, "premise": "PersonX is really bored", "hypothesis": "Before, PersonX needed nothing to do at home", "update": "PersonX works a reception desk", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32816", "update_paraphrase": "PersonX is a receptionist.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.38624338624338617, "pred_conf_shift": 0.12156426906585693, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.8979382514953613, 0.1020616814494133], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.32816.gpt3.6", "original_example": {"example_id": "atomic.train.32816", "premise_hypothesis_id": "atomic.train.14900", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "X4An66UT9v7N0RfQOP5ApA==", "AtomicEventRelationId": "x62haQRJHADFPl2VvSrm0Q==", "AtomicRelationType": "xNeed", "AtomicInference": "nothing to do at home"}, "premise": "PersonX is really bored", "hypothesis": "Before, PersonX needed nothing to do at home", "update": "PersonX works a reception desk", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32816", "update_paraphrase": "PersonX has a job working at a reception desk.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.36054421768707484, "pred_conf_shift": 0.21088051795959473, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.8699071407318115, 0.1300928294658661], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.32816.gpt3.2", "original_example": {"example_id": "atomic.train.32816", "premise_hypothesis_id": "atomic.train.14900", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "X4An66UT9v7N0RfQOP5ApA==", "AtomicEventRelationId": "x62haQRJHADFPl2VvSrm0Q==", "AtomicRelationType": "xNeed", "AtomicInference": "nothing to do at home"}, "premise": "PersonX is really bored", "hypothesis": "Before, PersonX needed nothing to do at home", "update": "PersonX works a reception desk", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32816", "update_paraphrase": "PersonX is responsible for managing the reception desk.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.41025641025641024, "pred_conf_shift": 0.18284940719604492, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.8748077154159546, 0.1251922845840454], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.32816.gpt3.4", "original_example": {"example_id": "atomic.train.32816", "premise_hypothesis_id": "atomic.train.14900", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "X4An66UT9v7N0RfQOP5ApA==", "AtomicEventRelationId": "x62haQRJHADFPl2VvSrm0Q==", "AtomicRelationType": "xNeed", "AtomicInference": "nothing to do at home"}, "premise": "PersonX is really bored", "hypothesis": "Before, PersonX needed nothing to do at home", "update": "PersonX works a reception desk", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32816", "update_paraphrase": "PersonX holds a job at a reception desk.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3384615384615384, "pred_conf_shift": 0.187749981880188, "syntactic_distance": 0.2}]}, "atomic.train.35718": {"original_confidence": [0.7726365923881531, 0.2273634523153305], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.5883771777153015, 0.4116228222846985], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.35718.gpt3.3", "original_example": {"example_id": "atomic.train.35718", "premise_hypothesis_id": "atomic.train.16194", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "uTsY5IIckDPS0kGX6TIu-Q==", "AtomicEventRelationId": "-udH3k8E_7ZRhVl9u-Me5Q==", "AtomicRelationType": "xWant", "AtomicInference": "to toast bread to eat with it"}, "premise": "PersonX makes scrambled eggs for breakfast", "hypothesis": "As a result, PersonX wants to toast bread to eat with it", "update": "PersonX is on a keto diet.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.35718", "update_paraphrase": "PersonX is eating a lot of fat and very few carbs in order to lose weight.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6375114784205693, "pred_conf_shift": -0.18425941467285156, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.7357380390167236, 0.26426202058792114], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.35718.gpt3.4", "original_example": {"example_id": "atomic.train.35718", "premise_hypothesis_id": "atomic.train.16194", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "uTsY5IIckDPS0kGX6TIu-Q==", "AtomicEventRelationId": "-udH3k8E_7ZRhVl9u-Me5Q==", "AtomicRelationType": "xWant", "AtomicInference": "to toast bread to eat with it"}, "premise": "PersonX makes scrambled eggs for breakfast", "hypothesis": "As a result, PersonX wants to toast bread to eat with it", "update": "PersonX is on a keto diet.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.35718", "update_paraphrase": "PersonX is following a keto diet plan.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3286713286713287, "pred_conf_shift": -0.03689855337142944, "syntactic_distance": 0.125}, {"confidence": [0.7598775625228882, 0.24012240767478943], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.35718.gpt3.0", "original_example": {"example_id": "atomic.train.35718", "premise_hypothesis_id": "atomic.train.16194", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "uTsY5IIckDPS0kGX6TIu-Q==", "AtomicEventRelationId": "-udH3k8E_7ZRhVl9u-Me5Q==", "AtomicRelationType": "xWant", "AtomicInference": "to toast bread to eat with it"}, "premise": "PersonX makes scrambled eggs for breakfast", "hypothesis": "As a result, PersonX wants to toast bread to eat with it", "update": "PersonX is on a keto diet.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.35718", "update_paraphrase": "PersonX is following a keto diet.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.09932659932659932, "pred_conf_shift": -0.012759029865264893, "syntactic_distance": 0.125}, {"confidence": [0.7113943099975586, 0.28860557079315186], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.35718.gpt3.1", "original_example": {"example_id": "atomic.train.35718", "premise_hypothesis_id": "atomic.train.16194", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "uTsY5IIckDPS0kGX6TIu-Q==", "AtomicEventRelationId": "-udH3k8E_7ZRhVl9u-Me5Q==", "AtomicRelationType": "xWant", "AtomicInference": "to toast bread to eat with it"}, "premise": "PersonX makes scrambled eggs for breakfast", "hypothesis": "As a result, PersonX wants to toast bread to eat with it", "update": "PersonX is on a keto diet.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.35718", "update_paraphrase": "PersonX is following a Ketogenic diet plan.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3582571274878967, "pred_conf_shift": -0.06124228239059448, "syntactic_distance": 0.125}, {"confidence": [0.626747190952301, 0.3732529282569885], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.35718.gpt3.2", "original_example": {"example_id": "atomic.train.35718", "premise_hypothesis_id": "atomic.train.16194", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "uTsY5IIckDPS0kGX6TIu-Q==", "AtomicEventRelationId": "-udH3k8E_7ZRhVl9u-Me5Q==", "AtomicRelationType": "xWant", "AtomicInference": "to toast bread to eat with it"}, "premise": "PersonX makes scrambled eggs for breakfast", "hypothesis": "As a result, PersonX wants to toast bread to eat with it", "update": "PersonX is on a keto diet.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.35718", "update_paraphrase": "PersonX is on a low-carbohydrate diet.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.12759170653907492, "pred_conf_shift": -0.14588940143585205, "syntactic_distance": 0.0}]}, "atomic.train.10232": {"original_confidence": [0.11398370563983917, 0.886016309261322], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.9760008454322815, 0.02399909310042858], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10232.gpt3.0", "original_example": {"example_id": "atomic.train.10232", "premise_hypothesis_id": "atomic.train.4819", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "p_1cjfEikFp2NhWopmG88Q==", "AtomicEventRelationId": "5SG4PZfEOj5h3CvfoKT2rw==", "AtomicRelationType": "xWant", "AtomicInference": "To explore"}, "premise": "PersonX gets closer", "hypothesis": "As a result, PersonX wants to explore", "update": "PersonX is close to something dangerous", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10232", "update_paraphrase": "PersonX is close to something that could be harmful.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2935185185185185, "pred_conf_shift": 0.8620171397924423, "syntactic_distance": 0.0}, {"confidence": [0.3984302580356598, 0.6015697717666626], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.10232.gpt3.4", "original_example": {"example_id": "atomic.train.10232", "premise_hypothesis_id": "atomic.train.4819", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "p_1cjfEikFp2NhWopmG88Q==", "AtomicEventRelationId": "5SG4PZfEOj5h3CvfoKT2rw==", "AtomicRelationType": "xWant", "AtomicInference": "To explore"}, "premise": "PersonX gets closer", "hypothesis": "As a result, PersonX wants to explore", "update": "PersonX is close to something dangerous", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10232", "update_paraphrase": "PersonX is in close proximity to something dangerous.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1785714285714286, "pred_conf_shift": 0.2844465523958206, "syntactic_distance": 0.1875}, {"confidence": [0.9769535660743713, 0.023046357557177544], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10232.gpt3.2", "original_example": {"example_id": "atomic.train.10232", "premise_hypothesis_id": "atomic.train.4819", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "p_1cjfEikFp2NhWopmG88Q==", "AtomicEventRelationId": "5SG4PZfEOj5h3CvfoKT2rw==", "AtomicRelationType": "xWant", "AtomicInference": "To explore"}, "premise": "PersonX gets closer", "hypothesis": "As a result, PersonX wants to explore", "update": "PersonX is close to something dangerous", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10232", "update_paraphrase": "Person X is close to something that could be harmful.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3377403846153846, "pred_conf_shift": 0.8629698604345322, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.9811103343963623, 0.01888982206583023], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10232.gpt3.3", "original_example": {"example_id": "atomic.train.10232", "premise_hypothesis_id": "atomic.train.4819", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "p_1cjfEikFp2NhWopmG88Q==", "AtomicEventRelationId": "5SG4PZfEOj5h3CvfoKT2rw==", "AtomicRelationType": "xWant", "AtomicInference": "To explore"}, "premise": "PersonX gets closer", "hypothesis": "As a result, PersonX wants to explore", "update": "PersonX is close to something dangerous", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10232", "update_paraphrase": "PersonX is near something that could be harmful.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4873174444603016, "pred_conf_shift": 0.8671266287565231, "syntactic_distance": 0.1875}]}, "atomic.train.10539": {"original_confidence": [0.6579379439353943, 0.3420620560646057], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.7758161425590515, 0.22418387234210968], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10539.gpt3.0", "original_example": {"example_id": "atomic.train.10539", "premise_hypothesis_id": "atomic.train.4961", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "PSANibAMU_ANyt2xZuY-mg==", "AtomicEventRelationId": "P9PRqSrawX4o_4h_2mAaPQ==", "AtomicRelationType": "xWant", "AtomicInference": "put suitcase in the car"}, "premise": "PersonX packs PersonX's suitcase", "hypothesis": "As a result, PersonX wants put suitcase in the car", "update": "PersonX puts boxes in their car.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10539", "update_paraphrase": "PersonX loads boxes into their car.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22895622895622897, "pred_conf_shift": -0.11787818372249603, "syntactic_distance": 0.0}, {"confidence": [0.7033253312110901, 0.2966747581958771], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10539.gpt3.1", "original_example": {"example_id": "atomic.train.10539", "premise_hypothesis_id": "atomic.train.4961", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "PSANibAMU_ANyt2xZuY-mg==", "AtomicEventRelationId": "P9PRqSrawX4o_4h_2mAaPQ==", "AtomicRelationType": "xWant", "AtomicInference": "put suitcase in the car"}, "premise": "PersonX packs PersonX's suitcase", "hypothesis": "As a result, PersonX wants put suitcase in the car", "update": "PersonX puts boxes in their car.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10539", "update_paraphrase": "Boxes are placed in the car by PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37857142857142856, "pred_conf_shift": -0.04538729786872864, "syntactic_distance": 0.42105263157894735}, {"confidence": [0.775854766368866, 0.2241450846195221], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10539.gpt3.2", "original_example": {"example_id": "atomic.train.10539", "premise_hypothesis_id": "atomic.train.4961", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "PSANibAMU_ANyt2xZuY-mg==", "AtomicEventRelationId": "P9PRqSrawX4o_4h_2mAaPQ==", "AtomicRelationType": "xWant", "AtomicInference": "put suitcase in the car"}, "premise": "PersonX packs PersonX's suitcase", "hypothesis": "As a result, PersonX wants put suitcase in the car", "update": "PersonX puts boxes in their car.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10539", "update_paraphrase": "PersonX loads boxes into their vehicle.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3234006734006734, "pred_conf_shift": -0.11791697144508362, "syntactic_distance": 0.0}, {"confidence": [0.7803092002868652, 0.21969087421894073], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10539.gpt3.3", "original_example": {"example_id": "atomic.train.10539", "premise_hypothesis_id": "atomic.train.4961", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "PSANibAMU_ANyt2xZuY-mg==", "AtomicEventRelationId": "P9PRqSrawX4o_4h_2mAaPQ==", "AtomicRelationType": "xWant", "AtomicInference": "put suitcase in the car"}, "premise": "PersonX packs PersonX's suitcase", "hypothesis": "As a result, PersonX wants put suitcase in the car", "update": "PersonX puts boxes in their car.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10539", "update_paraphrase": "PersonX puts boxes in the car.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0763888888888889, "pred_conf_shift": -0.12237118184566498, "syntactic_distance": 0.0}]}, "atomic.train.5729": {"original_confidence": [0.08381137996912003, 0.9161885976791382], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.7793503403663635, 0.2206496298313141], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5729.gpt3.5", "original_example": {"example_id": "atomic.train.5729", "premise_hypothesis_id": "atomic.train.2701", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gHSg0KIcyICyuO8jGvLCCA==", "AtomicEventRelationId": "buEOHUzFuhW8PKxM9OP8dg==", "AtomicRelationType": "xNeed", "AtomicInference": "To execute the murder plan"}, "premise": "PersonX kills PersonX's mother", "hypothesis": "Before, PersonX needed to execute the murder plan", "update": "PersonX stands there drenched in blood.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5729", "update_paraphrase": "PersonX is covered in blood, standing there motionless.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3965986394557823, "pred_conf_shift": -0.6955389678478241, "syntactic_distance": 0.29411764705882354}, {"confidence": [0.7570968866348267, 0.24290308356285095], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5729.gpt3.0", "original_example": {"example_id": "atomic.train.5729", "premise_hypothesis_id": "atomic.train.2701", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gHSg0KIcyICyuO8jGvLCCA==", "AtomicEventRelationId": "buEOHUzFuhW8PKxM9OP8dg==", "AtomicRelationType": "xNeed", "AtomicInference": "To execute the murder plan"}, "premise": "PersonX kills PersonX's mother", "hypothesis": "Before, PersonX needed to execute the murder plan", "update": "PersonX stands there drenched in blood.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5729", "update_paraphrase": "PersonX is covered in blood and stands there motionless.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39873015873015866, "pred_conf_shift": -0.6732855141162872, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.7354022860527039, 0.26459768414497375], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5729.gpt3.2", "original_example": {"example_id": "atomic.train.5729", "premise_hypothesis_id": "atomic.train.2701", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gHSg0KIcyICyuO8jGvLCCA==", "AtomicEventRelationId": "buEOHUzFuhW8PKxM9OP8dg==", "AtomicRelationType": "xNeed", "AtomicInference": "To execute the murder plan"}, "premise": "PersonX kills PersonX's mother", "hypothesis": "Before, PersonX needed to execute the murder plan", "update": "PersonX stands there drenched in blood.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5729", "update_paraphrase": "PersonX is covered in blood and cannot move.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5267676767676768, "pred_conf_shift": -0.6515909135341644, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.09294487535953522, 0.907055139541626], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.5729.gpt3.4", "original_example": {"example_id": "atomic.train.5729", "premise_hypothesis_id": "atomic.train.2701", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gHSg0KIcyICyuO8jGvLCCA==", "AtomicEventRelationId": "buEOHUzFuhW8PKxM9OP8dg==", "AtomicRelationType": "xNeed", "AtomicInference": "To execute the murder plan"}, "premise": "PersonX kills PersonX's mother", "hypothesis": "Before, PersonX needed to execute the murder plan", "update": "PersonX stands there drenched in blood.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5729", "update_paraphrase": "PersonX is standing there, covered in blood.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22686202686202683, "pred_conf_shift": -0.009133458137512207, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.09741715341806412, 0.9025828838348389], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.5729.gpt3.1", "original_example": {"example_id": "atomic.train.5729", "premise_hypothesis_id": "atomic.train.2701", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gHSg0KIcyICyuO8jGvLCCA==", "AtomicEventRelationId": "buEOHUzFuhW8PKxM9OP8dg==", "AtomicRelationType": "xNeed", "AtomicInference": "To execute the murder plan"}, "premise": "PersonX kills PersonX's mother", "hypothesis": "Before, PersonX needed to execute the murder plan", "update": "PersonX stands there drenched in blood.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5729", "update_paraphrase": "PersonX stands there, covered in blood.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1111111111111111, "pred_conf_shift": -0.013605713844299316, "syntactic_distance": 0.0}, {"confidence": [0.3337986469268799, 0.6662013530731201], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.5729.gpt3.3", "original_example": {"example_id": "atomic.train.5729", "premise_hypothesis_id": "atomic.train.2701", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "gHSg0KIcyICyuO8jGvLCCA==", "AtomicEventRelationId": "buEOHUzFuhW8PKxM9OP8dg==", "AtomicRelationType": "xNeed", "AtomicInference": "To execute the murder plan"}, "premise": "PersonX kills PersonX's mother", "hypothesis": "Before, PersonX needed to execute the murder plan", "update": "PersonX stands there drenched in blood.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5729", "update_paraphrase": "PersonX is covered in blood and is standing there.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45904761904761904, "pred_conf_shift": -0.24998724460601807, "syntactic_distance": 0.3}]}, "atomic.train.34862": {"original_confidence": [0.025752058252692223, 0.9742479920387268], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.035653699189424515, 0.9643462300300598], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34862.gpt3.1", "original_example": {"example_id": "atomic.train.34862", "premise_hypothesis_id": "atomic.train.15808", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "u6168AsNKsfmzzOG1ym4cw==", "AtomicEventRelationId": "VoJ__8zSOVFxm1jUdegbZw==", "AtomicRelationType": "xReact", "AtomicInference": "unburdened"}, "premise": "PersonX confronts PersonY", "hypothesis": "PersonX is seen as unburdened", "update": "PersonY is their best friend", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34862", "update_paraphrase": "PersonY is their closest friend.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.10909090909090907, "pred_conf_shift": 0.009901640936732292, "syntactic_distance": 0.0}, {"confidence": [0.027911147102713585, 0.9720888733863831], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34862.gpt3.0", "original_example": {"example_id": "atomic.train.34862", "premise_hypothesis_id": "atomic.train.15808", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "u6168AsNKsfmzzOG1ym4cw==", "AtomicEventRelationId": "VoJ__8zSOVFxm1jUdegbZw==", "AtomicRelationType": "xReact", "AtomicInference": "unburdened"}, "premise": "PersonX confronts PersonY", "hypothesis": "PersonX is seen as unburdened", "update": "PersonY is their best friend", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34862", "update_paraphrase": "PersonY is the best friend of theirs.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2973484848484848, "pred_conf_shift": 0.0021590888500213623, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.031209124252200127, 0.9687908291816711], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34862.gpt3.3", "original_example": {"example_id": "atomic.train.34862", "premise_hypothesis_id": "atomic.train.15808", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "u6168AsNKsfmzzOG1ym4cw==", "AtomicEventRelationId": "VoJ__8zSOVFxm1jUdegbZw==", "AtomicRelationType": "xReact", "AtomicInference": "unburdened"}, "premise": "PersonX confronts PersonY", "hypothesis": "PersonX is seen as unburdened", "update": "PersonY is their best friend", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34862", "update_paraphrase": "PersonY is their best friend and they love spending time with them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4117647058823529, "pred_conf_shift": 0.005457065999507904, "syntactic_distance": 0.4782608695652174}, {"confidence": [0.08969859778881073, 0.9103014469146729], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.34862.gpt3.2", "original_example": {"example_id": "atomic.train.34862", "premise_hypothesis_id": "atomic.train.15808", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "u6168AsNKsfmzzOG1ym4cw==", "AtomicEventRelationId": "VoJ__8zSOVFxm1jUdegbZw==", "AtomicRelationType": "xReact", "AtomicInference": "unburdened"}, "premise": "PersonX confronts PersonY", "hypothesis": "PersonX is seen as unburdened", "update": "PersonY is their best friend", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.34862", "update_paraphrase": "PersonY is their favorite person to hang out with.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.41229722658294077, "pred_conf_shift": 0.06394653953611851, "syntactic_distance": 0.17647058823529413}]}, "atomic.train.779": {"original_confidence": [0.5096526145935059, 0.4903474748134613], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.25905659794807434, 0.7409433722496033], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.779.gpt3.7", "original_example": {"example_id": "atomic.train.779", "premise_hypothesis_id": "atomic.train.368", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "cUkvijZxQ2DYYM2HtMU9Pg==", "AtomicEventRelationId": "0PMF1NvF3V2FwjwYyTD-6g==", "AtomicRelationType": "xNeed", "AtomicInference": "to prepare the bedroom: put down tarps, etc"}, "premise": "PersonX paints PersonY's bedroom", "hypothesis": "Before, PersonX needed to prepare the bedroom: put down tarps, etc", "update": "PersonX's room has new carpet.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.779", "update_paraphrase": "PersonX got new carpets for their room.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3959554334554334, "pred_conf_shift": 0.25059589743614197, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.7607952356338501, 0.23920460045337677], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.779.gpt3.6", "original_example": {"example_id": "atomic.train.779", "premise_hypothesis_id": "atomic.train.368", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "cUkvijZxQ2DYYM2HtMU9Pg==", "AtomicEventRelationId": "0PMF1NvF3V2FwjwYyTD-6g==", "AtomicRelationType": "xNeed", "AtomicInference": "to prepare the bedroom: put down tarps, etc"}, "premise": "PersonX paints PersonY's bedroom", "hypothesis": "Before, PersonX needed to prepare the bedroom: put down tarps, etc", "update": "PersonX's room has new carpet.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.779", "update_paraphrase": "PersonX's room has been updated with new carpet.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23076923076923073, "pred_conf_shift": -0.25114287436008453, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.812364399433136, 0.18763554096221924], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.779.gpt3.1", "original_example": {"example_id": "atomic.train.779", "premise_hypothesis_id": "atomic.train.368", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "cUkvijZxQ2DYYM2HtMU9Pg==", "AtomicEventRelationId": "0PMF1NvF3V2FwjwYyTD-6g==", "AtomicRelationType": "xNeed", "AtomicInference": "to prepare the bedroom: put down tarps, etc"}, "premise": "PersonX paints PersonY's bedroom", "hypothesis": "Before, PersonX needed to prepare the bedroom: put down tarps, etc", "update": "PersonX's room has new carpet.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.779", "update_paraphrase": "PersonX's room has been outfitted with new carpet.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23076923076923073, "pred_conf_shift": -0.30271193385124207, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.5091754198074341, 0.4908245801925659], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.779.gpt3.3", "original_example": {"example_id": "atomic.train.779", "premise_hypothesis_id": "atomic.train.368", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "cUkvijZxQ2DYYM2HtMU9Pg==", "AtomicEventRelationId": "0PMF1NvF3V2FwjwYyTD-6g==", "AtomicRelationType": "xNeed", "AtomicInference": "to prepare the bedroom: put down tarps, etc"}, "premise": "PersonX paints PersonY's bedroom", "hypothesis": "Before, PersonX needed to prepare the bedroom: put down tarps, etc", "update": "PersonX's room has new carpet.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.779", "update_paraphrase": "They put in new carpet in PersonX's room.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4945054945054945, "pred_conf_shift": 0.00047710537910461426, "syntactic_distance": 0.36363636363636365}, {"confidence": [0.30728235840797424, 0.6927175521850586], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.779.gpt3.2", "original_example": {"example_id": "atomic.train.779", "premise_hypothesis_id": "atomic.train.368", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "cUkvijZxQ2DYYM2HtMU9Pg==", "AtomicEventRelationId": "0PMF1NvF3V2FwjwYyTD-6g==", "AtomicRelationType": "xNeed", "AtomicInference": "to prepare the bedroom: put down tarps, etc"}, "premise": "PersonX paints PersonY's bedroom", "hypothesis": "Before, PersonX needed to prepare the bedroom: put down tarps, etc", "update": "PersonX's room has new carpet.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.779", "update_paraphrase": "There is new carpet in personX's room.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4076923076923077, "pred_conf_shift": 0.2023700773715973, "syntactic_distance": 0.25}, {"confidence": [0.48923540115356445, 0.5107646584510803], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.779.gpt3.0", "original_example": {"example_id": "atomic.train.779", "premise_hypothesis_id": "atomic.train.368", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "cUkvijZxQ2DYYM2HtMU9Pg==", "AtomicEventRelationId": "0PMF1NvF3V2FwjwYyTD-6g==", "AtomicRelationType": "xNeed", "AtomicInference": "to prepare the bedroom: put down tarps, etc"}, "premise": "PersonX paints PersonY's bedroom", "hypothesis": "Before, PersonX needed to prepare the bedroom: put down tarps, etc", "update": "PersonX's room has new carpet.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.779", "update_paraphrase": "The carpet in PersonX's room is new.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.35, "pred_conf_shift": 0.02041718363761902, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.8094908595085144, 0.19050909578800201], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.779.gpt3.5", "original_example": {"example_id": "atomic.train.779", "premise_hypothesis_id": "atomic.train.368", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "cUkvijZxQ2DYYM2HtMU9Pg==", "AtomicEventRelationId": "0PMF1NvF3V2FwjwYyTD-6g==", "AtomicRelationType": "xNeed", "AtomicInference": "to prepare the bedroom: put down tarps, etc"}, "premise": "PersonX paints PersonY's bedroom", "hypothesis": "Before, PersonX needed to prepare the bedroom: put down tarps, etc", "update": "PersonX's room has new carpet.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.779", "update_paraphrase": "PersonX's room has been updated with new carpeting.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3625246548323472, "pred_conf_shift": -0.2998383790254593, "syntactic_distance": 0.16666666666666666}]}, "atomic.train.36464": {"original_confidence": [0.3243524432182312, 0.675647497177124], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.386122465133667, 0.6138774156570435], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.36464.gpt3.1", "original_example": {"example_id": "atomic.train.36464", "premise_hypothesis_id": "atomic.train.16541", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZWGaOfXodp_n-cr0hlxMlw==", "AtomicEventRelationId": "QdhyfCD8e7STzLnqY5vqJQ==", "AtomicRelationType": "xNeed", "AtomicInference": "turns on light"}, "premise": "PersonX loses power", "hypothesis": "Before, PersonX needed turns on light", "update": "PersonX's TV just went off.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36464", "update_paraphrase": "PersonX's television just turned off.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3130952380952381, "pred_conf_shift": 0.06177002191543579, "syntactic_distance": 0.0}, {"confidence": [0.8989644646644592, 0.10103548318147659], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.36464.gpt3.3", "original_example": {"example_id": "atomic.train.36464", "premise_hypothesis_id": "atomic.train.16541", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZWGaOfXodp_n-cr0hlxMlw==", "AtomicEventRelationId": "QdhyfCD8e7STzLnqY5vqJQ==", "AtomicRelationType": "xNeed", "AtomicInference": "turns on light"}, "premise": "PersonX loses power", "hypothesis": "Before, PersonX needed turns on light", "update": "PersonX's TV just went off.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36464", "update_paraphrase": "The TV just turned off on its own.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.43436563436563436, "pred_conf_shift": 0.574612021446228, "syntactic_distance": 0.17391304347826086}, {"confidence": [0.3813568353652954, 0.6186431050300598], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.36464.gpt3.4", "original_example": {"example_id": "atomic.train.36464", "premise_hypothesis_id": "atomic.train.16541", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZWGaOfXodp_n-cr0hlxMlw==", "AtomicEventRelationId": "QdhyfCD8e7STzLnqY5vqJQ==", "AtomicRelationType": "xNeed", "AtomicInference": "turns on light"}, "premise": "PersonX loses power", "hypothesis": "Before, PersonX needed turns on light", "update": "PersonX's TV just went off.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36464", "update_paraphrase": "PersonX's TV just turned off.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.14666666666666667, "pred_conf_shift": 0.05700439214706421, "syntactic_distance": 0.0}]}, "atomic.train.38431": {"original_confidence": [0.2129092961549759, 0.7870907187461853], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.150804802775383, 0.849195122718811], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38431.gpt3.6", "original_example": {"example_id": "atomic.train.38431", "premise_hypothesis_id": "atomic.train.17440", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "u73xiPdJHte7z55lsqpJdg==", "AtomicEventRelationId": "7tGeCXcLLAaCxWJs2UMr3w==", "AtomicRelationType": "xEffect", "AtomicInference": "grabs lotion"}, "premise": "PersonX rubs the back of PersonY's neck", "hypothesis": "PersonX then grabs lotion", "update": "PersonY is at a spa", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38431", "update_paraphrase": "PersonY is enjoying some time at a spa.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23076923076923073, "pred_conf_shift": 0.06210440397262573, "syntactic_distance": 0.125}, {"confidence": [0.2146710306406021, 0.7853290438652039], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38431.gpt3.1", "original_example": {"example_id": "atomic.train.38431", "premise_hypothesis_id": "atomic.train.17440", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "u73xiPdJHte7z55lsqpJdg==", "AtomicEventRelationId": "7tGeCXcLLAaCxWJs2UMr3w==", "AtomicRelationType": "xEffect", "AtomicInference": "grabs lotion"}, "premise": "PersonX rubs the back of PersonY's neck", "hypothesis": "PersonX then grabs lotion", "update": "PersonY is at a spa", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38431", "update_paraphrase": "PersonY is relaxing at a spa.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.09090909090909094, "pred_conf_shift": -0.0017616748809814453, "syntactic_distance": 0.1875}, {"confidence": [0.376896470785141, 0.6231035590171814], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38431.gpt3.7", "original_example": {"example_id": "atomic.train.38431", "premise_hypothesis_id": "atomic.train.17440", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "u73xiPdJHte7z55lsqpJdg==", "AtomicEventRelationId": "7tGeCXcLLAaCxWJs2UMr3w==", "AtomicRelationType": "xEffect", "AtomicInference": "grabs lotion"}, "premise": "PersonX rubs the back of PersonY's neck", "hypothesis": "PersonX then grabs lotion", "update": "PersonY is at a spa", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38431", "update_paraphrase": "At the moment, PersonY is enjoying a relaxing day at the spa.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45098039215686275, "pred_conf_shift": -0.1639871597290039, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.238042950630188, 0.7619569897651672], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38431.gpt3.5", "original_example": {"example_id": "atomic.train.38431", "premise_hypothesis_id": "atomic.train.17440", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "u73xiPdJHte7z55lsqpJdg==", "AtomicEventRelationId": "7tGeCXcLLAaCxWJs2UMr3w==", "AtomicRelationType": "xEffect", "AtomicInference": "grabs lotion"}, "premise": "PersonX rubs the back of PersonY's neck", "hypothesis": "PersonX then grabs lotion", "update": "PersonY is at a spa", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38431", "update_paraphrase": "PersonY is relax and enjoying some time at a spa.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33333333333333337, "pred_conf_shift": -0.025133728981018066, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.3661898970603943, 0.6338101029396057], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38431.gpt3.3", "original_example": {"example_id": "atomic.train.38431", "premise_hypothesis_id": "atomic.train.17440", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "u73xiPdJHte7z55lsqpJdg==", "AtomicEventRelationId": "7tGeCXcLLAaCxWJs2UMr3w==", "AtomicRelationType": "xEffect", "AtomicInference": "grabs lotion"}, "premise": "PersonX rubs the back of PersonY's neck", "hypothesis": "PersonX then grabs lotion", "update": "PersonY is at a spa", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38431", "update_paraphrase": "PersonY is unwinding at a spa.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.09090909090909094, "pred_conf_shift": -0.1532806158065796, "syntactic_distance": 0.1875}, {"confidence": [0.38462144136428833, 0.6153784394264221], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38431.gpt3.4", "original_example": {"example_id": "atomic.train.38431", "premise_hypothesis_id": "atomic.train.17440", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "u73xiPdJHte7z55lsqpJdg==", "AtomicEventRelationId": "7tGeCXcLLAaCxWJs2UMr3w==", "AtomicRelationType": "xEffect", "AtomicInference": "grabs lotion"}, "premise": "PersonX rubs the back of PersonY's neck", "hypothesis": "PersonX then grabs lotion", "update": "PersonY is at a spa", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38431", "update_paraphrase": "PersonY is at a relaxation retreat.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2224598930481283, "pred_conf_shift": -0.17171227931976318, "syntactic_distance": 0.0}, {"confidence": [0.1254565417766571, 0.8745435476303101], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38431.gpt3.2", "original_example": {"example_id": "atomic.train.38431", "premise_hypothesis_id": "atomic.train.17440", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "u73xiPdJHte7z55lsqpJdg==", "AtomicEventRelationId": "7tGeCXcLLAaCxWJs2UMr3w==", "AtomicRelationType": "xEffect", "AtomicInference": "grabs lotion"}, "premise": "PersonX rubs the back of PersonY's neck", "hypothesis": "PersonX then grabs lotion", "update": "PersonY is at a spa", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38431", "update_paraphrase": "PersonY is pampering themselves at a spa.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.16666666666666663, "pred_conf_shift": 0.08745282888412476, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.05931800231337547, 0.9406821131706238], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.38431.gpt3.0", "original_example": {"example_id": "atomic.train.38431", "premise_hypothesis_id": "atomic.train.17440", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "u73xiPdJHte7z55lsqpJdg==", "AtomicEventRelationId": "7tGeCXcLLAaCxWJs2UMr3w==", "AtomicRelationType": "xEffect", "AtomicInference": "grabs lotion"}, "premise": "PersonX rubs the back of PersonY's neck", "hypothesis": "PersonX then grabs lotion", "update": "PersonY is at a spa", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.38431", "update_paraphrase": "At the spa, PersonY is getting pampered.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.43265993265993263, "pred_conf_shift": 0.15359139442443848, "syntactic_distance": 0.35}]}, "atomic.train.24956": {"original_confidence": [0.5097276568412781, 0.49027231335639954], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.9403921365737915, 0.05960783734917641], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.24956.gpt3.6", "original_example": {"example_id": "atomic.train.24956", "premise_hypothesis_id": "atomic.train.11417", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7qy3XQ51NA3u2aRXLqpocg==", "AtomicEventRelationId": "3T9p4E0XWVRRFyCf99iD9g==", "AtomicRelationType": "xWant", "AtomicInference": "to meet the doctor"}, "premise": "PersonX has to take PersonY to the doctor", "hypothesis": "As a result, PersonX wants to meet the doctor", "update": "They have an emergency", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24956", "update_paraphrase": "They're in the midst of an emergency.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.38701298701298703, "pred_conf_shift": 0.4306644797325134, "syntactic_distance": 0.1875}, {"confidence": [0.8803824782371521, 0.1196175217628479], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.24956.gpt3.4", "original_example": {"example_id": "atomic.train.24956", "premise_hypothesis_id": "atomic.train.11417", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7qy3XQ51NA3u2aRXLqpocg==", "AtomicEventRelationId": "3T9p4E0XWVRRFyCf99iD9g==", "AtomicRelationType": "xWant", "AtomicInference": "to meet the doctor"}, "premise": "PersonX has to take PersonY to the doctor", "hypothesis": "As a result, PersonX wants to meet the doctor", "update": "They have an emergency", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24956", "update_paraphrase": "They are facing an emergency situation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3857142857142858, "pred_conf_shift": 0.370654821395874, "syntactic_distance": 0.1875}, {"confidence": [0.9386354088783264, 0.06136459857225418], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.24956.gpt3.1", "original_example": {"example_id": "atomic.train.24956", "premise_hypothesis_id": "atomic.train.11417", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7qy3XQ51NA3u2aRXLqpocg==", "AtomicEventRelationId": "3T9p4E0XWVRRFyCf99iD9g==", "AtomicRelationType": "xWant", "AtomicInference": "to meet the doctor"}, "premise": "PersonX has to take PersonY to the doctor", "hypothesis": "As a result, PersonX wants to meet the doctor", "update": "They have an emergency", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24956", "update_paraphrase": "They are in the midst of an emergency.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.38095238095238093, "pred_conf_shift": 0.42890775203704834, "syntactic_distance": 0.1875}, {"confidence": [0.289010226726532, 0.7109898328781128], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.24956.gpt3.2", "original_example": {"example_id": "atomic.train.24956", "premise_hypothesis_id": "atomic.train.11417", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7qy3XQ51NA3u2aRXLqpocg==", "AtomicEventRelationId": "3T9p4E0XWVRRFyCf99iD9g==", "AtomicRelationType": "xWant", "AtomicInference": "to meet the doctor"}, "premise": "PersonX has to take PersonY to the doctor", "hypothesis": "As a result, PersonX wants to meet the doctor", "update": "They have an emergency", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24956", "update_paraphrase": "They have a crisis.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.35833333333333334, "pred_conf_shift": -0.2207174301147461, "syntactic_distance": 0.0}, {"confidence": [0.8331993222236633, 0.16680067777633667], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.24956.gpt3.3", "original_example": {"example_id": "atomic.train.24956", "premise_hypothesis_id": "atomic.train.11417", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7qy3XQ51NA3u2aRXLqpocg==", "AtomicEventRelationId": "3T9p4E0XWVRRFyCf99iD9g==", "AtomicRelationType": "xWant", "AtomicInference": "to meet the doctor"}, "premise": "PersonX has to take PersonY to the doctor", "hypothesis": "As a result, PersonX wants to meet the doctor", "update": "They have an emergency", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24956", "update_paraphrase": "There is an emergency situation.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39031339031339024, "pred_conf_shift": 0.32347166538238525, "syntactic_distance": 0.17647058823529413}]}, "atomic.train.2846": {"original_confidence": [0.40818652510643005, 0.5918134450912476], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.8513504862785339, 0.14864949882030487], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2846.gpt3.0", "original_example": {"example_id": "atomic.train.2846", "premise_hypothesis_id": "atomic.train.1342", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "fZDFSb47GCrvL0AABs93hw==", "AtomicEventRelationId": "mO8KYP1wxhL_BEoMmrNeKQ==", "AtomicRelationType": "xEffect", "AtomicInference": "gets stronger"}, "premise": "PersonX gains muscle", "hypothesis": "PersonX then gets stronger", "update": "PersonX is building a model of human anatomy.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2846", "update_paraphrase": "PersonX is constructing a replica of the human body.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3629233511586452, "pred_conf_shift": 0.4431639611721039, "syntactic_distance": 0.0}, {"confidence": [0.43784260749816895, 0.5621573328971863], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2846.gpt3.4", "original_example": {"example_id": "atomic.train.2846", "premise_hypothesis_id": "atomic.train.1342", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "fZDFSb47GCrvL0AABs93hw==", "AtomicEventRelationId": "mO8KYP1wxhL_BEoMmrNeKQ==", "AtomicRelationType": "xEffect", "AtomicInference": "gets stronger"}, "premise": "PersonX gains muscle", "hypothesis": "PersonX then gets stronger", "update": "PersonX is building a model of human anatomy.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2846", "update_paraphrase": "A model of human anatomy is being created by PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.29914529914529914, "pred_conf_shift": 0.02965608239173889, "syntactic_distance": 0.2857142857142857}, {"confidence": [0.5572344064712524, 0.44276556372642517], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2846.gpt3.2", "original_example": {"example_id": "atomic.train.2846", "premise_hypothesis_id": "atomic.train.1342", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "fZDFSb47GCrvL0AABs93hw==", "AtomicEventRelationId": "mO8KYP1wxhL_BEoMmrNeKQ==", "AtomicRelationType": "xEffect", "AtomicInference": "gets stronger"}, "premise": "PersonX gains muscle", "hypothesis": "PersonX then gets stronger", "update": "PersonX is building a model of human anatomy.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2846", "update_paraphrase": "PersonX is creating a model of the human body.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28743315508021394, "pred_conf_shift": 0.1490478813648224, "syntactic_distance": 0.0}, {"confidence": [0.6754299998283386, 0.32457002997398376], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2846.gpt3.5", "original_example": {"example_id": "atomic.train.2846", "premise_hypothesis_id": "atomic.train.1342", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "fZDFSb47GCrvL0AABs93hw==", "AtomicEventRelationId": "mO8KYP1wxhL_BEoMmrNeKQ==", "AtomicRelationType": "xEffect", "AtomicInference": "gets stronger"}, "premise": "PersonX gains muscle", "hypothesis": "PersonX then gets stronger", "update": "PersonX is building a model of human anatomy.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2846", "update_paraphrase": "PersonX is constructing a model of the human body.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2844919786096256, "pred_conf_shift": 0.26724347472190857, "syntactic_distance": 0.0}, {"confidence": [0.7960761189460754, 0.20392391085624695], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2846.gpt3.3", "original_example": {"example_id": "atomic.train.2846", "premise_hypothesis_id": "atomic.train.1342", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "fZDFSb47GCrvL0AABs93hw==", "AtomicEventRelationId": "mO8KYP1wxhL_BEoMmrNeKQ==", "AtomicRelationType": "xEffect", "AtomicInference": "gets stronger"}, "premise": "PersonX gains muscle", "hypothesis": "PersonX then gets stronger", "update": "PersonX is building a model of human anatomy.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2846", "update_paraphrase": "PersonX is constructing a replica of human anatomy.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.24166666666666664, "pred_conf_shift": 0.3878895938396454, "syntactic_distance": 0.0}, {"confidence": [0.3788757026195526, 0.6211243867874146], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2846.gpt3.1", "original_example": {"example_id": "atomic.train.2846", "premise_hypothesis_id": "atomic.train.1342", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "fZDFSb47GCrvL0AABs93hw==", "AtomicEventRelationId": "mO8KYP1wxhL_BEoMmrNeKQ==", "AtomicRelationType": "xEffect", "AtomicInference": "gets stronger"}, "premise": "PersonX gains muscle", "hypothesis": "PersonX then gets stronger", "update": "PersonX is building a model of human anatomy.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2846", "update_paraphrase": "PersonX is in the process of creating a model of human anatomy.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.25857142857142856, "pred_conf_shift": -0.02931082248687744, "syntactic_distance": 0.125}]}, "atomic.train.9189": {"original_confidence": [0.06216182932257652, 0.9378382563591003], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.5785015821456909, 0.42149850726127625], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9189.gpt3.0", "original_example": {"example_id": "atomic.train.9189", "premise_hypothesis_id": "atomic.train.4332", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "G254W8ZN8LrmBlwM8fBh0g==", "AtomicEventRelationId": "qzFctlBVlG0illHcj0iRCg==", "AtomicRelationType": "xWant", "AtomicInference": "to impart knowledge"}, "premise": "PersonX furthers PersonY's understanding", "hypothesis": "As a result, PersonX wants to impart knowledge", "update": "PersonX works in a college library.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9189", "update_paraphrase": "PersonX's job is to work in a college library.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22370370370370374, "pred_conf_shift": -0.5163397490978241, "syntactic_distance": 0.25}, {"confidence": [0.7134270668029785, 0.28657296299934387], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.9189.gpt3.1", "original_example": {"example_id": "atomic.train.9189", "premise_hypothesis_id": "atomic.train.4332", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "G254W8ZN8LrmBlwM8fBh0g==", "AtomicEventRelationId": "qzFctlBVlG0illHcj0iRCg==", "AtomicRelationType": "xWant", "AtomicInference": "to impart knowledge"}, "premise": "PersonX furthers PersonY's understanding", "hypothesis": "As a result, PersonX wants to impart knowledge", "update": "PersonX works in a college library.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9189", "update_paraphrase": "PersonX has a job working in a college library.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2698412698412698, "pred_conf_shift": -0.6512652933597565, "syntactic_distance": 0.1875}, {"confidence": [0.27337488532066345, 0.7266250252723694], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9189.gpt3.3", "original_example": {"example_id": "atomic.train.9189", "premise_hypothesis_id": "atomic.train.4332", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "G254W8ZN8LrmBlwM8fBh0g==", "AtomicEventRelationId": "qzFctlBVlG0illHcj0iRCg==", "AtomicRelationType": "xWant", "AtomicInference": "to impart knowledge"}, "premise": "PersonX furthers PersonY's understanding", "hypothesis": "As a result, PersonX wants to impart knowledge", "update": "PersonX works in a college library.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9189", "update_paraphrase": "PersonX is an employee at a college library.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3455869527298098, "pred_conf_shift": -0.21121323108673096, "syntactic_distance": 0.1875}, {"confidence": [0.06539127230644226, 0.9346087574958801], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9189.gpt3.2", "original_example": {"example_id": "atomic.train.9189", "premise_hypothesis_id": "atomic.train.4332", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "G254W8ZN8LrmBlwM8fBh0g==", "AtomicEventRelationId": "qzFctlBVlG0illHcj0iRCg==", "AtomicRelationType": "xWant", "AtomicInference": "to impart knowledge"}, "premise": "PersonX furthers PersonY's understanding", "hypothesis": "As a result, PersonX wants to impart knowledge", "update": "PersonX works in a college library.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9189", "update_paraphrase": "PersonX is employed at a college level library.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4175824175824176, "pred_conf_shift": -0.003229498863220215, "syntactic_distance": 0.1875}, {"confidence": [0.12180989980697632, 0.8781901001930237], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.9189.gpt3.4", "original_example": {"example_id": "atomic.train.9189", "premise_hypothesis_id": "atomic.train.4332", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "G254W8ZN8LrmBlwM8fBh0g==", "AtomicEventRelationId": "qzFctlBVlG0illHcj0iRCg==", "AtomicRelationType": "xWant", "AtomicInference": "to impart knowledge"}, "premise": "PersonX furthers PersonY's understanding", "hypothesis": "As a result, PersonX wants to impart knowledge", "update": "PersonX works in a college library.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.9189", "update_paraphrase": "PersonX is employed at a college library.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.30539119000657466, "pred_conf_shift": -0.05964815616607666, "syntactic_distance": 0.1875}]}, "atomic.train.14094": {"original_confidence": [0.05141362175345421, 0.9485864043235779], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.09409431368112564, 0.9059057235717773], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.14094.gpt3.4", "original_example": {"example_id": "atomic.train.14094", "premise_hypothesis_id": "atomic.train.6581", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "KHZLPog2OCOlagmrbXj-6Q==", "AtomicEventRelationId": "CQ-Wayoe7JPSyKJHVE759Q==", "AtomicRelationType": "xWant", "AtomicInference": "to start a new life"}, "premise": "PersonX sells oneself", "hypothesis": "As a result, PersonX wants to start a new life", "update": "They are really poor", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14094", "update_paraphrase": "They are really struggling financially.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3015873015873016, "pred_conf_shift": 0.04268069192767143, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.10761286318302155, 0.8923871517181396], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.14094.gpt3.2", "original_example": {"example_id": "atomic.train.14094", "premise_hypothesis_id": "atomic.train.6581", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "KHZLPog2OCOlagmrbXj-6Q==", "AtomicEventRelationId": "CQ-Wayoe7JPSyKJHVE759Q==", "AtomicRelationType": "xWant", "AtomicInference": "to start a new life"}, "premise": "PersonX sells oneself", "hypothesis": "As a result, PersonX wants to start a new life", "update": "They are really poor", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14094", "update_paraphrase": "They are extremely poor.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.13333333333333336, "pred_conf_shift": 0.05619924142956734, "syntactic_distance": 0.0}, {"confidence": [0.6204544901847839, 0.3795454800128937], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.14094.gpt3.1", "original_example": {"example_id": "atomic.train.14094", "premise_hypothesis_id": "atomic.train.6581", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "KHZLPog2OCOlagmrbXj-6Q==", "AtomicEventRelationId": "CQ-Wayoe7JPSyKJHVE759Q==", "AtomicRelationType": "xWant", "AtomicInference": "to start a new life"}, "premise": "PersonX sells oneself", "hypothesis": "As a result, PersonX wants to start a new life", "update": "They are really poor", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14094", "update_paraphrase": "They do not have much money.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5510822510822511, "pred_conf_shift": 0.5690408684313297, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.08196486532688141, 0.9180352091789246], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.14094.gpt3.3", "original_example": {"example_id": "atomic.train.14094", "premise_hypothesis_id": "atomic.train.6581", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "KHZLPog2OCOlagmrbXj-6Q==", "AtomicEventRelationId": "CQ-Wayoe7JPSyKJHVE759Q==", "AtomicRelationType": "xWant", "AtomicInference": "to start a new life"}, "premise": "PersonX sells oneself", "hypothesis": "As a result, PersonX wants to start a new life", "update": "They are really poor", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14094", "update_paraphrase": "They are very poor.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.15000000000000002, "pred_conf_shift": 0.0305512435734272, "syntactic_distance": 0.0}, {"confidence": [0.39423704147338867, 0.6057628989219666], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.14094.gpt3.0", "original_example": {"example_id": "atomic.train.14094", "premise_hypothesis_id": "atomic.train.6581", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "KHZLPog2OCOlagmrbXj-6Q==", "AtomicEventRelationId": "CQ-Wayoe7JPSyKJHVE759Q==", "AtomicRelationType": "xWant", "AtomicInference": "to start a new life"}, "premise": "PersonX sells oneself", "hypothesis": "As a result, PersonX wants to start a new life", "update": "They are really poor", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.14094", "update_paraphrase": "They don't have a lot of money.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5789059425423062, "pred_conf_shift": 0.34282341971993446, "syntactic_distance": 0.3333333333333333}]}, "atomic.train.2881": {"original_confidence": [0.3648364841938019, 0.6351635456085205], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.35992276668548584, 0.6400771737098694], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2881.gpt3.7", "original_example": {"example_id": "atomic.train.2881", "premise_hypothesis_id": "atomic.train.1356", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "NMNaV6wTblhFvNr3hgM7Cg==", "AtomicEventRelationId": "Gr7h_gs696KgRbBmj8wt3A==", "AtomicRelationType": "xReact", "AtomicInference": "completed"}, "premise": "PersonX uses PersonX's eyes", "hypothesis": "PersonX is seen as completed", "update": "PersonX was blind before now.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2881", "update_paraphrase": "Previously, PersonX was without vision.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4797474747474747, "pred_conf_shift": 0.004913628101348877, "syntactic_distance": 0.25}, {"confidence": [0.690555214881897, 0.30944475531578064], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2881.gpt3.0", "original_example": {"example_id": "atomic.train.2881", "premise_hypothesis_id": "atomic.train.1356", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "NMNaV6wTblhFvNr3hgM7Cg==", "AtomicEventRelationId": "Gr7h_gs696KgRbBmj8wt3A==", "AtomicRelationType": "xReact", "AtomicInference": "completed"}, "premise": "PersonX uses PersonX's eyes", "hypothesis": "PersonX is seen as completed", "update": "PersonX was blind before now.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2881", "update_paraphrase": "PersonX was not blind before this point.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.34444444444444444, "pred_conf_shift": -0.32571879029273987, "syntactic_distance": 0.09523809523809523}, {"confidence": [0.1831129938364029, 0.8168870806694031], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2881.gpt3.2", "original_example": {"example_id": "atomic.train.2881", "premise_hypothesis_id": "atomic.train.1356", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "NMNaV6wTblhFvNr3hgM7Cg==", "AtomicEventRelationId": "Gr7h_gs696KgRbBmj8wt3A==", "AtomicRelationType": "xReact", "AtomicInference": "completed"}, "premise": "PersonX uses PersonX's eyes", "hypothesis": "PersonX is seen as completed", "update": "PersonX was blind before now.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2881", "update_paraphrase": "PersonX used to be blind, but now they can see.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5624338624338624, "pred_conf_shift": 0.18172353506088257, "syntactic_distance": 0.5384615384615384}, {"confidence": [0.2534514367580414, 0.7465484738349915], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2881.gpt3.3", "original_example": {"example_id": "atomic.train.2881", "premise_hypothesis_id": "atomic.train.1356", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "NMNaV6wTblhFvNr3hgM7Cg==", "AtomicEventRelationId": "Gr7h_gs696KgRbBmj8wt3A==", "AtomicRelationType": "xReact", "AtomicInference": "completed"}, "premise": "PersonX uses PersonX's eyes", "hypothesis": "PersonX is seen as completed", "update": "PersonX was blind before now.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2881", "update_paraphrase": "PersonX was not able to see before, but now they can.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5415331196581197, "pred_conf_shift": 0.11138492822647095, "syntactic_distance": 0.48}, {"confidence": [0.7421573400497437, 0.25784263014793396], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2881.gpt3.5", "original_example": {"example_id": "atomic.train.2881", "premise_hypothesis_id": "atomic.train.1356", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "NMNaV6wTblhFvNr3hgM7Cg==", "AtomicEventRelationId": "Gr7h_gs696KgRbBmj8wt3A==", "AtomicRelationType": "xReact", "AtomicInference": "completed"}, "premise": "PersonX uses PersonX's eyes", "hypothesis": "PersonX is seen as completed", "update": "PersonX was blind before now.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2881", "update_paraphrase": "PersonX is now blind but wasn't before.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.30787037037037035, "pred_conf_shift": -0.37732091546058655, "syntactic_distance": 0.34782608695652173}, {"confidence": [0.2984603941440582, 0.7015396356582642], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2881.gpt3.1", "original_example": {"example_id": "atomic.train.2881", "premise_hypothesis_id": "atomic.train.1356", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "NMNaV6wTblhFvNr3hgM7Cg==", "AtomicEventRelationId": "Gr7h_gs696KgRbBmj8wt3A==", "AtomicRelationType": "xReact", "AtomicInference": "completed"}, "premise": "PersonX uses PersonX's eyes", "hypothesis": "PersonX is seen as completed", "update": "PersonX was blind before now.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2881", "update_paraphrase": "PersonX was not able to see before, but they can see now.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5243841126194068, "pred_conf_shift": 0.06637609004974365, "syntactic_distance": 0.52}, {"confidence": [0.2781303822994232, 0.7218695878982544], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2881.gpt3.4", "original_example": {"example_id": "atomic.train.2881", "premise_hypothesis_id": "atomic.train.1356", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "NMNaV6wTblhFvNr3hgM7Cg==", "AtomicEventRelationId": "Gr7h_gs696KgRbBmj8wt3A==", "AtomicRelationType": "xReact", "AtomicInference": "completed"}, "premise": "PersonX uses PersonX's eyes", "hypothesis": "PersonX is seen as completed", "update": "PersonX was blind before now.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2881", "update_paraphrase": "PersonX was unable to see before, but they can see now.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.49970862470862476, "pred_conf_shift": 0.08670604228973389, "syntactic_distance": 0.5}]}, "atomic.train.25178": {"original_confidence": [0.07147984951734543, 0.928520143032074], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.07629983872175217, 0.9237001538276672], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25178.gpt3.3", "original_example": {"example_id": "atomic.train.25178", "premise_hypothesis_id": "atomic.train.11513", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7zW3GWOzcYieILtCbrpSsQ==", "AtomicEventRelationId": "jiBs01APCUKNkQuDwHDpjw==", "AtomicRelationType": "xReact", "AtomicInference": "crude"}, "premise": "PersonX drops the f-bomb", "hypothesis": "PersonX is seen as crude", "update": "They are surrounded by men in a bar", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25178", "update_paraphrase": "The men surround them in the bar.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37037037037037035, "pred_conf_shift": 0.004819989204406738, "syntactic_distance": 0.4}, {"confidence": [0.1299515813589096, 0.8700485229492188], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25178.gpt3.4", "original_example": {"example_id": "atomic.train.25178", "premise_hypothesis_id": "atomic.train.11513", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7zW3GWOzcYieILtCbrpSsQ==", "AtomicEventRelationId": "jiBs01APCUKNkQuDwHDpjw==", "AtomicRelationType": "xReact", "AtomicInference": "crude"}, "premise": "PersonX drops the f-bomb", "hypothesis": "PersonX is seen as crude", "update": "They are surrounded by men in a bar", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25178", "update_paraphrase": "They are're surrounded by men in a bar", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.06026785714285715, "pred_conf_shift": 0.05847173184156418, "syntactic_distance": 0.0}, {"confidence": [0.08917301893234253, 0.9108270406723022], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25178.gpt3.2", "original_example": {"example_id": "atomic.train.25178", "premise_hypothesis_id": "atomic.train.11513", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7zW3GWOzcYieILtCbrpSsQ==", "AtomicEventRelationId": "jiBs01APCUKNkQuDwHDpjw==", "AtomicRelationType": "xReact", "AtomicInference": "crude"}, "premise": "PersonX drops the f-bomb", "hypothesis": "PersonX is seen as crude", "update": "They are surrounded by men in a bar", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25178", "update_paraphrase": "There are men surrounding them in a bar.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23586309523809523, "pred_conf_shift": 0.0176931694149971, "syntactic_distance": 0.29411764705882354}, {"confidence": [0.14678791165351868, 0.8532121181488037], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25178.gpt3.5", "original_example": {"example_id": "atomic.train.25178", "premise_hypothesis_id": "atomic.train.11513", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7zW3GWOzcYieILtCbrpSsQ==", "AtomicEventRelationId": "jiBs01APCUKNkQuDwHDpjw==", "AtomicRelationType": "xReact", "AtomicInference": "crude"}, "premise": "PersonX drops the f-bomb", "hypothesis": "PersonX is seen as crude", "update": "They are surrounded by men in a bar", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25178", "update_paraphrase": "There are men all around them in the bar.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3735994397759103, "pred_conf_shift": 0.07530806213617325, "syntactic_distance": 0.391304347826087}, {"confidence": [0.07455828040838242, 0.9254417419433594], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25178.gpt3.1", "original_example": {"example_id": "atomic.train.25178", "premise_hypothesis_id": "atomic.train.11513", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7zW3GWOzcYieILtCbrpSsQ==", "AtomicEventRelationId": "jiBs01APCUKNkQuDwHDpjw==", "AtomicRelationType": "xReact", "AtomicInference": "crude"}, "premise": "PersonX drops the f-bomb", "hypothesis": "PersonX is seen as crude", "update": "They are surrounded by men in a bar", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25178", "update_paraphrase": "They are standing in a bar, surrounded by men.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.18627450980392152, "pred_conf_shift": 0.0030784308910369873, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.07918696850538254, 0.9208130836486816], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25178.gpt3.6", "original_example": {"example_id": "atomic.train.25178", "premise_hypothesis_id": "atomic.train.11513", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7zW3GWOzcYieILtCbrpSsQ==", "AtomicEventRelationId": "jiBs01APCUKNkQuDwHDpjw==", "AtomicRelationType": "xReact", "AtomicInference": "crude"}, "premise": "PersonX drops the f-bomb", "hypothesis": "PersonX is seen as crude", "update": "They are surrounded by men in a bar", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25178", "update_paraphrase": "There are a lot of men surrounding them in the bar.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39724310776942356, "pred_conf_shift": 0.007707118988037109, "syntactic_distance": 0.35}, {"confidence": [0.08390922844409943, 0.9160906672477722], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25178.gpt3.0", "original_example": {"example_id": "atomic.train.25178", "premise_hypothesis_id": "atomic.train.11513", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7zW3GWOzcYieILtCbrpSsQ==", "AtomicEventRelationId": "jiBs01APCUKNkQuDwHDpjw==", "AtomicRelationType": "xReact", "AtomicInference": "crude"}, "premise": "PersonX drops the f-bomb", "hypothesis": "PersonX is seen as crude", "update": "They are surrounded by men in a bar", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25178", "update_paraphrase": "There are lots of men around them in the bar.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42691798941798936, "pred_conf_shift": 0.012429378926753998, "syntactic_distance": 0.391304347826087}]}, "atomic.train.15221": {"original_confidence": [0.8695709705352783, 0.1304289698600769], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.6410998106002808, 0.358900249004364], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15221.gpt3.1", "original_example": {"example_id": "atomic.train.15221", "premise_hypothesis_id": "atomic.train.7100", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "3QeM56CVpqTpdO053vKx7A==", "AtomicEventRelationId": "AJXTIW7mKH2xVlbjTULDkQ==", "AtomicRelationType": "xAttr", "AtomicInference": "famished"}, "premise": "PersonX gets chinese food", "hypothesis": "As a result, PersonX feels famished", "update": "PersonX ordered a side only", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15221", "update_paraphrase": "PersonX only ordered a side.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2, "pred_conf_shift": 0.2284712791442871, "syntactic_distance": 0.25}, {"confidence": [0.9606630802154541, 0.039336781948804855], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15221.gpt3.0", "original_example": {"example_id": "atomic.train.15221", "premise_hypothesis_id": "atomic.train.7100", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "3QeM56CVpqTpdO053vKx7A==", "AtomicEventRelationId": "AJXTIW7mKH2xVlbjTULDkQ==", "AtomicRelationType": "xAttr", "AtomicInference": "famished"}, "premise": "PersonX gets chinese food", "hypothesis": "As a result, PersonX feels famished", "update": "PersonX ordered a side only", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15221", "update_paraphrase": "PersonX just ordered a side dish.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.256198347107438, "pred_conf_shift": -0.09109218791127205, "syntactic_distance": 0.23809523809523808}, {"confidence": [0.6650800108909607, 0.3349199593067169], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15221.gpt3.3", "original_example": {"example_id": "atomic.train.15221", "premise_hypothesis_id": "atomic.train.7100", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "3QeM56CVpqTpdO053vKx7A==", "AtomicEventRelationId": "AJXTIW7mKH2xVlbjTULDkQ==", "AtomicRelationType": "xAttr", "AtomicInference": "famished"}, "premise": "PersonX gets chinese food", "hypothesis": "As a result, PersonX feels famished", "update": "PersonX ordered a side only", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15221", "update_paraphrase": "PersonX only ordered a side dish.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.14876033057851246, "pred_conf_shift": 0.20449098944664001, "syntactic_distance": 0.23809523809523808}, {"confidence": [0.9427671432495117, 0.057232800871133804], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15221.gpt3.2", "original_example": {"example_id": "atomic.train.15221", "premise_hypothesis_id": "atomic.train.7100", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "3QeM56CVpqTpdO053vKx7A==", "AtomicEventRelationId": "AJXTIW7mKH2xVlbjTULDkQ==", "AtomicRelationType": "xAttr", "AtomicInference": "famished"}, "premise": "PersonX gets chinese food", "hypothesis": "As a result, PersonX feels famished", "update": "PersonX ordered a side only", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15221", "update_paraphrase": "PersonX opted for a side dish only.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3138888888888889, "pred_conf_shift": -0.0731961689889431, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.9265443086624146, 0.07345572113990784], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15221.gpt3.4", "original_example": {"example_id": "atomic.train.15221", "premise_hypothesis_id": "atomic.train.7100", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "3QeM56CVpqTpdO053vKx7A==", "AtomicEventRelationId": "AJXTIW7mKH2xVlbjTULDkQ==", "AtomicRelationType": "xAttr", "AtomicInference": "famished"}, "premise": "PersonX gets chinese food", "hypothesis": "As a result, PersonX feels famished", "update": "PersonX ordered a side only", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15221", "update_paraphrase": "PersonX just wanted a side dish, not a full meal.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5278055278055278, "pred_conf_shift": -0.05697324872016907, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.7485527992248535, 0.25144723057746887], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.15221.gpt3.5", "original_example": {"example_id": "atomic.train.15221", "premise_hypothesis_id": "atomic.train.7100", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "3QeM56CVpqTpdO053vKx7A==", "AtomicEventRelationId": "AJXTIW7mKH2xVlbjTULDkQ==", "AtomicRelationType": "xAttr", "AtomicInference": "famished"}, "premise": "PersonX gets chinese food", "hypothesis": "As a result, PersonX feels famished", "update": "PersonX ordered a side only", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.15221", "update_paraphrase": "PersonX didn't want a main course, so they just ordered a side.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.48366013071895425, "pred_conf_shift": 0.12101826071739197, "syntactic_distance": 0.4444444444444444}]}, "atomic.train.25476": {"original_confidence": [0.6237688660621643, 0.3762310743331909], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.787991464138031, 0.2120085060596466], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.25476.gpt3.2", "original_example": {"example_id": "atomic.train.25476", "premise_hypothesis_id": "atomic.train.11642", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Dlk6N3BB8OGNb7S5Ug5GIQ==", "AtomicEventRelationId": "zgTK-xA56_x0gq6rkAqPcw==", "AtomicRelationType": "xNeed", "AtomicInference": "to listen to someone tell them to buy waffles"}, "premise": "PersonX orders pizza instead", "hypothesis": "Before, PersonX needed to listen to someone tell them to buy waffles", "update": "PersonX is alone", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25476", "update_paraphrase": "PersonX is not in the company of others.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5613477431659251, "pred_conf_shift": 0.1642225980758667, "syntactic_distance": 0.25}, {"confidence": [0.6978784203529358, 0.30212169885635376], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.25476.gpt3.1", "original_example": {"example_id": "atomic.train.25476", "premise_hypothesis_id": "atomic.train.11642", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Dlk6N3BB8OGNb7S5Ug5GIQ==", "AtomicEventRelationId": "zgTK-xA56_x0gq6rkAqPcw==", "AtomicRelationType": "xNeed", "AtomicInference": "to listen to someone tell them to buy waffles"}, "premise": "PersonX orders pizza instead", "hypothesis": "Before, PersonX needed to listen to someone tell them to buy waffles", "update": "PersonX is alone", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25476", "update_paraphrase": "Person X is by themselves.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4525641025641025, "pred_conf_shift": 0.07410955429077148, "syntactic_distance": 0.25}, {"confidence": [0.6951104402542114, 0.30488961935043335], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.25476.gpt3.3", "original_example": {"example_id": "atomic.train.25476", "premise_hypothesis_id": "atomic.train.11642", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Dlk6N3BB8OGNb7S5Ug5GIQ==", "AtomicEventRelationId": "zgTK-xA56_x0gq6rkAqPcw==", "AtomicRelationType": "xNeed", "AtomicInference": "to listen to someone tell them to buy waffles"}, "premise": "PersonX orders pizza instead", "hypothesis": "Before, PersonX needed to listen to someone tell them to buy waffles", "update": "PersonX is alone", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25476", "update_paraphrase": "PersonX is by themselves.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.35686274509803917, "pred_conf_shift": 0.07134157419204712, "syntactic_distance": 0.2}, {"confidence": [0.4480912983417511, 0.5519086718559265], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25476.gpt3.0", "original_example": {"example_id": "atomic.train.25476", "premise_hypothesis_id": "atomic.train.11642", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Dlk6N3BB8OGNb7S5Ug5GIQ==", "AtomicEventRelationId": "zgTK-xA56_x0gq6rkAqPcw==", "AtomicRelationType": "xNeed", "AtomicInference": "to listen to someone tell them to buy waffles"}, "premise": "PersonX orders pizza instead", "hypothesis": "Before, PersonX needed to listen to someone tell them to buy waffles", "update": "PersonX is alone", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25476", "update_paraphrase": "PersonX is lonely.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.15656565656565652, "pred_conf_shift": -0.1756775677204132, "syntactic_distance": 0.14285714285714285}]}, "atomic.train.22712": {"original_confidence": [0.37560349702835083, 0.6243965029716492], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.8636095523834229, 0.13639038801193237], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.22712.gpt3.5", "original_example": {"example_id": "atomic.train.22712", "premise_hypothesis_id": "atomic.train.10421", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "erxWB6BQKij1Gv7EVX65FQ==", "AtomicEventRelationId": "vSDDfnI131Bv2LJFcKfKPA==", "AtomicRelationType": "xNeed", "AtomicInference": "to get noisy objects"}, "premise": "PersonX makes loud noises", "hypothesis": "Before, PersonX needed to get noisy objects", "update": "PersonX claps their hands.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22712", "update_paraphrase": "PersonX applauds by clapping their hands together.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4093240093240093, "pred_conf_shift": 0.488006055355072, "syntactic_distance": 0.25}, {"confidence": [0.18090593814849854, 0.8190940618515015], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.22712.gpt3.2", "original_example": {"example_id": "atomic.train.22712", "premise_hypothesis_id": "atomic.train.10421", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "erxWB6BQKij1Gv7EVX65FQ==", "AtomicEventRelationId": "vSDDfnI131Bv2LJFcKfKPA==", "AtomicRelationType": "xNeed", "AtomicInference": "to get noisy objects"}, "premise": "PersonX makes loud noises", "hypothesis": "Before, PersonX needed to get noisy objects", "update": "PersonX claps their hands.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22712", "update_paraphrase": "PersonX claps their hands together to create noise.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33333333333333337, "pred_conf_shift": -0.1946975588798523, "syntactic_distance": 0.25}, {"confidence": [0.3319331109523773, 0.6680668592453003], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.22712.gpt3.4", "original_example": {"example_id": "atomic.train.22712", "premise_hypothesis_id": "atomic.train.10421", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "erxWB6BQKij1Gv7EVX65FQ==", "AtomicEventRelationId": "vSDDfnI131Bv2LJFcKfKPA==", "AtomicRelationType": "xNeed", "AtomicInference": "to get noisy objects"}, "premise": "PersonX makes loud noises", "hypothesis": "Before, PersonX needed to get noisy objects", "update": "PersonX claps their hands.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22712", "update_paraphrase": "Person X claps their hands together.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.21538461538461529, "pred_conf_shift": -0.04367038607597351, "syntactic_distance": 0.15789473684210525}, {"confidence": [0.7962671518325806, 0.20373281836509705], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.22712.gpt3.0", "original_example": {"example_id": "atomic.train.22712", "premise_hypothesis_id": "atomic.train.10421", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "erxWB6BQKij1Gv7EVX65FQ==", "AtomicEventRelationId": "vSDDfnI131Bv2LJFcKfKPA==", "AtomicRelationType": "xNeed", "AtomicInference": "to get noisy objects"}, "premise": "PersonX makes loud noises", "hypothesis": "Before, PersonX needed to get noisy objects", "update": "PersonX claps their hands.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22712", "update_paraphrase": "PersonX showed their enthusiasm by clapping their hands.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.42094017094017094, "pred_conf_shift": 0.42066365480422974, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.34384456276893616, 0.6561553478240967], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.22712.gpt3.6", "original_example": {"example_id": "atomic.train.22712", "premise_hypothesis_id": "atomic.train.10421", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "erxWB6BQKij1Gv7EVX65FQ==", "AtomicEventRelationId": "vSDDfnI131Bv2LJFcKfKPA==", "AtomicRelationType": "xNeed", "AtomicInference": "to get noisy objects"}, "premise": "PersonX makes loud noises", "hypothesis": "Before, PersonX needed to get noisy objects", "update": "PersonX claps their hands.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22712", "update_paraphrase": "PersonX claps their hands together.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.11111111111111116, "pred_conf_shift": -0.03175893425941467, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.3417936861515045, 0.6582062840461731], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.22712.gpt3.1", "original_example": {"example_id": "atomic.train.22712", "premise_hypothesis_id": "atomic.train.10421", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "erxWB6BQKij1Gv7EVX65FQ==", "AtomicEventRelationId": "vSDDfnI131Bv2LJFcKfKPA==", "AtomicRelationType": "xNeed", "AtomicInference": "to get noisy objects"}, "premise": "PersonX makes loud noises", "hypothesis": "Before, PersonX needed to get noisy objects", "update": "PersonX claps their hands.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.22712", "update_paraphrase": "PersonX claps his or her hands.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.28500000000000003, "pred_conf_shift": -0.033809810876846313, "syntactic_distance": 0.1111111111111111}]}, "atomic.train.32120": {"original_confidence": [0.5973047018051147, 0.40269526839256287], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.9247457385063171, 0.07525426894426346], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.32120.gpt3.1", "original_example": {"example_id": "atomic.train.32120", "premise_hypothesis_id": "atomic.train.14589", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "uTl49DUTtt3VoV6JHjYIcQ==", "AtomicEventRelationId": "yFiRtWmmxHtG_OPX9Q2l_Q==", "AtomicRelationType": "xIntent", "AtomicInference": "to get to know y"}, "premise": "PersonX arouses PersonY interest", "hypothesis": "Because PersonX wanted to get to know y", "update": "PersonX is a celebrity", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32120", "update_paraphrase": "PersonX is famous.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3520408163265306, "pred_conf_shift": 0.3274410367012024, "syntactic_distance": 0.2}, {"confidence": [0.8522176742553711, 0.1477823257446289], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.32120.gpt3.0", "original_example": {"example_id": "atomic.train.32120", "premise_hypothesis_id": "atomic.train.14589", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "uTl49DUTtt3VoV6JHjYIcQ==", "AtomicEventRelationId": "yFiRtWmmxHtG_OPX9Q2l_Q==", "AtomicRelationType": "xIntent", "AtomicInference": "to get to know y"}, "premise": "PersonX arouses PersonY interest", "hypothesis": "Because PersonX wanted to get to know y", "update": "PersonX is a celebrity", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32120", "update_paraphrase": "PersonX is a well-known figure.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2669753086419753, "pred_conf_shift": 0.25491297245025635, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.8426285982131958, 0.1573713719844818], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.32120.gpt3.2", "original_example": {"example_id": "atomic.train.32120", "premise_hypothesis_id": "atomic.train.14589", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "uTl49DUTtt3VoV6JHjYIcQ==", "AtomicEventRelationId": "yFiRtWmmxHtG_OPX9Q2l_Q==", "AtomicRelationType": "xIntent", "AtomicInference": "to get to know y"}, "premise": "PersonX arouses PersonY interest", "hypothesis": "Because PersonX wanted to get to know y", "update": "PersonX is a celebrity", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.32120", "update_paraphrase": "PersonX is a famous person.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.20113960113960117, "pred_conf_shift": 0.24532389640808105, "syntactic_distance": 0.058823529411764705}]}, "atomic.train.30237": {"original_confidence": [0.40675675868988037, 0.5932431817054749], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.27473926544189453, 0.7252607345581055], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30237.gpt3.2", "original_example": {"example_id": "atomic.train.30237", "premise_hypothesis_id": "atomic.train.13734", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aN4WvU_qnX3fZhuumYLgGw==", "AtomicEventRelationId": "VTKOwdDJgZI4Gewkkw08Zg==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gets apples for free"}, "premise": "PersonX plants an apple tree", "hypothesis": "PersonX then personX gets apples for free", "update": "PersonX planted the tree in their backyard", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30237", "update_paraphrase": "The tree was planted in the person's backyard.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.24285714285714283, "pred_conf_shift": 0.13201755285263062, "syntactic_distance": 0.4}, {"confidence": [0.4363085925579071, 0.5636914372444153], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30237.gpt3.1", "original_example": {"example_id": "atomic.train.30237", "premise_hypothesis_id": "atomic.train.13734", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aN4WvU_qnX3fZhuumYLgGw==", "AtomicEventRelationId": "VTKOwdDJgZI4Gewkkw08Zg==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gets apples for free"}, "premise": "PersonX plants an apple tree", "hypothesis": "PersonX then personX gets apples for free", "update": "PersonX planted the tree in their backyard", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30237", "update_paraphrase": "PersonX planted the tree in their backyard.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": -0.02955174446105957, "syntactic_distance": 0.0}, {"confidence": [0.29089680314064026, 0.7091030478477478], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30237.gpt3.3", "original_example": {"example_id": "atomic.train.30237", "premise_hypothesis_id": "atomic.train.13734", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aN4WvU_qnX3fZhuumYLgGw==", "AtomicEventRelationId": "VTKOwdDJgZI4Gewkkw08Zg==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gets apples for free"}, "premise": "PersonX plants an apple tree", "hypothesis": "PersonX then personX gets apples for free", "update": "PersonX planted the tree in their backyard", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30237", "update_paraphrase": "PersonX put a tree in the ground in their backyard.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2962566844919786, "pred_conf_shift": 0.11585986614227295, "syntactic_distance": 0.12}, {"confidence": [0.4520599842071533, 0.5479400157928467], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30237.gpt3.5", "original_example": {"example_id": "atomic.train.30237", "premise_hypothesis_id": "atomic.train.13734", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aN4WvU_qnX3fZhuumYLgGw==", "AtomicEventRelationId": "VTKOwdDJgZI4Gewkkw08Zg==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gets apples for free"}, "premise": "PersonX plants an apple tree", "hypothesis": "PersonX then personX gets apples for free", "update": "PersonX planted the tree in their backyard", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30237", "update_paraphrase": "PersonX put a tree in their backyard", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19982993197278914, "pred_conf_shift": -0.045303165912628174, "syntactic_distance": 0.045454545454545456}, {"confidence": [0.447532594203949, 0.5524673461914062], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30237.gpt3.0", "original_example": {"example_id": "atomic.train.30237", "premise_hypothesis_id": "atomic.train.13734", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aN4WvU_qnX3fZhuumYLgGw==", "AtomicEventRelationId": "VTKOwdDJgZI4Gewkkw08Zg==", "AtomicRelationType": "xEffect", "AtomicInference": "PersonX gets apples for free"}, "premise": "PersonX plants an apple tree", "hypothesis": "PersonX then personX gets apples for free", "update": "PersonX planted the tree in their backyard", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30237", "update_paraphrase": "The tree was planted by PersonX in their backyard.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.25, "pred_conf_shift": -0.040775835514068604, "syntactic_distance": 0.38095238095238093}]}, "atomic.train.5866": {"original_confidence": [0.7732816934585571, 0.22671838104724884], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.7400707006454468, 0.25992926955223083], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5866.gpt3.3", "original_example": {"example_id": "atomic.train.5866", "premise_hypothesis_id": "atomic.train.2763", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_XrSppKSRXVRrpcdTN5FZg==", "AtomicEventRelationId": "chDn7QEDeNLM6Z5g6qTmZg==", "AtomicRelationType": "xAttr", "AtomicInference": "near sighted"}, "premise": "PersonX almost hit", "hypothesis": "As a result, PersonX feels near sighted", "update": "PersonX slipped", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5866", "update_paraphrase": "PersonX lost their footing and fell down.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.7151515151515151, "pred_conf_shift": -0.03321099281311035, "syntactic_distance": 0.375}, {"confidence": [0.7773013114929199, 0.22269867360591888], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5866.gpt3.2", "original_example": {"example_id": "atomic.train.5866", "premise_hypothesis_id": "atomic.train.2763", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_XrSppKSRXVRrpcdTN5FZg==", "AtomicEventRelationId": "chDn7QEDeNLM6Z5g6qTmZg==", "AtomicRelationType": "xAttr", "AtomicInference": "near sighted"}, "premise": "PersonX almost hit", "hypothesis": "As a result, PersonX feels near sighted", "update": "PersonX slipped", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5866", "update_paraphrase": "PersonX lost their footing and fell.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6833333333333333, "pred_conf_shift": 0.004019618034362793, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.60410076379776, 0.3958991467952728], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5866.gpt3.0", "original_example": {"example_id": "atomic.train.5866", "premise_hypothesis_id": "atomic.train.2763", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_XrSppKSRXVRrpcdTN5FZg==", "AtomicEventRelationId": "chDn7QEDeNLM6Z5g6qTmZg==", "AtomicRelationType": "xAttr", "AtomicInference": "near sighted"}, "premise": "PersonX almost hit", "hypothesis": "As a result, PersonX feels near sighted", "update": "PersonX slipped", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5866", "update_paraphrase": "PersonX fell", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.38311688311688313, "pred_conf_shift": -0.16918092966079712, "syntactic_distance": 0.0}, {"confidence": [0.8605774641036987, 0.1394224762916565], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.5866.gpt3.1", "original_example": {"example_id": "atomic.train.5866", "premise_hypothesis_id": "atomic.train.2763", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_XrSppKSRXVRrpcdTN5FZg==", "AtomicEventRelationId": "chDn7QEDeNLM6Z5g6qTmZg==", "AtomicRelationType": "xAttr", "AtomicInference": "near sighted"}, "premise": "PersonX almost hit", "hypothesis": "As a result, PersonX feels near sighted", "update": "PersonX slipped", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.5866", "update_paraphrase": "PersonX tripped and fell.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.49999999999999994, "pred_conf_shift": 0.0872957706451416, "syntactic_distance": 0.16666666666666666}]}, "atomic.train.11569": {"original_confidence": [0.7762115001678467, 0.22378847002983093], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.45882683992385864, 0.5411732196807861], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.11569.gpt3.4", "original_example": {"example_id": "atomic.train.11569", "premise_hypothesis_id": "atomic.train.5441", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xTeIoVSlFZ2OqierOQNn5w==", "AtomicEventRelationId": "naXzYMzzh7L3XeFnsLih-Q==", "AtomicRelationType": "xNeed", "AtomicInference": "to decide on a marketing scheme"}, "premise": "PersonX markets and sell a product or service", "hypothesis": "Before, PersonX needed to decide on a marketing scheme", "update": "Person X is self-employed working from home.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11569", "update_paraphrase": "Person X earns a living by working from home, independently.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.43858670741023686, "pred_conf_shift": 0.3173847496509552, "syntactic_distance": 0.2857142857142857}, {"confidence": [0.8146238923072815, 0.18537606298923492], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11569.gpt3.1", "original_example": {"example_id": "atomic.train.11569", "premise_hypothesis_id": "atomic.train.5441", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xTeIoVSlFZ2OqierOQNn5w==", "AtomicEventRelationId": "naXzYMzzh7L3XeFnsLih-Q==", "AtomicRelationType": "xNeed", "AtomicInference": "to decide on a marketing scheme"}, "premise": "PersonX markets and sell a product or service", "hypothesis": "Before, PersonX needed to decide on a marketing scheme", "update": "Person X is self-employed working from home.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11569", "update_paraphrase": "Person X is their own boss and works from the comfort of their home.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.49262043998886107, "pred_conf_shift": -0.03841240704059601, "syntactic_distance": 0.23809523809523808}, {"confidence": [0.7118517756462097, 0.2881481647491455], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11569.gpt3.2", "original_example": {"example_id": "atomic.train.11569", "premise_hypothesis_id": "atomic.train.5441", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xTeIoVSlFZ2OqierOQNn5w==", "AtomicEventRelationId": "naXzYMzzh7L3XeFnsLih-Q==", "AtomicRelationType": "xNeed", "AtomicInference": "to decide on a marketing scheme"}, "premise": "PersonX markets and sell a product or service", "hypothesis": "Before, PersonX needed to decide on a marketing scheme", "update": "Person X is self-employed working from home.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11569", "update_paraphrase": "Person X is their own boss and works from the comfort of their own home.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5156831472620946, "pred_conf_shift": 0.06435969471931458, "syntactic_distance": 0.23809523809523808}, {"confidence": [0.7310746908187866, 0.268925279378891], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11569.gpt3.3", "original_example": {"example_id": "atomic.train.11569", "premise_hypothesis_id": "atomic.train.5441", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xTeIoVSlFZ2OqierOQNn5w==", "AtomicEventRelationId": "naXzYMzzh7L3XeFnsLih-Q==", "AtomicRelationType": "xNeed", "AtomicInference": "to decide on a marketing scheme"}, "premise": "PersonX markets and sell a product or service", "hypothesis": "Before, PersonX needed to decide on a marketing scheme", "update": "Person X is self-employed working from home.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11569", "update_paraphrase": "Person X has their own business and works from home.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.40522875816993464, "pred_conf_shift": 0.04513680934906006, "syntactic_distance": 0.23809523809523808}, {"confidence": [0.6346155405044556, 0.36538442969322205], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11569.gpt3.0", "original_example": {"example_id": "atomic.train.11569", "premise_hypothesis_id": "atomic.train.5441", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "xTeIoVSlFZ2OqierOQNn5w==", "AtomicEventRelationId": "naXzYMzzh7L3XeFnsLih-Q==", "AtomicRelationType": "xNeed", "AtomicInference": "to decide on a marketing scheme"}, "premise": "PersonX markets and sell a product or service", "hypothesis": "Before, PersonX needed to decide on a marketing scheme", "update": "Person X is self-employed working from home.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11569", "update_paraphrase": "Person X is their own boss and works from home.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33856209150326794, "pred_conf_shift": 0.1415959596633911, "syntactic_distance": 0.23809523809523808}]}, "atomic.train.28773": {"original_confidence": [0.5722165107727051, 0.4277835786342621], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.0715453028678894, 0.9284546375274658], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.28773.gpt3.2", "original_example": {"example_id": "atomic.train.28773", "premise_hypothesis_id": "atomic.train.13060", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aFgfLsLdBhhrLouS7TlKLQ==", "AtomicEventRelationId": "d0vBjC5jWWWN2c5gbo7TKw==", "AtomicRelationType": "xIntent", "AtomicInference": "to be near PersonY"}, "premise": "PersonX sits with PersonY", "hypothesis": "Because PersonX wanted to be near PersonY", "update": "They are on a ferris wheel", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.28773", "update_paraphrase": "They're currently enjoying a ride on the ferris wheel.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3358730158730159, "pred_conf_shift": 0.5006710588932037, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.46956831216812134, 0.5304316282272339], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.28773.gpt3.0", "original_example": {"example_id": "atomic.train.28773", "premise_hypothesis_id": "atomic.train.13060", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aFgfLsLdBhhrLouS7TlKLQ==", "AtomicEventRelationId": "d0vBjC5jWWWN2c5gbo7TKw==", "AtomicRelationType": "xIntent", "AtomicInference": "to be near PersonY"}, "premise": "PersonX sits with PersonY", "hypothesis": "Because PersonX wanted to be near PersonY", "update": "They are on a ferris wheel", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.28773", "update_paraphrase": "Right now, they are on a ferris wheel.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1428571428571429, "pred_conf_shift": 0.1026480495929718, "syntactic_distance": 0.15789473684210525}, {"confidence": [0.6665717363357544, 0.333428293466568], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.28773.gpt3.4", "original_example": {"example_id": "atomic.train.28773", "premise_hypothesis_id": "atomic.train.13060", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aFgfLsLdBhhrLouS7TlKLQ==", "AtomicEventRelationId": "d0vBjC5jWWWN2c5gbo7TKw==", "AtomicRelationType": "xIntent", "AtomicInference": "to be near PersonY"}, "premise": "PersonX sits with PersonY", "hypothesis": "Because PersonX wanted to be near PersonY", "update": "They are on a ferris wheel", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.28773", "update_paraphrase": "They are current occupants of a ferris wheel", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.237012987012987, "pred_conf_shift": -0.09435528516769409, "syntactic_distance": 0.1875}, {"confidence": [0.3904350697994232, 0.6095649600028992], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.28773.gpt3.3", "original_example": {"example_id": "atomic.train.28773", "premise_hypothesis_id": "atomic.train.13060", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aFgfLsLdBhhrLouS7TlKLQ==", "AtomicEventRelationId": "d0vBjC5jWWWN2c5gbo7TKw==", "AtomicRelationType": "xIntent", "AtomicInference": "to be near PersonY"}, "premise": "PersonX sits with PersonY", "hypothesis": "Because PersonX wanted to be near PersonY", "update": "They are on a ferris wheel", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.28773", "update_paraphrase": "They are currently riding on a ferris wheel.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1428571428571429, "pred_conf_shift": 0.18178138136863708, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.9192308187484741, 0.08076918870210648], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.28773.gpt3.1", "original_example": {"example_id": "atomic.train.28773", "premise_hypothesis_id": "atomic.train.13060", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aFgfLsLdBhhrLouS7TlKLQ==", "AtomicEventRelationId": "d0vBjC5jWWWN2c5gbo7TKw==", "AtomicRelationType": "xIntent", "AtomicInference": "to be near PersonY"}, "premise": "PersonX sits with PersonY", "hypothesis": "Because PersonX wanted to be near PersonY", "update": "They are on a ferris wheel", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.28773", "update_paraphrase": "The ferris wheel is where they are.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4725274725274725, "pred_conf_shift": -0.3470143899321556, "syntactic_distance": 0.3888888888888889}]}, "atomic.train.19107": {"original_confidence": [0.46698442101478577, 0.5330155491828918], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.5741366147994995, 0.4258633553981781], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19107.gpt3.1", "original_example": {"example_id": "atomic.train.19107", "premise_hypothesis_id": "atomic.train.8864", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aDXPLg6e-ZMXuytXpal3rQ==", "AtomicEventRelationId": "Hzlrk0vD5ajeOAjO8K7gWA==", "AtomicRelationType": "xWant", "AtomicInference": "to apologize"}, "premise": "PersonX plays old harry", "hypothesis": "As a result, PersonX wants to apologize", "update": "PersonX gave old harry a heart attack", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19107", "update_paraphrase": "PersonX caused old harry to have a heart attack.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.24062499999999998, "pred_conf_shift": -0.10715219378471375, "syntactic_distance": 0.4}, {"confidence": [0.11260911822319031, 0.8873909115791321], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.19107.gpt3.4", "original_example": {"example_id": "atomic.train.19107", "premise_hypothesis_id": "atomic.train.8864", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aDXPLg6e-ZMXuytXpal3rQ==", "AtomicEventRelationId": "Hzlrk0vD5ajeOAjO8K7gWA==", "AtomicRelationType": "xWant", "AtomicInference": "to apologize"}, "premise": "PersonX plays old harry", "hypothesis": "As a result, PersonX wants to apologize", "update": "PersonX gave old harry a heart attack", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19107", "update_paraphrase": "PersonX's actions caused old harry to have a heart attack.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23431372549019608, "pred_conf_shift": 0.35437536239624023, "syntactic_distance": 0.38095238095238093}, {"confidence": [0.09068641066551208, 0.9093136191368103], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.19107.gpt3.0", "original_example": {"example_id": "atomic.train.19107", "premise_hypothesis_id": "atomic.train.8864", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aDXPLg6e-ZMXuytXpal3rQ==", "AtomicEventRelationId": "Hzlrk0vD5ajeOAjO8K7gWA==", "AtomicRelationType": "xWant", "AtomicInference": "to apologize"}, "premise": "PersonX plays old harry", "hypothesis": "As a result, PersonX wants to apologize", "update": "PersonX gave old harry a heart attack", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19107", "update_paraphrase": "PersonX's actions gave old harry a heart attack.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.07555555555555549, "pred_conf_shift": 0.37629806995391846, "syntactic_distance": 0.04}, {"confidence": [0.10072475671768188, 0.8992753028869629], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.19107.gpt3.2", "original_example": {"example_id": "atomic.train.19107", "premise_hypothesis_id": "atomic.train.8864", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aDXPLg6e-ZMXuytXpal3rQ==", "AtomicEventRelationId": "Hzlrk0vD5ajeOAjO8K7gWA==", "AtomicRelationType": "xWant", "AtomicInference": "to apologize"}, "premise": "PersonX plays old harry", "hypothesis": "As a result, PersonX wants to apologize", "update": "PersonX gave old harry a heart attack", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19107", "update_paraphrase": "PersonX scared old harry so badly that he had a heart attack.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37894736842105264, "pred_conf_shift": 0.36625975370407104, "syntactic_distance": 0.17391304347826086}, {"confidence": [0.05702538415789604, 0.9429745674133301], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.19107.gpt3.3", "original_example": {"example_id": "atomic.train.19107", "premise_hypothesis_id": "atomic.train.8864", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "aDXPLg6e-ZMXuytXpal3rQ==", "AtomicEventRelationId": "Hzlrk0vD5ajeOAjO8K7gWA==", "AtomicRelationType": "xWant", "AtomicInference": "to apologize"}, "premise": "PersonX plays old harry", "hypothesis": "As a result, PersonX wants to apologize", "update": "PersonX gave old harry a heart attack", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19107", "update_paraphrase": "Old Harry had a heart attack when PersonX gave him a fright.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.368421052631579, "pred_conf_shift": 0.40995901823043823, "syntactic_distance": 0.32}]}, "atomic.train.25434": {"original_confidence": [0.053486417979002, 0.9465134739875793], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.14480730891227722, 0.8551928400993347], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25434.gpt3.3", "original_example": {"example_id": "atomic.train.25434", "premise_hypothesis_id": "atomic.train.11624", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "zt_6XKSJr0Hb16HWZtpt0w==", "AtomicEventRelationId": "kj81toZ2PKU9b9qzWntYaA==", "AtomicRelationType": "xNeed", "AtomicInference": "TO find out ways to be more productive"}, "premise": "PersonX increases PersonX's production", "hypothesis": "Before, PersonX needed tO find out ways to be more productive", "update": "PersonX was very lazy previously", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25434", "update_paraphrase": "PersonX used to be very lazy.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3874458874458875, "pred_conf_shift": 0.09132089093327522, "syntactic_distance": 0.35294117647058826}, {"confidence": [0.14836017787456512, 0.8516398072242737], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25434.gpt3.1", "original_example": {"example_id": "atomic.train.25434", "premise_hypothesis_id": "atomic.train.11624", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "zt_6XKSJr0Hb16HWZtpt0w==", "AtomicEventRelationId": "kj81toZ2PKU9b9qzWntYaA==", "AtomicRelationType": "xNeed", "AtomicInference": "TO find out ways to be more productive"}, "premise": "PersonX increases PersonX's production", "hypothesis": "Before, PersonX needed tO find out ways to be more productive", "update": "PersonX was very lazy previously", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25434", "update_paraphrase": "PersonX used to be extremely lazy.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.47387700019278967, "pred_conf_shift": 0.09487375989556313, "syntactic_distance": 0.35294117647058826}, {"confidence": [0.07593018561601639, 0.9240698218345642], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25434.gpt3.4", "original_example": {"example_id": "atomic.train.25434", "premise_hypothesis_id": "atomic.train.11624", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "zt_6XKSJr0Hb16HWZtpt0w==", "AtomicEventRelationId": "kj81toZ2PKU9b9qzWntYaA==", "AtomicRelationType": "xNeed", "AtomicInference": "TO find out ways to be more productive"}, "premise": "PersonX increases PersonX's production", "hypothesis": "Before, PersonX needed tO find out ways to be more productive", "update": "PersonX was very lazy previously", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25434", "update_paraphrase": "Previously, PersonX was very lazy.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.09999999999999998, "pred_conf_shift": 0.02244376763701439, "syntactic_distance": 0.2}, {"confidence": [0.14924342930316925, 0.8507565855979919], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25434.gpt3.0", "original_example": {"example_id": "atomic.train.25434", "premise_hypothesis_id": "atomic.train.11624", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "zt_6XKSJr0Hb16HWZtpt0w==", "AtomicEventRelationId": "kj81toZ2PKU9b9qzWntYaA==", "AtomicRelationType": "xNeed", "AtomicInference": "TO find out ways to be more productive"}, "premise": "PersonX increases PersonX's production", "hypothesis": "Before, PersonX needed tO find out ways to be more productive", "update": "PersonX was very lazy previously", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25434", "update_paraphrase": "PersonX used to be quite lazy.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5086580086580086, "pred_conf_shift": 0.09575701132416725, "syntactic_distance": 0.35294117647058826}, {"confidence": [0.16737544536590576, 0.832624614238739], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.25434.gpt3.2", "original_example": {"example_id": "atomic.train.25434", "premise_hypothesis_id": "atomic.train.11624", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "zt_6XKSJr0Hb16HWZtpt0w==", "AtomicEventRelationId": "kj81toZ2PKU9b9qzWntYaA==", "AtomicRelationType": "xNeed", "AtomicInference": "TO find out ways to be more productive"}, "premise": "PersonX increases PersonX's production", "hypothesis": "Before, PersonX needed tO find out ways to be more productive", "update": "PersonX was very lazy previously", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.25434", "update_paraphrase": "In the past, PersonX was very lazy.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.30952380952380953, "pred_conf_shift": 0.11388902738690376, "syntactic_distance": 0.2727272727272727}]}, "atomic.train.23194": {"original_confidence": [0.4261246919631958, 0.5738753080368042], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.6980351209640503, 0.3019648492336273], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.23194.gpt3.5", "original_example": {"example_id": "atomic.train.23194", "premise_hypothesis_id": "atomic.train.10634", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-azbkh5idQ5W8ZDR-Nnw-Q==", "AtomicEventRelationId": "q5X8Pq4nH2waLWiPeJvY5A==", "AtomicRelationType": "xAttr", "AtomicInference": "tired"}, "premise": "PersonX lets out a sigh of relief", "hypothesis": "As a result, PersonX feels tired", "update": "PersonX is watching a scary movie", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23194", "update_paraphrase": "Now PersonX is watching a scary movie, they were just trying to find something to watch that wasn't too unpleasant.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5384615384615384, "pred_conf_shift": 0.2719104290008545, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.7580516934394836, 0.2419482320547104], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.23194.gpt3.3", "original_example": {"example_id": "atomic.train.23194", "premise_hypothesis_id": "atomic.train.10634", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-azbkh5idQ5W8ZDR-Nnw-Q==", "AtomicEventRelationId": "q5X8Pq4nH2waLWiPeJvY5A==", "AtomicRelationType": "xAttr", "AtomicInference": "tired"}, "premise": "PersonX lets out a sigh of relief", "hypothesis": "As a result, PersonX feels tired", "update": "PersonX is watching a scary movie", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23194", "update_paraphrase": "PersonX is currently viewing a horror movie.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3272893772893773, "pred_conf_shift": 0.33192700147628784, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.6618025302886963, 0.3381974399089813], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.23194.gpt3.0", "original_example": {"example_id": "atomic.train.23194", "premise_hypothesis_id": "atomic.train.10634", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-azbkh5idQ5W8ZDR-Nnw-Q==", "AtomicEventRelationId": "q5X8Pq4nH2waLWiPeJvY5A==", "AtomicRelationType": "xAttr", "AtomicInference": "tired"}, "premise": "PersonX lets out a sigh of relief", "hypothesis": "As a result, PersonX feels tired", "update": "PersonX is watching a scary movie", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23194", "update_paraphrase": "PersonX is watching a horror film.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.26196488696488696, "pred_conf_shift": 0.2356778383255005, "syntactic_distance": 0.0}, {"confidence": [0.6968417763710022, 0.3031581938266754], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.23194.gpt3.2", "original_example": {"example_id": "atomic.train.23194", "premise_hypothesis_id": "atomic.train.10634", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-azbkh5idQ5W8ZDR-Nnw-Q==", "AtomicEventRelationId": "q5X8Pq4nH2waLWiPeJvY5A==", "AtomicRelationType": "xAttr", "AtomicInference": "tired"}, "premise": "PersonX lets out a sigh of relief", "hypothesis": "As a result, PersonX feels tired", "update": "PersonX is watching a scary movie", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23194", "update_paraphrase": "PersonX is currently watching a horror film.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.31532356532356537, "pred_conf_shift": 0.2707170844078064, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.7873507142066956, 0.21264927089214325], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.23194.gpt3.1", "original_example": {"example_id": "atomic.train.23194", "premise_hypothesis_id": "atomic.train.10634", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "-azbkh5idQ5W8ZDR-Nnw-Q==", "AtomicEventRelationId": "q5X8Pq4nH2waLWiPeJvY5A==", "AtomicRelationType": "xAttr", "AtomicInference": "tired"}, "premise": "PersonX lets out a sigh of relief", "hypothesis": "As a result, PersonX feels tired", "update": "PersonX is watching a scary movie", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.23194", "update_paraphrase": "PersonX is currently watching a scary movie.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.07692307692307687, "pred_conf_shift": 0.36122602224349976, "syntactic_distance": 0.1111111111111111}]}, "atomic.train.10970": {"original_confidence": [0.6646741628646851, 0.33532583713531494], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.3977169394493103, 0.6022831201553345], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.10970.gpt3.1", "original_example": {"example_id": "atomic.train.10970", "premise_hypothesis_id": "atomic.train.5162", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ThSKRzPCT2T6J2zvfj_8pg==", "AtomicEventRelationId": "0wMg8dkjXCk7sE0993HyeA==", "AtomicRelationType": "xEffect", "AtomicInference": "is too busy"}, "premise": "PersonX rings off the hook", "hypothesis": "PersonX then is too busy", "update": "PersonX is a celebrity", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10970", "update_paraphrase": "PersonX is a well-known figure.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2669753086419753, "pred_conf_shift": -0.26695722341537476, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.737619161605835, 0.2623807489871979], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10970.gpt3.2", "original_example": {"example_id": "atomic.train.10970", "premise_hypothesis_id": "atomic.train.5162", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ThSKRzPCT2T6J2zvfj_8pg==", "AtomicEventRelationId": "0wMg8dkjXCk7sE0993HyeA==", "AtomicRelationType": "xEffect", "AtomicInference": "is too busy"}, "premise": "PersonX rings off the hook", "hypothesis": "PersonX then is too busy", "update": "PersonX is a celebrity", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10970", "update_paraphrase": "PersonX is famous.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3520408163265306, "pred_conf_shift": 0.0729449987411499, "syntactic_distance": 0.2}, {"confidence": [0.6898241639137268, 0.31017592549324036], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10970.gpt3.3", "original_example": {"example_id": "atomic.train.10970", "premise_hypothesis_id": "atomic.train.5162", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ThSKRzPCT2T6J2zvfj_8pg==", "AtomicEventRelationId": "0wMg8dkjXCk7sE0993HyeA==", "AtomicRelationType": "xEffect", "AtomicInference": "is too busy"}, "premise": "PersonX rings off the hook", "hypothesis": "PersonX then is too busy", "update": "PersonX is a celebrity", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10970", "update_paraphrase": "PersonX is an A-lister.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.33854166666666663, "pred_conf_shift": 0.025150001049041748, "syntactic_distance": 0.0}, {"confidence": [0.6019776463508606, 0.3980223536491394], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10970.gpt3.4", "original_example": {"example_id": "atomic.train.10970", "premise_hypothesis_id": "atomic.train.5162", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ThSKRzPCT2T6J2zvfj_8pg==", "AtomicEventRelationId": "0wMg8dkjXCk7sE0993HyeA==", "AtomicRelationType": "xEffect", "AtomicInference": "is too busy"}, "premise": "PersonX rings off the hook", "hypothesis": "PersonX then is too busy", "update": "PersonX is a celebrity", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10970", "update_paraphrase": "PersonX is a famous person.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.20113960113960117, "pred_conf_shift": -0.06269651651382446, "syntactic_distance": 0.058823529411764705}, {"confidence": [0.40459370613098145, 0.5954062938690186], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.10970.gpt3.0", "original_example": {"example_id": "atomic.train.10970", "premise_hypothesis_id": "atomic.train.5162", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ThSKRzPCT2T6J2zvfj_8pg==", "AtomicEventRelationId": "0wMg8dkjXCk7sE0993HyeA==", "AtomicRelationType": "xEffect", "AtomicInference": "is too busy"}, "premise": "PersonX rings off the hook", "hypothesis": "PersonX then is too busy", "update": "PersonX is a celebrity", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10970", "update_paraphrase": "PersonX is a world-famous celebrity.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.11111111111111116, "pred_conf_shift": -0.2600804567337036, "syntactic_distance": 0.058823529411764705}]}, "atomic.train.36976": {"original_confidence": [0.31488287448883057, 0.6851171255111694], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.4713148772716522, 0.5286851525306702], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.36976.gpt3.2", "original_example": {"example_id": "atomic.train.36976", "premise_hypothesis_id": "atomic.train.16779", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7LORGSqvciPrhCQFIVXDOA==", "AtomicEventRelationId": "z53nQVTJjlN5TBgRjF9Dlg==", "AtomicRelationType": "xNeed", "AtomicInference": "to fight with PersonY"}, "premise": "PersonX gives PersonY another chance", "hypothesis": "Before, PersonX needed to fight with PersonY", "update": "PersonX judged PersonY ahead of time.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36976", "update_paraphrase": "PersonX made assumptions about PersonY before getting to know them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.565680846930847, "pred_conf_shift": 0.15643200278282166, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.5121262669563293, 0.48787376284599304], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.36976.gpt3.6", "original_example": {"example_id": "atomic.train.36976", "premise_hypothesis_id": "atomic.train.16779", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7LORGSqvciPrhCQFIVXDOA==", "AtomicEventRelationId": "z53nQVTJjlN5TBgRjF9Dlg==", "AtomicRelationType": "xNeed", "AtomicInference": "to fight with PersonY"}, "premise": "PersonX gives PersonY another chance", "hypothesis": "Before, PersonX needed to fight with PersonY", "update": "PersonX judged PersonY ahead of time.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36976", "update_paraphrase": "Before even getting to know PersonY, PersonX had already judged them.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5462184873949579, "pred_conf_shift": 0.19724339246749878, "syntactic_distance": 0.391304347826087}, {"confidence": [0.5037406086921692, 0.4962593913078308], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.36976.gpt3.5", "original_example": {"example_id": "atomic.train.36976", "premise_hypothesis_id": "atomic.train.16779", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7LORGSqvciPrhCQFIVXDOA==", "AtomicEventRelationId": "z53nQVTJjlN5TBgRjF9Dlg==", "AtomicRelationType": "xNeed", "AtomicInference": "to fight with PersonY"}, "premise": "PersonX gives PersonY another chance", "hypothesis": "Before, PersonX needed to fight with PersonY", "update": "PersonX judged PersonY ahead of time.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36976", "update_paraphrase": "PersonX was quick to judge PersonY without getting to know them first.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5511864678531345, "pred_conf_shift": 0.18885773420333862, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.20862440764904022, 0.7913755774497986], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.36976.gpt3.3", "original_example": {"example_id": "atomic.train.36976", "premise_hypothesis_id": "atomic.train.16779", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7LORGSqvciPrhCQFIVXDOA==", "AtomicEventRelationId": "z53nQVTJjlN5TBgRjF9Dlg==", "AtomicRelationType": "xNeed", "AtomicInference": "to fight with PersonY"}, "premise": "PersonX gives PersonY another chance", "hypothesis": "Before, PersonX needed to fight with PersonY", "update": "PersonX judged PersonY ahead of time.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36976", "update_paraphrase": "PersonX jumped to conclusions about PersonY without knowing all the facts.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5623249299719888, "pred_conf_shift": -0.10625846683979034, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.6609331369400024, 0.33906692266464233], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.36976.gpt3.1", "original_example": {"example_id": "atomic.train.36976", "premise_hypothesis_id": "atomic.train.16779", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7LORGSqvciPrhCQFIVXDOA==", "AtomicEventRelationId": "z53nQVTJjlN5TBgRjF9Dlg==", "AtomicRelationType": "xNeed", "AtomicInference": "to fight with PersonY"}, "premise": "PersonX gives PersonY another chance", "hypothesis": "Before, PersonX needed to fight with PersonY", "update": "PersonX judged PersonY ahead of time.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36976", "update_paraphrase": "PersonX pre-judged PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.45079365079365075, "pred_conf_shift": 0.3460502624511719, "syntactic_distance": 0.29411764705882354}]}, "atomic.train.10048": {"original_confidence": [0.4270614981651306, 0.5729385018348694], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.4270614981651306, 0.5729385018348694], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.10048.gpt3.2", "original_example": {"example_id": "atomic.train.10048", "premise_hypothesis_id": "atomic.train.4737", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ME1fb4OagoXw5x0y5MQzZg==", "AtomicEventRelationId": "N1i8EdEtqGVkXNK_4dWpMA==", "AtomicRelationType": "xReact", "AtomicInference": "relaxed"}, "premise": "PersonX enjoys PersonX's day off", "hypothesis": "PersonX is seen as relaxed", "update": "They ran a marathon.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10048", "update_paraphrase": "They ran a marathon.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": 0.0, "syntactic_distance": 0.0}, {"confidence": [0.24392937123775482, 0.7560706734657288], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.10048.gpt3.1", "original_example": {"example_id": "atomic.train.10048", "premise_hypothesis_id": "atomic.train.4737", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ME1fb4OagoXw5x0y5MQzZg==", "AtomicEventRelationId": "N1i8EdEtqGVkXNK_4dWpMA==", "AtomicRelationType": "xReact", "AtomicInference": "relaxed"}, "premise": "PersonX enjoys PersonX's day off", "hypothesis": "PersonX is seen as relaxed", "update": "They ran a marathon.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10048", "update_paraphrase": "After training for months, they finally ran the marathon.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5128205128205128, "pred_conf_shift": -0.1831321269273758, "syntactic_distance": 0.30434782608695654}, {"confidence": [0.36081182956695557, 0.6391881704330444], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.10048.gpt3.0", "original_example": {"example_id": "atomic.train.10048", "premise_hypothesis_id": "atomic.train.4737", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ME1fb4OagoXw5x0y5MQzZg==", "AtomicEventRelationId": "N1i8EdEtqGVkXNK_4dWpMA==", "AtomicRelationType": "xReact", "AtomicInference": "relaxed"}, "premise": "PersonX enjoys PersonX's day off", "hypothesis": "PersonX is seen as relaxed", "update": "They ran a marathon.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10048", "update_paraphrase": "They completed a marathon.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.25, "pred_conf_shift": -0.06624966859817505, "syntactic_distance": 0.0}]}, "atomic.train.11101": {"original_confidence": [0.9415988326072693, 0.058401256799697876], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.9291409254074097, 0.07085907459259033], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11101.gpt3.1", "original_example": {"example_id": "atomic.train.11101", "premise_hypothesis_id": "atomic.train.5224", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7eiXl-g7WIgslrCszbV_CQ==", "AtomicEventRelationId": "-bm6pKu20Qo5XAkvYMC6qQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to win over some voting event."}, "premise": "PersonX casts PersonX's vote", "hypothesis": "Because PersonX wanted to win over some voting event.", "update": "X voted for himself.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11101", "update_paraphrase": "X cast a ballot in his own favor.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5977272727272727, "pred_conf_shift": 0.012457817792892456, "syntactic_distance": 0.29411764705882354}, {"confidence": [0.9380713105201721, 0.06192869320511818], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11101.gpt3.2", "original_example": {"example_id": "atomic.train.11101", "premise_hypothesis_id": "atomic.train.5224", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7eiXl-g7WIgslrCszbV_CQ==", "AtomicEventRelationId": "-bm6pKu20Qo5XAkvYMC6qQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to win over some voting event."}, "premise": "PersonX casts PersonX's vote", "hypothesis": "Because PersonX wanted to win over some voting event.", "update": "X voted for himself.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11101", "update_paraphrase": "X voted for himself in the election.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2727272727272727, "pred_conf_shift": 0.0035274364054203033, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.958123505115509, 0.04187651351094246], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11101.gpt3.5", "original_example": {"example_id": "atomic.train.11101", "premise_hypothesis_id": "atomic.train.5224", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7eiXl-g7WIgslrCszbV_CQ==", "AtomicEventRelationId": "-bm6pKu20Qo5XAkvYMC6qQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to win over some voting event."}, "premise": "PersonX casts PersonX's vote", "hypothesis": "Because PersonX wanted to win over some voting event.", "update": "X voted for himself.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11101", "update_paraphrase": "X cast his vote for himself.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3111111111111111, "pred_conf_shift": -0.016524743288755417, "syntactic_distance": 0.35714285714285715}, {"confidence": [0.9481861591339111, 0.051813799887895584], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11101.gpt3.0", "original_example": {"example_id": "atomic.train.11101", "premise_hypothesis_id": "atomic.train.5224", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7eiXl-g7WIgslrCszbV_CQ==", "AtomicEventRelationId": "-bm6pKu20Qo5XAkvYMC6qQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to win over some voting event."}, "premise": "PersonX casts PersonX's vote", "hypothesis": "Because PersonX wanted to win over some voting event.", "update": "X voted for himself.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11101", "update_paraphrase": "He cast his ballot in favor of himself.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6477272727272727, "pred_conf_shift": -0.006587456911802292, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.9237318634986877, 0.07626805454492569], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11101.gpt3.4", "original_example": {"example_id": "atomic.train.11101", "premise_hypothesis_id": "atomic.train.5224", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7eiXl-g7WIgslrCszbV_CQ==", "AtomicEventRelationId": "-bm6pKu20Qo5XAkvYMC6qQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to win over some voting event."}, "premise": "PersonX casts PersonX's vote", "hypothesis": "Because PersonX wanted to win over some voting event.", "update": "X voted for himself.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11101", "update_paraphrase": "This person cast their ballot in favor of their own candidacy.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.7880808080808079, "pred_conf_shift": 0.017866797745227814, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.9374714493751526, 0.06252855807542801], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11101.gpt3.3", "original_example": {"example_id": "atomic.train.11101", "premise_hypothesis_id": "atomic.train.5224", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "7eiXl-g7WIgslrCszbV_CQ==", "AtomicEventRelationId": "-bm6pKu20Qo5XAkvYMC6qQ==", "AtomicRelationType": "xIntent", "AtomicInference": "to win over some voting event."}, "premise": "PersonX casts PersonX's vote", "hypothesis": "Because PersonX wanted to win over some voting event.", "update": "X voted for himself.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11101", "update_paraphrase": "X cast his ballot in favor of himself.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.540530303030303, "pred_conf_shift": 0.004127301275730133, "syntactic_distance": 0.29411764705882354}]}, "atomic.train.31864": {"original_confidence": [0.9867057800292969, 0.013294256292283535], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.9882346987724304, 0.011765255592763424], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31864.gpt3.1", "original_example": {"example_id": "atomic.train.31864", "premise_hypothesis_id": "atomic.train.14473", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "feGG3SDt2zAN_U_ve3d2Iw==", "AtomicEventRelationId": "LoBARZ-EcmgBTjx_-oefeg==", "AtomicRelationType": "xAttr", "AtomicInference": "brave"}, "premise": "PersonX ties a narrative bow on something", "hypothesis": "As a result, PersonX feels brave", "update": "PersonX is just passing the time", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31864", "update_paraphrase": "PersonX is just wasting time.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.16883116883116878, "pred_conf_shift": 0.001528918743133545, "syntactic_distance": 0.0}, {"confidence": [0.9876458048820496, 0.012354069389402866], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.31864.gpt3.0", "original_example": {"example_id": "atomic.train.31864", "premise_hypothesis_id": "atomic.train.14473", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "feGG3SDt2zAN_U_ve3d2Iw==", "AtomicEventRelationId": "LoBARZ-EcmgBTjx_-oefeg==", "AtomicRelationType": "xAttr", "AtomicInference": "brave"}, "premise": "PersonX ties a narrative bow on something", "hypothesis": "As a result, PersonX feels brave", "update": "PersonX is just passing the time", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.31864", "update_paraphrase": "PersonX is just killing time.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19480519480519476, "pred_conf_shift": 0.0009400248527526855, "syntactic_distance": 0.0}]}, "atomic.train.36800": {"original_confidence": [0.01292729377746582, 0.9870728254318237], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.015597531571984291, 0.984402596950531], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.36800.gpt3.4", "original_example": {"example_id": "atomic.train.36800", "premise_hypothesis_id": "atomic.train.16694", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ybKZcdLj_-QFnXx_9zsyLw==", "AtomicEventRelationId": "x7mjp5RwzMo43MQFU8Dxtw==", "AtomicRelationType": "xIntent", "AtomicInference": "to be friends"}, "premise": "PersonX puts PersonX's trust in PersonY", "hypothesis": "Because PersonX wanted to be friends", "update": "PersonX respects PersonY a lot.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36800", "update_paraphrase": "PersonX really admires PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.46349206349206346, "pred_conf_shift": 0.0026702377945184708, "syntactic_distance": 0.3684210526315789}, {"confidence": [0.0120222894474864, 0.987977921962738], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.36800.gpt3.1", "original_example": {"example_id": "atomic.train.36800", "premise_hypothesis_id": "atomic.train.16694", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ybKZcdLj_-QFnXx_9zsyLw==", "AtomicEventRelationId": "x7mjp5RwzMo43MQFU8Dxtw==", "AtomicRelationType": "xIntent", "AtomicInference": "to be friends"}, "premise": "PersonX puts PersonX's trust in PersonY", "hypothesis": "Because PersonX wanted to be friends", "update": "PersonX respects PersonY a lot.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36800", "update_paraphrase": "PersonX has a lot of admiration for PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.48023218611453905, "pred_conf_shift": -0.0009050043299794197, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.014083543792366982, 0.9859163761138916], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.36800.gpt3.3", "original_example": {"example_id": "atomic.train.36800", "premise_hypothesis_id": "atomic.train.16694", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ybKZcdLj_-QFnXx_9zsyLw==", "AtomicEventRelationId": "x7mjp5RwzMo43MQFU8Dxtw==", "AtomicRelationType": "xIntent", "AtomicInference": "to be friends"}, "premise": "PersonX puts PersonX's trust in PersonY", "hypothesis": "Because PersonX wanted to be friends", "update": "PersonX respects PersonY a lot.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36800", "update_paraphrase": "PersonX has a great deal of respect for PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.46507936507936515, "pred_conf_shift": 0.0011562500149011612, "syntactic_distance": 0.2222222222222222}, {"confidence": [0.012306802906095982, 0.9876930713653564], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.36800.gpt3.2", "original_example": {"example_id": "atomic.train.36800", "premise_hypothesis_id": "atomic.train.16694", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ybKZcdLj_-QFnXx_9zsyLw==", "AtomicEventRelationId": "x7mjp5RwzMo43MQFU8Dxtw==", "AtomicRelationType": "xIntent", "AtomicInference": "to be friends"}, "premise": "PersonX puts PersonX's trust in PersonY", "hypothesis": "Because PersonX wanted to be friends", "update": "PersonX respects PersonY a lot.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.36800", "update_paraphrase": "PersonX has a great deal of admiration and respect for PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5237745098039216, "pred_conf_shift": -0.0006204908713698387, "syntactic_distance": 0.2222222222222222}]}, "atomic.train.2579": {"original_confidence": [0.5302624702453613, 0.4697374403476715], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.850963830947876, 0.1490362286567688], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2579.gpt3.0", "original_example": {"example_id": "atomic.train.2579", "premise_hypothesis_id": "atomic.train.1215", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Lwfmm_pD99QoJJXbXC5gkg==", "AtomicEventRelationId": "euJtyqx3_dw1bhe_fBlg1w==", "AtomicRelationType": "xWant", "AtomicInference": "to go to a store"}, "premise": "PersonX goes from PersonY", "hypothesis": "As a result, PersonX wants to go to a store", "update": "It is Y's birthday today.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2579", "update_paraphrase": "Today is the day Y celebrates their birthday.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.46007326007326005, "pred_conf_shift": -0.3207012116909027, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.9592556953430176, 0.04074421897530556], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2579.gpt3.1", "original_example": {"example_id": "atomic.train.2579", "premise_hypothesis_id": "atomic.train.1215", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Lwfmm_pD99QoJJXbXC5gkg==", "AtomicEventRelationId": "euJtyqx3_dw1bhe_fBlg1w==", "AtomicRelationType": "xWant", "AtomicInference": "to go to a store"}, "premise": "PersonX goes from PersonY", "hypothesis": "As a result, PersonX wants to go to a store", "update": "It is Y's birthday today.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2579", "update_paraphrase": "Today is the day of Y's birth.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.39798534798534807, "pred_conf_shift": -0.42899322137236595, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.8162864446640015, 0.18371354043483734], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2579.gpt3.2", "original_example": {"example_id": "atomic.train.2579", "premise_hypothesis_id": "atomic.train.1215", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Lwfmm_pD99QoJJXbXC5gkg==", "AtomicEventRelationId": "euJtyqx3_dw1bhe_fBlg1w==", "AtomicRelationType": "xWant", "AtomicInference": "to go to a store"}, "premise": "PersonX goes from PersonY", "hypothesis": "As a result, PersonX wants to go to a store", "update": "It is Y's birthday today.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2579", "update_paraphrase": "Today is Y's birthday.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19047619047619052, "pred_conf_shift": -0.28602389991283417, "syntactic_distance": 0.16666666666666666}]}, "atomic.train.8190": {"original_confidence": [0.987216591835022, 0.012783462181687355], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.9863959550857544, 0.013604064472019672], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8190.gpt3.4", "original_example": {"example_id": "atomic.train.8190", "premise_hypothesis_id": "atomic.train.3860", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "H34_KkecTbUw_DGEqzb9Rw==", "AtomicEventRelationId": "dbx4ivw2q5Dwb4vC1sY_WA==", "AtomicRelationType": "xAttr", "AtomicInference": "patient"}, "premise": "PersonX waits to go", "hypothesis": "As a result, PersonX feels patient", "update": "PersonX is tapping their foot aggressively and looking at their watch.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8190", "update_paraphrase": "The person looks impatient, tapping their foot aggressively and checking their watch.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.22035355948399427, "pred_conf_shift": -0.0008206367492675781, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.9868687987327576, 0.013131219893693924], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8190.gpt3.6", "original_example": {"example_id": "atomic.train.8190", "premise_hypothesis_id": "atomic.train.3860", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "H34_KkecTbUw_DGEqzb9Rw==", "AtomicEventRelationId": "dbx4ivw2q5Dwb4vC1sY_WA==", "AtomicRelationType": "xAttr", "AtomicInference": "patient"}, "premise": "PersonX waits to go", "hypothesis": "As a result, PersonX feels patient", "update": "PersonX is tapping their foot aggressively and looking at their watch.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8190", "update_paraphrase": "PersonX seems impatient and is tapping their foot aggressively while looking at their watch.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.14500000000000002, "pred_conf_shift": -0.0003477931022644043, "syntactic_distance": 0.25}, {"confidence": [0.9861462116241455, 0.013853705488145351], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8190.gpt3.5", "original_example": {"example_id": "atomic.train.8190", "premise_hypothesis_id": "atomic.train.3860", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "H34_KkecTbUw_DGEqzb9Rw==", "AtomicEventRelationId": "dbx4ivw2q5Dwb4vC1sY_WA==", "AtomicRelationType": "xAttr", "AtomicInference": "patient"}, "premise": "PersonX waits to go", "hypothesis": "As a result, PersonX feels patient", "update": "PersonX is tapping their foot aggressively and looking at their watch.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8190", "update_paraphrase": "PersonX is tapping their foot impatiently and looking at their watch.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0615768670688579, "pred_conf_shift": -0.0010703802108764648, "syntactic_distance": 0.0}, {"confidence": [0.9829397797584534, 0.017060203477740288], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8190.gpt3.2", "original_example": {"example_id": "atomic.train.8190", "premise_hypothesis_id": "atomic.train.3860", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "H34_KkecTbUw_DGEqzb9Rw==", "AtomicEventRelationId": "dbx4ivw2q5Dwb4vC1sY_WA==", "AtomicRelationType": "xAttr", "AtomicInference": "patient"}, "premise": "PersonX waits to go", "hypothesis": "As a result, PersonX feels patient", "update": "PersonX is tapping their foot aggressively and looking at their watch.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8190", "update_paraphrase": "PersonX is impatiently tapping their foot and checking the time on their watch.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.26243961352656997, "pred_conf_shift": -0.0042768120765686035, "syntactic_distance": 0.1}, {"confidence": [0.9843650460243225, 0.015635022893548012], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8190.gpt3.3", "original_example": {"example_id": "atomic.train.8190", "premise_hypothesis_id": "atomic.train.3860", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "H34_KkecTbUw_DGEqzb9Rw==", "AtomicEventRelationId": "dbx4ivw2q5Dwb4vC1sY_WA==", "AtomicRelationType": "xAttr", "AtomicInference": "patient"}, "premise": "PersonX waits to go", "hypothesis": "As a result, PersonX feels patient", "update": "PersonX is tapping their foot aggressively and looking at their watch.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8190", "update_paraphrase": "PersonX is impatiently tapping their foot and looking at their watch.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.16177300959909657, "pred_conf_shift": -0.002851545810699463, "syntactic_distance": 0.1}, {"confidence": [0.9859372973442078, 0.014062754809856415], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8190.gpt3.1", "original_example": {"example_id": "atomic.train.8190", "premise_hypothesis_id": "atomic.train.3860", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "H34_KkecTbUw_DGEqzb9Rw==", "AtomicEventRelationId": "dbx4ivw2q5Dwb4vC1sY_WA==", "AtomicRelationType": "xAttr", "AtomicInference": "patient"}, "premise": "PersonX waits to go", "hypothesis": "As a result, PersonX feels patient", "update": "PersonX is tapping their foot aggressively and looking at their watch.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8190", "update_paraphrase": "PersonX looks annoyed and is impatiently tapping their foot while checking the time on their watch.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.34951829558251835, "pred_conf_shift": -0.001279294490814209, "syntactic_distance": 0.23809523809523808}, {"confidence": [0.9846111536026001, 0.01538892649114132], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.8190.gpt3.0", "original_example": {"example_id": "atomic.train.8190", "premise_hypothesis_id": "atomic.train.3860", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "H34_KkecTbUw_DGEqzb9Rw==", "AtomicEventRelationId": "dbx4ivw2q5Dwb4vC1sY_WA==", "AtomicRelationType": "xAttr", "AtomicInference": "patient"}, "premise": "PersonX waits to go", "hypothesis": "As a result, PersonX feels patient", "update": "PersonX is tapping their foot aggressively and looking at their watch.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.8190", "update_paraphrase": "PersonX is impatiently tapping their foot and checking their watch.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2396135265700483, "pred_conf_shift": -0.002605438232421875, "syntactic_distance": 0.1}]}, "atomic.train.13741": {"original_confidence": [0.51728755235672, 0.48271244764328003], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.1105962023139, 0.8894038200378418], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.13741.gpt3.0", "original_example": {"example_id": "atomic.train.13741", "premise_hypothesis_id": "atomic.train.6425", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y5W2t8wbLDuPZiplS_iLUg==", "AtomicEventRelationId": "-uwDOjOhDTbAHp4LoxF91Q==", "AtomicRelationType": "xNeed", "AtomicInference": "breath out"}, "premise": "PersonX takes a breath", "hypothesis": "Before, PersonX needed breath out", "update": "PersonX is inhaling.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13741", "update_paraphrase": "PersonX is taking a deep breath.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.47186147186147187, "pred_conf_shift": 0.40669137239456177, "syntactic_distance": 0.06666666666666667}, {"confidence": [0.2625977098941803, 0.7374022603034973], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.13741.gpt3.3", "original_example": {"example_id": "atomic.train.13741", "premise_hypothesis_id": "atomic.train.6425", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y5W2t8wbLDuPZiplS_iLUg==", "AtomicEventRelationId": "-uwDOjOhDTbAHp4LoxF91Q==", "AtomicRelationType": "xNeed", "AtomicInference": "breath out"}, "premise": "PersonX takes a breath", "hypothesis": "Before, PersonX needed breath out", "update": "PersonX is inhaling.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13741", "update_paraphrase": "PersonX is taking in a deep breath.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5206349206349206, "pred_conf_shift": 0.2546898126602173, "syntactic_distance": 0.125}, {"confidence": [0.14405353367328644, 0.8559464812278748], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.13741.gpt3.2", "original_example": {"example_id": "atomic.train.13741", "premise_hypothesis_id": "atomic.train.6425", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y5W2t8wbLDuPZiplS_iLUg==", "AtomicEventRelationId": "-uwDOjOhDTbAHp4LoxF91Q==", "AtomicRelationType": "xNeed", "AtomicInference": "breath out"}, "premise": "PersonX takes a breath", "hypothesis": "Before, PersonX needed breath out", "update": "PersonX is inhaling.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13741", "update_paraphrase": "PersonX is taking in deep breaths.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.46031746031746035, "pred_conf_shift": 0.3732340335845947, "syntactic_distance": 0.125}, {"confidence": [0.8871654272079468, 0.11283453553915024], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.13741.gpt3.4", "original_example": {"example_id": "atomic.train.13741", "premise_hypothesis_id": "atomic.train.6425", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y5W2t8wbLDuPZiplS_iLUg==", "AtomicEventRelationId": "-uwDOjOhDTbAHp4LoxF91Q==", "AtomicRelationType": "xNeed", "AtomicInference": "breath out"}, "premise": "PersonX takes a breath", "hypothesis": "Before, PersonX needed breath out", "update": "PersonX is inhaling.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13741", "update_paraphrase": "PersonX is breathing in.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3256302521008403, "pred_conf_shift": -0.3698779121041298, "syntactic_distance": 0.06666666666666667}, {"confidence": [0.06834078580141068, 0.9316593408584595], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.13741.gpt3.1", "original_example": {"example_id": "atomic.train.13741", "premise_hypothesis_id": "atomic.train.6425", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "y5W2t8wbLDuPZiplS_iLUg==", "AtomicEventRelationId": "-uwDOjOhDTbAHp4LoxF91Q==", "AtomicRelationType": "xNeed", "AtomicInference": "breath out"}, "premise": "PersonX takes a breath", "hypothesis": "Before, PersonX needed breath out", "update": "PersonX is inhaling.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.13741", "update_paraphrase": "PersonX is taking deep breaths.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3928571428571429, "pred_conf_shift": 0.44894689321517944, "syntactic_distance": 0.06666666666666667}]}, "atomic.train.11069": {"original_confidence": [0.9625492691993713, 0.03745066374540329], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.982507050037384, 0.017492879182100296], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11069.gpt3.1", "original_example": {"example_id": "atomic.train.11069", "premise_hypothesis_id": "atomic.train.5208", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "IrCusmjyTI5-T2H9qZowIw==", "AtomicEventRelationId": "fBiQnHKxx0m5R8PiohkcBg==", "AtomicRelationType": "xIntent", "AtomicInference": "to help"}, "premise": "PersonX finds my keys", "hypothesis": "Because PersonX wanted to help", "update": "PersonX was going in the opposite direction", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11069", "update_paraphrase": "PersonX was heading in the complete opposite direction.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.24285714285714283, "pred_conf_shift": -0.019957784563302994, "syntactic_distance": 0.0}, {"confidence": [0.9684716463088989, 0.03152838721871376], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11069.gpt3.4", "original_example": {"example_id": "atomic.train.11069", "premise_hypothesis_id": "atomic.train.5208", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "IrCusmjyTI5-T2H9qZowIw==", "AtomicEventRelationId": "fBiQnHKxx0m5R8PiohkcBg==", "AtomicRelationType": "xIntent", "AtomicInference": "to help"}, "premise": "PersonX finds my keys", "hypothesis": "Because PersonX wanted to help", "update": "PersonX was going in the opposite direction", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11069", "update_paraphrase": "PersonX was going the other way.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3729774499005268, "pred_conf_shift": -0.005922276526689529, "syntactic_distance": 0.0625}, {"confidence": [0.926348090171814, 0.07365194708108902], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11069.gpt3.2", "original_example": {"example_id": "atomic.train.11069", "premise_hypothesis_id": "atomic.train.5208", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "IrCusmjyTI5-T2H9qZowIw==", "AtomicEventRelationId": "fBiQnHKxx0m5R8PiohkcBg==", "AtomicRelationType": "xIntent", "AtomicInference": "to help"}, "premise": "PersonX finds my keys", "hypothesis": "Because PersonX wanted to help", "update": "PersonX was going in the opposite direction", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11069", "update_paraphrase": "PersonX was traveling in the other direction.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.26295133437990575, "pred_conf_shift": 0.03620128333568573, "syntactic_distance": 0.0}, {"confidence": [0.9781805872917175, 0.021819356828927994], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11069.gpt3.3", "original_example": {"example_id": "atomic.train.11069", "premise_hypothesis_id": "atomic.train.5208", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "IrCusmjyTI5-T2H9qZowIw==", "AtomicEventRelationId": "fBiQnHKxx0m5R8PiohkcBg==", "AtomicRelationType": "xIntent", "AtomicInference": "to help"}, "premise": "PersonX finds my keys", "hypothesis": "Because PersonX wanted to help", "update": "PersonX was going in the opposite direction", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11069", "update_paraphrase": "PersonX was heading the other way.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.40466798159105855, "pred_conf_shift": -0.015631306916475296, "syntactic_distance": 0.0625}, {"confidence": [0.9770932197570801, 0.02290681190788746], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.11069.gpt3.0", "original_example": {"example_id": "atomic.train.11069", "premise_hypothesis_id": "atomic.train.5208", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "IrCusmjyTI5-T2H9qZowIw==", "AtomicEventRelationId": "fBiQnHKxx0m5R8PiohkcBg==", "AtomicRelationType": "xIntent", "AtomicInference": "to help"}, "premise": "PersonX finds my keys", "hypothesis": "Because PersonX wanted to help", "update": "PersonX was going in the opposite direction", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.11069", "update_paraphrase": "PersonX was going in the other direction.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0908424908424908, "pred_conf_shift": -0.014543851837515831, "syntactic_distance": 0.0}]}, "atomic.train.27987": {"original_confidence": [0.31704026460647583, 0.6829597353935242], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.7475308179855347, 0.25246915221214294], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.27987.gpt3.7", "original_example": {"example_id": "atomic.train.27987", "premise_hypothesis_id": "atomic.train.12721", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_5HQHVzWVIDfTe86h8mM1Q==", "AtomicEventRelationId": "7iRcta8yQOAWb_EXSxWykQ==", "AtomicRelationType": "xWant", "AtomicInference": "to read newspaper sitting on it"}, "premise": "PersonX sits tight", "hypothesis": "As a result, PersonX wants to read newspaper sitting on it", "update": "PersonX is bored", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27987", "update_paraphrase": "PersonX is feeling bored and wants to find something to do.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6160714285714286, "pred_conf_shift": -0.4304905831813812, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.7229195237159729, 0.2770804762840271], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.27987.gpt3.0", "original_example": {"example_id": "atomic.train.27987", "premise_hypothesis_id": "atomic.train.12721", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_5HQHVzWVIDfTe86h8mM1Q==", "AtomicEventRelationId": "7iRcta8yQOAWb_EXSxWykQ==", "AtomicRelationType": "xWant", "AtomicInference": "to read newspaper sitting on it"}, "premise": "PersonX sits tight", "hypothesis": "As a result, PersonX wants to read newspaper sitting on it", "update": "PersonX is bored", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27987", "update_paraphrase": "PersonX is bored because there is nothing to do.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5, "pred_conf_shift": -0.40587925910949707, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.729961633682251, 0.27003833651542664], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.27987.gpt3.6", "original_example": {"example_id": "atomic.train.27987", "premise_hypothesis_id": "atomic.train.12721", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_5HQHVzWVIDfTe86h8mM1Q==", "AtomicEventRelationId": "7iRcta8yQOAWb_EXSxWykQ==", "AtomicRelationType": "xWant", "AtomicInference": "to read newspaper sitting on it"}, "premise": "PersonX sits tight", "hypothesis": "As a result, PersonX wants to read newspaper sitting on it", "update": "PersonX is bored", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27987", "update_paraphrase": "PersonX is feeling bored and would like to find something to do.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6416666666666666, "pred_conf_shift": -0.41292139887809753, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.204630509018898, 0.7953693866729736], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.27987.gpt3.2", "original_example": {"example_id": "atomic.train.27987", "premise_hypothesis_id": "atomic.train.12721", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_5HQHVzWVIDfTe86h8mM1Q==", "AtomicEventRelationId": "7iRcta8yQOAWb_EXSxWykQ==", "AtomicRelationType": "xWant", "AtomicInference": "to read newspaper sitting on it"}, "premise": "PersonX sits tight", "hypothesis": "As a result, PersonX wants to read newspaper sitting on it", "update": "PersonX is bored", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27987", "update_paraphrase": "PersonX needs something to do to break up the monotony.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.7383949383949384, "pred_conf_shift": 0.11240965127944946, "syntactic_distance": 0.26666666666666666}, {"confidence": [0.979404866695404, 0.020595163106918335], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.27987.gpt3.3", "original_example": {"example_id": "atomic.train.27987", "premise_hypothesis_id": "atomic.train.12721", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_5HQHVzWVIDfTe86h8mM1Q==", "AtomicEventRelationId": "7iRcta8yQOAWb_EXSxWykQ==", "AtomicRelationType": "xWant", "AtomicInference": "to read newspaper sitting on it"}, "premise": "PersonX sits tight", "hypothesis": "As a result, PersonX wants to read newspaper sitting on it", "update": "PersonX is bored", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27987", "update_paraphrase": "PersonX is not entertained and wants to do something else.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6346153846153846, "pred_conf_shift": -0.6623645722866058, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.9746277332305908, 0.025372279807925224], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.27987.gpt3.1", "original_example": {"example_id": "atomic.train.27987", "premise_hypothesis_id": "atomic.train.12721", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_5HQHVzWVIDfTe86h8mM1Q==", "AtomicEventRelationId": "7iRcta8yQOAWb_EXSxWykQ==", "AtomicRelationType": "xWant", "AtomicInference": "to read newspaper sitting on it"}, "premise": "PersonX sits tight", "hypothesis": "As a result, PersonX wants to read newspaper sitting on it", "update": "PersonX is bored", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27987", "update_paraphrase": "PersonX is not amused and would like to be doing something else.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6702380952380953, "pred_conf_shift": -0.657587455585599, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.9420713186264038, 0.05792870745062828], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.27987.gpt3.4", "original_example": {"example_id": "atomic.train.27987", "premise_hypothesis_id": "atomic.train.12721", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_5HQHVzWVIDfTe86h8mM1Q==", "AtomicEventRelationId": "7iRcta8yQOAWb_EXSxWykQ==", "AtomicRelationType": "xWant", "AtomicInference": "to read newspaper sitting on it"}, "premise": "PersonX sits tight", "hypothesis": "As a result, PersonX wants to read newspaper sitting on it", "update": "PersonX is bored", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27987", "update_paraphrase": "PersonX is not entertained and would like to find something to do.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6816666666666666, "pred_conf_shift": -0.6250310279428959, "syntactic_distance": 0.3157894736842105}, {"confidence": [0.7820168137550354, 0.2179831862449646], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.27987.gpt3.5", "original_example": {"example_id": "atomic.train.27987", "premise_hypothesis_id": "atomic.train.12721", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_5HQHVzWVIDfTe86h8mM1Q==", "AtomicEventRelationId": "7iRcta8yQOAWb_EXSxWykQ==", "AtomicRelationType": "xWant", "AtomicInference": "to read newspaper sitting on it"}, "premise": "PersonX sits tight", "hypothesis": "As a result, PersonX wants to read newspaper sitting on it", "update": "PersonX is bored", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27987", "update_paraphrase": "PersonX is bored and would like to find something fun to do.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6, "pred_conf_shift": -0.46497654914855957, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.3057621419429779, 0.6942378878593445], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.27987.gpt3.8", "original_example": {"example_id": "atomic.train.27987", "premise_hypothesis_id": "atomic.train.12721", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "_5HQHVzWVIDfTe86h8mM1Q==", "AtomicEventRelationId": "7iRcta8yQOAWb_EXSxWykQ==", "AtomicRelationType": "xWant", "AtomicInference": "to read newspaper sitting on it"}, "premise": "PersonX sits tight", "hypothesis": "As a result, PersonX wants to read newspaper sitting on it", "update": "PersonX is bored", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.27987", "update_paraphrase": "PersonX is bored and has nothing to do.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4545454545454546, "pred_conf_shift": 0.011278152465820312, "syntactic_distance": 0.2777777777777778}]}, "atomic.train.26955": {"original_confidence": [0.5418994426727295, 0.45810049772262573], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.3907403349876404, 0.6092596650123596], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.26955.gpt3.0", "original_example": {"example_id": "atomic.train.26955", "premise_hypothesis_id": "atomic.train.12267", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "hgPrYQckyeqZ7STrGG8iWQ==", "AtomicEventRelationId": "OpsWnirDtmfic8BLnTIonQ==", "AtomicRelationType": "xReact", "AtomicInference": "unaware"}, "premise": "PersonX runs through PersonY's head", "hypothesis": "PersonX is seen as unaware", "update": "X is committed to a girl other than Y.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26955", "update_paraphrase": "X is not committed to Y, but is instead committed to another girl.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37878787878787873, "pred_conf_shift": 0.1511591672897339, "syntactic_distance": 0.3333333333333333}, {"confidence": [0.5140077471733093, 0.48599228262901306], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.26955.gpt3.2", "original_example": {"example_id": "atomic.train.26955", "premise_hypothesis_id": "atomic.train.12267", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "hgPrYQckyeqZ7STrGG8iWQ==", "AtomicEventRelationId": "OpsWnirDtmfic8BLnTIonQ==", "AtomicRelationType": "xReact", "AtomicInference": "unaware"}, "premise": "PersonX runs through PersonY's head", "hypothesis": "PersonX is seen as unaware", "update": "X is committed to a girl other than Y.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26955", "update_paraphrase": "X is in a relationship with someone other than Y.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.31202204228520014, "pred_conf_shift": 0.02789178490638733, "syntactic_distance": 0.25}, {"confidence": [0.3760254383087158, 0.6239745616912842], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.26955.gpt3.1", "original_example": {"example_id": "atomic.train.26955", "premise_hypothesis_id": "atomic.train.12267", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "hgPrYQckyeqZ7STrGG8iWQ==", "AtomicEventRelationId": "OpsWnirDtmfic8BLnTIonQ==", "AtomicRelationType": "xReact", "AtomicInference": "unaware"}, "premise": "PersonX runs through PersonY's head", "hypothesis": "PersonX is seen as unaware", "update": "X is committed to a girl other than Y.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26955", "update_paraphrase": "X is loyal to another girl instead of Y.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.32533670033670037, "pred_conf_shift": 0.16587406396865845, "syntactic_distance": 0.1875}]}, "atomic.train.17788": {"original_confidence": [0.5259996652603149, 0.47400036454200745], "original_prediction": 0, "gold_label": 0, "bucket_confidences": [{"confidence": [0.39492687582969666, 0.6050732135772705], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17788.gpt3.0", "original_example": {"example_id": "atomic.train.17788", "premise_hypothesis_id": "atomic.train.8279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h694ebsT8Njn1QPdIoPFsA==", "AtomicEventRelationId": "NYHMqSFbciAeV1BsLsqNkg==", "AtomicRelationType": "xNeed", "AtomicInference": "to accuse hom"}, "premise": "PersonX puts PersonY away", "hypothesis": "Before, PersonX needed to accuse hom", "update": "PersonX illegally arrested PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17788", "update_paraphrase": "PersonY was arrested by PersonX unlawfully.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.35927318295739347, "pred_conf_shift": -0.1310727894306183, "syntactic_distance": 0.4117647058823529}, {"confidence": [0.4438456892967224, 0.5561543703079224], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17788.gpt3.3", "original_example": {"example_id": "atomic.train.17788", "premise_hypothesis_id": "atomic.train.8279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h694ebsT8Njn1QPdIoPFsA==", "AtomicEventRelationId": "NYHMqSFbciAeV1BsLsqNkg==", "AtomicRelationType": "xNeed", "AtomicInference": "to accuse hom"}, "premise": "PersonX puts PersonY away", "hypothesis": "Before, PersonX needed to accuse hom", "update": "PersonX illegally arrested PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17788", "update_paraphrase": "PersonX unlawfully arrested PersonY.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.1685855263157895, "pred_conf_shift": -0.08215397596359253, "syntactic_distance": 0.1875}, {"confidence": [0.5658881664276123, 0.43411195278167725], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.17788.gpt3.1", "original_example": {"example_id": "atomic.train.17788", "premise_hypothesis_id": "atomic.train.8279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h694ebsT8Njn1QPdIoPFsA==", "AtomicEventRelationId": "NYHMqSFbciAeV1BsLsqNkg==", "AtomicRelationType": "xNeed", "AtomicInference": "to accuse hom"}, "premise": "PersonX puts PersonY away", "hypothesis": "Before, PersonX needed to accuse hom", "update": "PersonX illegally arrested PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17788", "update_paraphrase": "PersonX arrested PersonY without cause or legal justification.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.46031746031746035, "pred_conf_shift": 0.03988850116729736, "syntactic_distance": 0.4444444444444444}, {"confidence": [0.3656604588031769, 0.6343395709991455], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17788.gpt3.2", "original_example": {"example_id": "atomic.train.17788", "premise_hypothesis_id": "atomic.train.8279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h694ebsT8Njn1QPdIoPFsA==", "AtomicEventRelationId": "NYHMqSFbciAeV1BsLsqNkg==", "AtomicRelationType": "xNeed", "AtomicInference": "to accuse hom"}, "premise": "PersonX puts PersonY away", "hypothesis": "Before, PersonX needed to accuse hom", "update": "PersonX illegally arrested PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17788", "update_paraphrase": "PersonY was arrested unlawfully by PersonX.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3592731829573935, "pred_conf_shift": -0.16033920645713806, "syntactic_distance": 0.4117647058823529}, {"confidence": [0.7630858421325684, 0.23691406846046448], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.17788.gpt3.4", "original_example": {"example_id": "atomic.train.17788", "premise_hypothesis_id": "atomic.train.8279", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "h694ebsT8Njn1QPdIoPFsA==", "AtomicEventRelationId": "NYHMqSFbciAeV1BsLsqNkg==", "AtomicRelationType": "xNeed", "AtomicInference": "to accuse hom"}, "premise": "PersonX puts PersonY away", "hypothesis": "Before, PersonX needed to accuse hom", "update": "PersonX illegally arrested PersonY.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17788", "update_paraphrase": "PersonY was arrested by PersonX without just cause.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.49476911976911975, "pred_conf_shift": 0.23708617687225342, "syntactic_distance": 0.4117647058823529}]}, "atomic.train.3759": {"original_confidence": [0.1943901926279068, 0.8056097030639648], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.05455290153622627, 0.9454470276832581], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.3759.gpt3.2", "original_example": {"example_id": "atomic.train.3759", "premise_hypothesis_id": "atomic.train.1767", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oHcFNi0rXb6mZdEjRYMq6A==", "AtomicEventRelationId": "o7c5w4-XT2e_exg5b1WTrQ==", "AtomicRelationType": "xReact", "AtomicInference": "angry"}, "premise": "PersonX is losing money", "hypothesis": "PersonX is seen as angry", "update": "PersonX has a gambling problem.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3759", "update_paraphrase": "PersonX's gambling addiction is a serious issue.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.478968253968254, "pred_conf_shift": 0.1398373246192932, "syntactic_distance": 0.15}, {"confidence": [0.5490285158157349, 0.45097148418426514], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3759.gpt3.0", "original_example": {"example_id": "atomic.train.3759", "premise_hypothesis_id": "atomic.train.1767", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oHcFNi0rXb6mZdEjRYMq6A==", "AtomicEventRelationId": "o7c5w4-XT2e_exg5b1WTrQ==", "AtomicRelationType": "xReact", "AtomicInference": "angry"}, "premise": "PersonX is losing money", "hypothesis": "PersonX is seen as angry", "update": "PersonX has a gambling problem.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3759", "update_paraphrase": "PersonX has an addiction to gambling.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.40404040404040403, "pred_conf_shift": -0.3546382188796997, "syntactic_distance": 0.17647058823529413}, {"confidence": [0.5066773295402527, 0.4933227002620697], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3759.gpt3.3", "original_example": {"example_id": "atomic.train.3759", "premise_hypothesis_id": "atomic.train.1767", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oHcFNi0rXb6mZdEjRYMq6A==", "AtomicEventRelationId": "o7c5w4-XT2e_exg5b1WTrQ==", "AtomicRelationType": "xReact", "AtomicInference": "angry"}, "premise": "PersonX is losing money", "hypothesis": "PersonX is seen as angry", "update": "PersonX has a gambling problem.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3759", "update_paraphrase": "PersonX is addicted to gambling.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5283333333333333, "pred_conf_shift": -0.31228700280189514, "syntactic_distance": 0.23529411764705882}, {"confidence": [0.7751415371894836, 0.22485844790935516], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.3759.gpt3.1", "original_example": {"example_id": "atomic.train.3759", "premise_hypothesis_id": "atomic.train.1767", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "oHcFNi0rXb6mZdEjRYMq6A==", "AtomicEventRelationId": "o7c5w4-XT2e_exg5b1WTrQ==", "AtomicRelationType": "xReact", "AtomicInference": "angry"}, "premise": "PersonX is losing money", "hypothesis": "PersonX is seen as angry", "update": "PersonX has a gambling problem.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.3759", "update_paraphrase": "PersonX needs help because they can't stop gambling.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5296037296037296, "pred_conf_shift": -0.5807512551546097, "syntactic_distance": 0.2631578947368421}]}, "atomic.train.17949": {"original_confidence": [0.48926082253456116, 0.5107392072677612], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.5480198860168457, 0.4519800841808319], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.17949.gpt3.1", "original_example": {"example_id": "atomic.train.17949", "premise_hypothesis_id": "atomic.train.8352", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "N37ZUypdlMDxVNSw2I1R7g==", "AtomicEventRelationId": "-pOSV_YMDbmFJDK3qjsf8A==", "AtomicRelationType": "xEffect", "AtomicInference": "Person x is splashed with water."}, "premise": "PersonX catches two fish", "hypothesis": "PersonX then person x is splashed with water.", "update": "PersonX releases one of the fish from the boat.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17949", "update_paraphrase": "PersonX sets one of the fish free from the boat.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.15789473684210525, "pred_conf_shift": -0.05875912308692932, "syntactic_distance": 0.13636363636363635}, {"confidence": [0.4986638128757477, 0.5013361573219299], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.17949.gpt3.0", "original_example": {"example_id": "atomic.train.17949", "premise_hypothesis_id": "atomic.train.8352", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "N37ZUypdlMDxVNSw2I1R7g==", "AtomicEventRelationId": "-pOSV_YMDbmFJDK3qjsf8A==", "AtomicRelationType": "xEffect", "AtomicInference": "Person x is splashed with water."}, "premise": "PersonX catches two fish", "hypothesis": "PersonX then person x is splashed with water.", "update": "PersonX releases one of the fish from the boat.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17949", "update_paraphrase": "PersonX frees one of the fish from the boat.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.06210826210826209, "pred_conf_shift": -0.009403049945831299, "syntactic_distance": 0.0}, {"confidence": [0.8108457922935486, 0.18915429711341858], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.17949.gpt3.2", "original_example": {"example_id": "atomic.train.17949", "premise_hypothesis_id": "atomic.train.8352", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "N37ZUypdlMDxVNSw2I1R7g==", "AtomicEventRelationId": "-pOSV_YMDbmFJDK3qjsf8A==", "AtomicRelationType": "xEffect", "AtomicInference": "Person x is splashed with water."}, "premise": "PersonX catches two fish", "hypothesis": "PersonX then person x is splashed with water.", "update": "PersonX releases one of the fish from the boat.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.17949", "update_paraphrase": "PersonX throws one of the fish back into the water from the boat.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2902097902097903, "pred_conf_shift": -0.32158491015434265, "syntactic_distance": 0.12}]}, "atomic.train.2801": {"original_confidence": [0.39203184843063354, 0.6079682111740112], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.3112313747406006, 0.6887686252593994], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2801.gpt3.5", "original_example": {"example_id": "atomic.train.2801", "premise_hypothesis_id": "atomic.train.1320", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZF6kYPO8tO0-Hq18Gi8e_w==", "AtomicEventRelationId": "_b2r5t2y5mSE-2WIDlCxhg==", "AtomicRelationType": "xReact", "AtomicInference": "frustrated"}, "premise": "PersonX yells silently", "hypothesis": "PersonX is seen as frustrated", "update": "PersonX lost their voice and wants a cup of coffee.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2801", "update_paraphrase": "PersonX lost their voice and is craving a cup of coffee.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.11337868480725616, "pred_conf_shift": 0.08080041408538818, "syntactic_distance": 0.045454545454545456}, {"confidence": [0.2420305460691452, 0.7579694986343384], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2801.gpt3.2", "original_example": {"example_id": "atomic.train.2801", "premise_hypothesis_id": "atomic.train.1320", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZF6kYPO8tO0-Hq18Gi8e_w==", "AtomicEventRelationId": "_b2r5t2y5mSE-2WIDlCxhg==", "AtomicRelationType": "xReact", "AtomicInference": "frustrated"}, "premise": "PersonX yells silently", "hypothesis": "PersonX is seen as frustrated", "update": "PersonX lost their voice and wants a cup of coffee.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2801", "update_paraphrase": "Person X needs a cup of coffee because they lost their voice.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3554778554778555, "pred_conf_shift": 0.15000128746032715, "syntactic_distance": 0.391304347826087}, {"confidence": [0.18151699006557465, 0.8184829354286194], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2801.gpt3.1", "original_example": {"example_id": "atomic.train.2801", "premise_hypothesis_id": "atomic.train.1320", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZF6kYPO8tO0-Hq18Gi8e_w==", "AtomicEventRelationId": "_b2r5t2y5mSE-2WIDlCxhg==", "AtomicRelationType": "xReact", "AtomicInference": "frustrated"}, "premise": "PersonX yells silently", "hypothesis": "PersonX is seen as frustrated", "update": "PersonX lost their voice and wants a cup of coffee.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2801", "update_paraphrase": "PersonX lost their voice and is in need of a cup of coffee.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.19530710835058673, "pred_conf_shift": 0.21051472425460815, "syntactic_distance": 0.045454545454545456}, {"confidence": [0.21356309950351715, 0.786436915397644], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2801.gpt3.7", "original_example": {"example_id": "atomic.train.2801", "premise_hypothesis_id": "atomic.train.1320", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZF6kYPO8tO0-Hq18Gi8e_w==", "AtomicEventRelationId": "_b2r5t2y5mSE-2WIDlCxhg==", "AtomicRelationType": "xReact", "AtomicInference": "frustrated"}, "premise": "PersonX yells silently", "hypothesis": "PersonX is seen as frustrated", "update": "PersonX lost their voice and wants a cup of coffee.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2801", "update_paraphrase": "PersonX needs a cup of coffee because they lost their voice.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.36507936507936506, "pred_conf_shift": 0.1784687042236328, "syntactic_distance": 0.3181818181818182}, {"confidence": [0.4219789505004883, 0.5780211687088013], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2801.gpt3.4", "original_example": {"example_id": "atomic.train.2801", "premise_hypothesis_id": "atomic.train.1320", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZF6kYPO8tO0-Hq18Gi8e_w==", "AtomicEventRelationId": "_b2r5t2y5mSE-2WIDlCxhg==", "AtomicRelationType": "xReact", "AtomicInference": "frustrated"}, "premise": "PersonX yells silently", "hypothesis": "PersonX is seen as frustrated", "update": "PersonX lost their voice and wants a cup of coffee.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2801", "update_paraphrase": "PersonX's throat is sore and they want some coffee to help them feel better.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5156746031746031, "pred_conf_shift": -0.02994704246520996, "syntactic_distance": 0.4074074074074074}]}, "atomic.train.30739": {"original_confidence": [0.11296252906322479, 0.8870373964309692], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.11611810326576233, 0.8838818669319153], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30739.gpt3.4", "original_example": {"example_id": "atomic.train.30739", "premise_hypothesis_id": "atomic.train.13956", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Mw3vOeuipdWCcqaY9Ht7xQ==", "AtomicEventRelationId": "aFQRyX_9kBreQV7pgwXQhA==", "AtomicRelationType": "xNeed", "AtomicInference": "get home sale classified ads"}, "premise": "PersonX needs a home", "hypothesis": "Before, PersonX needed get home sale classified ads", "update": "PersonX moves to a place they are unfamiliar qwith", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30739", "update_paraphrase": "PersonX relocates to an unknown area.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.49878618113912226, "pred_conf_shift": -0.003155529499053955, "syntactic_distance": 0.0625}, {"confidence": [0.06905754655599594, 0.9309424757957458], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30739.gpt3.1", "original_example": {"example_id": "atomic.train.30739", "premise_hypothesis_id": "atomic.train.13956", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Mw3vOeuipdWCcqaY9Ht7xQ==", "AtomicEventRelationId": "aFQRyX_9kBreQV7pgwXQhA==", "AtomicRelationType": "xNeed", "AtomicInference": "get home sale classified ads"}, "premise": "PersonX needs a home", "hypothesis": "Before, PersonX needed get home sale classified ads", "update": "PersonX moves to a place they are unfamiliar qwith", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30739", "update_paraphrase": "PersonX relocate to an unfamiliar area.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.400976800976801, "pred_conf_shift": 0.04390507936477661, "syntactic_distance": 0.125}, {"confidence": [0.07292123883962631, 0.9270788431167603], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30739.gpt3.2", "original_example": {"example_id": "atomic.train.30739", "premise_hypothesis_id": "atomic.train.13956", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Mw3vOeuipdWCcqaY9Ht7xQ==", "AtomicEventRelationId": "aFQRyX_9kBreQV7pgwXQhA==", "AtomicRelationType": "xNeed", "AtomicInference": "get home sale classified ads"}, "premise": "PersonX needs a home", "hypothesis": "Before, PersonX needed get home sale classified ads", "update": "PersonX moves to a place they are unfamiliar qwith", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30739", "update_paraphrase": "PersonX relocates to a new and unknown place.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.43730433349810505, "pred_conf_shift": 0.040041446685791016, "syntactic_distance": 0.0625}, {"confidence": [0.06591292470693588, 0.9340870380401611], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30739.gpt3.0", "original_example": {"example_id": "atomic.train.30739", "premise_hypothesis_id": "atomic.train.13956", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Mw3vOeuipdWCcqaY9Ht7xQ==", "AtomicEventRelationId": "aFQRyX_9kBreQV7pgwXQhA==", "AtomicRelationType": "xNeed", "AtomicInference": "get home sale classified ads"}, "premise": "PersonX needs a home", "hypothesis": "Before, PersonX needed get home sale classified ads", "update": "PersonX moves to a place they are unfamiliar qwith", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30739", "update_paraphrase": "PersonX moves to an unfamiliar place", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.3642857142857142, "pred_conf_shift": 0.047049641609191895, "syntactic_distance": 0.0}, {"confidence": [0.12079095095396042, 0.8792091012001038], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.30739.gpt3.3", "original_example": {"example_id": "atomic.train.30739", "premise_hypothesis_id": "atomic.train.13956", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "Mw3vOeuipdWCcqaY9Ht7xQ==", "AtomicEventRelationId": "aFQRyX_9kBreQV7pgwXQhA==", "AtomicRelationType": "xNeed", "AtomicInference": "get home sale classified ads"}, "premise": "PersonX needs a home", "hypothesis": "Before, PersonX needed get home sale classified ads", "update": "PersonX moves to a place they are unfamiliar qwith", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.30739", "update_paraphrase": "PersonX relocates to an unknown place.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.4892623716153127, "pred_conf_shift": -0.007828295230865479, "syntactic_distance": 0.0}]}, "atomic.train.19863": {"original_confidence": [0.30264824628829956, 0.6973516345024109], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.3264150619506836, 0.6735849380493164], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.19863.gpt3.2", "original_example": {"example_id": "atomic.train.19863", "premise_hypothesis_id": "atomic.train.9203", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "4xZTUIK6buyZuOZY5bWyGw==", "AtomicEventRelationId": "eIpPcrIiAL7QRpL2gypS4g==", "AtomicRelationType": "xReact", "AtomicInference": "bad"}, "premise": "PersonX gets tickets", "hypothesis": "PersonX is seen as bad", "update": "The tickets are speeding tickets.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19863", "update_paraphrase": "The tickets are for speeding offenses.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.29862258953168047, "pred_conf_shift": -0.023766696453094482, "syntactic_distance": 0.1111111111111111}, {"confidence": [0.5484650135040283, 0.4515349566936493], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.19863.gpt3.0", "original_example": {"example_id": "atomic.train.19863", "premise_hypothesis_id": "atomic.train.9203", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "4xZTUIK6buyZuOZY5bWyGw==", "AtomicEventRelationId": "eIpPcrIiAL7QRpL2gypS4g==", "AtomicRelationType": "xReact", "AtomicInference": "bad"}, "premise": "PersonX gets tickets", "hypothesis": "PersonX is seen as bad", "update": "The tickets are speeding tickets.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19863", "update_paraphrase": "The tickets are traffic tickets for speeding.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.23333333333333328, "pred_conf_shift": -0.2458166778087616, "syntactic_distance": 0.16666666666666666}, {"confidence": [0.2937907874584198, 0.7062092423439026], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.19863.gpt3.1", "original_example": {"example_id": "atomic.train.19863", "premise_hypothesis_id": "atomic.train.9203", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "4xZTUIK6buyZuOZY5bWyGw==", "AtomicEventRelationId": "eIpPcrIiAL7QRpL2gypS4g==", "AtomicRelationType": "xReact", "AtomicInference": "bad"}, "premise": "PersonX gets tickets", "hypothesis": "PersonX is seen as bad", "update": "The tickets are speeding tickets.", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.19863", "update_paraphrase": "The tickets are for speeding.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.18181818181818182, "pred_conf_shift": 0.0088576078414917, "syntactic_distance": 0.16666666666666666}]}, "atomic.train.10980": {"original_confidence": [0.2177082747220993, 0.7822917103767395], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.6401380300521851, 0.35986196994781494], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10980.gpt3.1", "original_example": {"example_id": "atomic.train.10980", "premise_hypothesis_id": "atomic.train.5166", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "cddf2oP1KKiwrEC3bHrEhg==", "AtomicEventRelationId": "q4NveTJn1nhxgu9PEh_xZg==", "AtomicRelationType": "xIntent", "AtomicInference": "to not get a cavity"}, "premise": "PersonX cleans PersonX's teeth", "hypothesis": "Because PersonX wanted to not get a cavity", "update": "PersonX wears dentures.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10980", "update_paraphrase": "PersonX has false teeth.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5131868131868131, "pred_conf_shift": 0.42242975533008575, "syntactic_distance": 0.06666666666666667}, {"confidence": [0.7541118264198303, 0.24588802456855774], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10980.gpt3.2", "original_example": {"example_id": "atomic.train.10980", "premise_hypothesis_id": "atomic.train.5166", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "cddf2oP1KKiwrEC3bHrEhg==", "AtomicEventRelationId": "q4NveTJn1nhxgu9PEh_xZg==", "AtomicRelationType": "xIntent", "AtomicInference": "to not get a cavity"}, "premise": "PersonX cleans PersonX's teeth", "hypothesis": "Because PersonX wanted to not get a cavity", "update": "PersonX wears dentures.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10980", "update_paraphrase": "PersonX has to wear fake teeth.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5213675213675213, "pred_conf_shift": 0.536403551697731, "syntactic_distance": 0.14285714285714285}, {"confidence": [0.6286718845367432, 0.3713280260562897], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10980.gpt3.0", "original_example": {"example_id": "atomic.train.10980", "premise_hypothesis_id": "atomic.train.5166", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "cddf2oP1KKiwrEC3bHrEhg==", "AtomicEventRelationId": "q4NveTJn1nhxgu9PEh_xZg==", "AtomicRelationType": "xIntent", "AtomicInference": "to not get a cavity"}, "premise": "PersonX cleans PersonX's teeth", "hypothesis": "Because PersonX wanted to not get a cavity", "update": "PersonX wears dentures.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10980", "update_paraphrase": "PersonX wears false teeth.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.36080586080586075, "pred_conf_shift": 0.41096360981464386, "syntactic_distance": 0.06666666666666667}, {"confidence": [0.31477057933807373, 0.685229480266571], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.10980.gpt3.4", "original_example": {"example_id": "atomic.train.10980", "premise_hypothesis_id": "atomic.train.5166", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "cddf2oP1KKiwrEC3bHrEhg==", "AtomicEventRelationId": "q4NveTJn1nhxgu9PEh_xZg==", "AtomicRelationType": "xIntent", "AtomicInference": "to not get a cavity"}, "premise": "PersonX cleans PersonX's teeth", "hypothesis": "Because PersonX wanted to not get a cavity", "update": "PersonX wears dentures.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10980", "update_paraphrase": "PersonX has a set of dentures that they wear.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5685185185185185, "pred_conf_shift": 0.09706230461597443, "syntactic_distance": 0.13333333333333333}, {"confidence": [0.3218890130519867, 0.6781108975410461], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.10980.gpt3.3", "original_example": {"example_id": "atomic.train.10980", "premise_hypothesis_id": "atomic.train.5166", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "cddf2oP1KKiwrEC3bHrEhg==", "AtomicEventRelationId": "q4NveTJn1nhxgu9PEh_xZg==", "AtomicRelationType": "xIntent", "AtomicInference": "to not get a cavity"}, "premise": "PersonX cleans PersonX's teeth", "hypothesis": "Because PersonX wanted to not get a cavity", "update": "PersonX wears dentures.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10980", "update_paraphrase": "PersonX uses dentures.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.17592592592592587, "pred_conf_shift": 0.10418073832988739, "syntactic_distance": 0.0}, {"confidence": [0.6616830825805664, 0.338316947221756], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.10980.gpt3.6", "original_example": {"example_id": "atomic.train.10980", "premise_hypothesis_id": "atomic.train.5166", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "cddf2oP1KKiwrEC3bHrEhg==", "AtomicEventRelationId": "q4NveTJn1nhxgu9PEh_xZg==", "AtomicRelationType": "xIntent", "AtomicInference": "to not get a cavity"}, "premise": "PersonX cleans PersonX's teeth", "hypothesis": "Because PersonX wanted to not get a cavity", "update": "PersonX wears dentures.", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.10980", "update_paraphrase": "PersonX has a set of false teeth.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6514141414141414, "pred_conf_shift": 0.4439748078584671, "syntactic_distance": 0.13333333333333333}]}, "atomic.train.2783": {"original_confidence": [0.3234393894672394, 0.6765605807304382], "original_prediction": 1, "gold_label": 1, "bucket_confidences": [{"confidence": [0.4879506826400757, 0.5120493173599243], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2783.gpt3.0", "original_example": {"example_id": "atomic.train.2783", "premise_hypothesis_id": "atomic.train.1312", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "nC0OtIZIPZrjudR6x0OhSg==", "AtomicEventRelationId": "t_onAJwCYZr1AfTN1ue9fw==", "AtomicRelationType": "xReact", "AtomicInference": "like he is in a hurry"}, "premise": "PersonX immediately ran", "hypothesis": "PersonX is seen as like he is in a hurry", "update": "The bus is going down the street", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2783", "update_paraphrase": "The bus is traveling down the street", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.11224489795918369, "pred_conf_shift": -0.16451126337051392, "syntactic_distance": 0.0}, {"confidence": [0.4735713005065918, 0.526428759098053], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.2783.gpt3.2", "original_example": {"example_id": "atomic.train.2783", "premise_hypothesis_id": "atomic.train.1312", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "nC0OtIZIPZrjudR6x0OhSg==", "AtomicEventRelationId": "t_onAJwCYZr1AfTN1ue9fw==", "AtomicRelationType": "xReact", "AtomicInference": "like he is in a hurry"}, "premise": "PersonX immediately ran", "hypothesis": "PersonX is seen as like he is in a hurry", "update": "The bus is going down the street", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2783", "update_paraphrase": "The bus is going down the street.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.0, "pred_conf_shift": -0.15013182163238525, "syntactic_distance": 0.0}, {"confidence": [0.6456378102302551, 0.3543621897697449], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2783.gpt3.3", "original_example": {"example_id": "atomic.train.2783", "premise_hypothesis_id": "atomic.train.1312", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "nC0OtIZIPZrjudR6x0OhSg==", "AtomicEventRelationId": "t_onAJwCYZr1AfTN1ue9fw==", "AtomicRelationType": "xReact", "AtomicInference": "like he is in a hurry"}, "premise": "PersonX immediately ran", "hypothesis": "PersonX is seen as like he is in a hurry", "update": "The bus is going down the street", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2783", "update_paraphrase": "The bus is travelling down the street.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.11428571428571427, "pred_conf_shift": -0.32219839096069336, "syntactic_distance": 0.0}, {"confidence": [0.6991239190101624, 0.3008762001991272], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.2783.gpt3.1", "original_example": {"example_id": "atomic.train.2783", "premise_hypothesis_id": "atomic.train.1312", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "nC0OtIZIPZrjudR6x0OhSg==", "AtomicEventRelationId": "t_onAJwCYZr1AfTN1ue9fw==", "AtomicRelationType": "xReact", "AtomicInference": "like he is in a hurry"}, "premise": "PersonX immediately ran", "hypothesis": "PersonX is seen as like he is in a hurry", "update": "The bus is going down the street", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.2783", "update_paraphrase": "The bus is driving down the street.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.10714285714285715, "pred_conf_shift": -0.37568438053131104, "syntactic_distance": 0.0}]}, "atomic.train.26172": {"original_confidence": [0.29954323172569275, 0.7004567980766296], "original_prediction": 1, "gold_label": 0, "bucket_confidences": [{"confidence": [0.4635483920574188, 0.5364515781402588], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.26172.gpt3.2", "original_example": {"example_id": "atomic.train.26172", "premise_hypothesis_id": "atomic.train.11939", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "w-1oXTmnELbugRFdxYJw_Q==", "AtomicEventRelationId": "_Rt0I-wRoinBqLIvxvQ3hQ==", "AtomicRelationType": "xAttr", "AtomicInference": "dependable"}, "premise": "PersonX is a happy couple", "hypothesis": "As a result, PersonX feels dependable", "update": "They don\u2019t make a lot of money", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26172", "update_paraphrase": "They don't earn a lot of money.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.2522321428571428, "pred_conf_shift": 0.16400516033172607, "syntactic_distance": 0.21052631578947367}, {"confidence": [0.529887318611145, 0.47011271119117737], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.26172.gpt3.1", "original_example": {"example_id": "atomic.train.26172", "premise_hypothesis_id": "atomic.train.11939", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "w-1oXTmnELbugRFdxYJw_Q==", "AtomicEventRelationId": "_Rt0I-wRoinBqLIvxvQ3hQ==", "AtomicRelationType": "xAttr", "AtomicInference": "dependable"}, "premise": "PersonX is a happy couple", "hypothesis": "As a result, PersonX feels dependable", "update": "They don\u2019t make a lot of money", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26172", "update_paraphrase": "They earn a modest income.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.5409554730983303, "pred_conf_shift": 0.23034408688545227, "syntactic_distance": 0.2777777777777778}, {"confidence": [0.2561563551425934, 0.7438434958457947], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.26172.gpt3.0", "original_example": {"example_id": "atomic.train.26172", "premise_hypothesis_id": "atomic.train.11939", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "w-1oXTmnELbugRFdxYJw_Q==", "AtomicEventRelationId": "_Rt0I-wRoinBqLIvxvQ3hQ==", "AtomicRelationType": "xAttr", "AtomicInference": "dependable"}, "premise": "PersonX is a happy couple", "hypothesis": "As a result, PersonX feels dependable", "update": "They don\u2019t make a lot of money", "update_type": "weakener", "label": 0, "annotated_paraphrases": null}, "original_example_id": "atomic.train.26172", "update_paraphrase": "They're not rolling in dough.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.6814058956916099, "pred_conf_shift": -0.043386876583099365, "syntactic_distance": 0.10526315789473684}]}, "atomic.train.24587": {"original_confidence": [0.8323596119880676, 0.16764038801193237], "original_prediction": 0, "gold_label": 1, "bucket_confidences": [{"confidence": [0.2539267838001251, 0.7460732460021973], "prediction": 1, "paraphrased_example": {"paraphrase_id": "atomic.train.24587.gpt3.2", "original_example": {"example_id": "atomic.train.24587", "premise_hypothesis_id": "atomic.train.11252", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZSjWJGKKEDoybKQC411XNQ==", "AtomicEventRelationId": "0wIOk5d6yWbs0fr1BdJiXw==", "AtomicRelationType": "xWant", "AtomicInference": "jump up and down"}, "premise": "PersonX also found", "hypothesis": "As a result, PersonX wants jump up and down", "update": "PersonX was searching for treasure in the ocean", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24587", "update_paraphrase": "PersonX was hoping to find some treasure while scuba diving in the ocean.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.37806637806637805, "pred_conf_shift": 0.5784328579902649, "syntactic_distance": 0.11764705882352941}, {"confidence": [0.9197885394096375, 0.08021146059036255], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.24587.gpt3.1", "original_example": {"example_id": "atomic.train.24587", "premise_hypothesis_id": "atomic.train.11252", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZSjWJGKKEDoybKQC411XNQ==", "AtomicEventRelationId": "0wIOk5d6yWbs0fr1BdJiXw==", "AtomicRelationType": "xWant", "AtomicInference": "jump up and down"}, "premise": "PersonX also found", "hypothesis": "As a result, PersonX wants jump up and down", "update": "PersonX was searching for treasure in the ocean", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24587", "update_paraphrase": "Person X was looking for treasure in the ocean.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.14140271493212664, "pred_conf_shift": -0.08742892742156982, "syntactic_distance": 0.10526315789473684}, {"confidence": [0.9155611991882324, 0.08443877100944519], "prediction": 0, "paraphrased_example": {"paraphrase_id": "atomic.train.24587.gpt3.0", "original_example": {"example_id": "atomic.train.24587", "premise_hypothesis_id": "atomic.train.11252", "data_source": "atomic", "source_example_metadata": {"AtomicEventId": "ZSjWJGKKEDoybKQC411XNQ==", "AtomicEventRelationId": "0wIOk5d6yWbs0fr1BdJiXw==", "AtomicRelationType": "xWant", "AtomicInference": "jump up and down"}, "premise": "PersonX also found", "hypothesis": "As a result, PersonX wants jump up and down", "update": "PersonX was searching for treasure in the ocean", "update_type": "strengthener", "label": 1, "annotated_paraphrases": null}, "original_example_id": "atomic.train.24587", "update_paraphrase": "PersonX was looking for treasure in the ocean.", "worker_id": "gpt3", "premise_paraphrase": null, "hypothesis_paraphrase": null, "automatic_system_metadata": {"model": "text-davinci-002", "temperature": 1.0, "top_p": 1.0, "max_tokens": 50}}, "lexical_distance": 0.078125, "pred_conf_shift": -0.08320161700248718, "syntactic_distance": 0.058823529411764705}]}}