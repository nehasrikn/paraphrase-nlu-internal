{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3106a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef06694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_json, PROJECT_ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c08819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_to_add_edit_defeasible(verification_row):\n",
    "    \"\"\"\n",
    "    In some cases, the paraphrases were edited for grammaticality, etc. \n",
    "    If something is valid, then grab the edited paraphrase if it exists.\n",
    "    \"\"\"\n",
    "    if pd.isnull(verification_row.paraphrase_edit):\n",
    "        return verification_row.paraphrase_example\n",
    "    \n",
    "    og_example = \"\\n\".join(verification_row.paraphrase_example.split('\\n')[:-2])\n",
    "    paraphrase_edit = verification_row.paraphrase_edit\n",
    "    return og_example + '\\n    Paraphrase: %s\\n' % paraphrase_edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dcc2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_to_add_edit_abductive(verification_row):\n",
    "    if pd.isnull(verification_row.paraphrase_edit_hyp1) and pd.isnull(verification_row.paraphrase_edit_hyp2):\n",
    "        return verification_row.paraphrase_example\n",
    "    \n",
    "    split = verification_row.paraphrase_example.split('\\n')\n",
    "    og_example = \"\\n\".join(split[:-3])\n",
    "    \n",
    "    hyp1 = verification_row.paraphrase_edit_hyp1 if not pd.isnull(verification_row.paraphrase_edit_hyp1) else split[8]\n",
    "    hyp2 = verification_row.paraphrase_edit_hyp2 if not pd.isnull(verification_row.paraphrase_edit_hyp2) else split[9]\n",
    "\n",
    "    if not hyp1.strip().startswith('Hyp 1 Paraphrase:'):\n",
    "        hyp1 = '    Hyp 1 Paraphrase: ' + hyp1\n",
    "    \n",
    "    if not hyp2.strip().startswith('Hyp 2 Paraphrase:'):\n",
    "        hyp2 = '    Hyp 2 Paraphrase: ' + hyp2\n",
    "    \n",
    "    return og_example + '\\n\\n%s\\n%s' % (hyp1, hyp2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2cb864",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_examples = []\n",
    "\n",
    "\n",
    "validation_dir = os.path.join(PROJECT_ROOT_DIR, 'annotated_data/paraphrase_validation/validation_annotation_files/human/')\n",
    "\n",
    "all_verification_examples = []\n",
    "\n",
    "for validation_file in os.listdir(validation_dir):\n",
    "    print(validation_file)\n",
    "    data_source = pd.read_csv(os.path.join(validation_dir, validation_file))\n",
    "    \n",
    "    ### SAMPLE FOR RACHEL\n",
    "    invalid = data_source[data_source['paraphrase_valid'] == 'invalid'].sample(12, random_state=42)\n",
    "    valid = data_source[data_source['paraphrase_valid'] == 'valid'].sample(13, random_state=42)\n",
    "    \n",
    "    verification = pd.concat([invalid, valid]).sample(frac=1, random_state=42)\n",
    "    modification_func = modify_to_add_edit_defeasible if not 'anli' in validation_file else modify_to_add_edit_abductive\n",
    "    \n",
    "    verification['paraphrase_example'] = verification.apply(modification_func, axis=1)\n",
    "    all_verification_examples.append(verification)\n",
    "    \n",
    "    \n",
    "    ### SAMPLE FOR INSTRUCTIONS\n",
    "    invalid_instructions = data_source[data_source['paraphrase_valid'] == 'invalid'].sample(5, random_state=123)\n",
    "    valid_instructions = data_source[data_source['paraphrase_valid'] == 'valid'].sample(5, random_state=123)\n",
    "    \n",
    "    instruction_verification = pd.concat([invalid_instructions, valid_instructions]).sample(frac=1, random_state=42)\n",
    "    \n",
    "    instruction_verification['paraphrase_example'] = instruction_verification.apply(modification_func, axis=1)\n",
    "    instruction_examples.append(instruction_verification)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ff2527",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sample = pd.concat(all_verification_examples)[['paraphrase_id', 'paraphrase_example', 'original_example_id', 'paraphrase_valid']]\n",
    "all_sample.to_csv(os.path.join(PROJECT_ROOT_DIR, 'experiments/data_characterization/validation_sample.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a13c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = pd.concat(instruction_examples)[['paraphrase_id', 'paraphrase_example', 'original_example_id', 'paraphrase_valid']]\n",
    "instructions.to_csv(os.path.join(PROJECT_ROOT_DIR, 'experiments/data_characterization/validation_instructions.csv'),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:para-nlu]",
   "language": "python",
   "name": "conda-env-para-nlu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
