{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d24e2328-88bb-4c2a-af0f-1cd9d50bff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "692f962b-203a-4e11-b70f-5c9a4bf07662",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('../../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81606d64-84e9-4fd2-b669-cdaca7ff0ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 26816.43it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 27745.98it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 23900.26it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 27495.70it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 25827.00it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 32607.00it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 20252.55it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 33213.27it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 30381.18it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 33807.58it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 28310.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 34710.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 29712.28it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 32730.16it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 28748.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 32826.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 32801.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 34094.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 26453.81it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 34908.32it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 31859.02it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 36120.43it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 31077.21it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 33741.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 35703.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 34503.98it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 35324.62it/s]\n"
     ]
    }
   ],
   "source": [
    "from experiments.adversarial_filtering.partial_input_baselines.partial_input_result_buckets import partial_input_human\n",
    "from experiments.result_buckets import roberta_specialized\n",
    "from experiments.bucket_analysis import BucketDatasetResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95ae1a35-6c4b-4e5d-94b2-c0184afec86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32msnli\u001b[0m\n",
      "Num examples with artifacts: 162 \n",
      "Num examples without artifacts: 88\n",
      "Artifact Examples:\n",
      " 0.9136816394956326 0.8576071788740203\n",
      "\n",
      "Non-artifact Examples:\n",
      " 0.840066176960795 0.7962838752509412\n",
      "\n",
      "Whole dataset:\n",
      " 0.9009562634337458\n",
      "\n",
      "\u001b[32matomic\u001b[0m\n",
      "Num examples with artifacts: 144 \n",
      "Num examples without artifacts: 106\n",
      "Artifact Examples:\n",
      " 0.8738089920171768 0.7804624765562913\n",
      "\n",
      "Non-artifact Examples:\n",
      " 0.8647201672184828 0.7919005918513963\n",
      "\n",
      "Whole dataset:\n",
      " 0.8709695949924339\n",
      "\n",
      "\u001b[32msocial\u001b[0m\n",
      "Num examples with artifacts: 136 \n",
      "Num examples without artifacts: 114\n",
      "Artifact Examples:\n",
      " 0.9087786432543185 0.8576346183544377\n",
      "\n",
      "Non-artifact Examples:\n",
      " 0.9348597589038101 0.9071291363480685\n",
      "\n",
      "Whole dataset:\n",
      " 0.9193559020581005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from simple_colors import * \n",
    "for dataset in ['snli', 'atomic', 'social']:\n",
    "    print(green(dataset))\n",
    "    artifacts_ids = []\n",
    "    non_artifacts_ids  = []\n",
    "    \n",
    "    for b in partial_input_human[f'{dataset}-human'].buckets:\n",
    "        if b.original_example_prediction.correct:\n",
    "            artifacts_ids.append(b.original_example_id)\n",
    "        else:\n",
    "            non_artifacts_ids.append(b.original_example_id)\n",
    "\n",
    "    artifacts = BucketDatasetResult(\n",
    "        [b for b in roberta_specialized[f'{dataset}-human'].buckets if b.original_example_id in artifacts_ids]\n",
    "    )\n",
    "    no_artifacts = BucketDatasetResult(\n",
    "        [b for b in roberta_specialized[f'{dataset}-human'].buckets if b.original_example_id in non_artifacts_ids]\n",
    "    )\n",
    "    print('Num examples with artifacts:', len(artifacts_ids), '\\nNum examples without artifacts:', len(non_artifacts_ids))\n",
    "\n",
    "    print('Artifact Examples:\\n', artifacts.linguistic_robustness_summary(roberta_specialized[f'{dataset}-test'])['stay_prob_corrected'], artifacts.linguistic_robustness_summary(roberta_specialized[f'{dataset}-test'])['paraphrase_accuracy_corrected'])\n",
    "    print()\n",
    "    print('Non-artifact Examples:\\n', no_artifacts.linguistic_robustness_summary(roberta_specialized[f'{dataset}-test'])['stay_prob_corrected'], no_artifacts.linguistic_robustness_summary(roberta_specialized[f'{dataset}-test'])['paraphrase_accuracy_corrected'])\n",
    "    print()\n",
    "    print('Whole dataset:\\n', roberta_specialized[f'{dataset}-human'].linguistic_robustness_summary(roberta_specialized[f'{dataset}-test'])['stay_prob_corrected'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab2f56f-47a3-4221-ae48-860a596e32b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "do the artifacts project through the paraphrase?\n",
    "\n",
    "partial input accuracy on paraphrased examples -> \n",
    "\n",
    "ideal outcome: inconsistency isn't fully due to artifacts (couldn't artifacts be the reason for inconsistency?)\n",
    "how much of the inconsistency is explained by artifacts\n",
    "\n",
    "\n",
    "even on examples that don't contain artifacts we observe inconsistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169e69cf-be68-4c72-9a8f-ab1575da9717",
   "metadata": {},
   "source": [
    "1. do the artifacts project through the paraphrase? -> partial input accuracy and full input accuracy on paraphrased examples compared to original examples (if the drop is more dramatic for partial input than full input then the artifacts aren't projecting)\n",
    "2. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "para-nlu",
   "language": "python",
   "name": "para-nlu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
