{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d24e2328-88bb-4c2a-af0f-1cd9d50bff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "692f962b-203a-4e11-b70f-5c9a4bf07662",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('../../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81606d64-84e9-4fd2-b669-cdaca7ff0ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 19175.89it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 22588.88it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 20956.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 23969.64it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 19437.15it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 22869.21it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 22216.06it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 28895.15it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 26748.02it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 28388.23it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 23843.19it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 26476.52it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 23407.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 23134.10it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 21247.74it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 24177.45it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 23345.27it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 23945.01it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 12928.46it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 25408.94it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 26635.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 27853.58it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 23643.20it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 26849.39it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 28102.16it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 29985.02it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 31687.65it/s]\n"
     ]
    }
   ],
   "source": [
    "from experiments.adversarial_filtering.partial_input_baselines.partial_input_result_buckets import partial_input_human\n",
    "from experiments.result_buckets import roberta_specialized\n",
    "from experiments.bucket_analysis import BucketDatasetResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95ae1a35-6c4b-4e5d-94b2-c0184afec86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32msnli\u001b[0m\n",
      "type            # exs    partial acc_original    full acc_original    partial acc 🪣    full acc 🪣    partial acc 🪣C    full acc 🪣c    P(STAY)    P(STAY)-corrected\n",
      "------------  -------  ----------------------  -------------------  ----------------  -------------  -----------------  --------------  ---------  -------------------\n",
      "artifacts         162                     100                 54.3              81.8           56.6               54.6            85.8       74.7                 91.4\n",
      "no artifacts       88                       0                 45.5              20.7           48.8                6.9            79.6       75.1                 84 \n",
      "\n",
      "\u001b[32matomic\u001b[0m\n",
      "type            # exs    partial acc_original    full acc_original    partial acc 🪣    full acc 🪣    partial acc 🪣C    full acc 🪣c    P(STAY)    P(STAY)-corrected\n",
      "------------  -------  ----------------------  -------------------  ----------------  -------------  -----------------  --------------  ---------  -------------------\n",
      "artifacts         144                     100                 55.6              77.6           58.3               53.9            78         76.4                 87.4\n",
      "no artifacts      106                       0                 50.9              21.3           49.9                8.3            79.2       75.9                 86.5 \n",
      "\n",
      "\u001b[32msocial\u001b[0m\n",
      "type            # exs    partial acc_original    full acc_original    partial acc 🪣    full acc 🪣    partial acc 🪣C    full acc 🪣c    P(STAY)    P(STAY)-corrected\n",
      "------------  -------  ----------------------  -------------------  ----------------  -------------  -----------------  --------------  ---------  -------------------\n",
      "artifacts         136                     100                 52.9              77.2           55.5               58.9            85.8       73.9                 90.9\n",
      "no artifacts      114                       0                 50                28.8           58.7                8.4            90.7       74.7                 93.5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from simple_colors import * \n",
    "from tabulate import tabulate\n",
    "\n",
    "for dataset in ['snli', 'atomic', 'social']:\n",
    "    print(green(dataset))\n",
    "    \n",
    "    artifacts_ids = []\n",
    "    non_artifacts_ids  = []\n",
    "    \n",
    "    for b in partial_input_human[f'{dataset}-human'].buckets:\n",
    "        if b.original_example_prediction.correct:\n",
    "            artifacts_ids.append(b.original_example_id)\n",
    "        else:\n",
    "            non_artifacts_ids.append(b.original_example_id)\n",
    "\n",
    "    full_input_on_artifacts = BucketDatasetResult([b for b in roberta_specialized[f'{dataset}-human'].buckets if b.original_example_id in artifacts_ids])\n",
    "    full_input_on_no_artifacts = BucketDatasetResult([b for b in roberta_specialized[f'{dataset}-human'].buckets if b.original_example_id in non_artifacts_ids])\n",
    "\n",
    "    partial_input_on_artifacts = BucketDatasetResult([b for b in partial_input_human[f'{dataset}-human'].buckets if b.original_example_id in artifacts_ids])\n",
    "    partial_input_on_no_artifacts = BucketDatasetResult([b for b in partial_input_human[f'{dataset}-human'].buckets if b.original_example_id in non_artifacts_ids])\n",
    "\n",
    "    \n",
    "    artifact_data = []\n",
    "\n",
    "    artifact_data.append([\n",
    "        'artifacts', \n",
    "        len(artifacts_ids), \n",
    "        round(100 * partial_input_on_artifacts.original_example_accuracy(), 1),\n",
    "        round(100 * full_input_on_artifacts.original_example_accuracy(), 1),\n",
    "        round(100 * partial_input_on_artifacts.paraphrase_accuracy(), 1),\n",
    "        round(100 * full_input_on_artifacts.paraphrase_accuracy(), 1),\n",
    "        round(100 * partial_input_on_artifacts.calculate_weighted_paraphrase_accuracy(partial_input_human[f'{dataset}-test']), 1),\n",
    "        round(100 * full_input_on_artifacts.calculate_weighted_paraphrase_accuracy(roberta_specialized[f'{dataset}-test']), 1),\n",
    "        round(100 * full_input_on_artifacts.linguistic_robustness_summary(roberta_specialized[f'{dataset}-test'])['stay_prob'], 1), \n",
    "        round(100 * full_input_on_artifacts.linguistic_robustness_summary(roberta_specialized[f'{dataset}-test'])['stay_prob_corrected'], 1)\n",
    "    ])\n",
    "\n",
    "    artifact_data.append([\n",
    "        'no artifacts', \n",
    "        len(non_artifacts_ids), \n",
    "        round(100 * partial_input_on_no_artifacts.original_example_accuracy(), 1),\n",
    "        round(100 * full_input_on_no_artifacts.original_example_accuracy(), 1),\n",
    "        round(100 * partial_input_on_no_artifacts.paraphrase_accuracy(), 1),\n",
    "        round(100 * full_input_on_no_artifacts.paraphrase_accuracy(), 1),\n",
    "        round(100 * partial_input_on_no_artifacts.calculate_weighted_paraphrase_accuracy(partial_input_human[f'{dataset}-test']), 1),\n",
    "        round(100 * full_input_on_no_artifacts.calculate_weighted_paraphrase_accuracy(roberta_specialized[f'{dataset}-test']), 1), \n",
    "        round(100 * full_input_on_no_artifacts.linguistic_robustness_summary(roberta_specialized[f'{dataset}-test'])['stay_prob'], 1),\n",
    "        round(100 * full_input_on_no_artifacts.linguistic_robustness_summary(roberta_specialized[f'{dataset}-test'])['stay_prob_corrected'], 1),\n",
    "    ])\n",
    "        \n",
    "\n",
    "    print(tabulate(artifact_data, headers=[\n",
    "        'type', \n",
    "        '# exs', \n",
    "        'partial acc_original',\n",
    "        'full acc_original',\n",
    "        'partial acc 🪣',\n",
    "        'full acc 🪣',\n",
    "        'partial acc 🪣C',\n",
    "        'full acc 🪣c',\n",
    "        'P(STAY)', \n",
    "        'P(STAY)-corrected']), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab2f56f-47a3-4221-ae48-860a596e32b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "do the artifacts project through the paraphrase?\n",
    "\n",
    "partial input accuracy on paraphrased examples -> \n",
    "\n",
    "ideal outcome: inconsistency isn't fully due to artifacts (couldn't artifacts be the reason for inconsistency?)\n",
    "how much of the inconsistency is explained by artifacts\n",
    "\n",
    "\n",
    "even on examples that don't contain artifacts we observe inconsistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169e69cf-be68-4c72-9a8f-ab1575da9717",
   "metadata": {},
   "source": [
    "1. do the artifacts project through the paraphrase? -> partial input accuracy and full input accuracy on paraphrased examples compared to original examples (if the drop is more dramatic for partial input than full input then the artifacts aren't projecting)\n",
    "2. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "para-nlu",
   "language": "python",
   "name": "para-nlu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
