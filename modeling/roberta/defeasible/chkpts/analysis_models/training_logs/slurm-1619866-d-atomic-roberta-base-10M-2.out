10/30/2023 21:44:11 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False
10/30/2023 21:44:11 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=IntervalStrategy.NO,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_min_num_params=0,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=5e-06,
length_column_name=length,
load_best_model_at_end=False,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=chkpts/analysis_models/minibertas/d-atomic-roberta-base-10M-2/runs/Oct30_21-44-11_clip02.umiacs.umd.edu,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=2.0,
optim=OptimizerNames.ADAMW_HF,
output_dir=chkpts/analysis_models/minibertas/d-atomic-roberta-base-10M-2,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=True,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=chkpts/analysis_models/minibertas/d-atomic-roberta-base-10M-2,
save_on_each_node=False,
save_steps=500,
save_strategy=IntervalStrategy.EPOCH,
save_total_limit=None,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
10/30/2023 21:44:11 - INFO - __main__ - load a local file for train: /fs/clip-projects/rlab/nehasrik/paraphrase-nlu/data_selection/defeasible/atomic/analysis_model_examples/train_examples.csv
10/30/2023 21:44:11 - INFO - __main__ - load a local file for validation: /fs/clip-projects/rlab/nehasrik/paraphrase-nlu/data_selection/defeasible/atomic/analysis_model_examples/dev_examples.csv
10/30/2023 21:44:11 - WARNING - datasets.builder - Using custom data configuration default-20eb8091327cd7b5
10/30/2023 21:44:11 - INFO - datasets.builder - Overwrite dataset info from restored data version.
10/30/2023 21:44:11 - INFO - datasets.info - Loading Dataset info from /fs/clip-projects/rlab/nehasrik/cache/csv/default-20eb8091327cd7b5/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58
10/30/2023 21:44:11 - WARNING - datasets.builder - Reusing dataset csv (/fs/clip-projects/rlab/nehasrik/cache/csv/default-20eb8091327cd7b5/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)
10/30/2023 21:44:11 - INFO - datasets.info - Loading Dataset info from /fs/clip-projects/rlab/nehasrik/cache/csv/default-20eb8091327cd7b5/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 13.12it/s]100%|██████████| 2/2 [00:00<00:00, 13.11it/s]
[INFO|configuration_utils.py:659] 2023-10-30 21:44:12,251 >> loading configuration file https://huggingface.co/nyu-mll/roberta-base-10M-2/resolve/main/config.json from cache at /fs/clip-projects/rlab/nehasrik/cache/e96b8f88d41858c970f350a2c2465f93734a237f140c8196b2c8d124dceb099b.be04f5d77b46017eb2ebd88b2246bc0ba7707d81cee11fcc7eac429cffb1e73a
[INFO|configuration_utils.py:708] 2023-10-30 21:44:12,258 >> Model config RobertaConfig {
  "_name_or_path": "nyu-mll/roberta-base-10M-2",
  "_num_labels": 2,
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_past": true,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.19.4",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_auto.py:371] 2023-10-30 21:44:12,303 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:659] 2023-10-30 21:44:12,361 >> loading configuration file https://huggingface.co/nyu-mll/roberta-base-10M-2/resolve/main/config.json from cache at /fs/clip-projects/rlab/nehasrik/cache/e96b8f88d41858c970f350a2c2465f93734a237f140c8196b2c8d124dceb099b.be04f5d77b46017eb2ebd88b2246bc0ba7707d81cee11fcc7eac429cffb1e73a
[INFO|configuration_utils.py:708] 2023-10-30 21:44:12,362 >> Model config RobertaConfig {
  "_name_or_path": "nyu-mll/roberta-base-10M-2",
  "_num_labels": 2,
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_past": true,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.19.4",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_utils_base.py:1782] 2023-10-30 21:44:13,072 >> loading file https://huggingface.co/nyu-mll/roberta-base-10M-2/resolve/main/vocab.json from cache at /fs/clip-projects/rlab/nehasrik/cache/5ec644c7a898e5f7379309ac115077986f3fb1c7a071f3325deffd8c29e0dfd2.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab
[INFO|tokenization_utils_base.py:1782] 2023-10-30 21:44:13,072 >> loading file https://huggingface.co/nyu-mll/roberta-base-10M-2/resolve/main/merges.txt from cache at /fs/clip-projects/rlab/nehasrik/cache/de75d5d85405274c2c6efc23d13ee1ebcd0d3133e2e5d4a3d26524c462bd3c90.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b
[INFO|tokenization_utils_base.py:1782] 2023-10-30 21:44:13,072 >> loading file https://huggingface.co/nyu-mll/roberta-base-10M-2/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1782] 2023-10-30 21:44:13,072 >> loading file https://huggingface.co/nyu-mll/roberta-base-10M-2/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1782] 2023-10-30 21:44:13,072 >> loading file https://huggingface.co/nyu-mll/roberta-base-10M-2/resolve/main/tokenizer_config.json from cache at None
[INFO|configuration_utils.py:659] 2023-10-30 21:44:13,119 >> loading configuration file https://huggingface.co/nyu-mll/roberta-base-10M-2/resolve/main/config.json from cache at /fs/clip-projects/rlab/nehasrik/cache/e96b8f88d41858c970f350a2c2465f93734a237f140c8196b2c8d124dceb099b.be04f5d77b46017eb2ebd88b2246bc0ba7707d81cee11fcc7eac429cffb1e73a
[INFO|configuration_utils.py:708] 2023-10-30 21:44:13,119 >> Model config RobertaConfig {
  "_name_or_path": "nyu-mll/roberta-base-10M-2",
  "_num_labels": 2,
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_past": true,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.19.4",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|modeling_utils.py:1953] 2023-10-30 21:44:13,771 >> loading weights file https://huggingface.co/nyu-mll/roberta-base-10M-2/resolve/main/pytorch_model.bin from cache at /fs/clip-projects/rlab/nehasrik/cache/da4b2d5dd7d0190a4135bfd69ff41e5ad053bd5ae53db52f9a79000cf3487510.e595b799660c9f175822c10719c7748e35cf053a42f5cfc616a1ef83a0688bfe
[WARNING|modeling_utils.py:2254] 2023-10-30 21:44:17,410 >> Some weights of the model checkpoint at nyu-mll/roberta-base-10M-2 were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:2265] 2023-10-30 21:44:17,410 >> Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at nyu-mll/roberta-base-10M-2 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
sentence1 sentence2
S1+S2 KEYS sentence1 sentence2
10/30/2023 21:44:18 - WARNING - datasets.fingerprint - Parameter 'function'=<function main.<locals>.preprocess_function at 0x7fcaf69114c0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
10/30/2023 21:44:18 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /fs/clip-projects/rlab/nehasrik/cache/csv/default-20eb8091327cd7b5/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-1c80317fa3b1799d.arrow
10/30/2023 21:44:19 - INFO - datasets.fingerprint - Parameter 'function'=<function main.<locals>.preprocess_function at 0x7fcaf69113a0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.
10/30/2023 21:44:19 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /fs/clip-projects/rlab/nehasrik/cache/csv/default-20eb8091327cd7b5/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-bdd640fb06671ad1.arrow
hi
10/30/2023 21:44:19 - INFO - __main__ - Sample 9012 of the training set: {'sentence1': 'PersonX lives happily ever after As a result, PersonX wants to build a house', 'sentence2': 'They are a contractor with house building experience', 'label': 1, 'input_ids': [0, 41761, 1000, 1074, 16534, 655, 71, 287, 10, 898, 6, 18404, 1000, 1072, 7, 1119, 10, 790, 2, 2, 1213, 32, 10, 9254, 19, 790, 745, 676, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/30/2023 21:44:19 - INFO - __main__ - Sample 8024 of the training set: {'sentence1': 'PersonX hands it to PersonY As a result, PersonX feels sincere', 'sentence2': 'PersonX gives a smile to PerosnY', 'label': 1, 'input_ids': [0, 41761, 1000, 1420, 24, 7, 18404, 975, 287, 10, 898, 6, 18404, 1000, 2653, 19255, 2, 2, 41761, 1000, 2029, 10, 6675, 7, 2595, 366, 282, 975, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/30/2023 21:44:19 - INFO - __main__ - Sample 7314 of the training set: {'sentence1': 'PersonX wears flip flops As a result, PersonX wants to walk around the house', 'sentence2': 'PersonX is in their bedroom', 'label': 1, 'input_ids': [0, 41761, 1000, 15033, 11113, 2342, 5090, 287, 10, 898, 6, 18404, 1000, 1072, 7, 1656, 198, 5, 790, 2, 2, 41761, 1000, 16, 11, 49, 8140, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
[INFO|trainer.py:622] 2023-10-30 21:44:36,125 >> The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: sentence1, sentence2. If sentence1, sentence2 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
/fs/clip-projects/rlab/nehasrik/miniconda3/envs/para-nlu/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
[INFO|trainer.py:1419] 2023-10-30 21:44:36,142 >> ***** Running training *****
[INFO|trainer.py:1420] 2023-10-30 21:44:36,142 >>   Num examples = 28350
[INFO|trainer.py:1421] 2023-10-30 21:44:36,142 >>   Num Epochs = 2
[INFO|trainer.py:1422] 2023-10-30 21:44:36,142 >>   Instantaneous batch size per device = 64
[INFO|trainer.py:1423] 2023-10-30 21:44:36,142 >>   Total train batch size (w. parallel, distributed & accumulation) = 64
[INFO|trainer.py:1424] 2023-10-30 21:44:36,142 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1425] 2023-10-30 21:44:36,142 >>   Total optimization steps = 886
[WARNING|training_args.py:1095] 2023-10-30 21:44:36,158 >> Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.
  0%|          | 0/886 [00:00<?, ?it/s]  0%|          | 1/886 [00:00<13:22,  1.10it/s]  0%|          | 2/886 [00:01<10:53,  1.35it/s]  0%|          | 3/886 [00:02<10:05,  1.46it/s]  0%|          | 4/886 [00:02<09:41,  1.52it/s]  1%|          | 5/886 [00:03<09:28,  1.55it/s]  1%|          | 6/886 [00:04<09:21,  1.57it/s]  1%|          | 7/886 [00:04<09:16,  1.58it/s]  1%|          | 8/886 [00:05<09:12,  1.59it/s]  1%|          | 9/886 [00:05<09:09,  1.59it/s]  1%|          | 10/886 [00:06<09:09,  1.59it/s]  1%|          | 11/886 [00:07<09:07,  1.60it/s]  1%|▏         | 12/886 [00:07<09:06,  1.60it/s]  1%|▏         | 13/886 [00:08<09:06,  1.60it/s]  2%|▏         | 14/886 [00:09<09:05,  1.60it/s]  2%|▏         | 15/886 [00:09<09:04,  1.60it/s]  2%|▏         | 16/886 [00:10<09:04,  1.60it/s]  2%|▏         | 17/886 [00:10<09:03,  1.60it/s]  2%|▏         | 18/886 [00:11<09:02,  1.60it/s]  2%|▏         | 19/886 [00:12<09:02,  1.60it/s]  2%|▏         | 20/886 [00:12<09:02,  1.60it/s]  2%|▏         | 21/886 [00:13<09:01,  1.60it/s]  2%|▏         | 22/886 [00:14<09:00,  1.60it/s]  3%|▎         | 23/886 [00:14<09:00,  1.60it/s]  3%|▎         | 24/886 [00:15<09:01,  1.59it/s]  3%|▎         | 25/886 [00:15<09:00,  1.59it/s]  3%|▎         | 26/886 [00:16<08:59,  1.59it/s]  3%|▎         | 27/886 [00:17<08:59,  1.59it/s]  3%|▎         | 28/886 [00:17<08:58,  1.59it/s]  3%|▎         | 29/886 [00:18<08:57,  1.59it/s]  3%|▎         | 30/886 [00:19<08:57,  1.59it/s]  3%|▎         | 31/886 [00:19<08:57,  1.59it/s]  4%|▎         | 32/886 [00:20<08:56,  1.59it/s]  4%|▎         | 33/886 [00:20<08:55,  1.59it/s]  4%|▍         | 34/886 [00:21<08:56,  1.59it/s]  4%|▍         | 35/886 [00:22<08:55,  1.59it/s]  4%|▍         | 36/886 [00:22<08:55,  1.59it/s]  4%|▍         | 37/886 [00:23<08:54,  1.59it/s]  4%|▍         | 38/886 [00:24<08:54,  1.59it/s]  4%|▍         | 39/886 [00:24<08:54,  1.59it/s]  5%|▍         | 40/886 [00:25<08:53,  1.59it/s]  5%|▍         | 41/886 [00:25<08:52,  1.59it/s]  5%|▍         | 42/886 [00:26<08:52,  1.58it/s]  5%|▍         | 43/886 [00:27<08:53,  1.58it/s]  5%|▍         | 44/886 [00:27<08:52,  1.58it/s]  5%|▌         | 45/886 [00:28<08:51,  1.58it/s]  5%|▌         | 46/886 [00:29<08:51,  1.58it/s]  5%|▌         | 47/886 [00:29<08:50,  1.58it/s]  5%|▌         | 48/886 [00:30<08:50,  1.58it/s]  6%|▌         | 49/886 [00:31<08:49,  1.58it/s]  6%|▌         | 50/886 [00:31<08:49,  1.58it/s]  6%|▌         | 51/886 [00:32<08:50,  1.57it/s]  6%|▌         | 52/886 [00:32<08:49,  1.58it/s]  6%|▌         | 53/886 [00:33<08:48,  1.58it/s]  6%|▌         | 54/886 [00:34<08:47,  1.58it/s]  6%|▌         | 55/886 [00:34<08:47,  1.58it/s]  6%|▋         | 56/886 [00:35<08:46,  1.58it/s]  6%|▋         | 57/886 [00:36<08:45,  1.58it/s]  7%|▋         | 58/886 [00:36<08:45,  1.57it/s]  7%|▋         | 59/886 [00:37<08:45,  1.57it/s]  7%|▋         | 60/886 [00:38<08:45,  1.57it/s]  7%|▋         | 61/886 [00:38<08:44,  1.57it/s]  7%|▋         | 62/886 [00:39<08:43,  1.57it/s]  7%|▋         | 63/886 [00:39<08:43,  1.57it/s]  7%|▋         | 64/886 [00:40<08:43,  1.57it/s]  7%|▋         | 65/886 [00:41<08:42,  1.57it/s]  7%|▋         | 66/886 [00:41<08:42,  1.57it/s]  8%|▊         | 67/886 [00:42<08:41,  1.57it/s]  8%|▊         | 68/886 [00:43<08:41,  1.57it/s]  8%|▊         | 69/886 [00:43<08:41,  1.57it/s]  8%|▊         | 70/886 [00:44<08:41,  1.57it/s]  8%|▊         | 71/886 [00:45<08:40,  1.57it/s]  8%|▊         | 72/886 [00:45<08:39,  1.57it/s]  8%|▊         | 73/886 [00:46<08:39,  1.57it/s]  8%|▊         | 74/886 [00:46<08:39,  1.56it/s]  8%|▊         | 75/886 [00:47<08:37,  1.57it/s]  9%|▊         | 76/886 [00:48<08:36,  1.57it/s]  9%|▊         | 77/886 [00:48<08:36,  1.57it/s]  9%|▉         | 78/886 [00:49<08:36,  1.56it/s]  9%|▉         | 79/886 [00:50<08:36,  1.56it/s]  9%|▉         | 80/886 [00:50<08:36,  1.56it/s]  9%|▉         | 81/886 [00:51<08:35,  1.56it/s]  9%|▉         | 82/886 [00:52<08:34,  1.56it/s]  9%|▉         | 83/886 [00:52<08:34,  1.56it/s]  9%|▉         | 84/886 [00:53<08:34,  1.56it/s] 10%|▉         | 85/886 [00:54<08:33,  1.56it/s] 10%|▉         | 86/886 [00:54<08:32,  1.56it/s] 10%|▉         | 87/886 [00:55<08:32,  1.56it/s] 10%|▉         | 88/886 [00:55<08:31,  1.56it/s] 10%|█         | 89/886 [00:56<08:31,  1.56it/s] 10%|█         | 90/886 [00:57<08:31,  1.56it/s] 10%|█         | 91/886 [00:57<08:30,  1.56it/s] 10%|█         | 92/886 [00:58<08:29,  1.56it/s] 10%|█         | 93/886 [00:59<08:29,  1.56it/s] 11%|█         | 94/886 [00:59<08:29,  1.56it/s] 11%|█         | 95/886 [01:00<08:28,  1.55it/s] 11%|█         | 96/886 [01:01<08:28,  1.55it/s] 11%|█         | 97/886 [01:01<08:26,  1.56it/s] 11%|█         | 98/886 [01:02<08:26,  1.56it/s] 11%|█         | 99/886 [01:02<08:25,  1.56it/s] 11%|█▏        | 100/886 [01:03<08:25,  1.55it/s] 11%|█▏        | 101/886 [01:04<08:25,  1.55it/s] 12%|█▏        | 102/886 [01:04<08:24,  1.55it/s] 12%|█▏        | 103/886 [01:05<08:24,  1.55it/s] 12%|█▏        | 104/886 [01:06<08:24,  1.55it/s] 12%|█▏        | 105/886 [01:06<08:23,  1.55it/s] 12%|█▏        | 106/886 [01:07<08:23,  1.55it/s] 12%|█▏        | 107/886 [01:08<08:23,  1.55it/s] 12%|█▏        | 108/886 [01:08<08:22,  1.55it/s] 12%|█▏        | 109/886 [01:09<08:21,  1.55it/s] 12%|█▏        | 110/886 [01:10<08:20,  1.55it/s] 13%|█▎        | 111/886 [01:10<08:20,  1.55it/s] 13%|█▎        | 112/886 [01:11<08:20,  1.55it/s] 13%|█▎        | 113/886 [01:12<08:20,  1.54it/s] 13%|█▎        | 114/886 [01:12<08:19,  1.54it/s] 13%|█▎        | 115/886 [01:13<08:18,  1.55it/s] 13%|█▎        | 116/886 [01:13<08:18,  1.55it/s] 13%|█▎        | 117/886 [01:14<08:17,  1.54it/s] 13%|█▎        | 118/886 [01:15<08:17,  1.54it/s] 13%|█▎        | 119/886 [01:15<08:16,  1.54it/s] 14%|█▎        | 120/886 [01:16<08:16,  1.54it/s] 14%|█▎        | 121/886 [01:17<08:15,  1.54it/s] 14%|█▍        | 122/886 [01:17<08:14,  1.54it/s] 14%|█▍        | 123/886 [01:18<08:13,  1.54it/s] 14%|█▍        | 124/886 [01:19<08:13,  1.54it/s] 14%|█▍        | 125/886 [01:19<08:13,  1.54it/s] 14%|█▍        | 126/886 [01:20<08:13,  1.54it/s] 14%|█▍        | 127/886 [01:21<08:12,  1.54it/s] 14%|█▍        | 128/886 [01:21<08:11,  1.54it/s] 15%|█▍        | 129/886 [01:22<08:10,  1.54it/s] 15%|█▍        | 130/886 [01:23<08:10,  1.54it/s] 15%|█▍        | 131/886 [01:23<08:10,  1.54it/s] 15%|█▍        | 132/886 [01:24<08:09,  1.54it/s] 15%|█▌        | 133/886 [01:25<08:08,  1.54it/s] 15%|█▌        | 134/886 [01:25<08:07,  1.54it/s] 15%|█▌        | 135/886 [01:26<08:06,  1.54it/s] 15%|█▌        | 136/886 [01:26<08:06,  1.54it/s] 15%|█▌        | 137/886 [01:27<08:06,  1.54it/s] 16%|█▌        | 138/886 [01:28<08:11,  1.52it/s] 16%|█▌        | 139/886 [01:28<08:10,  1.52it/s] 16%|█▌        | 140/886 [01:29<08:08,  1.53it/s] 16%|█▌        | 141/886 [01:30<08:08,  1.52it/s] 16%|█▌        | 142/886 [01:30<08:08,  1.52it/s] 16%|█▌        | 143/886 [01:31<08:06,  1.53it/s] 16%|█▋        | 144/886 [01:32<08:07,  1.52it/s] 16%|█▋        | 145/886 [01:32<08:07,  1.52it/s] 16%|█▋        | 146/886 [01:33<08:06,  1.52it/s] 17%|█▋        | 147/886 [01:34<08:05,  1.52it/s] 17%|█▋        | 148/886 [01:34<08:09,  1.51it/s] 17%|█▋        | 149/886 [01:35<08:07,  1.51it/s] 17%|█▋        | 150/886 [01:36<08:06,  1.51it/s] 17%|█▋        | 151/886 [01:36<08:05,  1.51it/s] 17%|█▋        | 152/886 [01:37<08:11,  1.49it/s] 17%|█▋        | 153/886 [01:38<08:10,  1.50it/s] 17%|█▋        | 154/886 [01:38<08:07,  1.50it/s] 17%|█▋        | 155/886 [01:39<08:03,  1.51it/s] 18%|█▊        | 156/886 [01:40<08:02,  1.51it/s] 18%|█▊        | 157/886 [01:40<08:01,  1.51it/s] 18%|█▊        | 158/886 [01:41<08:00,  1.51it/s] 18%|█▊        | 159/886 [01:42<08:00,  1.51it/s] 18%|█▊        | 160/886 [01:42<08:02,  1.50it/s] 18%|█▊        | 161/886 [01:43<08:01,  1.51it/s] 18%|█▊        | 162/886 [01:44<07:58,  1.51it/s] 18%|█▊        | 163/886 [01:44<07:57,  1.51it/s] 19%|█▊        | 164/886 [01:45<08:05,  1.49it/s] 19%|█▊        | 165/886 [01:46<08:04,  1.49it/s] 19%|█▊        | 166/886 [01:46<08:02,  1.49it/s] 19%|█▉        | 167/886 [01:47<07:58,  1.50it/s] 19%|█▉        | 168/886 [01:48<08:00,  1.50it/s] 19%|█▉        | 169/886 [01:48<07:58,  1.50it/s] 19%|█▉        | 170/886 [01:49<07:56,  1.50it/s] 19%|█▉        | 171/886 [01:50<07:52,  1.51it/s] 19%|█▉        | 172/886 [01:50<07:54,  1.50it/s] 20%|█▉        | 173/886 [01:51<07:53,  1.51it/s] 20%|█▉        | 174/886 [01:52<07:51,  1.51it/s] 20%|█▉        | 175/886 [01:52<07:50,  1.51it/s] 20%|█▉        | 176/886 [01:53<07:56,  1.49it/s] 20%|█▉        | 177/886 [01:54<07:53,  1.50it/s] 20%|██        | 178/886 [01:54<07:50,  1.50it/s] 20%|██        | 179/886 [01:55<07:47,  1.51it/s] 20%|██        | 180/886 [01:56<07:52,  1.49it/s] 20%|██        | 181/886 [01:56<07:49,  1.50it/s] 21%|██        | 182/886 [01:57<07:45,  1.51it/s] 21%|██        | 183/886 [01:58<07:43,  1.52it/s] 21%|██        | 184/886 [01:58<07:43,  1.51it/s] 21%|██        | 185/886 [01:59<07:45,  1.51it/s] 21%|██        | 186/886 [02:00<07:43,  1.51it/s] 21%|██        | 187/886 [02:00<07:40,  1.52it/s] 21%|██        | 188/886 [02:01<07:39,  1.52it/s] 21%|██▏       | 189/886 [02:02<07:43,  1.50it/s] 21%|██▏       | 190/886 [02:02<07:40,  1.51it/s] 22%|██▏       | 191/886 [02:03<07:38,  1.52it/s] 22%|██▏       | 192/886 [02:04<07:36,  1.52it/s] 22%|██▏       | 193/886 [02:04<07:45,  1.49it/s] 22%|██▏       | 194/886 [02:05<07:47,  1.48it/s] 22%|██▏       | 195/886 [02:06<07:44,  1.49it/s] 22%|██▏       | 196/886 [02:06<07:49,  1.47it/s] 22%|██▏       | 197/886 [02:07<07:49,  1.47it/s] 22%|██▏       | 198/886 [02:08<07:45,  1.48it/s] 22%|██▏       | 199/886 [02:08<07:50,  1.46it/s] 23%|██▎       | 200/886 [02:09<07:45,  1.47it/s] 23%|██▎       | 201/886 [02:10<07:41,  1.48it/s] 23%|██▎       | 202/886 [02:10<07:37,  1.50it/s] 23%|██▎       | 203/886 [02:11<07:37,  1.49it/s] 23%|██▎       | 204/886 [02:12<07:34,  1.50it/s] 23%|██▎       | 205/886 [02:12<07:31,  1.51it/s] 23%|██▎       | 206/886 [02:13<07:28,  1.51it/s] 23%|██▎       | 207/886 [02:14<07:34,  1.49it/s] 23%|██▎       | 208/886 [02:14<07:30,  1.50it/s] 24%|██▎       | 209/886 [02:15<07:28,  1.51it/s] 24%|██▎       | 210/886 [02:16<07:26,  1.52it/s] 24%|██▍       | 211/886 [02:16<07:31,  1.49it/s] 24%|██▍       | 212/886 [02:17<07:28,  1.50it/s] 24%|██▍       | 213/886 [02:18<07:26,  1.51it/s] 24%|██▍       | 214/886 [02:18<07:25,  1.51it/s] 24%|██▍       | 215/886 [02:19<07:29,  1.49it/s] 24%|██▍       | 216/886 [02:20<07:27,  1.50it/s] 24%|██▍       | 217/886 [02:20<07:25,  1.50it/s] 25%|██▍       | 218/886 [02:21<07:22,  1.51it/s] 25%|██▍       | 219/886 [02:22<07:28,  1.49it/s] 25%|██▍       | 220/886 [02:22<07:27,  1.49it/s] 25%|██▍       | 221/886 [02:23<07:25,  1.49it/s] 25%|██▌       | 222/886 [02:24<07:28,  1.48it/s] 25%|██▌       | 223/886 [02:24<07:25,  1.49it/s] 25%|██▌       | 224/886 [02:25<07:21,  1.50it/s] 25%|██▌       | 225/886 [02:26<07:19,  1.50it/s] 26%|██▌       | 226/886 [02:26<07:23,  1.49it/s] 26%|██▌       | 227/886 [02:27<07:22,  1.49it/s] 26%|██▌       | 228/886 [02:28<07:18,  1.50it/s] 26%|██▌       | 229/886 [02:28<07:15,  1.51it/s] 26%|██▌       | 230/886 [02:29<07:17,  1.50it/s] 26%|██▌       | 231/886 [02:30<07:16,  1.50it/s] 26%|██▌       | 232/886 [02:30<07:14,  1.51it/s] 26%|██▋       | 233/886 [02:31<07:13,  1.51it/s] 26%|██▋       | 234/886 [02:32<07:19,  1.48it/s] 27%|██▋       | 235/886 [02:32<07:18,  1.48it/s] 27%|██▋       | 236/886 [02:33<07:15,  1.49it/s] 27%|██▋       | 237/886 [02:34<07:17,  1.48it/s] 27%|██▋       | 238/886 [02:34<07:15,  1.49it/s] 27%|██▋       | 239/886 [02:35<07:12,  1.50it/s] 27%|██▋       | 240/886 [02:36<07:09,  1.50it/s] 27%|██▋       | 241/886 [02:36<07:09,  1.50it/s] 27%|██▋       | 242/886 [02:37<07:11,  1.49it/s] 27%|██▋       | 243/886 [02:38<07:08,  1.50it/s] 28%|██▊       | 244/886 [02:38<07:06,  1.51it/s] 28%|██▊       | 245/886 [02:39<07:10,  1.49it/s] 28%|██▊       | 246/886 [02:40<07:06,  1.50it/s] 28%|██▊       | 247/886 [02:40<07:05,  1.50it/s] 28%|██▊       | 248/886 [02:41<07:02,  1.51it/s] 28%|██▊       | 249/886 [02:42<07:08,  1.49it/s] 28%|██▊       | 250/886 [02:42<07:04,  1.50it/s] 28%|██▊       | 251/886 [02:43<07:02,  1.50it/s] 28%|██▊       | 252/886 [02:44<07:01,  1.51it/s] 29%|██▊       | 253/886 [02:44<07:05,  1.49it/s] 29%|██▊       | 254/886 [02:45<07:04,  1.49it/s] 29%|██▉       | 255/886 [02:46<07:01,  1.50it/s] 29%|██▉       | 256/886 [02:46<07:00,  1.50it/s] 29%|██▉       | 257/886 [02:47<07:01,  1.49it/s] 29%|██▉       | 258/886 [02:48<06:58,  1.50it/s] 29%|██▉       | 259/886 [02:48<06:55,  1.51it/s] 29%|██▉       | 260/886 [02:49<06:53,  1.51it/s] 29%|██▉       | 261/886 [02:50<06:57,  1.50it/s] 30%|██▉       | 262/886 [02:50<06:55,  1.50it/s] 30%|██▉       | 263/886 [02:51<06:52,  1.51it/s] 30%|██▉       | 264/886 [02:52<06:50,  1.52it/s] 30%|██▉       | 265/886 [02:52<06:52,  1.50it/s] 30%|███       | 266/886 [02:53<06:51,  1.51it/s] 30%|███       | 267/886 [02:54<06:50,  1.51it/s] 30%|███       | 268/886 [02:54<06:49,  1.51it/s] 30%|███       | 269/886 [02:55<06:56,  1.48it/s] 30%|███       | 270/886 [02:56<06:55,  1.48it/s] 31%|███       | 271/886 [02:56<06:53,  1.49it/s] 31%|███       | 272/886 [02:57<06:57,  1.47it/s] 31%|███       | 273/886 [02:58<06:53,  1.48it/s] 31%|███       | 274/886 [02:58<06:50,  1.49it/s] 31%|███       | 275/886 [02:59<06:47,  1.50it/s] 31%|███       | 276/886 [03:00<06:51,  1.48it/s] 31%|███▏      | 277/886 [03:00<06:48,  1.49it/s] 31%|███▏      | 278/886 [03:01<06:46,  1.50it/s] 31%|███▏      | 279/886 [03:02<06:44,  1.50it/s] 32%|███▏      | 280/886 [03:02<06:48,  1.48it/s] 32%|███▏      | 281/886 [03:03<06:47,  1.48it/s] 32%|███▏      | 282/886 [03:04<06:46,  1.49it/s] 32%|███▏      | 283/886 [03:04<06:50,  1.47it/s] 32%|███▏      | 284/886 [03:05<06:49,  1.47it/s] 32%|███▏      | 285/886 [03:06<06:46,  1.48it/s] 32%|███▏      | 286/886 [03:07<06:50,  1.46it/s] 32%|███▏      | 287/886 [03:07<06:48,  1.47it/s] 33%|███▎      | 288/886 [03:08<06:44,  1.48it/s] 33%|███▎      | 289/886 [03:09<06:47,  1.46it/s] 33%|███▎      | 290/886 [03:09<06:43,  1.48it/s] 33%|███▎      | 291/886 [03:10<06:39,  1.49it/s] 33%|███▎      | 292/886 [03:11<06:41,  1.48it/s] 33%|███▎      | 293/886 [03:11<06:37,  1.49it/s] 33%|███▎      | 294/886 [03:12<06:34,  1.50it/s] 33%|███▎      | 295/886 [03:13<06:31,  1.51it/s] 33%|███▎      | 296/886 [03:13<06:29,  1.51it/s] 34%|███▎      | 297/886 [03:14<06:36,  1.48it/s] 34%|███▎      | 298/886 [03:15<06:35,  1.49it/s] 34%|███▎      | 299/886 [03:15<06:31,  1.50it/s] 34%|███▍      | 300/886 [03:16<06:31,  1.50it/s] 34%|███▍      | 301/886 [03:17<06:29,  1.50it/s] 34%|███▍      | 302/886 [03:17<06:27,  1.51it/s] 34%|███▍      | 303/886 [03:18<06:26,  1.51it/s] 34%|███▍      | 304/886 [03:19<06:24,  1.51it/s] 34%|███▍      | 305/886 [03:19<06:29,  1.49it/s] 35%|███▍      | 306/886 [03:20<06:28,  1.49it/s] 35%|███▍      | 307/886 [03:21<06:25,  1.50it/s] 35%|███▍      | 308/886 [03:21<06:27,  1.49it/s] 35%|███▍      | 309/886 [03:22<06:24,  1.50it/s] 35%|███▍      | 310/886 [03:23<06:22,  1.51it/s] 35%|███▌      | 311/886 [03:23<06:19,  1.51it/s] 35%|███▌      | 312/886 [03:24<06:19,  1.51it/s] 35%|███▌      | 313/886 [03:25<06:22,  1.50it/s] 35%|███▌      | 314/886 [03:25<06:20,  1.50it/s] 36%|███▌      | 315/886 [03:26<06:18,  1.51it/s] 36%|███▌      | 316/886 [03:27<06:17,  1.51it/s] 36%|███▌      | 317/886 [03:27<06:21,  1.49it/s] 36%|███▌      | 318/886 [03:28<06:20,  1.49it/s] 36%|███▌      | 319/886 [03:29<06:18,  1.50it/s] 36%|███▌      | 320/886 [03:29<06:24,  1.47it/s] 36%|███▌      | 321/886 [03:30<06:27,  1.46it/s] 36%|███▋      | 322/886 [03:31<06:24,  1.47it/s] 36%|███▋      | 323/886 [03:31<06:25,  1.46it/s] 37%|███▋      | 324/886 [03:32<06:20,  1.48it/s] 37%|███▋      | 325/886 [03:33<06:16,  1.49it/s] 37%|███▋      | 326/886 [03:33<06:13,  1.50it/s] 37%|███▋      | 327/886 [03:34<06:15,  1.49it/s] 37%|███▋      | 328/886 [03:35<06:13,  1.49it/s] 37%|███▋      | 329/886 [03:35<06:11,  1.50it/s] 37%|███▋      | 330/886 [03:36<06:16,  1.48it/s] 37%|███▋      | 331/886 [03:37<06:15,  1.48it/s] 37%|███▋      | 332/886 [03:37<06:13,  1.48it/s] 38%|███▊      | 333/886 [03:38<06:09,  1.50it/s] 38%|███▊      | 334/886 [03:39<06:11,  1.49it/s] 38%|███▊      | 335/886 [03:39<06:07,  1.50it/s] 38%|███▊      | 336/886 [03:40<06:04,  1.51it/s] 38%|███▊      | 337/886 [03:41<06:02,  1.52it/s] 38%|███▊      | 338/886 [03:41<06:04,  1.51it/s] 38%|███▊      | 339/886 [03:42<06:03,  1.50it/s] 38%|███▊      | 340/886 [03:43<06:01,  1.51it/s] 38%|███▊      | 341/886 [03:43<06:01,  1.51it/s] 39%|███▊      | 342/886 [03:44<06:05,  1.49it/s] 39%|███▊      | 343/886 [03:45<06:03,  1.49it/s] 39%|███▉      | 344/886 [03:45<06:01,  1.50it/s] 39%|███▉      | 345/886 [03:46<06:01,  1.50it/s] 39%|███▉      | 346/886 [03:47<06:06,  1.47it/s] 39%|███▉      | 347/886 [03:47<06:05,  1.48it/s] 39%|███▉      | 348/886 [03:48<06:01,  1.49it/s] 39%|███▉      | 349/886 [03:49<06:03,  1.48it/s] 40%|███▉      | 350/886 [03:49<05:59,  1.49it/s] 40%|███▉      | 351/886 [03:50<05:56,  1.50it/s] 40%|███▉      | 352/886 [03:51<05:54,  1.51it/s] 40%|███▉      | 353/886 [03:51<05:58,  1.48it/s] 40%|███▉      | 354/886 [03:52<06:01,  1.47it/s] 40%|████      | 355/886 [03:53<05:58,  1.48it/s] 40%|████      | 356/886 [03:53<06:00,  1.47it/s] 40%|████      | 357/886 [03:54<05:59,  1.47it/s] 40%|████      | 358/886 [03:55<05:56,  1.48it/s] 41%|████      | 359/886 [03:55<05:58,  1.47it/s] 41%|████      | 360/886 [03:56<05:56,  1.47it/s] 41%|████      | 361/886 [03:57<05:54,  1.48it/s] 41%|████      | 362/886 [03:58<05:58,  1.46it/s] 41%|████      | 363/886 [03:58<05:55,  1.47it/s] 41%|████      | 364/886 [03:59<05:52,  1.48it/s] 41%|████      | 365/886 [04:00<05:54,  1.47it/s] 41%|████▏     | 366/886 [04:00<05:50,  1.48it/s] 41%|████▏     | 367/886 [04:01<05:46,  1.50it/s] 42%|████▏     | 368/886 [04:02<05:45,  1.50it/s] 42%|████▏     | 369/886 [04:02<05:48,  1.48it/s] 42%|████▏     | 370/886 [04:03<05:48,  1.48it/s] 42%|████▏     | 371/886 [04:04<05:46,  1.49it/s] 42%|████▏     | 372/886 [04:04<05:43,  1.50it/s] 42%|████▏     | 373/886 [04:05<05:45,  1.49it/s] 42%|████▏     | 374/886 [04:06<05:42,  1.50it/s] 42%|████▏     | 375/886 [04:06<05:39,  1.51it/s] 42%|████▏     | 376/886 [04:07<05:36,  1.51it/s] 43%|████▎     | 377/886 [04:08<05:40,  1.49it/s] 43%|████▎     | 378/886 [04:08<05:38,  1.50it/s] 43%|████▎     | 379/886 [04:09<05:36,  1.51it/s] 43%|████▎     | 380/886 [04:10<05:35,  1.51it/s] 43%|████▎     | 381/886 [04:10<05:40,  1.48it/s] 43%|████▎     | 382/886 [04:11<05:39,  1.49it/s] 43%|████▎     | 383/886 [04:12<05:36,  1.49it/s] 43%|████▎     | 384/886 [04:12<05:39,  1.48it/s] 43%|████▎     | 385/886 [04:13<05:38,  1.48it/s] 44%|████▎     | 386/886 [04:14<05:35,  1.49it/s] 44%|████▎     | 387/886 [04:14<05:35,  1.49it/s] 44%|████▍     | 388/886 [04:15<05:37,  1.48it/s] 44%|████▍     | 389/886 [04:16<05:34,  1.48it/s] 44%|████▍     | 390/886 [04:16<05:31,  1.50it/s] 44%|████▍     | 391/886 [04:17<05:32,  1.49it/s] 44%|████▍     | 392/886 [04:18<05:29,  1.50it/s] 44%|████▍     | 393/886 [04:18<05:28,  1.50it/s] 44%|████▍     | 394/886 [04:19<05:26,  1.50it/s] 45%|████▍     | 395/886 [04:20<05:29,  1.49it/s] 45%|████▍     | 396/886 [04:20<05:26,  1.50it/s] 45%|████▍     | 397/886 [04:21<05:25,  1.50it/s] 45%|████▍     | 398/886 [04:22<05:22,  1.51it/s] 45%|████▌     | 399/886 [04:22<05:24,  1.50it/s] 45%|████▌     | 400/886 [04:23<05:23,  1.50it/s] 45%|████▌     | 401/886 [04:24<05:22,  1.51it/s] 45%|████▌     | 402/886 [04:24<05:21,  1.51it/s] 45%|████▌     | 403/886 [04:25<05:23,  1.49it/s] 46%|████▌     | 404/886 [04:26<05:22,  1.50it/s] 46%|████▌     | 405/886 [04:26<05:20,  1.50it/s] 46%|████▌     | 406/886 [04:27<05:18,  1.51it/s] 46%|████▌     | 407/886 [04:28<05:22,  1.49it/s] 46%|████▌     | 408/886 [04:28<05:21,  1.49it/s] 46%|████▌     | 409/886 [04:29<05:18,  1.50it/s] 46%|████▋     | 410/886 [04:30<05:21,  1.48it/s] 46%|████▋     | 411/886 [04:30<05:18,  1.49it/s] 47%|████▋     | 412/886 [04:31<05:15,  1.50it/s] 47%|████▋     | 413/886 [04:32<05:14,  1.51it/s] 47%|████▋     | 414/886 [04:32<05:17,  1.48it/s] 47%|████▋     | 415/886 [04:33<05:18,  1.48it/s] 47%|████▋     | 416/886 [04:34<05:16,  1.48it/s] 47%|████▋     | 417/886 [04:34<05:20,  1.46it/s] 47%|████▋     | 418/886 [04:35<05:19,  1.47it/s] 47%|████▋     | 419/886 [04:36<05:16,  1.47it/s] 47%|████▋     | 420/886 [04:36<05:19,  1.46it/s] 48%|████▊     | 421/886 [04:37<05:17,  1.46it/s] 48%|████▊     | 422/886 [04:38<05:14,  1.48it/s] 48%|████▊     | 423/886 [04:38<05:14,  1.47it/s] 48%|████▊     | 424/886 [04:39<05:11,  1.48it/s] 48%|████▊     | 425/886 [04:40<05:08,  1.49it/s] 48%|████▊     | 426/886 [04:40<05:06,  1.50it/s] 48%|████▊     | 427/886 [04:41<05:10,  1.48it/s] 48%|████▊     | 428/886 [04:42<05:09,  1.48it/s] 48%|████▊     | 429/886 [04:42<05:06,  1.49it/s] 49%|████▊     | 430/886 [04:43<05:03,  1.50it/s] 49%|████▊     | 431/886 [04:44<05:03,  1.50it/s] 49%|████▉     | 432/886 [04:44<05:01,  1.51it/s] 49%|████▉     | 433/886 [04:45<05:00,  1.51it/s] 49%|████▉     | 434/886 [04:46<04:58,  1.51it/s] 49%|████▉     | 435/886 [04:46<04:59,  1.50it/s] 49%|████▉     | 436/886 [04:47<04:59,  1.50it/s] 49%|████▉     | 437/886 [04:48<04:57,  1.51it/s] 49%|████▉     | 438/886 [04:48<04:56,  1.51it/s] 50%|████▉     | 439/886 [04:49<05:01,  1.48it/s] 50%|████▉     | 440/886 [04:50<04:59,  1.49it/s] 50%|████▉     | 441/886 [04:50<04:56,  1.50it/s] 50%|████▉     | 442/886 [04:51<04:54,  1.51it/s] 50%|█████     | 443/886 [04:52<04:54,  1.50it/s][INFO|trainer.py:2340] 2023-10-30 21:49:28,484 >> Saving model checkpoint to chkpts/analysis_models/minibertas/d-atomic-roberta-base-10M-2/checkpoint-443
[INFO|configuration_utils.py:446] 2023-10-30 21:49:28,494 >> Configuration saved in chkpts/analysis_models/minibertas/d-atomic-roberta-base-10M-2/checkpoint-443/config.json
[INFO|modeling_utils.py:1542] 2023-10-30 21:49:31,238 >> Model weights saved in chkpts/analysis_models/minibertas/d-atomic-roberta-base-10M-2/checkpoint-443/pytorch_model.bin
[INFO|tokenization_utils_base.py:2108] 2023-10-30 21:49:31,247 >> tokenizer config file saved in chkpts/analysis_models/minibertas/d-atomic-roberta-base-10M-2/checkpoint-443/tokenizer_config.json
[INFO|tokenization_utils_base.py:2114] 2023-10-30 21:49:31,253 >> Special tokens file saved in chkpts/analysis_models/minibertas/d-atomic-roberta-base-10M-2/checkpoint-443/special_tokens_map.json
 50%|█████     | 444/886 [05:00<20:44,  2.81s/it] 50%|█████     | 445/886 [05:00<15:54,  2.16s/it] 50%|█████     | 446/886 [05:01<12:32,  1.71s/it] 50%|█████     | 447/886 [05:02<10:11,  1.39s/it] 51%|█████     | 448/886 [05:02<08:32,  1.17s/it] 51%|█████     | 449/886 [05:03<07:22,  1.01s/it] 51%|█████     | 450/886 [05:03<06:33,  1.11it/s] 51%|█████     | 451/886 [05:04<05:59,  1.21it/s] 51%|█████     | 452/886 [05:05<05:36,  1.29it/s] 51%|█████     | 453/886 [05:05<05:19,  1.36it/s] 51%|█████     | 454/886 [05:06<05:07,  1.41it/s] 51%|█████▏    | 455/886 [05:07<04:58,  1.44it/s] 51%|█████▏    | 456/886 [05:07<04:52,  1.47it/s] 52%|█████▏    | 457/886 [05:08<04:47,  1.49it/s] 52%|█████▏    | 458/886 [05:09<04:44,  1.51it/s] 52%|█████▏    | 459/886 [05:09<04:42,  1.51it/s] 52%|█████▏    | 460/886 [05:10<04:43,  1.50it/s] 52%|█████▏    | 461/886 [05:11<04:42,  1.51it/s] 52%|█████▏    | 462/886 [05:11<04:40,  1.51it/s] 52%|█████▏    | 463/886 [05:12<04:40,  1.51it/s] 52%|█████▏    | 464/886 [05:13<04:38,  1.51it/s] 52%|█████▏    | 465/886 [05:13<04:37,  1.52it/s] 53%|█████▎    | 466/886 [05:14<04:35,  1.52it/s] 53%|█████▎    | 467/886 [05:15<04:34,  1.53it/s] 53%|█████▎    | 468/886 [05:15<04:33,  1.53it/s] 53%|█████▎    | 469/886 [05:16<04:37,  1.51it/s] 53%|█████▎    | 470/886 [05:17<04:35,  1.51it/s] 53%|█████▎    | 471/886 [05:17<04:34,  1.51it/s] 53%|█████▎    | 472/886 [05:18<04:32,  1.52it/s] 53%|█████▎    | 473/886 [05:19<04:35,  1.50it/s] 53%|█████▎    | 474/886 [05:19<04:33,  1.50it/s] 54%|█████▎    | 475/886 [05:20<04:32,  1.51it/s] 54%|█████▎    | 476/886 [05:21<04:31,  1.51it/s] 54%|█████▍    | 477/886 [05:21<04:35,  1.48it/s] 54%|█████▍    | 478/886 [05:22<04:34,  1.49it/s] 54%|█████▍    | 479/886 [05:23<04:33,  1.49it/s] 54%|█████▍    | 480/886 [05:23<04:35,  1.47it/s] 54%|█████▍    | 481/886 [05:24<04:33,  1.48it/s] 54%|█████▍    | 482/886 [05:25<04:30,  1.49it/s] 55%|█████▍    | 483/886 [05:25<04:31,  1.49it/s] 55%|█████▍    | 484/886 [05:26<04:35,  1.46it/s] 55%|█████▍    | 485/886 [05:27<04:35,  1.45it/s] 55%|█████▍    | 486/886 [05:27<04:37,  1.44it/s] 55%|█████▍    | 487/886 [05:28<04:32,  1.46it/s] 55%|█████▌    | 488/886 [05:29<04:29,  1.48it/s] 55%|█████▌    | 489/886 [05:29<04:31,  1.46it/s] 55%|█████▌    | 490/886 [05:30<04:28,  1.47it/s] 55%|█████▌    | 491/886 [05:31<04:26,  1.48it/s] 56%|█████▌    | 492/886 [05:31<04:23,  1.49it/s] 56%|█████▌    | 493/886 [05:32<04:24,  1.48it/s] 56%|█████▌    | 494/886 [05:33<04:22,  1.49it/s] 56%|█████▌    | 495/886 [05:33<04:20,  1.50it/s] 56%|█████▌    | 496/886 [05:34<04:18,  1.51it/s] 56%|█████▌    | 497/886 [05:35<04:20,  1.49it/s] 56%|█████▌    | 498/886 [05:35<04:19,  1.50it/s] 56%|█████▋    | 499/886 [05:36<04:17,  1.50it/s] 56%|█████▋    | 500/886 [05:37<04:15,  1.51it/s]                                                  56%|█████▋    | 500/886 [05:37<04:15,  1.51it/s] 57%|█████▋    | 501/886 [05:37<04:19,  1.48it/s] 57%|█████▋    | 502/886 [05:38<04:20,  1.48it/s] 57%|█████▋    | 503/886 [05:39<04:19,  1.48it/s] 57%|█████▋    | 504/886 [05:40<04:16,  1.49it/s] 57%|█████▋    | 505/886 [05:40<04:14,  1.50it/s] 57%|█████▋    | 506/886 [05:41<04:13,  1.50it/s] 57%|█████▋    | 507/886 [05:41<04:11,  1.51it/s] 57%|█████▋    | 508/886 [05:42<04:11,  1.50it/s] 57%|█████▋    | 509/886 [05:43<04:11,  1.50it/s] 58%|█████▊    | 510/886 [05:43<04:09,  1.51it/s] 58%|█████▊    | 511/886 [05:44<04:08,  1.51it/s] 58%|█████▊    | 512/886 [05:45<04:11,  1.49it/s] 58%|█████▊    | 513/886 [05:45<04:09,  1.49it/s] 58%|█████▊    | 514/886 [05:46<04:07,  1.50it/s] 58%|█████▊    | 515/886 [05:47<04:07,  1.50it/s] 58%|█████▊    | 516/886 [05:48<04:10,  1.48it/s] 58%|█████▊    | 517/886 [05:48<04:10,  1.48it/s] 58%|█████▊    | 518/886 [05:49<04:08,  1.48it/s] 59%|█████▊    | 519/886 [05:50<04:11,  1.46it/s] 59%|█████▊    | 520/886 [05:50<04:08,  1.47it/s] 59%|█████▉    | 521/886 [05:51<04:05,  1.49it/s] 59%|█████▉    | 522/886 [05:52<04:06,  1.47it/s] 59%|█████▉    | 523/886 [05:52<04:04,  1.49it/s] 59%|█████▉    | 524/886 [05:53<04:02,  1.49it/s] 59%|█████▉    | 525/886 [05:54<04:01,  1.50it/s] 59%|█████▉    | 526/886 [05:54<04:03,  1.48it/s] 59%|█████▉    | 527/886 [05:55<04:02,  1.48it/s] 60%|█████▉    | 528/886 [05:56<04:00,  1.49it/s] 60%|█████▉    | 529/886 [05:56<04:03,  1.47it/s] 60%|█████▉    | 530/886 [05:57<04:02,  1.47it/s] 60%|█████▉    | 531/886 [05:58<03:59,  1.48it/s] 60%|██████    | 532/886 [05:58<03:59,  1.48it/s] 60%|██████    | 533/886 [05:59<03:56,  1.49it/s] 60%|██████    | 534/886 [06:00<03:54,  1.50it/s] 60%|██████    | 535/886 [06:00<03:54,  1.50it/s] 60%|██████    | 536/886 [06:01<03:56,  1.48it/s] 61%|██████    | 537/886 [06:02<03:54,  1.49it/s] 61%|██████    | 538/886 [06:02<03:52,  1.50it/s] 61%|██████    | 539/886 [06:03<03:50,  1.50it/s] 61%|██████    | 540/886 [06:04<03:51,  1.49it/s] 61%|██████    | 541/886 [06:04<03:50,  1.50it/s] 61%|██████    | 542/886 [06:05<03:48,  1.50it/s] 61%|██████▏   | 543/886 [06:06<03:47,  1.51it/s] 61%|██████▏   | 544/886 [06:06<03:50,  1.48it/s] 62%|██████▏   | 545/886 [06:07<03:49,  1.49it/s] 62%|██████▏   | 546/886 [06:08<03:46,  1.50it/s] 62%|██████▏   | 547/886 [06:08<03:47,  1.49it/s] 62%|██████▏   | 548/886 [06:09<03:46,  1.49it/s] 62%|██████▏   | 549/886 [06:10<03:45,  1.50it/s] 62%|██████▏   | 550/886 [06:10<03:43,  1.50it/s] 62%|██████▏   | 551/886 [06:11<03:46,  1.48it/s] 62%|██████▏   | 552/886 [06:12<03:44,  1.49it/s] 62%|██████▏   | 553/886 [06:12<03:43,  1.49it/s] 63%|██████▎   | 554/886 [06:13<03:46,  1.47it/s] 63%|██████▎   | 555/886 [06:14<03:44,  1.47it/s] 63%|██████▎   | 556/886 [06:14<03:42,  1.48it/s] 63%|██████▎   | 557/886 [06:15<03:44,  1.46it/s] 63%|██████▎   | 558/886 [06:16<03:42,  1.48it/s] 63%|██████▎   | 559/886 [06:16<03:39,  1.49it/s] 63%|██████▎   | 560/886 [06:17<03:37,  1.50it/s] 63%|██████▎   | 561/886 [06:18<03:39,  1.48it/s] 63%|██████▎   | 562/886 [06:18<03:37,  1.49it/s] 64%|██████▎   | 563/886 [06:19<03:36,  1.49it/s] 64%|██████▎   | 564/886 [06:20<03:34,  1.50it/s] 64%|██████▍   | 565/886 [06:20<03:34,  1.49it/s] 64%|██████▍   | 566/886 [06:21<03:33,  1.50it/s] 64%|██████▍   | 567/886 [06:22<03:31,  1.51it/s] 64%|██████▍   | 568/886 [06:22<03:30,  1.51it/s] 64%|██████▍   | 569/886 [06:23<03:32,  1.49it/s] 64%|██████▍   | 570/886 [06:24<03:31,  1.50it/s] 64%|██████▍   | 571/886 [06:24<03:29,  1.50it/s] 65%|██████▍   | 572/886 [06:25<03:27,  1.51it/s] 65%|██████▍   | 573/886 [06:26<03:28,  1.50it/s] 65%|██████▍   | 574/886 [06:26<03:27,  1.50it/s] 65%|██████▍   | 575/886 [06:27<03:26,  1.50it/s] 65%|██████▌   | 576/886 [06:28<03:26,  1.50it/s] 65%|██████▌   | 577/886 [06:28<03:28,  1.48it/s] 65%|██████▌   | 578/886 [06:29<03:27,  1.49it/s] 65%|██████▌   | 579/886 [06:30<03:25,  1.49it/s] 65%|██████▌   | 580/886 [06:31<03:26,  1.48it/s] 66%|██████▌   | 581/886 [06:31<03:24,  1.49it/s] 66%|██████▌   | 582/886 [06:32<03:23,  1.50it/s] 66%|██████▌   | 583/886 [06:32<03:21,  1.50it/s] 66%|██████▌   | 584/886 [06:33<03:23,  1.48it/s] 66%|██████▌   | 585/886 [06:34<03:23,  1.48it/s] 66%|██████▌   | 586/886 [06:35<03:21,  1.49it/s] 66%|██████▋   | 587/886 [06:35<03:23,  1.47it/s] 66%|██████▋   | 588/886 [06:36<03:22,  1.47it/s] 66%|██████▋   | 589/886 [06:37<03:20,  1.48it/s] 67%|██████▋   | 590/886 [06:37<03:22,  1.46it/s] 67%|██████▋   | 591/886 [06:38<03:20,  1.47it/s] 67%|██████▋   | 592/886 [06:39<03:17,  1.49it/s] 67%|██████▋   | 593/886 [06:39<03:19,  1.47it/s] 67%|██████▋   | 594/886 [06:40<03:16,  1.48it/s] 67%|██████▋   | 595/886 [06:41<03:15,  1.49it/s] 67%|██████▋   | 596/886 [06:41<03:14,  1.49it/s] 67%|██████▋   | 597/886 [06:42<03:16,  1.47it/s] 67%|██████▋   | 598/886 [06:43<03:15,  1.48it/s] 68%|██████▊   | 599/886 [06:43<03:13,  1.48it/s] 68%|██████▊   | 600/886 [06:44<03:13,  1.48it/s] 68%|██████▊   | 601/886 [06:45<03:11,  1.49it/s] 68%|██████▊   | 602/886 [06:45<03:09,  1.50it/s] 68%|██████▊   | 603/886 [06:46<03:08,  1.50it/s] 68%|██████▊   | 604/886 [06:47<03:10,  1.48it/s] 68%|██████▊   | 605/886 [06:47<03:09,  1.49it/s] 68%|██████▊   | 606/886 [06:48<03:07,  1.49it/s] 69%|██████▊   | 607/886 [06:49<03:07,  1.49it/s] 69%|██████▊   | 608/886 [06:49<03:06,  1.49it/s] 69%|██████▊   | 609/886 [06:50<03:05,  1.49it/s] 69%|██████▉   | 610/886 [06:51<03:04,  1.50it/s] 69%|██████▉   | 611/886 [06:51<03:06,  1.48it/s] 69%|██████▉   | 612/886 [06:52<03:06,  1.47it/s] 69%|██████▉   | 613/886 [06:53<03:04,  1.48it/s] 69%|██████▉   | 614/886 [06:53<03:06,  1.46it/s] 69%|██████▉   | 615/886 [06:54<03:05,  1.46it/s] 70%|██████▉   | 616/886 [06:55<03:03,  1.48it/s] 70%|██████▉   | 617/886 [06:56<03:04,  1.46it/s] 70%|██████▉   | 618/886 [06:56<03:02,  1.47it/s] 70%|██████▉   | 619/886 [06:57<03:00,  1.48it/s] 70%|██████▉   | 620/886 [06:58<03:01,  1.46it/s] 70%|███████   | 621/886 [06:58<03:00,  1.47it/s] 70%|███████   | 622/886 [06:59<02:58,  1.48it/s] 70%|███████   | 623/886 [07:00<02:57,  1.48it/s] 70%|███████   | 624/886 [07:00<02:57,  1.48it/s] 71%|███████   | 625/886 [07:01<02:56,  1.48it/s] 71%|███████   | 626/886 [07:02<02:54,  1.49it/s] 71%|███████   | 627/886 [07:02<02:55,  1.48it/s] 71%|███████   | 628/886 [07:03<02:53,  1.49it/s] 71%|███████   | 629/886 [07:04<02:51,  1.50it/s] 71%|███████   | 630/886 [07:04<02:50,  1.50it/s] 71%|███████   | 631/886 [07:05<02:50,  1.49it/s] 71%|███████▏  | 632/886 [07:06<02:49,  1.50it/s] 71%|███████▏  | 633/886 [07:06<02:48,  1.51it/s] 72%|███████▏  | 634/886 [07:07<02:46,  1.51it/s] 72%|███████▏  | 635/886 [07:08<02:47,  1.50it/s] 72%|███████▏  | 636/886 [07:08<02:46,  1.50it/s] 72%|███████▏  | 637/886 [07:09<02:45,  1.51it/s] 72%|███████▏  | 638/886 [07:10<02:43,  1.51it/s] 72%|███████▏  | 639/886 [07:10<02:45,  1.49it/s] 72%|███████▏  | 640/886 [07:11<02:44,  1.49it/s] 72%|███████▏  | 641/886 [07:12<02:43,  1.50it/s] 72%|███████▏  | 642/886 [07:12<02:42,  1.50it/s] 73%|███████▎  | 643/886 [07:13<02:42,  1.50it/s] 73%|███████▎  | 644/886 [07:14<02:41,  1.50it/s] 73%|███████▎  | 645/886 [07:14<02:39,  1.51it/s] 73%|███████▎  | 646/886 [07:15<02:38,  1.51it/s] 73%|███████▎  | 647/886 [07:16<02:38,  1.50it/s] 73%|███████▎  | 648/886 [07:16<02:37,  1.51it/s] 73%|███████▎  | 649/886 [07:17<02:36,  1.51it/s] 73%|███████▎  | 650/886 [07:18<02:35,  1.51it/s] 73%|███████▎  | 651/886 [07:18<02:36,  1.50it/s] 74%|███████▎  | 652/886 [07:19<02:35,  1.50it/s] 74%|███████▎  | 653/886 [07:20<02:34,  1.50it/s] 74%|███████▍  | 654/886 [07:20<02:34,  1.51it/s] 74%|███████▍  | 655/886 [07:21<02:35,  1.49it/s] 74%|███████▍  | 656/886 [07:22<02:35,  1.48it/s] 74%|███████▍  | 657/886 [07:22<02:33,  1.49it/s] 74%|███████▍  | 658/886 [07:23<02:35,  1.47it/s] 74%|███████▍  | 659/886 [07:24<02:34,  1.47it/s] 74%|███████▍  | 660/886 [07:24<02:31,  1.49it/s] 75%|███████▍  | 661/886 [07:25<02:30,  1.49it/s] 75%|███████▍  | 662/886 [07:26<02:29,  1.50it/s] 75%|███████▍  | 663/886 [07:26<02:28,  1.51it/s] 75%|███████▍  | 664/886 [07:27<02:26,  1.51it/s] 75%|███████▌  | 665/886 [07:28<02:25,  1.52it/s] 75%|███████▌  | 666/886 [07:28<02:26,  1.50it/s] 75%|███████▌  | 667/886 [07:29<02:25,  1.51it/s] 75%|███████▌  | 668/886 [07:30<02:24,  1.51it/s] 76%|███████▌  | 669/886 [07:30<02:23,  1.51it/s] 76%|███████▌  | 670/886 [07:31<02:24,  1.50it/s] 76%|███████▌  | 671/886 [07:32<02:23,  1.50it/s] 76%|███████▌  | 672/886 [07:32<02:21,  1.51it/s] 76%|███████▌  | 673/886 [07:33<02:21,  1.51it/s] 76%|███████▌  | 674/886 [07:34<02:22,  1.49it/s] 76%|███████▌  | 675/886 [07:34<02:21,  1.49it/s] 76%|███████▋  | 676/886 [07:35<02:20,  1.49it/s] 76%|███████▋  | 677/886 [07:36<02:19,  1.50it/s] 77%|███████▋  | 678/886 [07:36<02:21,  1.47it/s] 77%|███████▋  | 679/886 [07:37<02:20,  1.47it/s] 77%|███████▋  | 680/886 [07:38<02:18,  1.49it/s] 77%|███████▋  | 681/886 [07:38<02:18,  1.48it/s] 77%|███████▋  | 682/886 [07:39<02:17,  1.49it/s] 77%|███████▋  | 683/886 [07:40<02:15,  1.50it/s] 77%|███████▋  | 684/886 [07:40<02:13,  1.51it/s] 77%|███████▋  | 685/886 [07:41<02:13,  1.50it/s] 77%|███████▋  | 686/886 [07:42<02:12,  1.51it/s] 78%|███████▊  | 687/886 [07:42<02:11,  1.51it/s] 78%|███████▊  | 688/886 [07:43<02:10,  1.52it/s] 78%|███████▊  | 689/886 [07:44<02:12,  1.49it/s] 78%|███████▊  | 690/886 [07:44<02:11,  1.49it/s] 78%|███████▊  | 691/886 [07:45<02:10,  1.50it/s] 78%|███████▊  | 692/886 [07:46<02:09,  1.50it/s] 78%|███████▊  | 693/886 [07:46<02:09,  1.49it/s] 78%|███████▊  | 694/886 [07:47<02:08,  1.50it/s] 78%|███████▊  | 695/886 [07:48<02:07,  1.50it/s] 79%|███████▊  | 696/886 [07:48<02:06,  1.50it/s] 79%|███████▊  | 697/886 [07:49<02:05,  1.51it/s] 79%|███████▉  | 698/886 [07:50<02:04,  1.51it/s] 79%|███████▉  | 699/886 [07:50<02:03,  1.52it/s] 79%|███████▉  | 700/886 [07:51<02:02,  1.52it/s] 79%|███████▉  | 701/886 [07:52<02:03,  1.50it/s] 79%|███████▉  | 702/886 [07:52<02:02,  1.50it/s] 79%|███████▉  | 703/886 [07:53<02:01,  1.51it/s] 79%|███████▉  | 704/886 [07:54<02:00,  1.51it/s] 80%|███████▉  | 705/886 [07:54<02:00,  1.50it/s] 80%|███████▉  | 706/886 [07:55<01:59,  1.50it/s] 80%|███████▉  | 707/886 [07:56<01:58,  1.51it/s] 80%|███████▉  | 708/886 [07:56<01:57,  1.51it/s] 80%|████████  | 709/886 [07:57<01:58,  1.49it/s] 80%|████████  | 710/886 [07:58<01:57,  1.50it/s] 80%|████████  | 711/886 [07:58<01:56,  1.51it/s] 80%|████████  | 712/886 [07:59<01:55,  1.51it/s] 80%|████████  | 713/886 [08:00<01:57,  1.48it/s] 81%|████████  | 714/886 [08:00<01:57,  1.46it/s] 81%|████████  | 715/886 [08:01<01:56,  1.47it/s] 81%|████████  | 716/886 [08:02<01:55,  1.47it/s] 81%|████████  | 717/886 [08:02<01:53,  1.48it/s] 81%|████████  | 718/886 [08:03<01:52,  1.50it/s] 81%|████████  | 719/886 [08:04<01:53,  1.48it/s] 81%|████████▏ | 720/886 [08:04<01:51,  1.48it/s] 81%|████████▏ | 721/886 [08:05<01:50,  1.50it/s] 81%|████████▏ | 722/886 [08:06<01:48,  1.51it/s] 82%|████████▏ | 723/886 [08:06<01:49,  1.49it/s] 82%|████████▏ | 724/886 [08:07<01:48,  1.49it/s] 82%|████████▏ | 725/886 [08:08<01:47,  1.50it/s] 82%|████████▏ | 726/886 [08:08<01:46,  1.50it/s] 82%|████████▏ | 727/886 [08:09<01:47,  1.48it/s] 82%|████████▏ | 728/886 [08:10<01:47,  1.48it/s] 82%|████████▏ | 729/886 [08:10<01:45,  1.48it/s] 82%|████████▏ | 730/886 [08:11<01:46,  1.47it/s] 83%|████████▎ | 731/886 [08:12<01:45,  1.47it/s] 83%|████████▎ | 732/886 [08:12<01:44,  1.48it/s] 83%|████████▎ | 733/886 [08:13<01:44,  1.46it/s] 83%|████████▎ | 734/886 [08:14<01:43,  1.46it/s] 83%|████████▎ | 735/886 [08:14<01:42,  1.47it/s] 83%|████████▎ | 736/886 [08:15<01:42,  1.46it/s] 83%|████████▎ | 737/886 [08:16<01:40,  1.48it/s] 83%|████████▎ | 738/886 [08:16<01:38,  1.50it/s] 83%|████████▎ | 739/886 [08:17<01:37,  1.50it/s] 84%|████████▎ | 740/886 [08:18<01:38,  1.49it/s] 84%|████████▎ | 741/886 [08:18<01:37,  1.49it/s] 84%|████████▎ | 742/886 [08:19<01:36,  1.50it/s] 84%|████████▍ | 743/886 [08:20<01:34,  1.51it/s] 84%|████████▍ | 744/886 [08:20<01:34,  1.50it/s] 84%|████████▍ | 745/886 [08:21<01:33,  1.51it/s] 84%|████████▍ | 746/886 [08:22<01:32,  1.51it/s] 84%|████████▍ | 747/886 [08:22<01:31,  1.51it/s] 84%|████████▍ | 748/886 [08:23<01:31,  1.50it/s] 85%|████████▍ | 749/886 [08:24<01:30,  1.51it/s] 85%|████████▍ | 750/886 [08:24<01:30,  1.51it/s] 85%|████████▍ | 751/886 [08:25<01:29,  1.51it/s] 85%|████████▍ | 752/886 [08:26<01:30,  1.49it/s] 85%|████████▍ | 753/886 [08:26<01:29,  1.49it/s] 85%|████████▌ | 754/886 [08:27<01:28,  1.49it/s] 85%|████████▌ | 755/886 [08:28<01:28,  1.48it/s] 85%|████████▌ | 756/886 [08:29<01:27,  1.49it/s] 85%|████████▌ | 757/886 [08:29<01:25,  1.50it/s] 86%|████████▌ | 758/886 [08:30<01:24,  1.51it/s] 86%|████████▌ | 759/886 [08:30<01:23,  1.52it/s] 86%|████████▌ | 760/886 [08:31<01:23,  1.50it/s] 86%|████████▌ | 761/886 [08:32<01:23,  1.50it/s] 86%|████████▌ | 762/886 [08:32<01:22,  1.51it/s] 86%|████████▌ | 763/886 [08:33<01:21,  1.51it/s] 86%|████████▌ | 764/886 [08:34<01:21,  1.50it/s] 86%|████████▋ | 765/886 [08:34<01:20,  1.50it/s] 86%|████████▋ | 766/886 [08:35<01:19,  1.51it/s] 87%|████████▋ | 767/886 [08:36<01:18,  1.51it/s] 87%|████████▋ | 768/886 [08:36<01:18,  1.50it/s] 87%|████████▋ | 769/886 [08:37<01:17,  1.51it/s] 87%|████████▋ | 770/886 [08:38<01:16,  1.51it/s] 87%|████████▋ | 771/886 [08:38<01:15,  1.52it/s] 87%|████████▋ | 772/886 [08:39<01:15,  1.50it/s] 87%|████████▋ | 773/886 [08:40<01:15,  1.50it/s] 87%|████████▋ | 774/886 [08:40<01:14,  1.51it/s] 87%|████████▋ | 775/886 [08:41<01:13,  1.51it/s] 88%|████████▊ | 776/886 [08:42<01:13,  1.50it/s] 88%|████████▊ | 777/886 [08:42<01:12,  1.50it/s] 88%|████████▊ | 778/886 [08:43<01:11,  1.51it/s] 88%|████████▊ | 779/886 [08:44<01:10,  1.51it/s] 88%|████████▊ | 780/886 [08:44<01:10,  1.50it/s] 88%|████████▊ | 781/886 [08:45<01:09,  1.51it/s] 88%|████████▊ | 782/886 [08:46<01:08,  1.51it/s] 88%|████████▊ | 783/886 [08:46<01:08,  1.51it/s] 88%|████████▊ | 784/886 [08:47<01:07,  1.52it/s] 89%|████████▊ | 785/886 [08:48<01:07,  1.50it/s] 89%|████████▊ | 786/886 [08:48<01:06,  1.50it/s] 89%|████████▉ | 787/886 [08:49<01:05,  1.51it/s] 89%|████████▉ | 788/886 [08:50<01:05,  1.51it/s] 89%|████████▉ | 789/886 [08:50<01:05,  1.48it/s] 89%|████████▉ | 790/886 [08:51<01:04,  1.49it/s] 89%|████████▉ | 791/886 [08:52<01:03,  1.50it/s] 89%|████████▉ | 792/886 [08:52<01:03,  1.48it/s] 90%|████████▉ | 793/886 [08:53<01:02,  1.49it/s] 90%|████████▉ | 794/886 [08:54<01:01,  1.50it/s] 90%|████████▉ | 795/886 [08:54<01:00,  1.51it/s] 90%|████████▉ | 796/886 [08:55<01:00,  1.49it/s] 90%|████████▉ | 797/886 [08:56<01:00,  1.48it/s] 90%|█████████ | 798/886 [08:56<00:59,  1.49it/s] 90%|█████████ | 799/886 [08:57<00:59,  1.47it/s] 90%|█████████ | 800/886 [08:58<00:58,  1.48it/s] 90%|█████████ | 801/886 [08:58<00:56,  1.49it/s] 91%|█████████ | 802/886 [08:59<00:56,  1.50it/s] 91%|█████████ | 803/886 [09:00<00:55,  1.48it/s] 91%|█████████ | 804/886 [09:00<00:55,  1.49it/s] 91%|█████████ | 805/886 [09:01<00:54,  1.49it/s] 91%|█████████ | 806/886 [09:02<00:53,  1.50it/s] 91%|█████████ | 807/886 [09:02<00:52,  1.50it/s] 91%|█████████ | 808/886 [09:03<00:52,  1.50it/s] 91%|█████████▏| 809/886 [09:04<00:51,  1.51it/s] 91%|█████████▏| 810/886 [09:04<00:50,  1.51it/s] 92%|█████████▏| 811/886 [09:05<00:49,  1.50it/s] 92%|█████████▏| 812/886 [09:06<00:49,  1.51it/s] 92%|█████████▏| 813/886 [09:06<00:48,  1.51it/s] 92%|█████████▏| 814/886 [09:07<00:47,  1.51it/s] 92%|█████████▏| 815/886 [09:08<00:47,  1.49it/s] 92%|█████████▏| 816/886 [09:08<00:47,  1.48it/s] 92%|█████████▏| 817/886 [09:09<00:46,  1.49it/s] 92%|█████████▏| 818/886 [09:10<00:46,  1.47it/s] 92%|█████████▏| 819/886 [09:11<00:45,  1.48it/s] 93%|█████████▎| 820/886 [09:11<00:44,  1.49it/s] 93%|█████████▎| 821/886 [09:12<00:44,  1.47it/s] 93%|█████████▎| 822/886 [09:13<00:43,  1.48it/s] 93%|█████████▎| 823/886 [09:13<00:42,  1.49it/s] 93%|█████████▎| 824/886 [09:14<00:41,  1.50it/s] 93%|█████████▎| 825/886 [09:15<00:41,  1.49it/s] 93%|█████████▎| 826/886 [09:15<00:40,  1.49it/s] 93%|█████████▎| 827/886 [09:16<00:39,  1.50it/s] 93%|█████████▎| 828/886 [09:17<00:38,  1.51it/s] 94%|█████████▎| 829/886 [09:17<00:38,  1.48it/s] 94%|█████████▎| 830/886 [09:18<00:37,  1.48it/s] 94%|█████████▍| 831/886 [09:19<00:36,  1.49it/s] 94%|█████████▍| 832/886 [09:19<00:36,  1.47it/s] 94%|█████████▍| 833/886 [09:20<00:35,  1.48it/s] 94%|█████████▍| 834/886 [09:21<00:34,  1.49it/s] 94%|█████████▍| 835/886 [09:21<00:34,  1.50it/s] 94%|█████████▍| 836/886 [09:22<00:33,  1.48it/s] 94%|█████████▍| 837/886 [09:23<00:33,  1.48it/s] 95%|█████████▍| 838/886 [09:23<00:32,  1.49it/s] 95%|█████████▍| 839/886 [09:24<00:32,  1.47it/s] 95%|█████████▍| 840/886 [09:25<00:31,  1.47it/s] 95%|█████████▍| 841/886 [09:25<00:30,  1.48it/s] 95%|█████████▌| 842/886 [09:26<00:30,  1.47it/s] 95%|█████████▌| 843/886 [09:27<00:29,  1.48it/s] 95%|█████████▌| 844/886 [09:27<00:28,  1.49it/s] 95%|█████████▌| 845/886 [09:28<00:27,  1.50it/s] 95%|█████████▌| 846/886 [09:29<00:26,  1.48it/s] 96%|█████████▌| 847/886 [09:29<00:26,  1.48it/s] 96%|█████████▌| 848/886 [09:30<00:25,  1.49it/s] 96%|█████████▌| 849/886 [09:31<00:25,  1.47it/s] 96%|█████████▌| 850/886 [09:31<00:24,  1.48it/s] 96%|█████████▌| 851/886 [09:32<00:23,  1.49it/s] 96%|█████████▌| 852/886 [09:33<00:22,  1.50it/s] 96%|█████████▋| 853/886 [09:33<00:22,  1.50it/s] 96%|█████████▋| 854/886 [09:34<00:21,  1.50it/s] 97%|█████████▋| 855/886 [09:35<00:20,  1.50it/s] 97%|█████████▋| 856/886 [09:35<00:19,  1.51it/s] 97%|█████████▋| 857/886 [09:36<00:19,  1.50it/s] 97%|█████████▋| 858/886 [09:37<00:18,  1.50it/s] 97%|█████████▋| 859/886 [09:37<00:17,  1.51it/s] 97%|█████████▋| 860/886 [09:38<00:17,  1.51it/s] 97%|█████████▋| 861/886 [09:39<00:16,  1.48it/s] 97%|█████████▋| 862/886 [09:39<00:16,  1.48it/s] 97%|█████████▋| 863/886 [09:40<00:15,  1.49it/s] 98%|█████████▊| 864/886 [09:41<00:14,  1.47it/s] 98%|█████████▊| 865/886 [09:41<00:14,  1.48it/s] 98%|█████████▊| 866/886 [09:42<00:13,  1.49it/s] 98%|█████████▊| 867/886 [09:43<00:12,  1.50it/s] 98%|█████████▊| 868/886 [09:43<00:12,  1.48it/s] 98%|█████████▊| 869/886 [09:44<00:11,  1.49it/s] 98%|█████████▊| 870/886 [09:45<00:10,  1.49it/s] 98%|█████████▊| 871/886 [09:45<00:10,  1.48it/s] 98%|█████████▊| 872/886 [09:46<00:09,  1.48it/s] 99%|█████████▊| 873/886 [09:47<00:08,  1.50it/s] 99%|█████████▊| 874/886 [09:47<00:07,  1.50it/s] 99%|█████████▉| 875/886 [09:48<00:07,  1.48it/s] 99%|█████████▉| 876/886 [09:49<00:06,  1.46it/s] 99%|█████████▉| 877/886 [09:50<00:06,  1.47it/s] 99%|█████████▉| 878/886 [09:50<00:05,  1.47it/s] 99%|█████████▉| 879/886 [09:51<00:04,  1.48it/s] 99%|█████████▉| 880/886 [09:52<00:04,  1.49it/s] 99%|█████████▉| 881/886 [09:52<00:03,  1.47it/s]100%|█████████▉| 882/886 [09:53<00:02,  1.48it/s]100%|█████████▉| 883/886 [09:54<00:02,  1.49it/s]100%|█████████▉| 884/886 [09:54<00:01,  1.50it/s]100%|█████████▉| 885/886 [09:55<00:00,  1.47it/s]100%|██████████| 886/886 [09:56<00:00,  1.47it/s][INFO|trainer.py:2340] 2023-10-30 21:54:32,317 >> Saving model checkpoint to chkpts/analysis_models/minibertas/d-atomic-roberta-base-10M-2/checkpoint-886
[INFO|configuration_utils.py:446] 2023-10-30 21:54:32,326 >> Configuration saved in chkpts/analysis_models/minibertas/d-atomic-roberta-base-10M-2/checkpoint-886/config.json
[INFO|modeling_utils.py:1542] 2023-10-30 21:54:34,673 >> Model weights saved in chkpts/analysis_models/minibertas/d-atomic-roberta-base-10M-2/checkpoint-886/pytorch_model.bin
[INFO|tokenization_utils_base.py:2108] 2023-10-30 21:54:34,682 >> tokenizer config file saved in chkpts/analysis_models/minibertas/d-atomic-roberta-base-10M-2/checkpoint-886/tokenizer_config.json
[INFO|tokenization_utils_base.py:2114] 2023-10-30 21:54:34,689 >> Special tokens file saved in chkpts/analysis_models/minibertas/d-atomic-roberta-base-10M-2/checkpoint-886/special_tokens_map.json
[INFO|trainer.py:1662] 2023-10-30 21:54:38,859 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|██████████| 886/886 [10:02<00:00,  1.47it/s]100%|██████████| 886/886 [10:02<00:00,  1.47it/s]
[INFO|trainer.py:2340] 2023-10-30 21:54:38,876 >> Saving model checkpoint to chkpts/analysis_models/minibertas/d-atomic-roberta-base-10M-2
[INFO|configuration_utils.py:446] 2023-10-30 21:54:38,881 >> Configuration saved in chkpts/analysis_models/minibertas/d-atomic-roberta-base-10M-2/config.json
[INFO|modeling_utils.py:1542] 2023-10-30 21:54:40,723 >> Model weights saved in chkpts/analysis_models/minibertas/d-atomic-roberta-base-10M-2/pytorch_model.bin
[INFO|tokenization_utils_base.py:2108] 2023-10-30 21:54:40,730 >> tokenizer config file saved in chkpts/analysis_models/minibertas/d-atomic-roberta-base-10M-2/tokenizer_config.json
[INFO|tokenization_utils_base.py:2114] 2023-10-30 21:54:40,735 >> Special tokens file saved in chkpts/analysis_models/minibertas/d-atomic-roberta-base-10M-2/special_tokens_map.json
{'loss': 0.6966, 'learning_rate': 2.178329571106095e-06, 'epoch': 1.13}
{'train_runtime': 602.7166, 'train_samples_per_second': 94.074, 'train_steps_per_second': 1.47, 'train_loss': 0.6918922234873202, 'epoch': 2.0}
***** train metrics *****
  epoch                    =        2.0
  train_loss               =     0.6919
  train_runtime            = 0:10:02.71
  train_samples            =      28350
  train_samples_per_second =     94.074
  train_steps_per_second   =       1.47
10/30/2023 21:54:40 - INFO - __main__ - *** Evaluate ***
[INFO|trainer.py:622] 2023-10-30 21:54:40,890 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: sentence1, sentence2. If sentence1, sentence2 are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
[WARNING|training_args.py:1095] 2023-10-30 21:54:40,892 >> Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.
[WARNING|training_args.py:1095] 2023-10-30 21:54:40,892 >> Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.
[INFO|trainer.py:2590] 2023-10-30 21:54:40,892 >> ***** Running Evaluation *****
[INFO|trainer.py:2592] 2023-10-30 21:54:40,892 >>   Num examples = 2839
[INFO|trainer.py:2595] 2023-10-30 21:54:40,892 >>   Batch size = 64
  0%|          | 0/45 [00:00<?, ?it/s]  4%|▍         | 2/45 [00:00<00:04,  8.75it/s]  7%|▋         | 3/45 [00:00<00:06,  6.24it/s]  9%|▉         | 4/45 [00:00<00:07,  5.42it/s] 11%|█         | 5/45 [00:00<00:07,  5.04it/s] 13%|█▎        | 6/45 [00:01<00:08,  4.82it/s] 16%|█▌        | 7/45 [00:01<00:08,  4.69it/s] 18%|█▊        | 8/45 [00:01<00:08,  4.61it/s] 20%|██        | 9/45 [00:01<00:07,  4.55it/s] 22%|██▏       | 10/45 [00:02<00:07,  4.51it/s] 24%|██▍       | 11/45 [00:02<00:07,  4.49it/s] 27%|██▋       | 12/45 [00:02<00:07,  4.47it/s] 29%|██▉       | 13/45 [00:02<00:07,  4.45it/s] 31%|███       | 14/45 [00:02<00:06,  4.45it/s] 33%|███▎      | 15/45 [00:03<00:06,  4.44it/s] 36%|███▌      | 16/45 [00:03<00:06,  4.43it/s] 38%|███▊      | 17/45 [00:03<00:06,  4.43it/s] 40%|████      | 18/45 [00:03<00:06,  4.43it/s] 42%|████▏     | 19/45 [00:04<00:05,  4.43it/s] 44%|████▍     | 20/45 [00:04<00:05,  4.43it/s] 47%|████▋     | 21/45 [00:04<00:05,  4.42it/s] 49%|████▉     | 22/45 [00:04<00:05,  4.43it/s] 51%|█████     | 23/45 [00:04<00:04,  4.43it/s] 53%|█████▎    | 24/45 [00:05<00:04,  4.42it/s] 56%|█████▌    | 25/45 [00:05<00:04,  4.43it/s] 58%|█████▊    | 26/45 [00:05<00:04,  4.42it/s] 60%|██████    | 27/45 [00:05<00:04,  4.43it/s] 62%|██████▏   | 28/45 [00:06<00:03,  4.43it/s] 64%|██████▍   | 29/45 [00:06<00:03,  4.42it/s] 67%|██████▋   | 30/45 [00:06<00:03,  4.42it/s] 69%|██████▉   | 31/45 [00:06<00:03,  4.42it/s] 71%|███████   | 32/45 [00:07<00:02,  4.42it/s] 73%|███████▎  | 33/45 [00:07<00:02,  4.42it/s] 76%|███████▌  | 34/45 [00:07<00:02,  4.42it/s] 78%|███████▊  | 35/45 [00:07<00:02,  4.42it/s] 80%|████████  | 36/45 [00:07<00:02,  4.42it/s] 82%|████████▏ | 37/45 [00:08<00:01,  4.42it/s] 84%|████████▍ | 38/45 [00:08<00:01,  4.42it/s] 87%|████████▋ | 39/45 [00:08<00:01,  4.42it/s] 89%|████████▉ | 40/45 [00:08<00:01,  4.42it/s] 91%|█████████ | 41/45 [00:09<00:00,  4.41it/s] 93%|█████████▎| 42/45 [00:09<00:00,  4.41it/s] 96%|█████████▌| 43/45 [00:09<00:00,  4.41it/s] 98%|█████████▊| 44/45 [00:09<00:00,  4.41it/s][WARNING|training_args.py:1095] 2023-10-30 21:54:50,953 >> Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.
100%|██████████| 45/45 [00:09<00:00,  4.58it/s]
[WARNING|training_args.py:1095] 2023-10-30 21:54:50,988 >> Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.
[WARNING|training_args.py:1095] 2023-10-30 21:54:50,989 >> Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.
[INFO|modelcard.py:460] 2023-10-30 21:54:51,057 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Text Classification', 'type': 'text-classification'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.5804860591888428}]}
***** eval metrics *****
  epoch                   =        2.0
  eval_accuracy           =     0.5805
  eval_loss               =     0.6779
  eval_runtime            = 0:00:10.06
  eval_samples            =       2839
  eval_samples_per_second =    282.177
  eval_steps_per_second   =      4.473
