{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637c0771",
   "metadata": {},
   "source": [
    "# MTurk: Approve / Reject Assignments + Post-Task Completion Processing of HITs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ba65c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "import ast\n",
    "from simple_colors import *\n",
    "from typing import Dict\n",
    "import re\n",
    "import pprint\n",
    "import string\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ca5f669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mturk_processing_utils import (\n",
    "    programmatically_review_HITs,\n",
    "    get_dataset, \n",
    "    get_hit_id_dict, \n",
    "    parse_batch, \n",
    "    approved_parsed_batch_2_dicts,\n",
    "    view_assignment,\n",
    "    mturk,\n",
    "    get_completetion_progress\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eb09a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT_DIR = '/Users/nehasrikanth/Documents/paraphrase-nlu/'\n",
    "dataset_name = ['atomic', 'snli', 'social']\n",
    "\n",
    "\n",
    "raw_data_paths = {d: os.path.join(PROJECT_ROOT_DIR, f'raw-data/defeasible-nli/defeasible-{d}') for d in dataset_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4980435d",
   "metadata": {},
   "source": [
    "### Social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a928212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique premise-hypothesis pairs: 7893 / 77016\n",
      "Loaded 77016 nonempty train examples...(skipped 3314 examples)\n",
      "Unique premise-hypothesis pairs: 979 / 9343\n",
      "Loaded 9343 nonempty dev examples...(skipped 467 examples)\n",
      "Unique premise-hypothesis pairs: 982 / 9439\n",
      "Loaded 9439 nonempty test examples...(skipped 421 examples)\n"
     ]
    }
   ],
   "source": [
    "social_batches = [\n",
    "    'mturk_data/creation/social_dnli_annotation_examples_2.json',\n",
    "]\n",
    "\n",
    "dnli_social = get_dataset(raw_data_paths['social'], 'social')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6f2942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, hit_id_2_example_id_social_2, _ = get_hit_id_dict(social_batches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed51fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_completetion_progress(hit_id_2_example_id_social_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c4da2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker:  A3D943YJI95XZY AssignmentId:  30LSNF239UV6CQPS8NUDWN5T502I27\n",
      "Premise:  \n",
      "Hypothesis:  It's wrong to expect money out of people.\n",
      "Update:  You let them borrow from you before\n",
      "Update Type:  weakener\n",
      "\n",
      "{'paraphrase_1': 'You gave them money previously. ',\n",
      " 'paraphrase_2': 'They took stuff from you before.',\n",
      " 'paraphrase_3': 'You lent them money in the past.'}\n"
     ]
    }
   ],
   "source": [
    "view_assignment('30LSNF239UV6CQPS8NUDWN5T502I27', dnli_social, hit_id_2_example_id_social_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b97afaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = mturk.approve_assignment(\n",
    "      AssignmentId='30LSNF239UV6CQPS8NUDWN5T502I27',\n",
    "      RequesterFeedback='Thanks for doing a great job!',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6010bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = mturk.reject_assignment(\n",
    "    AssignmentId='39LNWE0K4UWFW2YUR74J260LONXUI5',\n",
    "    RequesterFeedback='These are not 3 paraphrases of the evidence sentence.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ab31fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = mturk.create_worker_block(\n",
    "    WorkerId='A2B8YUXLFIDKUG',\n",
    "    Reason='Worker is spamming.'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:para-nlu]",
   "language": "python",
   "name": "conda-env-para-nlu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
